{
	"data": {
		"responseHeader": {
			"status": 0,
			"QTime": 24,
			"params": {
				"spellcheck": "true",
				"fl": "*",
				"start": "0",
				"q": "blood",
				"collection": "profeducation",
				"wt": "javabin",
				"version": "2",
				"rows": "50"
			}
		},
		"response": {
			"numFound": 10492,
			"start": 0,
			"maxScore": 13.659702,
			"docs": [{
				"id": "pdctm_0901c79180afdbc1",
				"activeCME": 1,
				"activityExpirationDate": 1518757200000,
				"authors": ["Claudia Korn", " Simón Méndez-Ferrer"],
				"body": "Abstract and Introduction Abstract and Introduction Abstract Research in the last few years has revealed a sophisticated interaction network between multiple bone marrow cells that regulate different hematopoietic stem cell (HSC) properties such as proliferation, differentiation, localization, and self-renewal during homeostasis. These mechanisms are essential to keep the physiological HSC numbers in check and interfere with malignant progression. In addition to the identification of multiple mutations and chromosomal aberrations driving the progression of myeloid malignancies, alterations in the niche compartment recently gained attention for contributing to disease progression. Leukemic cells can remodel the niche into a permissive environment favoring leukemic stem cell expansion over normal HSC maintenance, and evidence is accumulating that certain niche alterations can even induce leukemic transformation. Relapse after chemotherapy is still a major challenge during treatment of myeloid malignancies, and cure is only rarely achieved. Recent progress in understanding the niche-imposed chemoresistance mechanisms will likely contribute to the improvement of current therapeutic strategies. This article discusses the role of different niche cells and their stage- and disease-specific roles during progression of myeloid malignancies and in response to chemotherapy. Introduction Myeloid malignancies are clonal hematopoietic disorders characterized by excessive proliferation, abnormal self-renewal, and/or differentiation defects of hematopoietic stem cells (HSCs) and myeloid progenitor cells. They mainly consist of myeloproliferative neoplasms (MPNs), myelodysplastic syndrome (MDS), and acute myeloid leukemia (AML), caused by different genetic and epigenetic changes in HSCs and functional changes in bone marrow (BM) niche cells. Genetic and epigenetic modifications have also been noted in BM mesenchymal stromal cells (BMSCs) in MDS and AML. The end results of these alterations are phenotypically distinct diseases that likely require the design of specific treatments. However, the use of selective inhibitors is challenging, because they sometimes also affect the normal hematopoietic counterparts, and clones carrying other mutations often cause relapse after chemotherapy. In this case, overcoming common mechanisms of resistance might be more likely to succeed therapeutically. The World Health Organization subdivided MPNs into four distinct diseases: chronic myelogenous leukemia (CML), characterized by the BCR-ABL oncogene fusion (Philadelphia chromosome [Ph + ]) protein and the three Ph – disorders named polycythemia vera (PV), essential thrombocythemia (ET), and primary myelofibrosis (PMF). [1] Whereas PV is primarily associated with high erythrocyte counts, patients with ET have high platelet counts, and PMF is mainly related to BM failure as a result of fibrotic BM degeneration. These different clinical symptoms suggest that each MPN subtype is an independent disease, but transitions among them are observed in some patients. Alterations of BM Niches Contribute to the Progression of Myeloid Malignancies Alterations of BM Niches Contribute to the Progression of Myeloid Malignancies Streaming from the discovery of driver mutations, myeloid malignancies were initially regarded as primarily driven by leukemic cell–autonomous mechanisms. However, cumulative evidence indicates that leukemic cells can exploit physiological niche signals and can overcome control by the normal microenvironment and/or remodel BM niches into permissive/self-reinforcing environments that support disease progression at the expense of normal hematopoiesis. During leukemogenesis, malignant clones become progressively independent of niche-imposed physiological control mechanisms. In early leukemogenesis, BM homing and spatial localization of early leukemic stem cells (LSCs), which are also called pre-LSCs, are similar to that of normal HSCs. However, at later stages, LSCs home similarly to committed progenitors and become progressively independent of microenvironmental WNT signals. [2] Some LSC alterations can simultaneously stimulate proliferation and myeloid skewing without affecting self-renewal. For instance, reduced JunB expression observed in many myeloid malignancies diminishes the responsiveness of LSCs to Notch and transforming growth factor β (TGF-β) niche signals. [3] LSCs can become progressively insensitive to TGF-β during disease evolution from chronic to acute leukemia. [4] The first indications of microenvironmental contribution to myeloid malignancies derive from reciprocal BM transplantation experiments showing that myeloid malignancies can arise from originally nonmutated hematopoietic cells in an altered microenvironment. For instance, MPN-like disease is observed in mice carrying a constitutive nonhematopoietic retinoic acid receptor γ deletion. [5] MPN-like disease also develops after combined retinoblastoma protein deletion in nonhematopoietic and myeloid cells. [6,7] Similarly, Notch pathway inhibition by the deletion of ubiquitin E3 ligase Mind bomb 1 ( Mib1 ) in nonhematopoietic cells causes nontransplantable MPN-like disease, which can be reverted by microenvironmental Notch activation. [8] Altogether, these pioneering studies represent strong evidence that the microenvironment exerts more than a mere bystander effect in myeloid malignancies. Role of the BM Vasculature Role of the BM Vasculature Several myeloid malignancies, including AML, MPN, and MDS, have been correlated with increased BM angiogenesis. [9-13] BM vascularization in MPN patients correlates with janus kinase (JAK2) allele burden and stage, being highest in PMF, followed by CML, PV, and ET patients. [11,12,14] MDS is characterized by lower vascularization, but blood vessel density similarly increases with disease aggressiveness and specifically correlates with progression to fibrosis. [13,15] In addition to the increased vascular density, BM vessel morphology is disorganized and irregular in MPN and AML. [11,16] Hence, increased and disorganized BM vascularization is a common niche alteration of myeloid malignancies. Figure 1. Role of BM blood vessels in myeloid malignancies. Angiogenesis increases during progression of myeloid malignancies and is particularly associated with fibrotic stages of the disease. Leukemic cells produce angiogenic factors such as VEGF and inflammatory cytokines (blue arrows) to stimulate proliferation of ECs, expression of adhesion molecules, and secretion of angiocrine factors. EC-derived angiocrine factors (red arrows) stimulate leukemic cell proliferation and survival, triggering a vicious cycle to remodel the BM into a self-reinforcing niche. OB, osteoblast. Figure 1. Progression of myeloid malignancies is supported by synergistic crosstalk between malignant blasts and endothelial cells (ECs). Enhanced BM vascularization correlates with upregulation of angiogenic factors, including vascular endothelial growth factor (VEGF)–A and interleukins (ILs). [10,12,17-20] Whereas blasts secrete proangiogenic molecules, ECs release angiocrine factors that promote blast survival and proliferation. [9,17] Blast-derived angiogenic factors act in a paracrine manner and also stimulate leukemic cell survival and proliferation via autocrine pathways. [19,21,22] Similar to solid tumors, leukemic cells produce the key proangiogenic factor VEGF-A, which stimulates angiogenesis by paracrine mechanisms and increases blast survival and proliferation via autocrine VEGFR2-dependent pathways. [17,19,21,23] Endothelial VEGF signaling stimulates blood vessel formation and also induces angiocrine factor (such as granulocyte-macrophage colony-stimulating factor [GM-CSF], macrophage CSF [M-CSF], granulocyte CSF [G-CSF], IL-6, and stem cell factor) production in ECs, which promotes proliferation of malignant cells (Figure 1). [24-26] VEGF-dependent EC activation similarly increases EC-AML cell adhesion and AML aggressiveness. [26] Leukemic cell–derived proangiogenic and proinflammatory factors such as IL-1β and basic fibroblast growth factor (bFGF) can stimulate ECs to release VEGF-C, thereby supporting blast survival and proliferation. [22] Megakaryocytes represent an alternative VEGF source in MDS and might also stimulate angiogenesis in ET and PMF. [13] High VEGF-A and VEGF-C plasma concentrations are associated with adverse prognosis in AML and CML, and VEGF-A levels correlate with MPN disease stage (PMF>PV>ET). [10-12,18,27] Targeting VEGF signaling with bevacizumab has not been successful so far, but adjuvant treatment with different tyrosine kinase inhibitors (TKIs) in AML and MPN might normalize the microenvironment and eradicate malignant cells. However, patient response to therapy is heterogeneous and identifying susceptible subgroups is crucial. [18,28-30] The angiopoietin 1 (ANG)/TIE signaling system—a master regulator of solid tumor angiogenesis—is also gaining recognition in myeloid malignancies. High ANG2 levels in AML patients do not correlate with changes in vessel density but may be of prognostic value because they correlate with improved survival when VEGF expression is low. [31-33] Abnormal ANG/TIE signaling has been detected in ECs and also in leukemic cells. [34,35] Autocrine ANG1/TIE2 signaling in blasts induces signal transducer and activator of transcription 1 (STAT1)/3/5/6 and ERK pathways, which support leukemic cell proliferation, [34,36] and TIE2/IP-3 kinase signaling increases AML cell survival. [35] Other proangiogenic factors such as bFGF and HGF are also upregulated in AML, CML, and MDS. [10] Likewise, proinflammatory cytokines, including tumor necrosis factor α (TNF-α), IL-6, and IL-1β, are increased when AML blasts are cocultured with ECs. These cytokines stimulate EC proliferation and G-CSF and GM-CSF production, thereby promoting leukemic cell expansion. [25,37] Secretion of TNF-α and IL-1β by AML blasts upregulates endothelial adhesion receptors such as selectins VCAM-1 and ICAM-1 to support vascular adhesion and proliferation. [38] EC activation by inflammatory cytokines might compromise vascular integrity and favor thrombosis, further aggravating the proinflammatory environment. Alterations in ECs might be a predisposing factor for the development of myeloid malignancies. MPN-like disease has also been observed in response to deletion of endothelial-specific Rbpj . [39] Loss of endothelial Notch signaling upregulates microRNA 155 (miR-155), which de-represses nuclear factor κB (NF-κB) leading to G-CSF and TNF-α overexpression and myeloid expansion. The potential relevance of this pathway is emphasized by an increased miR-155 level in human PMF BM. [39] CML cells and ECs also communicate via exosomes by shuttling miR-126 to downregulate VCAM-1 and CXCL12 in ECs and decrease CML adhesion and migration. [40] Despite the release of multiple proangiogenic factors in the tumor microenvironment, hypoxia represents a common feature of myeloid malignancies and can influence LSC cycling, quiescence, differentiation, metabolism, and chemotherapy resistance. However, the role of hypoxia and downstream hypoxia-inducible factor 1α (HIF-1α) signaling in leukemia remains controversial, with published evidence for both supporting and inhibitory roles. In some studies, hematopoietic HIF-1α deletion promotes AML and MPN progression in mice. [41,42] Similarly, combined deletion of HIF-1α and HIF-2α can accelerate AML initiation, but it is dispensable for disease maintenance. [43] In contrast, other studies indicate that HIF-1α and HIF-2α support LSC survival by inducing p16 and p19 signaling and reducing reactive oxygen species (ROS) levels and endoplasmic reticulum stress, respectively. [44,45] Hypoxia-induced VEGF production in a mouse model of CML correlates with increased clonogenicity, maintenance, repopulation capacity, and TKI resistance of BCR-ABL + cells. [46] Cytarabine and doxorubicin resistance is partly conferred by HIF-1α signaling, which induces quiescence in AML subclones by interfering with apoptosis and supporting survival signaling. [47,48] Hypoxia might also favor leukemogenic niche metabolism and cytokine secretion. In addition to hypoxia, cytokines, interferon alfa, hormones, and genetic modifications can stimulate HIF-1α signaling, and their deregulation in a leukemic niche might similarly control this pathway in a hypoxia-independent manner. [49] HIF-1α might be a prognostic marker for high-risk AML and CML patients and a valuable therapeutic target. These divergent results on the role of hypoxia in the LSC niche call for further studies on this particular aspect of environmental control. Intense morphologic and functional remodeling of BM vessels has been observed in myeloid malignancies and generally result in increased but dysfunctional vasculature. A synergistic crosstalk is established between ECs and leukemic cells, which stimulates the growth of both. Increased permeability of an activated endothelium might also favor adhesion and mobilization of both inflammatory and leukemic cells, further aggravating inflammation, invasion of peripheral organs, and resistance (discussed below). Role of BMSCs Role of BMSCs Although initial in vitro studies did not observe major alterations in BMSCs, recent in vivo characterization has identified BMSCs as essential components of the HSC niche that are deregulated in a disease-specific manner in myeloid malignancies. The niche might have disparate roles in various myeloid malignancies, and these roles might also change during disease evolution (Figure 2). Figure 2. Microenvironmental changes during leukemogenesis. In the BM niche, HSC function is tightly controlled by a specialized microenvironment comprising sympathetic neurons, BMSCs, OBs, and ECs. (A) During early stages of myeloid malignancies, HSPCs acquire genetic alterations that transform them into LSCs. These mutations also create a proinflammatory environment that damages sensitive elements of the microenvironment, such as Schwann cells and their associated nerve terminals. (B) During intermediate stages of the disease, the environment remodels into a self-reinforcing niche that interferes with normal hematopoiesis. LSCs become independent of niche signals and localize more centrally in the BM. MSCs acquire an abnormal phenotype, and angiogenesis increases as a result of high VEGF and cytokine levels. (C) Late stages of the disease are characterized by a proinflammatory environment and myelofibrosis, high blood vessel density, and central LSC localization. Rarγ, retinoic acid receptor γ; Rb, retinoblastoma protein; TPO, thrombopoeitin. Figure 2. The first evidence of a possible role for BMSCs in myeloid malignancies arose from studies that identified chromosomal abnormalities such as hypodiploidy and chromosomal translocations, duplications, and deletions in hematopoietic cells of patients with myeloid malignancies and also in BMSCs. [50-56] These cytogenetic abnormalities have been observed in 30% to 70% of the BMSCs from patients with MDS or AML and are different from hematopoietic mutations in the same individuals. [50,52] Yet stromal genomic alterations are associated with unfavorable prognostic chromosomal abnormalities in hematopoietic cells. [51,52] Likewise, 55% of the BMSCs from patients with MDS showed abnormal karyotypes, and 57% of the BMSCs from patients with AML who had trisomy 8 and monosomy 7 in hematopoietic cells showed cytogenetic aberrations. [54] Similarly, trisomy 8 mosaicism is associated with increased incidence of myeloid leukemia and MDS, and stromal cells in these patients favor leukemic cell proliferation. [57] Chromosomal and epigenetic abnormalities in BMSCs from patients with MDS and AML have been linked to certain disease subtypes and distinctive gene-expression programs. [53,56,58] These genetic abnormalities in BMSCs suggest enhanced genetic susceptibility and an active role of BMSCs in the progression of MDS or AML. The functional consequences of these BMSC alterations are still debated. Several studies have noted normal differentiation, adhesion, expression and survival and the ability to support hematopoiesis ex vivo in BMSCs from patients with MDS, CML, or AML. [50-52,54,59-62] In contrast, other studies showed abnormal differentiation, defective hematopoietic supportive capacity, reduced expression of adhesion molecules, increased apoptosis, and increased production of IL-1β and stem cell factor in BMSCs of patients with myeloid malignancies. [55,56,63-75] These in vitro studies proposed some divergent views on BMSC alterations and contributions to disease, but more recent in vivo studies on several myeloid malignancies have reported altered BMSC growth and differentiation and the production of cytokine and HSC retention factor. Whether these BMSC alterations were predisposing or initiating factors for disease has remained elusive so far. The first evidence that alterations of BMSCs can drive myeloid malignancies arose from the deletion of the RNA processing enzyme Dicer1 in osteoprogenitor cells, which caused MDS-like disease with sporadic transformation to AML. The disease could be reverted by transplanting leukemic cells from mice with Dicer1 -deleted osteoprogenitors into wild-type mice. Loss of DICER1 in osteoprogenitor cells (but not in mature osteoblasts) resulted in downregulation of the ribosome maturation protein SBDS, which is mutated in human Shwachman-Bodian-Diamond syndrome and is associated with congenital BM failure and leukemic predisposition. [76] Reduced expression of DICER, DROSHA, and SBDS has been noted in BMSCs from patients with MDS, [77] emphasizing the potential clinical relevance of these findings. A recent study has provided mechanistic insight on genotoxic stress caused by mutations in BMSCs, which can impair normal hematopoiesis and favor leukemogenesis. Loss of Sbds in BMSCs in mice recapitulates the characteristic osteoporosis found in human Shwachman-Bodian-Diamond syndrome. It also stimulates BMSC p53 signaling and secretion of the inflammatory molecules S100A8 and S100A9. S100A8/A9 activates toll-like receptor 4 on normal hematopoietic stem and progenitor cells (HSPCs), which leads to inflammatory damage, including hyperpolarized mitochondria, which triggers increased ROS production and DNA double-strand breaks. The potential relevance of niche S100A8/A9 expression in human leukemogenesis is emphasized by the correlation of S100A8/A9 expression in BMSCs and bone lining cells and the leukemic evolution of patients with MDS. [78] Patients with Noonan syndrome often carry a mutation in the RAS signaling mediator PTPN11 and are at increased risk for developing childhood MPNs. A recent study has now shown that leukemogenic effects of activating PTPN11 mutations are not solely hematopoietic cell autonomous, but that PTPN11 mutations in BMSCs and osteoprogenitor cells can similarly drive MPN progression. Excessive CCL3 production by PTPN11-activated BMSCs results in the recruitment of monocytes to BMSCs, which hyperactivate HSCs by secreting inflammatory cytokines, including IL-1β, thereby exacerbating disease progression. [79] Recent studies using mouse models of CML, MPNs, and AML demonstrate that specific BMSC-leukemic cell interactions are important for leukemogenesis ( Table 1 ). [16,80,81] In an inducible BCR-ABL mouse model, CML cells support BMSC proliferation and abnormal differentiation, which generate functionally altered and inflammatory osteoblasts. BMSCs in CML failed to maintain normal HSCs because of reduced Cxcl12 expression, favoring the expansion of less niche-dependent LSCs. Osteoblastic cells in CML secrete proinflammatory cytokines (IL-1β and TNF-α) that amplify disease progression by triggering myeloid cell proliferation and creating a self-reinforcing niche. [81] CML cells also instruct BMSCs to secrete PIGF, which stimulates angiogenesis and promotes CML proliferation and metabolism, in part independently of BCR-ABL1 signaling. [82] Progression of Ph – MPN also disrupts normal BMSC function, thus promoting disease progression. Proinflammatory cytokines produced by JAK2 V617F hematopoietic cells, such as IL-1β, can cause local neuropathy and microenvironmental damage that leads to disease manifestation. In this inflammatory environment, MPN-associated neuropathy sensitizes nestin + BMSCs to undergo apoptosis and reduces their HSC niche properties (including Cxcl12 expression). Genetic depletion of nestin + cells can worsen myelofibrosis and thrombocytosis, which is also observed in mice lacking the β 3 -adrenergic receptor. In contrast, neural protection by neurotrophic factors or neural stimulation of the microenvironment by chronic treatment with β 3 -adrenergic agonists rescues nestin + cells and improves Cxcl12 and IL-1β expression, neutrophilia, thrombocytosis, and myelofibrosis. [80] Similar neuropathy-driven microenvironmental deregulation has been reported in AML. [16] Yet the neuropathy might be comparatively less relevant in AML because neural interventions did not significantly affect leukemogenesis in that study. Whether neuropathy-driven microenvironmental changes are more broadly relevant in other hematologic malignancies remains to be investigated. Reciprocal leukemic-niche interactions have also been highlighted in MDS. On one hand, patient-derived MDS cell engraftment is dependent on niche factors, such as LIF, VEGF, IGF-BP2, and N-cadherin. On the other hand, exposure of normal BMSCs to MDS renders them malignant-like, which highlights MDS-induced BMSC reprogramming. [83] Alterations of WNT signaling in BMSCs have been associated with defective BMSC proliferation in MDS, [84,85] partially because of the induction of senescence. [86] Communication between BMSCs and MDS cells is partly mediated by extracellular vesicles. [87] Exosome-mediated crosstalk between CML cells and human BMSCs triggers IL-8–dependent survival. [88,89] Similarly, primary leukemic cells and cell lines release microvesicles containing RNAs that alter the secretion of niche-reprograming factors. [90] Together, these studies highlight the role of BMSCs as key elements of predisposition, manifestation, and evolution of myeloid malignancies. Whereas functionally or genetically altered BMSCs increase inflammation and genotoxic stress, mutated hematopoietic cells critically compromise the normal function of BMSCs in the HSC niche, hampering normal hematopoiesis and favoring leukemogenesis. Whether these changes in BMSCs initiate disease in humans and/or select for particular mutated clones is a subject of intense research. Anchoring of Myeloid Leukemic Cells to Their Niches Anchoring of Myeloid Leukemic Cells to Their Niches Adhesion molecules are important for LSC engraftment and interaction with the niche. CD44 is a glycoprotein receptor for hyaluronan, selectins, and osteopontin. A specialized glycoform of CD44 named HCELL is a BM homing receptor. [91] CD44 is overexpressed in CML, [92] and homing and engraftment of CML and AML LSCs to their BM niches is much more dependent on CD44 compared with normal HSCs or B-cell acute lymphoblastic leukemia cells. Anti-CD44 treatment reduces CML incidence and AML burden in xenografts. [93,94] In addition to directing LSC homing, CD44 also maintains LSCs in a primitive state, [94,95] and high CD44 levels correlate with AML induction and relapse in AML mouse models. [96,97] CD44 is a potent E-selectin receptor in CML, and E-selectin blockade can also reduce LSC numbers in CML. [98] E-selectin is overexpressed on BM endothelium in AML, and antagonizing E-selectin can sensitize AML cells to chemotherapy. [99] CD44 cooperates with other adhesion molecules, such as CD49d [100] and integrin β1, which inhibit CML proliferation. [101] Treatment with INF-α can restore impaired integrin β1–mediated adhesion of CML cells and inhibit their proliferation. [102,103] This interaction might be relevant in other malignancies because integrin β1–mediated adhesion influences chemotherapy sensitivity in AML and increased fibronectin secretion in early fibrotic stages of MPN. [104,105] Downregulation of BM Cxcl12 helps different myeloid malignancies [16,80,106] and correlates with HSPC mobilization and extramedullary hematopoiesis. GCSF produced by CML cells decreases Cxcl12 expression by BMSCs and directly impairs normal hematopoiesis in an inducible BCR-ABL transgenic model. Long-term LSCs show reduced homing and retention in the BM because of increased G-CSF and decreased CXCL12 levels. [106] Leukemic cells can further highjack normal BM vascular niches dependent on CXCL12 and E-selectin. [107] Activation of CXCL12 receptor CXCR4 in leukemic cells is important for AML cell survival and BM retention. Neutralizing CXCR4 antibodies decreases human AML cell numbers in xenografts. [108] Role of Osteoblasts Role of Osteoblasts Reduced trabecular bone mass in retinoic acid receptor γ– or retinoblastoma protein–deficient mice correlates with aggravated MPN, suggesting that endosteal niche alterations can promote MPN progression. [5,6] The role of osteoblasts in leukemia progression seems to be disease specific, because constitutive parathyroid hormone receptor activation in osteoblasts increases bone remodeling and attenuates CML progression but stimulates MLL-AF9 AML progression. Increased bone remodeling in mice with constitutively active parathyroid hormone signaling causes TGF-β release from bone, reducing LSC proliferation and maintenance in CML but not in AML, probably because of reduced TGFBR1 expression or higher constitutive pSMAD2/3 signaling in AML. [4] These differences suggest that the niche or niches might play different roles at various stages of leukemogenesis and/or in a disease-specific manner (Figure 2). The increased osteogenic potential of BMSCs can contribute to PMF. [109] Similarly, increased osteoblastic priming has been observed in BMSCs from childhood MDS. [110] Osteoblasts also expand during the chronic phase of CML, [81] when they negatively regulate normal and malignant HSC proliferation. [111] This is reminiscent of the role of nestin + BMSCs in Ph – MPN, in which depletion of nestin + cells or their Cxcl12 production can accelerate MPN progression. [80] Therefore, MPN preleukemic cells seem to retain sensitivity to normal cues from the microenvironment, and protecting the niche might be beneficial at this stage. In contrast, during the blast crisis of this disease, which resembles acute leukemia, osteoblasts are markedly reduced, [112] suggesting that osteoblasts are differentially affected in AML and CML. AML has been associated with increased bone remodeling and accumulation of osteoblast-primed BMSCs, which do not seem to be able to mature into osteoblasts, correlating with decreased mineralized bone. [16] Strikingly, expression of a constitutively activated form of β-catenin in osteoblasts might be sufficient for driving AML-like disease. Activated β-catenin signaling increases osteoblastic Jagged expression, leading to aberrant Notch signaling in HSCs. Inhibition of osteoblastic Notch signaling by Jagged deletion or pharmacologic treatment with γ-secretase inhibitors prevents AML development in mice. [113] The same group has shown that 38% of patients with MDS, AML, or MDS with leukemic transformation have increased nuclear β-catenin in Runx2 -expressing osteoblastic cells associated with increased Notch activity in CD34 + HSPCs. [114] Osteoblasts are decreased in patients with MDS or AML, and osteoblast recovery correlates with better prognosis. [115] Overall, this represents another example of potential mechanisms of niche-driven oncogenesis in myeloid malignancies. The Niche in Response to Chemotherapy The Niche in Response to Chemotherapy High-dose chemotherapy (HDC) is used to eradicate leukemic cells in AML and advanced MDS. Cytotoxic agents can damage the BM microenvironment and compromise niche function, regeneration, and maintenance of normal hematopoiesis (Figure 3). Chronic stromal damage by HDC is manifested by reduced BMSCs and CD44 expression in allogenic BM transplantation recipients, which is associated with slower hematopoietic recovery. [116,117] Myelosuppression can cause endothelial regression that leads to a discontinuous, hemorrhagic endothelium accompanied by endothelial denudation. Sinusoidal vessels are particularly sensitive to irradiation, and subsequent EC regeneration via VEGFR2 signaling is critical for hematopoietic reconstitution. [118] Chemotherapy-triggered BM sympathetic neuropathy can lead to loss of nestin + cells and ECs, which interferes with hematopoietic regeneration. Neuroprotective agents have been reported to protect nerves from chemotherapy-induced injury and to support the survival of blood vessels and associated nestin + cells, which leads to accelerated hematopoietic recovery. [119] Osteoblasts are reduced after multiple rounds of chemotherapy, and osteoprogenitor numbers are decreased in response to HDC, eventually causing osteopenia. [120,121] Adipocyte accumulation in aplastic BM might compromise niche function by negatively influencing hematopoietic recovery after myeloablation. [122] Therefore, the damage inflicted by chemotherapy in the BM microenvironment can interfere with normal hematopoiesis and eventually result in BM failure. Figure 3. Protection of LSCs from chemotherapy by the microenvironment. Chemotherapy eradicates LSCs but at the same time damages multiple cell types of the niche and triggers subsequent niche regeneration. Prolonged treatment induces the development of resistance mechanisms, some of which are mediated by niche cells, including BMSCs and ECs. MT, mitochondria; FN, fibronectin. Figure 3. HSC transplantation used in relapsed or high-risk AML can rapidly induce neoplasia from malignant or premalignant donor HSCs. [123] A dysfunctional host microenvironment resulting from mutations or HDC might also promote transformation of donor-derived HSCs into malignant cells. Likewise, growth of LSCs can alter the microenvironment and compromise normal HSC growth after allogenic HSC transplantation. Although multiple LSC-intrinsic mechanisms of chemoresistance have been described, the microenvironment has recently attracted attention in protecting LSCs from chemotherapy (Figure 3). Early coculture studies showed that cytarabine treatment of BMSCs interferes with apoptosis and enhances survival of AML cells. [124,125] BMSC-derived TGF-β1 is a mediator of resistance during cytarabine treatment of AML. [126] Another key chemotherapy resistance–conferring pathway is CXCL12/CXCR4. Chemotherapy upregulates CXCR4 in AML cells, and imatinib enhances CXCR4 expression in BCR-ABL + cells, which results in increased CXCL12/CXCR4 survival signaling and lodgment into protective niches. [127-130] Adjuvant treatment of AML and CML with CXCR4 inhibitors decreases BMSC-induced survival pathways and sensitizes AML and CML cells to chemotherapy and imatinib treatment, respectively. [127-130] Co-recruitment of CXCR4 and its downstream mediator Lyn into lipid rafts is another imatinib-induced chemotherapy resistance mechanism in CML. [131] In fact, pharmacologic targeting of lipid rafts in combination with CXCR4/TGF-β1 can further sensitize CML cells to therapy. [126,131] BMSC-induced CML chemotherapy resistance also occurs via upregulation of galectin-3, which stimulates leukemic cell proliferation, protection from apoptosis, and BM lodgment. [132] Likewise, N-cadherin–dependent interaction of stromal and CML cells has been proposed to activate β-catenin signaling in CML cells, thereby shielding leukemic cells from TKI treatment. [133] Reciprocal activation of NF-κB signaling via VCAM-1/very late antigen 4 (VLA-4) interaction occurs in BMSCs and AML cells, and blockade of stromal NF-κB signaling can sensitize AML cells to chemotherapy. [134] Likewise, leukemic and stromal cell interaction via VLA-4 and fibronectin interferes with drug-induced apoptosis. Combined treatment of cocultures with VLA-4–specific antibodies and cytarabine improves survival, and patients with VLA-4–negative AML have a favorable prognosis. [135] Human AML cells preferentially home and engraft in the endosteal BM of immunodeficient mice where they remain more quiescent and protected from chemotherapy. [136] ECs can also confer chemotherapy resistance to AML cells, and blocking VEGFR2 signaling can increase the susceptibility of leukemic cells to chemotherapy. [26,137] Leukemic cell adhesion to the vasculature has been proposed to induce quiescence, resistance to chemotherapy, and relapse. [138] One study observed that AML cells acquired EC-like features and integrated into the blood vessel where they can become quiescent and evade chemotherapeutic treatment. [139] Alternatively, ECs can protect AML cells from chemotherapy by producing high levels of VEGF and platelet-derived growth factor (PDGF) in response to cytarabine. [140] Emerging evidence indicates that BMSCs shield LSCs from therapy by affecting their energy metabolism. Coculture of AML cells and BMSCs upregulates the mitochondrial proteins BCL2 and UCP2, which modify cellular energy metabolism by uncoupling leukemic mitochondria, suppressing ROS level, increasing the apoptotic threshold, and supporting aerobic glycolysis (Warburg effect). The increased apoptotic threshold resulting from decreased mitochondrial membrane potential and reduced ROS level can also protect LSCs from chemotherapy. [141,142] A recent study has shown that BMSCs can modify LSC metabolism by directly transferring mitochondria to AML blasts in a cell-cell contact- and endocytosis-dependent manner. Mitochondrial uptake by the leukemic blasts increases their adenosine triphosphate production and protects them from mitochondrial depolarization after chemotherapy, thereby providing a survival advantage. [143] BMSCs cocultured with AML cells promote chemotherapy resistance by increasing c-myc levels in AML cells, and c-myc inhibition can rescue AML cells from microenvironment-mediated drug resistance. [144] Conditioned medium from BMSCs has been shown to support Stat3 survival signaling in CML cells in response to imatinib. [145] Combining CML targeting by TKIs with the JAK2 inhibitor ruxolitinib can overcome resistance by blocking JAK/STAT signaling activated by BMSC-derived cytokines. [146] Evidence for BMSC-induced chemotherapy resistance has been obtained mainly from studies on AML and CML, but other cytokines produced by BMSCs (including IL-6, FGF, and CXCL10) can also promote JAK2 V617F+ cell resistance to atiprimod. Cytokine neutralizing antibodies may effectively restore apoptosis in Ph – MPN cells. [147] Treating the AML subtype acute promyelocytic leukemia (APL) with all- trans -retinoic acid induces LSC differentiation and improves patient survival. Non-APL AML is unresponsive to differentiation therapy, and APL patients eventually relapse. [148] Several leukemic cell–intrinsic resistance mechanisms have been identified, but upregulation of the all- trans -retinoic acid–metabolizing enzyme cytochrome P450 gene CYP26 by stromal cells contributes to development of minimal residual disease. [149] Likewise, CYP3A4 upregulation in stromal cells confers resistance during etoposide treatment of AML. [150] The understanding of niche-controlled resistance is still in its infancy, and despite the continuous development of novel treatment options, evading resistance mechanisms might arise. An important additional challenge is to avoid the elimination of normal HSCs. Therefore, identifying factors released by tumor cells that trigger resistance mechanisms conferred by niche cells is of importance to eventually interfere with disease relapse (Figure 3). Development of more selective drugs that act only on the mutated hematopoietic cells and/or combined treatment targeting not only the mutated cells but also the microenvironment might improve the outcome. However, the therapeutic strategies targeting the microenvironment should discriminate phases of normal HSPC niche damage vs advanced niche transformation. At early-stage disease and/or to diminish the damage caused by chemotherapy on normal niches, preventive strategies aiming at protecting the normal microenvironment might boost normal hematopoiesis and help to control preleukemic cells. However, at advanced disease stages, when the microenvironment has been profoundly transformed to support leukemogenesis, different niche-targeting strategies will be needed. Future Directions Future Directions Significant progress over the past few years has revealed important roles of the BM microenvironment in the pathogenesis of myeloid malignancies. However, the underlying mechanisms are only beginning to be elucidated, and an increasing complexity is becoming apparent, with different roles in distinct diseases and disease stages. Therefore, caution should be taken when extrapolating conclusions. Future focus on the complex interaction of neoplastic and microenvironmental cells will improve the development of niche-targeting strategies. Important questions remain for the future. For instance, do LSCs reside within specific niches? Do they interact with specific cell types? And are these cell types different from those interacting with normal HSCs? Do other cells regulating normal HSCs also play a role in leukemogenesis? Immune cells such as macrophages play key roles in the microenvironment of solid tumors and lymphoid malignancies, but their contribution to the myeloid malignancies remains much less explored. Do distinct niches for progenitor cells contribute to specific subtypes of malignancies? Are there key niche alterations during leukemogenesis leading to leukemic transformation (from preleukemia to leukemia)? Do somatic mutations in nonhematopoietic cells contribute to hematologic malignancies and how? Adjuvant therapies targeting the contribution of the microenvironment to leukemogenesis and resistance will likely be needed to fully eradicate LSCs. However, rational design of novel treatment strategies first requires proper understanding of the normal niches and their alterations in myeloid malignancies. Because the incidence of these diseases increases with age, parallel study of the aging process is of major importance. The reduced tolerance to chemotherapy, which contributes to the increased lethality of myeloid malignancies in the elderly, might be partially the result of impaired niche recovery during aging. The current state-of-the art literature highlights the importance of the BM niche in contributing to myeloid malignancy progression by inducing or facilitating disease development, as well as conferring resistance to chemotherapy. The emerging recognition of the environment as a crucial player in multiple steps of the leukemic cascade lays the foundation for tackling leukemia from a different angle to improve current treatments. ",
				"clientUrl": "/viewarticle/875650",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 1557,
				"leadConcept": "Myelodysplastic Syndrome",
				"concept": ["Chronic Myelogenous Leukemia", "Acute Myeloblastic Leukemia", "Chemotherapy", "Leukemia", "Genomic Medicine", "Vascular Endothelial Growth Factor (VEGF)", "Bone Marrow", "Pathogenesis", "Tumor Genetics", "Myeloproliferative Disease", "Drug Resistance"],
				"leadSpecialtyId": 7,
				"leadSpecialty": "Hematology-Oncology",
				"allSpecialties": ["Hematology-Oncology", "Pathology & Lab Medicine"],
				"contentGroup": "Journal Article",
				"origContentType": "Journal Article",
				"contentType": ["Journal Article"],
				"description": "Various niche cells in the bone marrow play stage- and disease-specific roles in progression of myeloid malignancies and in response to chemotherapy.",
				"legacyID": 875650,
				"siteOn": 2003,
				"title": "Myeloid Malignancies and the Microenvironment",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/Blood-thumb.jpg"],
				"publicationDate": 1487221200000,
				"postingDate": 1487221200000,
				"_version_": 1573508884312621056,
				"last_index_date": 1500615009622
			}, {
				"id": "pdctm_0901c79180a49d32",
				"activeCME": 1,
				"activityExpirationDate": 1505451600000,
				"authors": ["Yoshihiro Inamoto", " Paul J. Martin", " Mary E.D. Flowers", " Stephanie J. Lee", " Paul A. Carpenter", " Edus H. Warren", " Daniel E. Geraghty", " Ni Lee", " Michael J. Boeckh", " Barry E. Storer", " David M. Levine", " Wenhong Fan", " Lue-Ping Zhao", " John A. Hansen"],
				"body": "Abstract and Introduction Abstract and Introduction Abstract Sclerotic graft-versus-host disease (GVHD) is a distinctive phenotype of chronic GVHD after allogeneic hematopoietic cell transplantation, characterized by fibrosis of skin or fascia. Sclerotic GVHD has clinical and histopathological similarities with systemic sclerosis, an autoimmune disease whose risk is influenced by genetic polymorphisms. We examined 13 candidate single-nucleotide polymorphisms (SNPs) that have a well-documented association with systemic sclerosis to determine whether these SNPs are also associated with the risk of sclerotic GVHD. The study cohort included 847 consecutive patients who were diagnosed with chronic GVHD. Genotyping was performed using microarrays, followed by imputation of unobserved SNPs. The donor rs10516487 ( BANK1 : B-cell scaffold protein with ankyrin repeats 1) TT genotype was associated with lower risk of sclerotic GVHD (hazard ratio [HR], 0.43; 95% confidence interval [CI], 0.21-0.87; P = .02). Donor and recipient rs2056626 ( CD247 : T-cell receptor ζ subunit) GG or GT genotypes were associated with higher risk of sclerotic GVHD (HR, 1.57; 95% CI, 1.13-2.18; P = .007 and HR, 1.66; 95% CI, 1.19-2.32; P = .003, respectively). Donor and recipient rs987870 (5′-flanking region of HLA-DPA1 ) CC genotypes were associated with higher risk of sclerotic GVHD (HR, 2.50; 95% CI, 1.22-5.11; P = .01 and HR, 2.13; 95% CI, 1.00-4.54; P = .05, respectively). In further analyses, the recipient DPA1*01:03∼DPB1*04:01 haplotype and certain amino acid substitutions in the recipient P1 peptide-binding pocket of the HLA-DP heterodimer were associated with risk of sclerotic GVHD. Genetic components associated with systemic sclerosis are also associated with sclerotic GVHD. HLA-DP–mediated antigen presentation, T-cell response, and B-cell activation have important roles in the pathogenic mechanisms of both diseases. Introduction Sclerotic graft-versus-host disease (GVHD) represents a distinctive phenotype of chronic GVHD, characterized by fibrosis of skin or fascia, and is often associated with severe disability and morbidity after allogeneic hematopoietic cell transplantation. [1] The 3-year cumulative incidence of sclerosis is 20% after initial systemic treatment among patients with chronic GVHD, and the prevalence reaches 53% in patients with severe chronic GVHD. [2,3] Pathogenic mechanisms of sclerotic GVHD remain elusive, but the cutaneous clinical manifestations resemble systemic sclerosis, a rare autoimmune disease whose risk is influenced by genetic polymorphisms. Both diseases are characterized by thickening of the skin due to accumulation of collagen and extensive fibrosis, but some manifestations differ. For example, systemic sclerosis often causes pulmonary hypertension, renal dysfunction, and cardiac dysfunction, whereas these manifestations rarely occur in patients with sclerotic GVHD. [4,5] Therefore, pathogenic mechanisms of the two diseases are thought to differ, although they might share some similar mechanisms. [4,6] To date, genetic risk factors for sclerotic GVHD have not been well defined, but candidate gene and genome-wide association studies have identified single-nucleotide polymorphisms (SNPs) associated with systemic sclerosis. [7] These SNPs include HLA and non-HLA variants involved in adaptive and innate immune responses. We hypothesized that the same SNPs might also have associations with the development of sclerosis in patients with chronic GVHD if the two diseases have similar pathogenic mechanisms. Therefore, we selected candidate SNPs that have a well-documented association with systemic sclerosis and examined their association with risk of sclerosis in patients with chronic GVHD. Identification of such associations would suggest similar pathogenic mechanisms between the two diseases, and might help to elucidate genetic mechanisms and treatment targets. Methods Methods Literature Search A broad PubMed search was performed to identify SNPs published by June 2013, that met all of the following criteria using the terms “systemic sclerosis” and “polymorphism”: (1) SNPs associated with any form of systemic sclerosis, (2) SNPs identified in a large cohort including at least 1000 patients, (3) minor allele frequency (MAF) ≥0.05, and (4) SNPs reported in at least 2 publications or reported with odds ratios (OR) ≥2.0, or ≤0.5 if the association was reported in only a single publication. SNPs from the same gene that shared strong linkage disequilibrium (LD) with D prime >0.90 were combined, and a single “tag” SNP was chosen as representative of all SNPs in the LD group. Study Cohort We identified 977 consecutive relapse-free patients who received systemic treatment of chronic GVHD after a first allogeneic hematopoietic cell transplantation between May 2000 and December 2009 at the Fred Hutchinson Cancer Research Center (FHCRC)/Seattle Cancer Care Alliance. [3] Among the 977 patients, 847 had recipient (n = 778) or donor (n = 808) samples available for genotyping, and 198 (23%) of the 847 patients developed sclerotic GVHD. Recipients and donors had given written consent allowing medical records and collected samples to be used for research in accordance with the Declaration of Helsinki, and the Institutional Review Board of the FHCRC approved the study. Clinical Assessments and Definitions Chronic GVHD was diagnosed by the National Institutes of Health (NIH) consensus criteria. [1] The onset of sclerotic GVHD was defined when manifestations of cutaneous sclerosis, fasciitis, or joint contracture were first documented in the medical record. [3] Sample Preparation, Genotyping, and Imputation All recipient and donor samples were collected before transplantation according to approved research protocols. Genomic DNA was extracted from blood mononuclear cells or Esptein-Barr virus transformed B-lymphocyte cell lines using a Puregene kit (Qiagen, Valencia, CA). Genotyping assays used 3 different platforms: (1) the Affymetrix 5.0 Human GeneChip (206 recipients and 198 donors), (2) the Illumina 1M Quad (476 recipients and 458 donors), and (3) the Illumina 2.5M BeadArray (96 recipients and 152 donors). Amplification and hybridization for the Affymetrix 5.0 array was performed at the Affymetrix Service Laboratory (Santa Clara, CA), and amplification and hybridization for the Illumina BeadArrays was performed by the FHCRC Genomics Shared Resource laboratory. Data quality was assessed via 3 different methods: the Affymetrix Bayesian Robust Linear Model with Mahalanobis distance classifier-based “QC call rate,” the clustering call rate, and a polymerase chain reaction-based ABO and XY genotyping-based sample verification method. The genotypes of the candidate SNPs were determined separately for each platform using the Affymetrix Bayesian Robust Linear Model with Mahalanobis distance classifier algorithm for the Affymetrix array () and the GeneCall algorithm for the Illumina array (). Candidate SNPs not genotyped on the array were imputed using the 1000 Genomes Project phase 1 SNPs as a reference panel and the software IMPUTE version 2 (). The posterior probability of the most probable genotype is calculated as the probability of observing an unobserved genotype at the imputed locus, given all of the observed genotypes in the flanking region. The imputed SNP genotype was retained only if the average posterior probability exceeded 0.8. The imputed genotype was treated as missing if the average posterior probability was <0.8. The call rate reflects the percentage of nonmissing genotypes in each platform, and SNPs were treated as a quality control “failure” and excluded from analyses if the call rate in any typing platform was <0.90. HLA-DPA1 and -DPB1 genotypes were determined by next-generation sequencing (MiSeq; Illumina Inc, San Diego, CA) using commercial next-generation sequencing HLA reagents (Scisco Genetics Inc., Seattle, WA) in 165 recipients and 172 donors, and were imputed in 613 recipients and 636 donors with the use of SNP genotypes according to “Methods” described previously. [8] The frequencies of HLA-DPA1 and -DPB1 alleles in the study cohort were comparable to those reported in a large population-based study. [9] Statistical Analysis Sclerotic manifestations present at the onset of initial treatment of chronic GVHD were treated as an event at day 1 after treatment, and all patients were included in the analysis. [3] In this cohort study, Cox regression models were used to examine allelic (additive) and genotypic (dominant and recessive) associations of donor and recipient SNPs with the risk of sclerotic GVHD. [10] Results were analyzed without and with adjustments for clinical risk factors as defined in our previous study. [3] These included stem cell graft source, HLA matching at A, B, C, DRB1, and DQB1 loci, donor-recipient ABO compatibility, and total body irradiation (TBI) exposure. [3] Donor type (related vs unrelated) was not adjusted, because it was not associated with the risk of sclerotic GVHD. [3] Models adjusted for clinical risk factors were also adjusted for the first 4 principal components to control for population stratification. P values are two-sided, without adjustment for multiple comparisons. Results Results Characteristics of the Study Cohort The median age of the patients was 48 years (range, 1 to 78); 502 patients (59%) were males, 694 (82%) were white, and 745 (88%) received mobilized blood cell grafts. The median follow-up after onset of chronic GVHD among survivors was 81 months (range, 6 to 135). The cumulative incidence of sclerotic manifestations was 24% (95% confidence interval [CI], 21% to 27%) at 5 years after the initial systemic treatment of chronic GVHD. Other demographics of the study cohort are summarized in Table 1 . Figure 1. Figure 1. Cumulative incidence frequencies of sclerosis in patients with chronic GVHD, according to rs10516487 ( BANK1 ), rs2056626 ( CD247 ), and rs987870 ( HLA-DPA1 ) genotypes in the donors and recipients. Black solid lines represent groups with the homozygous minor allele, gray solid lines represent groups with the homozygous major allele, and dotted black lines represent heterozygotes. Figure 1. Candidate Genes and SNPs A broad search of the PubMed database identified 15 SNPs in 13 genes that were associated with susceptibility to systemic sclerosis and met all of the required criteria described in “Methods”: B-cell scaffold protein with ankyrin repeats 1 ( BANK1 ), BLK , CD247 , HLA-DRA , HLA-DQB1 , HLA-DPA1 , IL12RB2 , IRF8 , PTPN22 , STAT4 , TNFSF4 , TNIP1 , and TNPO3-IRF5 . Thirteen of these 15 SNPs yielded genotyped or imputed data that passed quality control, and all had an MAF ≥0.05 ( Table 2 ). The MAF for each SNP was consistent with the values reported in studies of systemic sclerosis. [11-19] Two SNPs (rs11642873 and rs1234314) did not pass quality control because of low call rates on one of the genotyping platforms (see supplemental Table 1, available on the Blood Web site). Supplemental Table 2 shows the genotype distributions and MAFs for each SNP, according to the presence or absence of sclerosis. Candidate SNPs Associated With Risk of Sclerotic GVHD Three SNPs showed statistically significant associations with risk of sclerosis in patients with chronic GVHD ( Table 3 ). SNP rs10516487 ( BANK1 ) in donors was associated with a decreased risk of sclerotic GVHD in the recessive model (adjusted hazard ratio [HR] 0.43; 95% CI, 0.21-0.87; P = .02). SNP rs2056626 ( CD247 : T-cell receptor [TCR] ζ subunit) in both donors and recipients was associated with an increased risk of sclerotic GVHD in the allelic model (adjusted HR, 1.23; 95% CI, 1.00-1.51; P = .04 and adjusted HR, 1.24; 95% CI, 1.01-1.52; P = .04, respectively), and in the dominant model (adjusted HR, 1.57; 95% CI, 1.13-2.18; P = .007 and adjusted HR, 1.66; 95% CI, 1.19-2.32; P = .003, respectively). SNP rs987870 ( HL A-DPA1 ) in both donors and recipients was associated with an increased risk of sclerosis in the recessive model (adjusted HR, 2.50; 95% CI, 1.22-5.11; P = .01 and adjusted HR, 2.13; 95% CI, 1.00-4.54; P = .05, respectively). We evaluated the joint association of donor and recipient genotypes with the risk of sclerotic GVHD among patients with both donor and recipient genotyping. The results for rs2056626 ( CD247 ) and rs987870 ( HLA-DPA1 ) were inconclusive as to whether the donor and recipient associations are independent. Cumulative incidence frequencies of sclerotic GVHD according to genotypes of these 3 SNPs are shown in Figure 1. Results for other candidates are shown in supplemental Table 3. Overall, adjustment had only minor effects on the association results. Polymorphisms in HLA-DRA and HLA-DQB1 were not statistically associated with the risk of sclerotic GVHD, although power to observe a statistically significant association is ≥80% based on the OR reported for systemic sclerosis shown in Table 2 . Figure 2. Figure 2. Cumulative incidence frequencies of sclerosis in patients with chronic GVHD. Results are shown (A) according to the presence or absence of the HLA-DPA1*01:03∼DPB1*04:01 haplotype in the recipient, and (B) according to presence or absence of HLA-DPA1 and HLA-DPB1 alleles encoding heterodimers with a Q∼GPM P1 pocket. Solid lines represent groups with the haplotype or P1 pocket, and dotted lines represent groups without the haplotype or P1 pocket. Figure 2. Analysis of HLA-DPB1 Mismatching Results for rs987870 ( HLA-DPA1 ) motivated further exploration of the association between HLA-DPB1 mismatching and the risk of sclerotic GVHD. Among 619 HLA-A, B, C, DRB1, and DQB1-matched patient and donor pairs, recipient mismatching at HLA-DPB1 was present in 243 (39%) pairs but was not statistically associated with the risk of sclerotic GVHD (HR, 1.05; 95% CI, 0.76-1.45; P = .77). Likewise, nonpermissive recipient T-cell epitope mismatching at HLA-DPB1 [20] was present in 56 (9%) pairs but was not statistically associated with the risk of sclerotic GVHD (HR, 0.58; 95% CI, 0.30-1.14; P = .11). The recently reported SNP rs92777534 linked to HLA-DP expression [21] was also not statistically associated with the risk of sclerotic GVHD (data not shown). Analysis of HLA-DPA1∼B1 haplotype and HLA-DP P1 Peptide-Binding Pocket The risk of sclerotic GVHD was increased when donors or recipients were homozygous for the rs987870 minor C allele but was paradoxically decreased when donors or recipients were heterozygous, as compared with donors or recipients homozygous for the major T allele (Figure 1). We used 2 approaches to unravel this paradox. Because this SNP is located in the 5′-flanking region of HLA-DPA1 , we tested whether any of the most frequent HLA-DPA1∼DPB1 haplotypes were associated with the risk of sclerotic GVHD ( Table 4 ). [22] Among 4 common HLA-DPA1∼B1 haplotypes with frequencies ≥5%, DPA1*01:03∼DPB1*04:01 in the recipient was associated with an increased risk of sclerotic GVHD (adjusted HR, 1.54; 95% CI, 1.10-2.15; P = .01) ( Table 4 ; Figure 2A). Figure 3. Figure 3. Crystal structure of an HLA-DP2 heterodimer in complex with a self-peptide. The HLA-DPα chain is shown in yellow, and the HLA-DPβ chain is shown in blue. Shown in red is the P1 pocket formed in part by residue 31 of the α chain and residues 85 to 87 of the β chain. The self-peptide filling the gap between the α helices of the heterodimer is shown in green. HLA-DP2 is a heterodimer encoded by DPA1*0103 and DPB1*0201 with M at position 31 of the α chain and GPM at positions 85 to 87 of the β chain. The hydrophobic aromatic side chain of phenylalanine at the P1 anchor position of the peptide projects into the hydrophobic M∼GPM P1 pocket. Substitution of Q for M at position 31 in the α chain would replace a hydrophobic residue with a more hydrophilic residue. This substitution would not alter the overall structure of the heterodimer but would change the P1 anchor residues that fit the pocket and the repertoire of peptides that can be presented. The crystal structure of an HLA-DPB1 heterodimer with a Q∼GPM P1 pocket has not been determined. The structure shown in the figure was rendered with PyMOL (The PyMOL Molecular Graphics System, version 1.7.4.4, Schrödinger, LLC.). Figure 3. HLA-DP molecules have peptide-presentation P1 peptide-binding pockets characterized by M (methionine) or Q (glutamine) at position 31 of the DPα chain and by glutamic acid-alanine-valine (EAV) or glycine-proline-methionine (GPM) motifs at positions 85 to 87 of the DPβ chain (Figure 3). [9] As a second approach in unraveling the paradox, we evaluated associations of each P1 pocket motif with the risk of sclerotic GVHD ( Table 5 ). Previous studies have shown significant negative LD between HLA-DPA1 alleles encoding Q and HLA-DPB1 alleles encoding GPM. Haplotype frequencies for these Q and GPM encoding alleles occur much less frequently than expected from their respective individual frequencies. [9] Nonetheless, staining with two different HLA-DP–specific antibodies demonstrated surface expression of HLA-DP on B cells from individuals with alleles encoding only Q-bearing DPα chains and GPM-bearing DPβ chains, indicating no intrinsic physical constraint on their ability to form stable heterodimers (supplemental Figure 1). Therefore, we defined P1 pocket motifs by considering DPα∼DPβ heterodimers encoded in trans , together with those encoded in cis . The risk of sclerotic GVHD was decreased in recipients who had HLA-DPA1 and HLA-DPB1 alleles encoding Q∼GPM P1 pockets compared with those who did not (adjusted HR, 0.62; 95% CI, 0.42-0.92; P = .02) ( Table 5 ; Figure 2B). With adjustments for the presence of DPA1*01:03∼DPB1*04:01 haplotypes and Q∼GPM P1 pockets, differences in the risk of sclerotic GVHD between rs987870 heterozygotes and TT homozygotes were not statistically significant (supplemental Tables 4 and 5). Within the entire cohort, rs987870 genotypes, DPA1*01:03∼DPB1*04:01 haplotypes, and Q∼GPM P1 pockets showed independent associations with the risk of sclerotic GVHD ( Table 6 ). Discussion Discussion We examined 13 candidate SNPs that had a well-documented association with susceptibility to systemic sclerosis, under the hypothesis that the same SNPs may also have associations with development of sclerotic GVHD if the two diseases share similar pathogenic mechanisms. The candidate SNPs all map to genes or regions involved in immune function. We found that donor rs10516487 ( BANK1 ), and donor and recipient rs2056626 ( CD247 ), and rs987870 (5′-flanking region of HLA-DPA1 ) were associated with the risk of sclerosis in patients with chronic GVHD. Despite adequate power to detect associations, candidate SNPs in HLA-DRA and HLA-DQB1 did not show statistically significant associations with risk of sclerotic GVHD. These results highlight similarities and differences in the mechanisms that cause sclerotic GVHD as compared with systemic sclerosis, and suggest a critical role of the adaptive immune system including B-cell activation, T-cell antigen receptor response, and HLA-DP–mediated antigen presentation in the pathogenic mechanisms of both sclerotic GVHD and systemic sclerosis. BANK1 is expressed exclusively in B cells and encodes a signaling molecule with stimulatory and inhibitory functions. BANK1 is a Lyn tyrosine kinase substrate that promotes tyrosine phosphorylation of inositol 1,4,5-triphosphate receptors implicated in B-cell activation. [23] On the other hand, BANK1 modulates hyperactive B-cell responses by inhibiting AKT activation in CD40-mediated pathways. [24] SNP rs10516487 ( BANK1 ) is 1 of 3 functional SNPs affecting BANK1 regulatory sites. [25,26] As compared with the rs10516487 C major allele, the T minor allele decreases BANK1 expression, reduces the activity of BANK1 variants with increased potential for self-association, and thereby reduces B-cell responses. [27] In several large studies, the same minor allele has been associated with decreased susceptibility to systemic sclerosis, [11,28] systemic lupus erythematosus, [25] and rheumatoid arthritis. [26] These results suggest that sclerotic GVHD shares a BANK1- mediated pathogenic mechanism with several autoimmune diseases. These results also suggest that sclerotic GVHD might be ameliorated or prevented by inhibition of BANK1 function or related components of B-cell activation. In fact, rituximab has efficacy for treatment of sclerotic GVHD, [29] and patients with higher percentages of activated B cells had better clinical responses to rituximab. [30] A recent study showed that antibodies from donor B cells perpetuate cutaneous sclerotic GVHD in mice. [31] Functional activation of T cells depends on surface expression of TCR-CD3 complexes. CD247 encodes the TCR ζ (CD3ζ) subunit and plays a crucial role in coupling antigen recognition to several intracellular signal-transduction pathways. [32] CD3ζ is a key element in the signaling function of chimeric antigen receptors in cancer immunotherapy. [33] Altered expression of CD247 may cause T-cell dysfunction, and failure of tolerance in chronic autoimmune and inflammatory disorders. [34,35] The G minor allele of SNP rs2056626 ( CD247 ) has shown allelic associations with reduced susceptibility to systemic sclerosis in 4 independent studies. [13,14,19,36] In addition, minor alleles of two other CD247 SNPs in LD with rs2056626 were associated with reduced susceptibility to rheumatoid arthritis, celiac disease, and juvenile idiopathic arthritis. [37-39] Although causal effects of these SNPs on CD247 expression and function have not been completely characterized, variation in this gene correlated with altered T-cell activation and autoimmune diabetes in mice. [40] In our study, the rs2056626 G minor allele in both recipients and donors showed allelic and dominant associations with increased risk of sclerosis in patients with chronic GVHD. These results suggest that variable expression of CD3ζ might play a pathogenic role in sclerotic GVHD and other autoimmune diseases by altering TCR signaling. We note that the rs2056626 ( CD247 ) minor allele was associated with an increased risk of sclerotic chronic GVHD but with a decreased susceptibility to systemic sclerosis. We can only speculate that the downstream effect of variable signaling through the TCR may differ in the context of an allo-immune response as compared with the autoimmune response involved in systemic sclerosis. HLA-DP variants have been associated with susceptibility to certain immune-mediated diseases. [14,41] We found that SNP rs987870 ( HLA-DPA1 ) was associated with the risk of sclerotic GVHD. The same SNP has been associated with increased susceptibility to asthma, as well as systemic sclerosis. [14,42] SNP rs987870 is located in the 5′ noncoding region of HLA-DPA1 , a region characterized by strong LD and constrained haplotypic pairings between HLA-DPA1 and DPB1 alleles. Our results suggest that differences in the frequencies of DPA1*01:03∼DPB1*04:01 haplotypes or HLA-DP molecules with Q∼GPM motifs account for the decreased risk of sclerosis among rs987870-heterozygous patients as compared with those who are homozygous for the major T allele. Previous studies have not evaluated associations of the DPA1*01:03∼DPB1*04:01 haplotype or the Q∼GPM motif with either systemic sclerosis or sclerotic GVHD. These 3 mutually independent associations require verification in other cohorts of patients with sclerotic GVHD and systemic sclerosis. In previous studies, HLA-DPB1 mismatching between the donor and recipient was associated with an increased risk of acute GVHD. [43] In the present study, neither HLA-DPB1 mismatching nor HLA-DPB1 nonpermissive mismatching was statistically associated with risk of sclerotic GVHD. The recently reported SNP rs92777534 linked to HLA-DP expression [21] was also not statistically associated with the risk of sclerotic GVHD. Taken together, these results suggest that intrinsic HLA-DP functional mechanisms account for the association of HLA-DP variants with the risk of sclerotic GVHD. This study has limitations. Power to examine some of the weaker SNP associations reported for systemic sclerosis was low, and our analysis did not adjust for multiple comparisons. We were unable to determine whether the donor and recipient CD247 and HLA-DPB1 genotypes contribute independently to the risk of sclerosis. No other cohort currently has sufficient numbers of patients with chronic GVHD, together with the annotated onset of sclerosis and the DNA samples needed for a replication study. Therefore, collaborative efforts will be needed so that future studies could verify whether positive results from this study hold true in other cohorts of patients with chronic GVHD. Our findings suggest that genetic variation can modify the immune pathology and significantly alter the disease phenotype of chronic GVHD. Our results also support the hypothesis that HLA-DP–mediated presentation of specific peptides may have pathogenic or protective effects related to sclerotic GVHD. Further efforts to identify such peptides and genetic variations associated with specific phenotypes of chronic GVHD may expand our understanding of the responsible pathogenic mechanisms, thereby suggesting novel approaches for targeted therapy. ",
				"clientUrl": "/viewarticle/868569",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 3032536,
				"leadConcept": "Stem Cell Research and Therapy",
				"concept": ["Allograft", "Human Leukocyte Antigen (HLA)", "Graft Versus Host Disease", "Genetics", "Clinical Pathology", "Systemic Sclerosis"],
				"leadSpecialtyId": 7,
				"leadSpecialty": "Hematology-Oncology",
				"allSpecialties": ["Hematology-Oncology", "Transplantation", "Dermatology", "Allergy & Clinical Immunology", "Pathology & Lab Medicine"],
				"contentGroup": "Journal Article",
				"origContentType": "Journal Article",
				"contentType": ["Journal Article"],
				"description": "The risk for sclerotic graft-versus-host disease is increased with genetic polymorphisms associated with systemic sclerosis.",
				"legacyID": 868569,
				"pubDisplay": "Blood",
				"siteOn": 2003,
				"title": "Genetic Risk Factors for Sclerotic Graft-Versus-Host Disease",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/Blood-thumb.jpg"],
				"publicationDate": 1473915600000,
				"postingDate": 1473915600000,
				"_version_": 1573508889563889664,
				"last_index_date": 1500615014622
			}, {
				"id": "pdctm_0901c79180a97181",
				"activeCME": 1,
				"activityExpirationDate": 1510894800000,
				"authors": ["Elisa Rumi", " Mario Cazzola"],
				"body": "Abstract and Introduction Abstract and Introduction Abstract Essential thrombocythemia (ET) is an indolent myeloproliferative neoplasm that may be complicated by vascular events, including both thrombosis and bleeding. This disorder may also transform into more aggressive myeloid neoplasms, in particular into myelofibrosis. The identification of somatic mutations of JAK2 , CALR , or MPL , found in about 90% of patients, has considerably improved the diagnostic approach to this disorder. Genomic profiling also holds the potential to improve prognostication and, more generally, clinical decision-making because the different driver mutations are associated with distinct clinical features. Prevention of vascular events has been so far the main objective of therapy, and continues to be extremely important in the management of patients with ET. Low-dose aspirin and cytoreductive drugs can be administered to this purpose, with cytoreductive treatment being primarily given to patients at high risk of vascular complications. Currently used cytoreductive drugs include hydroxyurea, mainly used in older patients, and interferon α, primarily given to younger patients. There is a need for disease-modifying drugs that can eradicate clonal hematopoiesis and/or prevent progression to more aggressive myeloid neoplasms, especially in younger patients. In this article, we use a case-based discussion format to illustrate our approach to diagnosis and treatment of ET. Introduction Essential thrombocythemia (ET) is one of the Philadelphia-negative classical myeloproliferative neoplasms (MPNs), a category of the World Health Organization (WHO) classification of tumors of hematopoietic and lymphoid tissues that also includes polycythemia vera (PV) and primary myelofibrosis (PMF). [1,2] In the last few years, there have been significant advances in our understanding of the genetic basis, pathophysiology, and clinical course of ET. [3-20] Our article aims to offer up-to-date information and guidance regarding diagnosis and treatment of ET patients. To provide directions in the therapeutic management of common or complex clinical situations of the disease, we will first use clinical vignettes illustrating representative cases of ET ( Table 1 ) and will later consider specific situations of interest. How We Diagnose ET How We Diagnose ET Thrombocytosis is defined as a platelet (PLT) count ≥450 × 10 9 /L. The major types of thrombocytosis include reactive (or secondary) thrombocytosis, clonal myeloid neoplasms, and familial or hereditary thrombocytosis. [21] As the most common cause is a reactive process, at the time of the first visit we always consider secondary thrombocytosis through a complete interview, physical examination, and first-level tests as reported in Table 2 and Figure 1. Figure 1. Our approach to the differential diagnosis of thrombocytosis. For the analysis of JAK2 / CALR / MPL mutations status, we use granulocyte DNA and perform the following tests sequentially: (1) a quantitative polymerase chain reaction–based allelic discrimination assay for JAK2 (V617F) with a sensitivity of <0.1%; (2) if JAK2 (V617F) is absent, Sanger sequencing for detection of CALR exon 9 indels; (3) if JAK2 (V617F) is absent and CALR exon 9 is wild type, a high-resolution melt assay for detection of MPL exon 10 mutations followed by Sanger sequencing in case of mutant pattern. H&E, hematoxylin and eosin. Figure 1. Assessment of symptom burden in MPNs has shown that although ET has the lowest symptom severity, the prevalence of constitutional symptoms reported by patients is relatively high. [22] It should be noted, however, that in this study patients were an average of 6.7 years out from diagnosis at survey completion. In our experience, most patients with ET are asymptomatic at diagnosis, and detection of thrombocytosis is typically incidental. First-level laboratory tests include screening for mutations in the 3 MPN driver genes (Figure 1). In a recent study of 745 patients, [10] we found that 466 (62%) carried JAK2 (V617F), 176 (24%) had CALR exon 9 indels, and 28 (4%) had MPL exon 10 mutations: only 75 (10%) patients did not carry any of the above driver mutations. In our practice, search for JAK2 (V617F) on granulocyte DNA is the initial investigation performed in all patients with suspected ET; if JAK2 (V617F) is absent, we screen for CALR exon 9 indels, and then, if this latter screening is also negative, we search for MPL exon 10 mutations. Once the results of first-level tests are available, we follow the flowchart reported in Figure 1. The detection of a driver mutation confirms the presence of a myeloid neoplasm, but the absence does not rule out this possibility because as many as 1 in 10 ET patients can be triple negative, that is, negative for canonical mutations in the above driver genes. Two recent studies have indeed shown that a few triple-negative patients carry activating mutations of MPL outside exon 10, and that these noncanonical mutations may be either inherited or somatically acquired. [23,24] One study has also shown that some patients carry noncanonical, activating mutations of JAK2 , which appear to be germ line in most instances. [23] Finally, some patients have evidence of polyclonal hematopoiesis, and most likely do not have a true MPN. [23,24] Thus, the so-called triple-negative cases may include patients with ET associated with noncanonical mutations of MPL , individuals with hereditary thrombocytosis (see “Distinguishing familial ET from hereditary thrombocytosis”), and also subjects with nonclonal thrombocytosis (Figure 1). The myelodysplastic (MDS)/MPN with ring sideroblasts and thrombocytosis (MDS/MPN-RS-T) can mimic ET. [25] Most patients with MDS/MPN-RS-T have a combination of SF3B1 mutation (as a driver genetic lesion) and JAK2 , MPL , or CALR mutation (as a subclonal genetic lesion); however, up to one-third of patients may have wild-type SF3B1 . [25-27] Recent reports have described an atypical MPN associated with both BCR-ABL1 rearrangement and CALR mutation [28-30] : this further underlines the importance of strictly adhering to the WHO criteria, screening for BCR-ABL1 in the diagnostic approach. An interesting study has shown that about one-fourth of ET patients carry additional somatic mutations in non-MPM driver genes. [14] Although in the whole population of MPN patients the presence of 2 or more somatic mutations represented a negative prognostic factor, its significance in ET patients was less clear. In our clinical practice, we are currently using the 2016 WHO criteria for the diagnosis of ET, as reported in Table 3 . [2] Because these criteria have underlined the importance of distinguishing true ET from early prefibrotic stages of PMF, Table 3 also includes the 2016 WHO diagnostic criteria for prefibrotic myelofibrosis. Clinical Vignettes: Establishing Diagnosis Clinical Vignettes: Establishing Diagnosis Clinical vignettes are explored in detail in Table 1 . Case 1: Low-risk JAK2 -mutant ET This woman had normal body iron status and no evidence of inflammation. JAK2 (V617F) was detected on granulocyte DNA with a low percentage of mutant alleles, which is a common finding in ET, [31] and a bone marrow biopsy unequivocally confirmed the diagnosis of ET. Case 2: Low-risk CALR -mutant ET This young woman had normal body iron status and a normal C-reactive protein (CRP). Because JAK2 (V617F) was not detected on granulocyte DNA, CALR exon 9 was sequenced, and the type 1 CALR mutation (c.1092_1143del, L367fs*46) was detected. Bone marrow biopsy showed normal age-adjusted cellularity, and an increased number of giant megakaryocytes; reticulin fibrosis was absent. A final diagnosis of CALR -mutant ET was performed; CALR mutation is often associated with a very high platelet count, [10,11] as in this case. Case 3: JAK2 -mutant ET Progressing to PV The initial diagnosis of ET was based on the complete blood cell (CBC) count, positivity for JAK2 (V617F), and a typical bone marrow biopsy. Three years later, this woman developed erythrocytosis: serum erythropoietin was low at this time whereas the granulocyte JAK2 (V617F)-mutant allele burden was increased, indicating a polycythemic transformation. We did not repeat bone marrow biopsy because a diagnosis of PV could be made otherwise according to the British Committee for Standards in Hematology (BCSH) criteria, [32] and more importantly because a phlebotomy program was already indicated. JAK2 (V617F)-mutant ET has a cumulative risk of polycythemic transformation equal to 29% at 15 years. [10] We check the JAK2 (V617F)-mutant allele burden during follow-up in all patients who show an increase in hemoglobin level above the upper normal limit. Case 4: High-risk JAK2 -mutant ET The diagnostic process was simple in this man. He had normal body iron status and no evidence of inflammation, and more importantly he carried JAK2 (V617F). This case is reported mainly to emphasize the concept that advanced age represents a risk factor for thrombosis per se. Case 5: MPL -mutant MDS/MPN-RS-T mimicking ET The combination of mild anemia and thrombocytosis suggested MDS/MPN-RS-T: this diagnosis was confirmed by the examination of bone marrow aspirate and biopsy, including Perls staining. No SF3B1 mutation was detected in this woman, as happens in about one-third of these patients. This case illustrates the importance of performing bone marrow aspirate and biopsy to make an accurate morphologic diagnosis of ET and to distinguish this disorder from other myeloid neoplasms. To this purpose, evaluation of bone marrow biopsy should always include Perls and Gomori staining: without Perls staining, this patient might have been misdiagnosed as MPL -mutant ET. How We Communicate Diagnosis of ET How We Communicate Diagnosis of ET We inform our patients that ET belongs to MPNs and that these are disorders of the bone marrow characterized by excessive production of peripheral blood cells. We underline that although ET is a tumor (that is, a neoplasm), this is a chronic disorder with a minimal impact on the patient’s life expectancy. [33] We also explain that ET is an acquired disorder and that the driver mutation (in JAK2 , CALR , or MPL ) is always somatically acquired. Although familial cases exist, [34,35] likely caused by a genetic predisposition to acquire the above somatic mutations, we emphasize that ET cannot be directly inherited by the progeny. We suggest screening of relatives only in familial trees with 2 or more subjects affected with MPNs (see “Distinguishing familial ET from hereditary thrombocytosis”). We then illustrate the 3 most important complications that can occur during follow-up [10,36] : (1) vascular complication (15-year cumulative risk of thrombosis ranging from 10% to 25% depending on the molecular subtype, higher in JAK2 -mutant than in CALR -mutant ET) [10] ; (2) progression to myelofibrosis (15-year cumulative risk of about 10% on average, higher in type 1 CALR -mutant than in JAK2 -mutant ET) [37] ; and (3) leukemic transformation (15-year cumulative risk of about 3% on average). [10] Very often, patients ask whether they should modify their dietary habits, physical activity, or their lifestyle in general. We recommend continuing a normal life without deprivation of food, sports, and enjoyment, just taking into account that antiplatelet therapy may expose the patient to bleeding in the case of extreme sports. We advise stopping smoking and recommend treating obesity, hypertension, and dyslipidemia. Finally, we discuss the importance of an optimal follow-up. We suggest checking CBC count regularly, monthly if a cytoreductive treatment is started, and planning a hematologic visit every 6 months. When the condition is stable, CBC counts can be checked less frequently. Abdominal ultrasound is recommended when myelofibrotic transformation is suspected based on clinical and/or hematologic criteria. How We Treat Patients With ET According to Their Individual Risk How We Treat Patients With ET According to Their Individual Risk Currently available treatments for ET patients are mainly aimed at minimizing the risk of thrombosis and/or bleeding. As shown in Table 4 , age ≥60 years, history of vascular complications (thrombosis or major bleeding), and PLT count ≥1500 × 10 9 /L are the 3 risk factors used to classify patients with ET into low (no risk factors) and high risk (1 or more risk factors). [38] A PLT count ≥1500 × 10 9 /L represents an indication to cytoreductive treatment because extreme thrombocytosis is frequently associated with acquired von Willebrand syndrome. [38] The International Prognostic Score for Essential Thrombocythemia (IPSET) is based on age >60 years, white blood cell (WBC) count >11 × 10 9 /L, and history of thrombosis [3] : although it provides prognostic information, we do not use it for clinical decision-making at present. As illustrated in Table 4 , in our current practice we treat low-risk patients with low-dose aspirin or just follow them regularly; we treat high-risk patients with low-dose aspirin combined with a cytoreductive treatment. According to the European LeukemiaNet (ELN) recommendations, [38] all ET patients should be managed with low-dose aspirin if microvascular disturbances are present. A study conducted on low-risk ET patients showed that antiplatelet therapy reduces the incidence of venous thrombosis in JAK2 -mutated patients and the rate of arterial thrombosis in those with cardiovascular risk factors. [39] In the remaining low-risk patients, antiplatelet therapy was not effective as primary prophylaxis of thrombosis. Subsequent studies have confirmed that cardiovascular risk factors and JAK2 (V617F) represent independent risk factors for thrombosis in ET. [4,40,41] A more recent work has evaluated the benefit-to-risk ratio of low-dose aspirin in 433 low-risk ET patients who were on antiplatelet therapy or observation only. [42] In JAK2 (V617F)-mutated patients, low-dose aspirin was associated with a reduced incidence of venous thrombosis with no effect on the risk of bleeding. By contrast, in CALR -mutated patients, antiplatelet therapy did not affect the risk of thrombosis whereas it was associated with a higher incidence of bleeding. Thus, the available evidence indicates that JAK2 (V617F) plays a major role in the pathogenesis of thrombosis, whereas CALR or MPL mutation and triple negativity identify patients with lower thromboembolic risk. Based on the available evidence, we use low-dose aspirin in ET patients as summarized in Table 4 . We prescribe aspirin 100 mg once daily, preferably at the end of a meal, and do not try to modulate the dosing interval as suggested by a study on thromboxane biosynthesis. [43] We administer antiplatelet therapy to all high-risk ET patients with the only exception being those with extreme thrombocytosis (≥1500 × 10 9 /L). In low-risk patients, we base our decision on the molecular subtype and the presence of cardiovascular risk factors or microvascular symptoms ( Table 4 ). In case of marked thrombocytosis (≥1000 × 10 9 /L) or of any evidence of bleeding, before starting low-dose aspirin, we assess von Willebrand factor in terms of antigen level and ristocetin cofactor activity to exclude an acquired von Willebrand syndrome; if present, we do not administer aspirin. In case of gastric intolerance, we suggest taking antacid drugs or switching to ticlopidine. Although cytoreductive treatment is not indicated in low-risk ET patients who have an incidence of thrombosis similar to that of a healthy control population, [44] it is definitely indicated in high-risk patients. [45,46] Our criteria for the choice of the optimal cytoreductive drug are reported in Table 5 . The ELN experts recommended hydroxyurea as first-line cytoreductive therapy at any age, although they also underlined that its use should be carefully considered in patients younger than 40 years of age. [38] In our current practice, we start hydroxyurea at a dose of 1 g per day, and then modify the dose according to the hematologic response. The objective of treatment is dual, that is: (1) to lower PLT count below 450 × 10 9 /L and (2) to correct leukocytosis (WBC count ≥11 × 10 9 /L), if present. We consider correcting leukocytosis very important, whereas we are relatively flexible with respect to the PLT count: actually, we consider acceptable also values between 450 × 10 9 /L and 600 × 10 9 /L, especially if these values can be achieved with lower doses of hydroxyurea (eg, 500 mg per day). Our clinical practice is supported by a number of studies showing that the actuarial probability of thrombosis is influenced by leukocytosis and not by PLT count. [47 -50] In the prospective Thrombocythemia 1 Trial (PT-1) cohort, PLT count outside of the normal range during follow-up was not associated with a risk of thrombosis, but rather with a risk of bleeding. [50] In patients younger than 40 years of age and in selected cases between 40 and 60 years of age ( Table 5 ), we use interferon α: this represents an off-label use because ET is not an approved indication. Although there is no evidence that hydroxyurea can increase the risk of leukemic transformation, [51] this drug is not completely devoid of adverse effects [52] ; more importantly, it does not specifically target the mutant clone and is therefore unlikely to modify the natural history of disease. On the contrary, pegylated interferon α-2a has been shown to induce sustained complete molecular response in a subset of patients with JAK2 (V617F)-mutant ET. [53,54] In addition, recent reports describe the positive effect of interferon α in patients with CALR -mutant ET [16,55] : this treatment was found to produce high rates of hematologic and molecular responses that in some cases could be maintained after discontinuation of the drug. [55] Although these observations do not necessarily mean that interferon α can modify the natural history of disease, they at least indicate that this drug can target the myeloproliferative clone. [56] Before starting treatment with interferon α, we suggest evaluating liver and thyroid function, and excluding the presence of autoantibodies (anti-nuclear and anti-double-stranded DNA antibodies, rheumatoid factor, and anti-neutrophil cytoplasmic antibodies). We generally start with 3 × 10 6 /million units of interferon α 3 times a week, and then titrate the dose according to efficacy and side-effects. To avoid flu-like symptoms, we recommend the use of paracetamol, 1000 mg per os, at the beginning of treatment. Adverse effects of interferon α treatment are not trivial, and include, besides flu-like symptoms, nausea, fatigue, and psychiatric sequelae. [57] Previous studies have indeed reported discontinuation of treatment in almost one-fourth of cases. [58] Patients must therefore be supported and motivated, underlying that this represents so far the only treatment capable of targeting the mutant cells in their bone marrow. The PT-1 trial showed that hydroxyurea plus low-dose aspirin is superior to anagrelide plus low-dose aspirin for patients with ET at high risk for vascular events. [59] More recently, the ANAHYDRET study concluded that anagrelide is not inferior compared with hydroxyurea in the prevention of thrombotic complications in patients with ET diagnosed according to the 2008 WHO criteria. [7] The US Food and Drug Administration (FDA) has approved anagrelide for the treatment of ET, whereas the European Medicine Agency (EMA) has been more restrictive, approving the drug for treatment of patients with high-risk ET who are intolerant to their current therapy or whose elevated PLT counts are not reduced to an acceptable level by their current therapy. An expert panel has provided a definition of clinical resistance/intolerance to hydroxyurea in ET. [60] So far, we have only occasionally considered the use of anagrelide, mainly because the number of ET patients with resistance/intolerance to hydroxyurea is small in our experience. However, we are fully aware that anagrelide is widely used alone and in combination in other institutions. [61] Because of the potential cardiovascular toxicity associated with anagrelide, especially in older patients, a careful cardiac evaluation is recommended before starting treatment. Busulfan and pipobroman have been used as second-line treatment in older patients who are unresponsive or intolerant to hydroxyurea. We currently use busulfan to this purpose: before prescribing this drug, we inform the patient that alkylating agents and the sequential use of different cytoreductive treatments might increase the risk of leukemic transformation. [36,51,62] Microvascular symptoms such as erythromelalgia and acroparesthesia generally resolve with low-dose aspirin. We consider an ad hoc cytoreductive treatment only in the few patients whose symptoms severely affect quality of life and do not respond to low-dose aspirin. Clinical Vignettes: Defining the Individual Risk and Deciding Therapy Clinical Vignettes: Defining the Individual Risk and Deciding Therapy Clinical vignettes are explored in detail in Table 1 . Case 1: Low-dose Aspirin in Low-risk JAK2 -mutant ET This patient had low-risk JAK2 (V617F)-mutant ET. She was given low-dose aspirin (100 mg per day) because JAK2 (V617F) specifically involves a high risk of thrombosis. [10] This patient is currently seen a couple of times a year in the Outpatient Department. Case 2: Low-risk CALR -mutant ET with Acquired von Willebrand Syndrome This woman had CALR-mutant ET and a history of oral mucosal bleeding after tooth brushing. Because of marked thrombocytosis (PLT count, 1069 × 10 9 /L), we assessed von Willebrand factor and found reduced ristocetin cofactor activity (30%) associated with normal antigen level, a combination that indicates an acquired von Willebrand syndrome. We decided on a watchful-waiting strategy: cytoreductive treatment with interferon α would be considered if PLT count increases to ≥1500 × 10 9 /L and/or bleeding becomes more severe. Case 3: JAK2 -mutant ET Requiring Phlebotomies Because of Progression to PV This woman had low-risk JAK2 (V617F)-mutant ET and therefore we prescribed low-dose aspirin. She then progressed to PV and a phlebotomy program to maintain hematocrit <45% was started. Her subsequent clinical course has been characterized by a progressive increase in PLT count due to the iron deficiency caused by phlebotomies. If PLT count increases to ≥1500 × 10 9 and/or leukocytosis develops, we would discontinue phlebotomies and start a cytoreductive treatment with hydroxyurea. Case 4: Low-dose Aspirin and Hydroxyurea in High-risk JAK2 -mutant ET This man was over 60 years of age and therefore had high-risk JAK2 (V617F)-mutant ET. He was treated with low-dose aspirin and hydroxyurea (1 g per day): PLT count normalized quickly and remained steadily below 300 × 10 9 /L after the dose of hydroxyurea was reduced to 500 mg per day. This optimal response to hydroxyurea is not uncommon in patients with JAK2 (V617F)-mutant ET. Case 5: Lack of Evidence Regarding Treatment of a Rare Myeloid Neoplasm MDS/MPN-RS-T is a very rare disease and the available evidence regarding its treatment is limited. We do not use cytoreductive drugs in these patients because they might significantly worsen anemia and/or negatively impact on the risk of leukemic transformation. Low-dose aspirin was given to this 64-year-old woman for primary prevention of thromboembolic complications. Distinguishing Familial ET From Hereditary Thrombocytosis Distinguishing Familial ET From Hereditary Thrombocytosis Case 6 in Table 6 illustrates our approach to the identification of familial cases of ET. Familial thrombocytosis includes hereditary thrombocytosis and familial ET. Hereditary thrombocytosis may be associated with germ line mutations of THPO , the thrombopoietin gene, [63,64] or MPL , the thrombopoietin receptor gene. [23,24,65] Recent reports have described cases of hereditary thrombocytosis associated with noncanonical germ line mutations of JAK2 . [23,66-69] In familial ET, JAK2 (V617F) is always a somatically acquired event, as in the familial tree reported in Figure 2. [34,70,71] Figure 2. Familial ET. In this family, JAK2 (V617F) was a somatically acquired mutation found in circulating granulocytes (with variable values for mutant allele burden in the different patients) but not in circulating T lymphocytes. Familial ET must be distinguished from hereditary thrombocytosis, a Mendelian genetic disease attributable to germ line mutations of JAK2 , MPL , or THPO . Figure 2. In our clinical practice, we interview all patients with thrombocytosis to find out if there is a family history of thrombocytosis or MPN. In familial trees with at least 2 cases of MPN, we suggest performing a CBC count in all apparently healthy relatives with the aim of identifying an early asymptomatic MPN phenotype. We manage and treat patients with familial ET in the same way as patients with sporadic ET; a recent study found survival to be similar in familial and sporadic MPN patients. [72] In familial trees with suspected hereditary thrombocytosis, we now sequence the entire coding region of JAK2 and MPL as well as the THPO gene. How We Manage Pregnancy in Women with ET How We Manage Pregnancy in Women with ET Case 7 in Table 6 provides an example of how we manage pregnancy in a woman with ET. ET occurs in women of childbearing age and pregnancy is a relatively common issue in the clinical management of young women with this disorder. Previous studies have shown live birth rates of 50% to 70%, and spontaneous abortion rates of 25% to 50%, mostly during the first trimester. [73] The pathogenesis of these complications is unclear; age, parity, thrombophilia, PLT count, WBC count, and hemoglobin level have not been found to be predictive of pregnancy outcome in ET. [74-76] Whether the use of aspirin can improve pregnancy outcome is uncertain [74-77] ; however, a meta-analysis of randomized trials conducted outside ET concluded that low-dose aspirin is effective in preventing preeclampsia, being safe for both mother and fetus. [78] Pregnancy complications in women with ET are associated with a higher risk of subsequent thrombosis. [79] In our practice, we inform the patient and her partner that pregnancy is not discouraged in ET, although they should be aware that the risk of fetal loss is 3 times higher compared with that of healthy women. We recommend aspirin for all pregnant women with ET, unless contraindicated. If PLT count is ≥1000 × 10 9 /L, an acquired von Willebrand syndrome should be excluded as indicated before. In agreement with the ELN recommendations, we add low-molecular-weight heparin (LMWH) to low-dose aspirin in case of previous major thrombosis or severe pregnancy complication, and consider interferon α if the PLT count is ≥1500 × 10 9 /L or in case of previous major bleeding. [38] We discuss with obstetricians and anesthetists the optimal time to discontinue antiplatelet treatment (generally about 2 weeks before delivery) in order to account for any possible event, including instrumental delivery and epidural or spinal anesthesia. After delivery, we recommend treating all women with ET with LMWH for 6 weeks to prevent deep vein thrombosis. [79] Returning to case 7, we used a combination of low-dose aspirin and LMWH as this pregnancy was classified as high risk because of the previous history of severe preeclampsia with preterm delivery. Potentially Catastrophic Events: How We Manage SVT in Patients With ET Potentially Catastrophic Events: How We Manage SVT in Patients With ET Case 8 in Table 6 provides an example of how we manage splanchnic vein thrombosis (SVT) in patients with ET. MPNs are the leading cause of SVT, being responsible for about half of cases of Budd-Chiari syndrome and one-third of cases of portal vein thrombosis. [80] In a meta-analysis of 831 patients with SVT, the mean prevalence of positivity for JAK2 (V617F) was 32.7% [81] : because this may be the first marker of a latent MPN, we recommend routine screening for JAK2 (V617F) in patients with a SVT. Although the incidence of CALR mutations is low in patients with SVT, [82] we have now also included mutation analysis of CALR exon 9 in the workup of these subjects. Genetic and acquired thrombophilia, in particular the presence of an antiphospholipid syndrome, should be studied in all cases of ET with SVT. Because ET patients with genetic or acquired thrombophilia are at high risk of recurrent thrombosis, [83] we prescribe cytoreductive treatment (generally hydroxyurea) and oral anticoagulation through life. These patients should be regularly monitored for portal hypertension and esophageal varices. Resistance to Conventional Treatments and the Use of Experimental Drugs Resistance to Conventional Treatments and the Use of Experimental Drugs Case 9 in Table 6 provides an example of the efficacy of ruxolitinib in a patient with ET who was resistant to conventional treatments, including interferon α and hydroxyurea. In a phase 2 open-label study, [84] ruxolitinib treatment was well tolerated in a population of patients with ET who were refractory or intolerant to hydroxyurea, and resulted in improvements in PLT count and disease-related symptoms in most cases. Interestingly, 2 patients with JAK2 (V617F)-mutant ET enrolled in this study achieved complete molecular remission after 5 years of ruxolitinib treatment. [85] It should also be noted that patient 8 ( Table 6 ) had a complete hematologic response to ruxolitinib after enrollment in a clinical trial on the use of this JAK inhibitor for treatment of SVT associated with MPNs. In a phase 2, open-label study, the telomerase inhibitor imetelstat has been administered to 18 patients with ET who had not had a response to or who had unacceptable side-effects from prior therapies. [86] This study showed hematologic and molecular responses but also nonnegligible adverse events. It has been suggested that imetelstat may change the natural history of MPN, [87] but its side-effect profile appears hardly acceptable in ET patients. Conclusions and Perspectives Conclusions and Perspectives Although our understanding of the genetic basis of ET has improved considerably in the last few years, there has been less progress than we would have liked in the management of this disorder. Low-dose aspirin combined with hydroxyurea may represent a satisfactory treatment of patients over the age of 60 years, but there is a need of disease-modifying drugs for younger patients. Current areas of uncertainty in the management of ET patients are reported in Table 7 . Table 7 also includes a list of potential disease-modifying drugs. The ongoing randomized trial of pegylated interferon α-2a vs hydroxyurea in PV and ET (ClinicalTrials.gov Identifier: NCT01259856) may provide important information about the ability of this drug to modify the natural history of disease. Ropeginterferon α-2, a monopegylated interferon α-2b isoform that can be administered every 2 weeks, has been recently shown to be safe and effective in the treatment of PV [88] : in this study, two-thirds of patients showed a reduction in the JAK2 -mutant allele burden during treatment. Whether JAK inhibitors can provide beneficial effects in patients with ET remains to be established in ad hoc clinical trials, but ruxolitinib has already proved to be effective in patients with a relatively aggressive disease. [84] ",
				"clientUrl": "/viewarticle/871788",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 0,
				"concept": ["Thrombocytosis", "Thrombosis", "Interferon Therapy", "Hemorrhage", "Immunosuppressive Therapy", "Antineoplastic Drug", "Hematology", "Tumor Genetics", "Myeloproliferative Disease", "Myelofibrosis", "Essential Thrombocytosis"],
				"leadSpecialtyId": 7,
				"leadSpecialty": "Hematology-Oncology",
				"allSpecialties": ["Hematology-Oncology"],
				"contentGroup": "Journal Article",
				"origContentType": "Journal Article",
				"contentType": ["Journal Article"],
				"description": "Essential thrombocythemia is an indolent myeloproliferative disease with possible complications of thrombosis, bleeding, and transformation into aggressive myelofibrosis.",
				"legacyID": 871788,
				"pubDisplay": "Blood",
				"siteOn": 2003,
				"title": "How I Treat Essential Thrombocythemia",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/Blood-thumb.jpg"],
				"publicationDate": 1479358800000,
				"postingDate": 1479358800000,
				"_version_": 1573508889351028736,
				"last_index_date": 1500615014436
			}, {
				"id": "pdctm_0901c79180b4e9a0",
				"activeCME": 1,
				"activityExpirationDate": 1524200400000,
				"authors": ["Frederika A. van Nimwegen", " Georgios Ntentas", " Sarah C. Darby", " Michael Schaapveld", " Michael Hauptmann", " Pieternella J. Lugtenburg", " Cecile P.M. Janus", " Laurien Daniels", " Flora E. van Leeuwen", " David J. Cutter", " Berthe M.P. Aleman"],
				"body": "Abstract and Introduction Abstract and Introduction Abstract Hodgkin lymphoma (HL) survivors treated with radiotherapy and/or chemotherapy are known to have increased risks of heart failure (HF), but a radiation dose-response relationship has not previously been derived. A case-control study, nested in a cohort of 2617 five-year survivors of HL diagnosed before age 51 years during 1965 to 1995, was conducted. Cases (n = 91) had moderate or severe HF as their first cardiovascular diagnosis. Controls (n = 278) were matched to cases on age, sex, and HL diagnosis date. Treatment and follow-up information were abstracted from medical records. Mean heart doses and mean left ventricular doses (MLVD) were estimated by reconstruction of individual treatments on representative computed tomography datasets. Average MLVD was 16.7 Gy for cases and 13.8 Gy for controls ( P difference = .003). HF rate increased with MLVD: relative to 0 Gy, HF rates following MVLD of 1-15, 16-20, 21-25, and ≥26 Gy were 1.27, 1.65, 3.84, and 4.39, respectively ( P trend < .001). Anthracycline-containing chemotherapy increased HF rate by a factor of 2.83 (95% CI: 1.43-5.59), and there was no significant interaction with MLVD ( P interaction = .09). Twenty-five–year cumulative risks of HF following MLVDs of 0-15 Gy, 16-20 Gy, and ≥21 Gy were 4.4%, 6.2%, and 13.3%, respectively, in patients treated without anthracycline-containing chemotherapy, and 11.2%, 15.9%, and 32.9%, respectively, in patients treated with anthracyclines. We have derived quantitative estimates of HF risk in patients treated for HL following radiotherapy with or without anthracycline-containing chemotherapy. Our results enable estimation of HF risk for patients before treatment, during radiotherapy planning, and during follow-up. Introduction With 10-year survival rates >80%, Hodgkin lymphoma (HL) is a model of a curable malignancy. [1] The efficacy and safety of treatments continue to improve, but late effects, including cardiovascular diseases, have caused substantial treatment-related morbidity and mortality in HL survivors treated in the past. It has been shown that mediastinal radiotherapy and/or anthracycline-containing chemotherapy increase the risk of coronary heart disease (CHD), valvular heart disease (VHD), and heart failure (HF) in HL survivors. [2-9] We previously found a linear dose-response relationship for the risk of radiation-related CHD in HL survivors with the excess rate increasing by 7.4% per Gy, [10] and a nonlinear dose-response relationship for VHD, with 1.4-, 3.1-, 5.4-, and 11.8-fold increased VHD rates for doses of ≤30 Gy, 31-35 Gy, 36-40 Gy, and >40 Gy, respectively. [3] Mediastinal radiotherapy has also been associated with HF in survivors of both HL and childhood cancer. [9,11] However, the shape of the radiation dose-response relationship has not previously been described, either for patients who received radiotherapy alone or for patients who received radiotherapy in combination with anthracyclines. Radiotherapy use has declined but still remains an important component of HL treatment. Anthracyclines have been commonly used since the early 1980s and remain the backbone of HL chemotherapy regimens used today. With this study, we aimed to determine the radiation dose-response relationship for HF in long-term survivors of adolescent and adult HL, to estimate cumulative risk of HF after radiotherapy given with and without anthracyclines, and to assess other determinants of HF risk. Methods Methods Study Population A nested case-control study was conducted within an existing multicenter hospital-based cohort (N = 2617) of HL survivors treated in The Netherlands between 1965 and 1995 before the age of 51 years, who had survived ≥5 years after HL diagnosis. The cohort was identified through hospital-based cancer registries in 4 large university hospitals and 1 cancer center. Over time, a wide variety of treatments was used in the cohort. The majority of patients were treated according to European Organization for Research and Treatment of Cancer Lymphoma Group protocols for primary treatment. [12] Briefly, in the 1960s, patients were treated with orthovoltage therapy or cobalt-60; from the 1970s onwards, linear accelerators were used. Individual blocks were used to shield normal tissues as much as possible. Patients usually received 40 Gy in fractions of 1.5 to 2.0 Gy when they were treated with radiotherapy only and 30 to 36 Gy when they also received chemotherapy. Mantle field irradiation (including mediastinal, axillary, and neck nodes) was the most commonly applied radiation from the early 1970s to the late 1980s. Since the late 1980s, a growing number of patients received more limited radiation fields (involved fields). Treatment of recurrences was generally less standardized. From the 1960s to 1980s, chemotherapy consisted mainly of MOPP (mechlorethamine, vincristine, procarbazine, prednisone). In the 1980s, anthracycline-containing regimens such as MOPP/ABV (MOPP/doxorubicin, bleomycin, vinblastine) and ABVD (ABV and dacarbazine) were introduced as part of primary treatment. Anthracycline dose was estimated in milligrams anthracycline per square meter body surface, based on number of cycles received times the standard anthracycline dose in the corresponding chemotherapy regimen during that time period. Standard doses of anthracycline per regimen per cycle were 25 mg/m 2 at days 1 and 15 for ABVD and alternating MOPP-ABVD and 35 mg/m 2 at day 8 for MOPP-ABV hybrid. A detailed description of patient selection, data collection, and treatments has been published previously [2,9,13-15] as well as assessment of cardiovascular events during follow-up. [9] Patients were eligible for this study if (1) they survived at least 5 years after HL diagnosis; (2) they were diagnosed with HL before the age of 51 years; (3) HL was their first primary malignancy (except for nonmelanoma skin cancer or carcinoma in situ of the cervix uteri or the breast); and (4) radiotherapy for HL was the only radiotherapy given to the neck or trunk prior to the cutoff date, which was defined as date of HF for the cases, whereas for each control it was defined as date of HL diagnosis plus a time interval equal to the interval from date of HL diagnosis to date of HF diagnosis of the corresponding case. Cases and Controls Cases (n = 91) were patients who developed HF in the form of either symptomatic congestive HF or cardiomyopathy, with an ejection fraction of <50% (or a ≥10% drop from baseline) or a fractional shortening of <24% (based on a combination of the Common Terminology Criteria for Adverse Events versions 3.0 and 4.0: grade ≥2; see supplemental Text 1, available on the Blood Web site) [16] as their first clinically significant heart disease. Cases were identified from medical records or postal questionnaires completed by the patient’s general practitioner (GP) [9] and verified using cardiac notes from either the GP or the treating cardiologist. The data abstraction forms and coding instructions were developed in collaboration with physicians, and it has been shown that the Common Terminology Criteria for Adverse Events can be used to properly grade cardiovascular events from medical records. [17] A total of 53 further cases of HF were excluded (see supplemental Table 1 for reasons). Follow-up was complete to October 2013. For each case with HF, we attempted to select 4 controls from the cohort, individually matched on sex, age at HL diagnosis (≤1 year), and date of HL diagnosis (≤3 years). Controls had to be free of any cardiac disease grade ≥2 at the cutoff date. In total, 278 controls were matched to the cases. Cases were eligible to be controls up to the date they developed HF, and controls were selected with replacement. Data Collection Detailed treatment information, including radiation doses and fields and cumulative chemotherapy doses, was collected from medical records. Copies of original radiotherapy prescription sheets and simulation films were obtained. Where original prescriptions were unavailable, information about radiotherapy, including dates, anatomical areas, dose, fractionation, and treatment energy, was abstracted from other clinical notes. If cumulative chemotherapy doses were not available, regimen-specific standard doses were multiplied by the number of cycles that a patient received. Cardiotoxicity equivalence ratios of 0.50 for daunorubicin and epirubicin to doxorubicin were used. [18,19] Vital status and dates of death were obtained up to July 2013 by linkage with the Dutch Central Bureau of Genealogy. In The Netherlands, the law requires that GP and hospital records must be kept throughout a patient’s lifetime and for at least 15 years after their death. Detailed data on medical history, smoking, and established cardiovascular risk factors, both at diagnosis of HL and at diagnosis of HF (or cutoff date for controls), could therefore be collected for all patients from GP questionnaires in 2004 (for 94% of the cohort) and in 2013 (for 83% of the cohort), and from hospital records. In addition, a questionnaire on established cardiovascular risk factors and lifestyle was mailed to all patients in the cohort still alive in 2013 (n = 475; response rate: 70%), resulting in questionnaire data for 45 cases and 186 controls. Further details are given elsewhere. [2,10,20] This study was approved by the ethics review board of The Netherlands Cancer Institute. Retrospective Radiation Dosimetry Methods The radiation dosimetry method is described elsewhere. [3] Radiotherapy regimens were reconstructed using the Eclipse treatment planning system (Version 13.0.28; Varian Medical System, Palo Alto, CA). Two substitute computed tomography (CT) data sets (for men and women, respectively) were chosen from a library of 50 to be representative regarding average anatomy and estimated heart dose from a standardized mantle field. The heart and substructures of the heart were outlined as per published guidelines. [21] Treatment planning was performed for each individual patient using variables such as beam arrangement, energy, prescribed dose, field size, and field shielding, which were extracted from each patient’s original radiotherapy prescription charts and simulation films. Standard mantle fields, as well as paraaortic and splenic fields for patients who received such treatments, were created. The dose distributions from all fields were then summed, and cardiac doses were extracted. Mean heart dose (MHD) and mean left ventricular dose (MLVD) were calculated and converted into equivalent dose in 2-Gy fractions (EQD2) and biologically effective dose. [22,23] When fraction size varied during treatment, EQD2 and biologically effective dose were calculated separately for each fraction size before summation (supplemental Text 2). V20 and V30 (volume of structure receiving at least 20 or 30 Gy, respectively) were calculated for the heart and left ventricle and expressed in percentages. For patients with neither radiation chart nor simulation film (22 cases and 103 controls), MHD and MLVD were estimated, for each combination of hospital, treatment period, sex, and radiation field, as the average value for patients with either a chart or a film. Statistical Analysis Rate ratios (RRs) for HF for different levels of each factor were estimated using logistic regression, conditional on sets of individual cases and their matched controls. Confidence intervals (CIs) for factors with 2 levels were based on the Wald method. CIs for factors with >2 levels used the amount of information in each category, including the reference category. [24] Multiple regression was used to control for confounding and to assess the combined effect of radiation dose and other factors. The dose-response was estimated by modeling HF rate as Κ m (1 + βd), where d is radiation dose, Κ m is a constant specific to each matched set, and β is the increase in excess HF relative rate per unit increase in dose. Nonlinearity was evaluated by including an exponential term: Κ m [1 + βd·exp(δd)], and goodness of fit was assessed by likelihood ratio tests. Approximate cumulative risks of HF for categories of radiation dose were estimated from the HF RRs together with the cumulative risk of HF for the entire cohort (supplemental Text 3). Significance tests were 2-sided, and P ≤ .05 was taken to indicate statistical significance. Analyses were performed using STATA statistical software version 13.0 (STATAcorp 2013) [25] and Epicure version 1.8 (Hirosoft International). [26] Results Results In the 91 cases, HF occurred after a median interval of 20.6 years (interquartile range [IQR]: 13.7-25.2) ( Table 1 ). The majority of HF diagnoses were grade 2 (44%) or 3 (43%) (supplemental Table 1). The median age at HL diagnosis was 28.3 years (IQR: 21.9-37.7). Fifty-seven percent of the HF cases had died by the end of follow-up, with median time from HF to death of 3.6 years (IQR: 0.2-5.6). Radiotherapy, Chemotherapy, and Splenectomy For patients given mediastinal radiotherapy (cases: 90.1%; controls: 82.3%; P difference = .078), the average prescribed dose was 30.5 Gy (cases: 32.7 Gy; controls: 29.8 Gy; P difference = .088), whereas the average MHD was lower at 20.9 Gy (cases: 23.2 Gy; controls: 20.1 Gy; P difference = .009), and the average MLVD was even lower, at 14.5 Gy (cases: 16.7 Gy; controls: 13.8 Gy; P difference = .003). MHD and MLVD were strongly correlated (correlation coefficient: 0.93; supplemental Figure 1). For all 3 measures of dose, HF rate increased with increasing dose (prescribed mediastinal dose: P trend = .027; MHD: P trend = .002; MVLD: P trend < .001; Table 2 ). For MHD, the dose-response relationship was nonlinear ( P curvature = .029; supplemental Table 2), with little evidence of an increase for MHDs in the range 1 to 25 Gy, but increasing steeply with MHDs of ≥25 Gy (Figure 1A). For MLVD, there was no significant departure from linearity ( P curvature = .09) (Figure 1B). HF rate also increased with increasing V30 and V20 for the left ventricle ( Table 2 ). When the analysis was repeated omitting patients with neither radiation chart nor simulation film, results were similar (supplemental Table 3; supplemental Figure 2). Figure 1. Relationship between HF rate and cardiac dose. RRs for HF by MHD (A) and by MLVD (B) in Gy compared with no radiation exposure. RRs are calculated conditionally on matched sets after adjustment for anthracycline-based chemotherapy (yes/no). Squares indicate anthracycline-adjusted estimates for the following dose categories: MHD: 0 Gy, 1-20 Gy, 20-25 Gy, 26-30 Gy, ≥31 Gy; MLVD: 0 Gy, 1-15 Gy, 16-20 Gy, 21-25 Gy, ≥26 Gy, and are plotted at the median dose in each category (0 Gy, 16 Gy, 23 Gy, 28 Gy, and 33 Gy for MHD; 0 Gy, 13 Gy, 19 Gy, 23 Gy, and 30 Gy for MLVD). Vertical lines are 95% CIs. For MHD, there was a statistically significant linear dose-response relationship ( P = .006) and allowing for curvature improved the fit significantly ( P ≤ .001). For MLVD, there was a statistically significant linear dose-response relationship ( P = .004), and allowing for curvature did not significantly improve the fit ( P = .09). Further details are given in supplemental Table 2. Figure 1. Chemotherapy without anthracyclines was not significantly associated with HF (RR: 0.93; 95% CI: 0.63-1.37). However, for anthracycline-based chemotherapy, the HF rate was increased by a factor of nearly 3 (RR: 2.83; 95% CI: 1.43-5.59). Among those who received anthracyclines, HF rates were similar for those with cumulative doses <280 mg/m 2 and those with cumulative doses ≥280 mg/m 2 ( P difference = .97). HF rates were similar among those with and without splenectomy (RR: 0.85; 95% CI: 0.49-1.45). Among those who received mediastinal RT as primary therapy, HF rates did not differ significantly between those who received anthracyclines only as primary therapy and those who received anthracyclines only as salvage therapy (RR: 2.30; 95% CI 1.02-5.21 versus RR: 3.85; 95% CI 1.59-9.36; P difference = .4) ( Table 2 ). Only 2 patients received anthracyclines for primary as well as salvage treatment; both were cases. Figure 2. Approximate cumulative risks of HF by MLVD and whether treatment with anthracyclines was given. Modeled cumulative risk of HF as first cardiac event among 5-year survivors of HL by time since initial HL treatment of categories of MLVD (Gy). Lines indicate estimated cumulative incidences for dose categories (0-15 Gy, 16-20 Gy, and ≥21 Gy) with and without anthracycline exposure. Cumulative risks were calculated with other heart disease or death as a competing risk. Further details are given in supplemental Text 3. Figure 2. HF RRs in individuals with MHD or MLVD ≥26 Gy relative to 0 to 25 Gy did not differ significantly according to use of anthracycline chemotherapy ( P interaction = .45 for MHD, .09 for MLVD) or with splenectomy ( P interaction = .71 for MHD, .62 for MLVD). Classical Cardiovascular Disease Risk Factors None of the known classical cardiovascular disease risk factors differed significantly between HF cases and matched controls. Diagnosis of diabetes mellitus between HL and cutoff was associated with a nonsignificantly increased HF rate (RR: 1.59; 95% CI 0.63-4.05) compared with those not diagnosed with the disease (supplemental Table 4). When taking into account all risk factors that were diagnosed before the end of follow-up, instead of only those diagnosed prior to HF/cutoff date, hypertension (RR: 1.80; 95% CI: 0.73-4.44), diabetes mellitus (RR: 1.83; 95% CI: 0.96-3.47), and having at least 1 risk factor (RR: 1.53; 95% CI: 0.93-2.52) were all associated with nonsignificantly increased HF rates, whereas patients with a high level of physical activity (≥3 hours per week) at time of follow-up had a nonsignificantly lower HF rate than those who were not (<1 hour per week) (RR: 0.59; 95% CI: 0.32-1.10). HF RRs in individuals with MHDs or MLVDs ≥26 Gy relative to 0-25 Gy did not differ significantly according to presence of at least 1 cardiovascular risk factor, sex, age at HL diagnosis, or time since HL diagnosis (all P interaction values >.50; supplemental Table 5A-B). Estimated HF Rates and Cumulative Risks Our analyses showed that the only factors significantly associated with HF rate were radiation dose and whether anthracyclines were used, with no significant multiplicative interaction between the 2. Summary HF rates were therefore estimated based on 3 broad categories of MHD or MLVD and whether anthracyclines had been given, with the assumption that the multiplicative increase in HF rate with anthracyclines did not differ according to MHD or MLVD ( Table 3 ). Based on these estimates, approximate cumulative incidence curves for HF were derived for patients in these 6 groups (Figure 2). In patients treated without anthracyclines, 25-year cumulative risks of HF following MLVDs of 0-15 Gy, 16-20 Gy, and ≥21 Gy were 4.4%, 6.2%, and 13.3%, whereas in patients treated with anthracyclines, the 25-year cumulative risks were 11.2%, 15.9%, and 32.9%, respectively. For patients treated without anthracyclines, 35-year cumulative risks of HF following MLVDs of 0-15 Gy, 16-20 Gy, and ≥21 Gy were 7.2%, 10.2%, and 21.8%, respectively. Patients treated with anthracyclines have not yet been followed long enough to estimate risks beyond 25 years. Discussion Discussion In this study, we have examined, for the first time, dose-response relationships for HF rate based on cardiac radiation exposure in 5-year survivors of adolescent or adult HL. We conducted analyses based on estimates of both MHD and MLVD derived from individual radiotherapy plans. Both measures of dose suggested that there is little increase in HF risk for lower doses, up to 25 Gy MHD or up to 15 Gy MLVD, but that HF rates increase rapidly at higher doses. We also found that treatment with anthracyclines increase the HF rate, approximately threefold, irrespective of cardiac radiation exposure. A radiation dose-response relationship for self-reported HF has previously been observed in the Childhood Cancer Survivor Study (CCSS). [11,27] In that cohort, HF risk was increased by factors of 1.6, 3.1, and 10.5 following MHDs of 5 to 14, 15 to 34, and ≥35 Gy, respectively, compared with patients who did not have any cardiac radiation exposure. [27] These proportional increases are somewhat higher than those in our present study, possibly due to the patients' younger ages at cancer treatment: 82.4% of the CCSS cohort were aged <15 years at cancer diagnosis compared with only 3.5% in the present study. A clearly increasing HF risk with increasing anthracycline dose was also seen in the CCSS study, and risk was increased by factors of 2.1, 3.7, and 10.5 for cumulative anthracycline doses of <100, 100 to 249, and ≥250 mg/m 2 compared with those not exposed to anthracyclines. In the CCSS, the therapy-associated risk of HF was potentiated by the presence of cardiovascular risk factors, such as hypertension and diabetes mellitus, and by lack of physical activity. [28,29] In our current study, no such associations were apparent. However, the CCSS studies were based on patient-reported outcomes of cardiovascular risk factors, and probably also included risk factors diagnosed at the same time as or even after the cardiovascular disease of interest, possibly resulting in an overestimation of the strength of the associations. In contrast, our conservative approach of including only risk factors diagnosed prior to HF may have resulted in an underestimation. Despite this, it seems likely that risk factor control in high-risk patients who received cardiotoxic treatment may be important in risk-reduction strategies for cardiovascular diseases after HL treatment. The strengths of our study include that it was performed in a complete, multi-institutional population with long-term, detailed follow-up, including information from cardiologists and GPs. The outcome (HF) was GP reported and, if necessary, confirmed by cardiologists, which is an important advantage in comparison with studies relying on patient-reported outcomes or registry data. [6,30-32] Instead of using prescribed radiation dose, radiation-related HF risks were estimated using individual patient dosimetric parameters such as MHD and MLVD, which were converted into EQD2 and adjusted for dose distribution and varying fractionation schedules. Where available, individual cumulative anthracycline doses were analyzed, rather than protocol prescription chemotherapy doses. A limitation of our study is that a total of only 90 patients were prescribed anthracyclines, all but 11 of whom also received mediastinal radiotherapy. Furthermore, the range of cumulative anthracycline doses was limited, with most patients being prescribed either 280 or 300 mg/m 2 doxorubicin equivalent, and follow-up for patients who received anthracyclines was shorter than for patients treated with radiotherapy alone. Therefore, our ability to study the interaction between radiation exposure of the heart and anthracycline exposure was limited, and we were unable to estimate a separate dose-response relationship for anthracyclines. The results indicate that salvage therapy with anthracyclines following primary treatment with mediastinal radiotherapy would be more harmful than primary treatment with mediastinal radiotherapy and anthracyclines. However, the small number of patients treated with anthracyclines makes it impossible to draw any firm conclusions regarding the possible effect of the time elapsed between exposure of the heart to anthracyclines and to radiation. It is hypothesized that this increased risk is associated with an increased radiation dose during primary treatment, and perhaps an increased anthracycline dose for salvage treatment, compared with the doses for combined primary treatment. Further research may indicate whether treatment sequence may influence HF risk, which may contribute to risk prediction models of cardiovascular disease in survivors who have been treated in the past. Detailed radiotherapy information was collected for each patient, but radiotherapy was applied before the era of CT-based treatment planning. Dose reconstructions were therefore carried out using representative CT datasets, and these cannot take into account patient-specific variations in heart size, shape, and position. For a proportion of patients, both the radiotherapy chart and the simulation film were missing, and the MHD and MLVD were estimated rather than reconstructed (see “Methods”). However, a sensitivity analysis including only patients for whom MHD and MLVD were reconstructed showed similar results (supplemental Table 3; supplemental Figure 2). Our study includes only cases in which HF was the first cardiovascular diagnosis, in order to eliminate the effects of other cardiovascular diseases such as CHD or VHD on the risk of developing HF. However, in a previous study, [9] we showed that HF occurred frequently subsequent to CHD or VHD, rather than as a first event. Additional research is needed to study the influence of previous cardiovascular diseases and to identify risk factors for developing multiple cardiovascular diseases. For patients treated today, MHDs and MLVDs will usually be well below the average values of 20.9 Gy and 14.5 Gy reported in this study, due to reductions in both treatment volumes and prescribed doses. Involved field radiotherapy has been reported to give a median MHD of 17.2 Gy for prescribed doses of 35 Gy and involved node radiotherapy leads to even lower doses (median MHDs of 7.7-12.0 Gy for prescribed doses of 36 Gy). [33-35] Also, anthracycline doses are nowadays frequently lower than the doses received by the majority of patients in our study. Therefore, patients treated today are likely to be at a substantially lower risk of treatment-related HF than the patients included in this study. Studies in larger populations of HL survivors treated more recently would be helpful in characterizing the risks from modern treatments more precisely. More accurate dosimetry based on a patient’s individual CT scan may also help to determine whether MHD, MLVD, or another dosimetric parameter is the best measure to predict radiation-related HF risk. However, in the absence of more precise measures, these dose-response relationships for MHD and MLVD can be used to estimate HF risk both in patients treated today and in survivors treated in more recent decades. In conclusion, cardiac radiation exposure and treatment with anthracyclines are important risk factors for the development of HF in HL survivors. Our findings are important for clinicians to provide information regarding risks of HF before treatment, during radiation treatment planning, and during long-term follow-up of HL survivors, including patients treated in the past. ",
				"clientUrl": "/viewarticle/878632",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 1545,
				"leadConcept": "Hodgkin Lymphoma",
				"concept": ["Chemotherapy", "Heart Failure (HF)", "Radiation Therapy", "Anthracyclines", "Cancer Treatment Related Toxicity", "Cardiotoxicity", "Pharmacologic Adverse Events", "Cancer Survivor"],
				"leadSpecialtyId": 7,
				"leadSpecialty": "Hematology-Oncology",
				"allSpecialties": ["Hematology-Oncology", "Cardiology", "Internal Medicine"],
				"contentGroup": "Journal Article",
				"origContentType": "Journal Article",
				"contentType": ["Journal Article"],
				"description": "In patients with Hodgkin lymphoma, the risk for heart failure increases with increasing radiation dose to the heart and independently with anthracycline treatment.",
				"legacyID": 878632,
				"pubDisplay": "Blood",
				"siteOn": 2003,
				"title": "Risk of Heart Failure in Survivors of Hodgkin Lymphoma: Effects of Cardiac Exposure to Radiation and Anthracyclines",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/Blood-thumb.jpg"],
				"publicationDate": 1492664400000,
				"postingDate": 1492664400000,
				"_version_": 1573508892299624448,
				"last_index_date": 1500615017233
			}, {
				"id": "pdctm_0901c79180a73889",
				"activeCME": 1,
				"activityExpirationDate": 1508475600000,
				"authors": ["Kazuhiko Kakihana", " Yuki Fujioka", " Wataru Suda", " Yuho Najima", " Go Kuwata", " Satoshi Sasajima", " Iyo Mimura", " Hidetoshi Morita", " Daisuke Sugiyama", " Hiroyoshi Nishikawa", " Masahira Hattori", " Yutaro Hino", " Shuntaro Ikegawa", " Keita Yamamoto", " Takashi Toya", " Noriko Doki", " Koichi Koizumi", " Kenya Honda", " Kazuteru Ohashi"],
				"body": "Abstract and Introduction Abstract and Introduction Abstract Increasing evidence indicates that the gut microbiota is closely associated with acute graft-versus-host disease (aGVHD) in stem cell transplantation (SCT). Fecal microbiota transplantation (FMT) could represent an alternative treatment option for aGVHD. However, FMT for SCT patients carries a potential risk of infection by infused microbiota because of the severely immunosuppressed status. We therefore conducted a pilot study to evaluate the safety of FMT in SCT. A total of 4 patients with steroid-resistant (n = 3) or steroid-dependent gut aGVHD (n = 1) received FMT. No severe adverse events attributed to FMT were observed. All patients responded to FMT, with 3 complete responses and 1 partial response. Temporal dynamics of microbiota seemed to be linked to the gut condition of patients and peripheral effector regulatory T cells also increased during response to FMT. FMT was safely performed in our patients and might offer a novel therapeutic option for aGVHD. This trial was registered at the University Hospital Medical Information Network (?recptno=R000017575) as #UMIN000015115. ( Blood . 2016;128(16):2083-2088) Introduction Although allogeneic stem cell transplantation (allo-SCT) is a curative treatment of various hematological diseases, acute graft-versus-host disease (aGVHD) represents a major cause of morbidity and mortality. Glucocorticoids are used as the first-line therapy for aGVHD, but only about half of patients respond [1] and no second-line treatment has yet been established. The gut microbiota and its metabolites have been reported to play pivotal roles in intestinal inflammation and the immune system. [2,3] Also in allo-SCT, increasing evidence indicates that the gut microbiota is closely associated with aGVHD. [4-10] Fecal microbiota transplantation (FMT) refers to infusion of a fecal suspension from a healthy donor into the gastrointestinal tract of a patient to restore a healthy microbiota and cure disease. Manipulation of the intestinal microbiota by FMT may influence the immune system and improve immune-mediated enteritis such as gut aGVHD. However, FMT carries a potential risk of infection by the infused microbiota for SCT recipients. We therefore conducted this pilot study to evaluate the safety of FMT for treating steroid-resistant or steroid-dependent gut aGVHD. Study Design Study Design Four patients with gut aGVHD (steroid-resistant, n = 3; steroid-dependent, n = 1) underwent this pilot study ( Table 1 [11] ). The patient’s spouse or a relative who passed the screening for transmissible diseases could be a candidate for FMT donor. The maximum number of treatments was 2 and all adverse events (AEs) that first arose or progressed within 1 week after each infusion were evaluated in terms of the safety of FMT. Response to FMT was evaluated 28 days after the final FMT (cases 1-3) or at the time of maximum response (case 4). Microbial analyses were performed using 16 ribosomal RNA gene sequencing. For immunological assays, peripheral mononuclear cells were isolated before and after FMT, and analyzed by flow cytometry (detailed information about the study protocol is provided in supplemental Methods, available on the Blood Web site). Results and Discussion Results and Discussion The underlying disease in all patients was acute myeloid leukemia ( Table 1 ). Case 3 was diagnosed with late-onset aGVHD. The first FMT was performed at a median of 92 days after SCT (60-174 days). All patients received the first FMT while receiving methylprednisolone (mPSL) at ≥1 mg/kg and showed comorbid infectious complications at the start of FMT ( Table 1 ). Median feces volume was 126 g (34-307 g) and the final volume of the fecal suspension was 180 to 230 mL. Fecal suspensions were administered over 4 to 8 minutes via a nasoduodenal tube. FMTs were performed at a median of 6 hours (2.75-9 hours) after feces collection (supplemental Table 1). All AEs that were obviously related to FMT were mild and transient (underlined in Table 1 ). Case 4 developed AEs such as hypoxia, paroxysmal atrial fibrillation (PAF), lower gastrointestinal bleeding, cholestatic liver damage, and transplant-associated thrombotic microangiopathy. In addition, case 4 also developed fever 2 days after the second FMT. The possibility of an association between FMT and these AEs could not be completely ruled out. Indeed, gastrointestinal bleeding and PAF may be induced by FMT-related complications such as mechanical mucosal damage by tube insertion, or mental discomfort. However, the patient presented with fresh blood in the stool, not tarry stool, and PAF occurred 4 days after the second FMT. Thus, it seemed more plausible that various underlying conditions, such as poor performance status, hypoalbuminemia (≤2 g/dL), severe cytopenias, use of various drugs, or Epstein-Barr virus reactivation, contributed to the development of these AEs. A febrile episode after the second FMT resolved within 1 day and no pathogens were detected. These results thus suggest that normal microbiota [12,13] might be administered safely in SCT patients (for the detailed clinical course of each patient, please see supplemental Results and discussion). With regard to response, FMT was effective in all patients, with complete response in 3 patients and partial response in 1 case, and improvement of gastrointestinal symptoms was observed within several days in the steroid-resistant cases. Moreover, the steroid dose was able to be successfully reduced by more than half (mean, 69% reduction) compared with that before FMT in cases 1 to 3 (supplemental Figure 1). Figure 1. Components of microbiota and immunological assay. (A) Temporal dynamics of the microbiota (at the genus level) and clinical course in each patient: (i) case 1, (ii) case 2, (iii) case 3, and (iv) case 4. *1: Data from the day after first FMT could not be obtained because of the lack of fecal sample. (B) (i) Subpopulation of Tregs. Tregs can be dissected into 3 subpopulations by expression levels of FoxP3, CD45RA. FoxP3 lo CD45RA + cells (fraction 1), designated as naive Tregs, which differentiate into eTregs under antigenic stimulation; FoxP3 hi CD45RA − cells (fraction 2), designated eTregs, which are terminally differentiated and highly suppressive; and FoxP3 lo CD45RA − non-Tregs (fraction 3), which do not possess suppressive activity, but secrete proinflammatory cytokines. 20 (ii) The absolute number of eTregs (red lines) and the eTreg/CD8 + T-cell ratio (green lines) in peripheral blood of each patient. CAZ, ceftazidime; CFPM, cefepime; FK, tacrolimus; Fr, fraction; LVFX, levofloxacin; MEPM, meropenem; PSL, prednisolone; ST, sulfamethoxazole/trimethoprim; TAZ/PIPC, tazobactam/piperacillin; TEIC, teicoplanin; VCM, vancomycin. Figure 1. Clinical courses and temporal microbiota dynamics in each patient are shown in Figure 1A. Case 1 showed favorable recovery from gastrointestinal symptoms after FMT and the final microbiota composition was dominated by Lactobacillus and Bacteroides (Figure 1Ai). In case 2, improvement of gastrointestinal symptoms after the first FMT was transient and minimal, but gradually improved after the second FMT. Streptococcus decreased after FMT and this became more prominent after the second FMT. The final microbiota composition was dominated by Bacteroides , Lactobacillus , and Bifidobacterium (Figure 1Aii). In case 3, gastrointestinal symptoms remitted after reescalating mPSL and were not exacerbated. The microbiota after FMT mainly comprised Bacteroides , Bifidobacterium , and Faecalibacterium , and this composition was maintained during the study period (Figure 1Aiii). In case 4, gastrointestinal symptoms gradually improved after 2 courses of FMT, but eventually flared after rapid reduction of mPSL and tacrolimus for transplant-associated thrombotic microangiopathy (13 days after the second FMT). This patient’s feces were eventually occupied by Escherichia at the time of recurrence of gut aGVHD (Figure 1Aiv). Temporal microbiota dynamics thus seemed to be linked to the gut condition of the patient. Beneficial bacteria such as Bacteroides , [5] Lactobacillus , [8] Bifidobacterium , and Faecalibacterium [14] were dominant in cases 1 to 3, [15] whereas Escherichia , which has been strongly correlated with GVHD in a mouse model, [9] was increased at the recurrence of aGVHD in case 4. The number of operational taxonomic units and diversity of the intestinal microbiota did not fully recover after FMT, even with apparent clinical response (supplemental Figure 2). These results indicate that full recovery of the microbiota might not be indispensable for response to FMT. Indeed, in most SCT patients, the operational taxonomic unit count was very low compared with that in healthy volunteers, even in patients without aGVHD (K. Kakihana and N.D., unpublished data). Although antibiotics had to be resumed in cases 1 and 2, these patients responded to FMT and did not show exacerbation after restarting antibiotics (Figure 1A). Reduced activity against intestinal anaerobic bacteria of the antibiotics used might have contributed to conserve the response to FMT. [16] Furthermore, FMT could be performed without exacerbating comorbid infections in any patients. FMT thus may not negatively affect immunity against infection. Regulatory T cells (Tregs) have been reported as a prognostic cellular biomarker for aGVHD [17,18] and the number of peripheral effector Tregs (eTregs; Figure 1Bi), [19] which have been reported as terminally differentiated and highly suppressive, [20] increased during responding to FMT. The eTreg/CD8 + T-cell ratio showed a similar trend in most cases (Figure 1Bii). Similar results were obtained for overall FoxP3 + CD4 + T cells (supplemental Figure 3). Although somewhat conflicting, our results indicate that FMT might shift the systemic allogeneic immune response to an anti-inflammatory state by changing the intestinal microbiota and might be effective against other forms of aGVHD. Indeed, the intestinal microbiota has been reported to be associated with the entire spectrum of aGVHD. [4,5,10] In summary, FMT was safely performed in SCT patients and offers promise as a potential treatment option for aGVHD. Further evaluation to confirm the safety and efficacy of FMT for aGVHD is warranted. Despite the very small number of patients, our results are highly suggestive for elucidating the associations between microbiota and human immunity. ",
				"clientUrl": "/viewarticle/870174",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 3032536,
				"leadConcept": "Stem Cell Research and Therapy",
				"concept": ["Acute Myeloblastic Leukemia", "Corticosteroids", "Graft Versus Host Disease", "Infection in Immunocompromised Host", "Acute Leukemia", "Fecal Transplant", "Microbiome"],
				"leadSpecialtyId": 7,
				"leadSpecialty": "Hematology-Oncology",
				"allSpecialties": ["Hematology-Oncology", "Gastroenterology", "Transplantation"],
				"contentGroup": "Journal Article",
				"origContentType": "Journal Article",
				"contentType": ["Journal Article"],
				"description": "Fecal microbiota transplantation appears safe and effective for acute graft-versus-host disease in stem cell transplantation, although further research is needed.",
				"legacyID": 870174,
				"pubDisplay": "Blood",
				"siteOn": 2003,
				"title": "Fecal Microbiota Transplantation for Patients With Steroid-Resistant Acute Graft-versus-Host Disease of the Gut",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/Blood-thumb.jpg"],
				"publicationDate": 1476939600000,
				"postingDate": 1476939600000,
				"_version_": 1573508881382899712,
				"last_index_date": 1500615006818
			}, {
				"id": "pdctm_0901c79180b948fd",
				"activeCME": 1,
				"activityExpirationDate": 1529038800000,
				"authors": ["Paola Guglielmelli", " Annalisa Pacilli", " Giada Rotunno", " Elisa Rumi", " Vittorio Rosti", " Federica Delaini", " Margherita Maffioli", " Tiziana Fanelli", " Alessandro Pancrazzi", " Daniela Pietra", " Silvia Salmoiraghi", " Carmela Mannarelli", " Annalisa Franci", " Chiara Paoli", " Alessandro Rambaldi", " Francesco Passamonti", " Giovanni Barosi", " Tiziano Barbui", " Mario Cazzola", " Alessandro M. Vannucchi"],
				"body": "Abstract and Introduction Abstract and Introduction Abstract The 2016 revision of the World Health Organization (WHO) classification of myeloproliferative neoplasms defines 2 stages of primary myelofibrosis (PMF): prefibrotic/early (pre-PMF) and overt fibrotic (overt PMF) phase. In this work, we studied the clinical and molecular features of patients belonging to these categories of PMF. The diagnosis of 661 PMF patients with a bone marrow biopsy at presentation was revised according to modern criteria; clinical information and annotation of somatic mutations in both driver and selected nondriver myeloid genes were available for all patients. Compared with pre-PMF, overt PMF was enriched in patients with anemia, thrombocytopenia, leukopenia, higher blast count, symptoms, large splenomegaly, and unfavorable karyotype. The different types of driver mutations were similarly distributed between the 2 categories, whereas selected mutations comprising the high mutation risk (HMR) category (any mutations in ASXL1 , SRSF2 , IDH1/2 , EZH2 ) were more represented in overt PMF. More patients with overt PMF were in higher International Prognostic Scoring System risk categories at diagnosis, and the frequency increased during follow-up, suggesting greater propensity to disease progression compared with pre-PMF. Median survival was significantly shortened in overt PMF (7.2 vs 17.6 years), with triple negativity for driver mutations and presence of HMR mutations representing independent predictors of unfavorable outcome. The findings of this “real-life” study indicate that adherence to 2016 WHO criteria allows for identification of 2 distinct categories of patients with PMF where increased grades of fibrosis are associated with more pronounced disease manifestations, adverse mutation profile, and worse outcome, overall suggesting they might represent a phenotypic continuum. Introduction The revised 2016 World Health Organization (WHO) classification of myeloid neoplasms dictated distinct criteria for prefibrotic/early primary myelofibrosis (pre-PMF) and overt fibrotic PMF (overt PMF). [1] Criteria mainly rely on bone marrow (BM) morphology (with megakaryocyte proliferation and atypia in both diseases, and increased age-adjusted cellularity with granulocyte proliferation and often decreased erythropoiesis in pre-PMF) and fibrosis grade (grade 0-1 indicates pre-PMF and grade 2-3 overt PMF); accordingly, grade 1 fibrosis is included in the pre-PMF category. This contrasts with the 2008 WHO classification where criteria did not explicitly define the grade of fibrosis, [2] thereby resulting in variable proportions of patients with initial fibrosis included among overt PMF. Finally, peripheral blood leukoerythroblastosis constitutes a minor diagnostic criterion of overt PMF in the 2016 WHO classification, whereas anemia, leukocytosis, increased lactate dehydrogenase (LDH) and palpable splenomegaly may be present in both diseases. [1] The existence of pre-PMF as a separate entity and its differentiation from strictly WHO-defined essential thrombocythemia (ET) has been debated for the last several years, [3] sometimes with contrasting results. [4-7] A low interobserver concordance in applying the WHO-based histopathology criteria for pre-PMF was questioned by some experts, [6-8] whereas others clearly delineated the reproducibility of those criteria and the clinical relevance of adopting the diagnostic concept of pre-PMF. [9-11] In the largest multicenter study, which included 1104 patients with a diagnosis of ET who underwent revision of their diagnostic biopsies (resulting in 16% of them to be reclassified as pre-PMF), significant differences were found in the occurrence of bleeding, [12] rate of death, progression to overt myelofibrosis, and transformation to leukemia, signifying the relevance of differentiating pre-PMF from ET. [12] In this study, we aimed at assessing, in a real-life setting, the importance of distinguishing pre-PMF and overt PMF, as delineated by modern WHO criteria, concerning the clinical and hematologic presentation, the molecular profile, and the outcome. The data shown here indicate that pre-PMF and overt PMF are distinct diseases in terms of presentation and outcome, thereby reinforcing the appropriateness of making such a distinction in the clinical practice; at the same time, current findings support the concept that pre-PMF and overt PMF are aligned along a continuum where higher grades of fibrosis are associated with more advanced forms, more complex genetic background, and less favorable outcome. Materials and Methods Materials and Methods Study Population Clinical and hematologic information of 787 patients with a diagnosis of PMF was collected from 5 tertiary Italian centers (Florence, 2 in Pavia, Bergamo, Varese) belonging to the cooperative group Associazione Italiana per la Ricerca sul Cancro (AIRC) Gruppo Italiano Malattie Mieloproliferative (AGIMM). The study was performed in accordance with the Declaration of Helsinki after approval by ethical committees; informed consent was obtained. Histopathology, hematologic, and clinical data were reviewed, and diagnoses were attributed to pre-PMF and overt PMF based on the revised 2016 WHO criteria. Histopathology analysis was performed locally, blinded of patient’s history and clinical information except for sex and age. A total of 661 patients (84%) with adequate follow-up and data were finally included. Clinical and hematologic information were coincident (±6 months) with the diagnostic biopsy. Mutation Analysis Analysis was performed on DNA from peripheral blood granulocytes collected at diagnosis or within 1 year. JAK2 V617F mutation was assessed by real-time quantitative polymerase chain reaction (PCR); for MPL mutations, high-resolution melting analysis and bidirectional Sanger sequencing were used. MPL 515x indicates any mutation at codon 515. [13] Calreticulin ( CALR ) mutations were identified by capillary electrophoresis and bidirectional sequencing, and classified as type 1/type 1-like or type 2/type 2-like. [14,15] Patients lacking mutations in the 3 driver genes were defined as “triple negative” (TN). A next-generation sequencing (NGS) approach with the PGM Ion Torrent platform was used to detect mutations across the entire coding region of EZH2 and ASXL1 , and mutation hotspots for IDH1 , IDH2 , and SRSF2 . A high mutation risk (HMR) and low mutation risk (LMR) status was defined, respectively, by the presence of at least 1 mutated gene or the absence of any mutation. [16,17] In case of variants not previously reported, only those considered potentially damaging by Polyphen and the SIFT algorithm () were included in the database. Genotyping for driver mutations was performed locally, whereas analysis of HMR mutations was centralized (Florence). Statistical Analysis Numerical variables were summarized by their median and range, and categorical variables by count and relative frequency (percentage). Patient characteristics were compared with the χ 2 test or the Fisher exact test for categorical variables. Differences in the distribution of continuous variables between categories were analyzed by Mann-Whitney (2 groups) or Kruskal-Wallis (3 or more groups) tests. The cumulative incidence of anemia, thrombocytopenia, leukocytosis, transfusion dependency, acquisition of constitutional symptoms and peripheral blood blasts, and leukemic transformation was estimated with a competing risk approach. The cumulative probability of overall survival (OS) and leukemia free-survival (LFS) was estimated using the Kaplan-Meier method. Patients undergoing stem cell transplantation were censored at the time of the procedure. Differences in OS between the groups were compared by a log-rank test in univariate analysis. Multivariate analysis was carried out by Cox regression. Cox proportional hazard models were used to calculate hazard ratio (HR) and the 95% confidence interval (95% CI). A P < .05 was considered statistically significant. The IBM Statistical Package for Social Sciences (SPSS) statistics v23 was used. Results Results Clinical, Hematologic, and Molecular Characteristics of Study Population This study included 661 patients with PMF, of whom 278 (42%) were classified as pre-PMF and 383 (58%) as overt PMF according to the 2016 WHO criteria. A total of 201 patients (30.4%) previously classified as primary-MF with fibrosis grade 1 according to the WHO 2008 criteria were now included in the category of pre-PMF, whereas no patients were moved from prefibrotic-PMF to overt PMF. The main clinical and hematologic characteristics are reported in Table 1 , and differences were noted. Compared with overt PMF, patients with pre-PMF were more frequently female (44% vs 35%; P = .013), younger (median, 57 years vs 64 years; P < .0001), and had higher hemoglobin ( P < .0001), leukocyte ( P = .009), and platelet counts ( P < .0001); accordingly, patients with anemia and thrombocytopenia, 2 adverse risk factors in the International Prognostic Scoring System (IPSS)/Dynamic International Prognostic Scoring System (DIPSS) (anemia) and DIPSS-Plus (anemia and thrombocytopenia) prognostic scores, [18-20] were enriched in overt PMF. In detail, 13.3% and 6.8% of patients with pre-PMF were anemic and thrombocytopenic, respectively, compared with 35.5% and 17.5% of overt PMF ( P < .0001 for both). The percentage of patients with leukocytosis (>25 × 10 9 /L) was similar in the 2 groups, whereas patients with leukocytes <4 × 10 9 /L (an adverse risk factor in the Lille score [21] ) were more frequent in overt PMF (14.9% vs 3.6% in pre-PMF; P < .0001). Peripheral blood blasts ≥1% were found in 11.9% of pre-PMF and 25.8% overt PMF ( P < .0001). Although most patients in both cohorts displayed abnormal LDH value, the median LDH level was significantly higher in overt PMF (669 U/L vs 388 U/L in pre-PMF; P < .0001). Patients with overt PMF were more frequently symptomatic (33.7% vs 20.5%) and had larger spleen (>10 cm palpable from the costal margin; 24.0% vs 10.4%) than patients with pre-PMF ( P < .0001 for all contrasts). Cytogenetic information was available in 50.2% of the entire series, 54% of pre-PMF, and 49% overt PMF patients. An abnormal karyotype was twice more frequent in overt PMF (38% vs 18%; P < .0001); the unfavorable karyotype category [20] ( Table 1 ) was also more represented in overt PMF (12.0% vs 4.0%; P = .006). According to the IPSS criteria, patients with pre-PMF were included largely in the lower-risk categories (74.8%) whereas most patients with overt PMF were in the higher-risk categories (48.0%; P < .0001). We then analyzed separately patients with pre-PMF and fibrosis grade 0 or 1 and patients with overt MF, corresponding to 8.3%, 33.7%, and 57.9% of the series (supplemental Table 1, see supplemental Data available at the Blood Web site). Pre-PMF patients with absent fibrosis differed from those with fibrosis grade 1 for being more female, of younger age, with higher hemoglobin, and a prevalence of IPSS lower-risk category. Conversely, patients with grade 1 fibrosis had higher leukocytes and platelets, less common anemia, splenomegaly, symptoms, blasts, cytogenetic abnormalities, and were in lower IPSS risk categories than overt fibrosis. Similar findings were detected when comparing patients with no fibrosis vs any grade of fibrosis (supplemental Table 1). Molecular Characteristics of Study Population The 3 driver mutated genes ( JAK2 V617F, MPL W515x, and CALR ) were similarly distributed in the 2 cohorts ( Table 2 ). JAK2 V617F mutation was found in 67.2% of pre-PMF and 58.2% of overt PMF, CALR type 1 and type 2 in 12.2% and 5.8%, and 17.8% and 4.4%, respectively, of pre-PMF and overt PMF; MPL W515x-mutated patients were 4.7% and 6.0% in the 2 cohorts. The proportion of TN patients, a prognostically negative condition, [22] was similar: 10.1% and 13.6% in pre-PMF and overt PMF. The allelic burden of the 3 driver mutations approximated 50% in both cohorts, suggesting a prevalence of homozygosity. The proportion of patients with abnormal karyotype was higher in the TN group compared with CALR mutation (26% vs 8% in pre-PMF and 46% vs 27% in overt PMF; P = .033); also, the unfavorable cytogenetics were enriched in TN patients with pre-PMF (11% vs 4% in CALR and 2% in JAK2 V617F/ MPL W515x mutation; P = .018). With regard to nondriver mutations, significantly more patients with overt PMF had mutations in ASXL1 (33.7%) and EZH2 (12.0%) compared with pre-PMF (18.0% and 3.6%; P < .0001), thereby resulting in more overt PMF patients being comprised in the HMR category (44.4% vs 27.0%; P < .0001); SRSF2 and IDH1/2 mutations were similarly represented. Also, the number of patients with ≥2 HMR-mutated genes, which is prognostically unfavorable, [17] was greater in overt PMF (13.6%) than pre-PMF (5.4%; P < .0001). Analysis of mutations according to fibrosis grade showed no difference in distribution and allelic burden of driver mutations, whereas any grade of fibrosis was associated with more ASXL1 and EZH2 mutations, more HMR-positive patients, and with ≥2 HMR mutations compared with absent fibrosis (supplemental Table 2). OS and LFS At the latest follow-up, after a median of 4.6 years and 3.1 years for pre-PMF and overt PMF, 69 patients (24.8%) and 163 patients (42.6%) had died ( P < .0001). In a competitive risk analysis model, the median (range) OS was significantly shorter in overt PMF (7.2 years [5.7-8.7 years]) compared with pre-PMF (14.7 years [7.7-21.8 years]) ( P < .0001) (Figure 1A). Diagnosis of overt PMF vs pre-PMF corresponded to a HR for reduced survival of 2.3 (95% CI, 1.8-3.1; P < .0001). For comparison, among 421 patients randomly selected from our database with revised diagnosis of ET according to 2016 WHO criteria, the median survival was 30.2 years (range, 23.7-31.2 years). Using ET patients as the reference category, the HR for OS was 2.7 (95% CI, 1.9-3.7; P < .0001) for pre-PMF and 5.9 (95% CI, 4.5-7.8; P < .0001) for overt PMF. Furthermore, compared with ET, survival was progressively shortened depending on fibrosis grade, with HR of 1.8, 2.8. 5.3, and 6.2 for fibrosis grade 0, 1, 2, and 3 (supplemental Table 3; supplemental Figure 1A). Figure 1. OS and LFS in relation to diagnosis and IPSS risk categories in study patients population. (A-B) The Kaplan-Meier estimate of OS (A) and LFS (B) in patients with pre-MF and overt PMF using competitive risk analysis for disease-related deaths. The difference between the 2 patient populations was statistically significant at P < .0001 for OS and P = .001 for LFS. For comparison, OS and LFS curves of a population of 421 WHO 2016-defined patients with ET are also shown. (C-D) The Kaplan-Meier estimate of OS according to the 4 risk categories (low, intermediate-1, intermediate-2, high risk) in which the patients with pre-PMF (C) and overt PMF (D), respectively, were stratified at diagnosis according to the IPSS criteria. Overall, the curves were significantly different at P < .0001. Figure 1. Transformation to acute leukemia was diagnosed in 72 patients (10.9%), 23 with pre-PMF (8.3%) and 49 with overt PMF (12.8%; P = .04). The rate of leukemia transformation was 5.4%, 8.9%, 13.9%, and 10.9% in fibrosis grade 0, 1, 2, and 3. LFS was shorter in overt PMF than pre-PMF (21.6 years vs 27.6 years; P < .001; HR, 2.2 [95% CI, 1.3-3.7; P < .002]) (Figure 1B). The cumulative incidence of leukemia was 7% and 11% at 5 years, and 12% and 23% at 10 years, respectively, for pre-PMF and overt PMF ( P < .0001), contrasting with 0% and 1% at 5 and 10 years, respectively, in the ET cohort ( P < .001). Compared with ET, the HR significantly increased depending on the grade of fibrosis: HR, 6.4, 12.0, 24.1, and 23.6 in fibrosis grade 0, 1, 2, and 3, respectively (supplemental Table 3; supplemental Figure 1B). Survival was predicted by the IPSS score in both pre-PMF and overt PMF (Figure 1C-D), although optimal resolution of the 4 risk categories was not achieved in all instances. In pre-PMF, curves of intermediate-1 and intermediate-2 patients did not differ ( P = .205; Figure 1C); using the low risk as the reference category, the HR for intermediate-1, intermediate-2, and the high risk category was 5.3 (95% CI, 2.4-11.8), 12.2 (95% CI, 5.0-30.1), and 34.8 (95% CI, 15.7-77.2). In overt PMF, the intermediate-2 and high-risk category were superimposed ( P = .170; Figure 1D); the HR was 2.9 (95% CI, 1.6-5.2), 7.8 (95% CI, 4.4-14.0), and 10.4 (95% CI, 5.8-19.0) for intermediate-1, intermediate-2, and the high-risk category. Considering patients with fibrosis grade 0, the IPSS score delineated differences only between the low- and high-risk category; in the case of fibrosis grade 1 and fibrosis grade >1, the intermediate-1 and intermediate-2 and the intermediate-2 and high-risk categories, respectively, did not result in statistical difference (supplemental Figure 1C-E). Impact of Molecular Characteristics on Survival and Transformation to Leukemia The impact of driver and nondriver mutations on OS is represented in Figure 2. In both pre-PMF and overt PMF, CALR type 1 mutation was the most favorable, with median survival of 27.7 years and 17.8 years, respectively (Figure 2A-B). Using this as the reference category, we calculated the HR for the other mutation categories; JAK2 V617F and MPL W515 mutations were merged because preliminary analysis did not disclose significant differences. In pre-PMF, the HR for reduced survival was 3.8 (95% CI, 1.3-10.6; P = .013) for JAK2 V617F/ MPL W515 mutation, 6.1 (95% CI, 1.6-23.3; P = .008) for CALR type 2, and 22.8 (95% CI, 7.1-73.3; P < .0001) for TN. In overt PMF, the respective HRs were 3.5 (95% CI, 4.9-7.0; P < .001), 2.6 (95% CI, 1.6-5.8; P = .040), and 5.3 (95% CI, 2.8-9.9; P < .0001). In both cohorts, the survival of patients with JAK2/MPL and CALR type 2 mutations was not statistically different. Figure 2. Impact of driver and HMR mutations on OS in study patients population. Kaplan-Meier estimates of OS in patients with a diagnosis of pre-PMF (A) and overt PMF (B) who were stratified according to their CALR type 1/type 1–like, CALR type 2/type 2–like, and JAK2 V617F/ MPL W515x mutation status. The survival curve of patients negative for the above driver mutations, that is, TN, is also shown. (C-D) The OS by Kaplan-Meier estimates in patients being stratified in a HMR (patients harboring mutation in at least 1 of ASXL1 , EZH2 , SRSF2 , IDH1 , or IDH2 ) and LMR (ie, no mutation in the above genes) category. (C-D) Pre-PMF and overt PMF, respectively. The survival curves of patients with 2 or more mutated genes of the HMR category are also shown. Figure 2. Then, we analyzed the impact of HMR mutations. The HMR category was associated with significantly shorter survival in both pre-PMF and overt PMF (Figure 2C-D). Median (range) survival was 8.3 years (3.6-13.0 years) and 4.5 years (3.3-5.7 years) in pre-PMF and overt PMF, respectively, compared with 20.2 years (13.1-27.3 years) and 11.8 years (7.0-16.6 years) for the LMR category ( P < .0001). The HR for a HMR status was 2.5 (95% CI, 1.6-4.1; P < .0001) and 2.3 (95% CI, 1.7-3.1; P < .0001) in pre-PMF and overt PMF. All 5 genes comprising the HMR category, when mutated, individually signified for worse survival (supplemental Tables 4 and 5). The impact of ≥2 mutated genes was also evaluated (Figure 2C-D). In pre-PMF, median survival was 12.7 years vs 2.6 years in patients with 1 and ≥2 mutated genes ( P < .0001); the corresponding HRs (using LMR as the reference category) were 1.7 (95% CI, 1.0-3.1) and 8.4 (95% CI, 4.3-16.3). In overt PMF, median survival was 5.3 years in patients with 1 mutated gene and 2.5 years if ≥2 mutated genes were present ( P < .0001); HRs were 2.0 (95% CI, 1.4-2.9) and 3.0 (95% CI, 1.9-4.5), respectively. Driver mutations deserved no prognostic significance for LFS, except for TN patients with pre-PMF in whom the risk to progress to leukemia was significantly higher compared with CALR type 1 (HR, 10.5; 95% CI, 2.2-49.6) (supplemental Figure 2A-B). Conversely, pre-PMF and overt PMF patients harboring HMR mutations experienced significantly shortened LFS compared with the LMR category. LFS was 22.7 years (14.0-24.6 years; P < .001) and 13.5 years (95% CI, 4.6-12.3 years; P < .001) in HMR patients with pre-PMF and overt PMF, compared with 27.6 years (95% CI, 6.1-29.2 years) and 21.6 years (95% CI, 10.6-22.7 years) for the corresponding LMR categories (supplemental Figure 2C-D). The impact of adverse karyotype on OS and LFS was analyzed for 332 patients who had cytogenetic information. In pre-PMF, unfavorable karyotype predicted for shortened OS (median [range], 3.2 years [2.7-3.7 years]) and LFS (3.1 years [2.6-3.6 years]) (supplemental Figure 3A,C) compared with patients lacking unfavorable karyotype (median OS not reached). There was a trend for shorter survival also in overt PMF patients with unfavorable karyotype (5.9 years vs 8.4 years), but no difference concerning LFS (supplemental Figure 3B,D). Figure 3. Time to disease progression in study patients population. Kaplan-Meier estimate of the time to disease progression in pre-PMF and overt PMF (A). Time to progression was defined as the time to acquisition of any 1 (except age) of the prognostically adverse clinical and hematologic variables included in the DIPSS-Plus score (anemia; leukocytosis; blasts ≥1% in peripheral blood; thrombocytopenia; appearance of constitutional symptoms; transfusion dependence; we did not consider adverse cytogenetics for which we had too few data). (B) Cumulative incidence for each of the individual prognostically unfavorable variables is shown. Cumulative incidence was estimated with a competing risk approach, considering death for any other cause as a competing event. Vertical tick marks indicate right-censored patients. Figure 3. In a multivariate analysis, that included the IPSS score, diagnosis of pre-PMF or overt PMF, driver and nondriver mutations, the variables that remained significantly associated with reduced survival were the IPSS score (intermediate-1: HR, 3.1; 95% CI, 2.0-5.0) (intermediate-2: 8.6; HR, 5.3-13.9) (high risk: HR, 11.2; 95% CI, 6.8-18.3) (all P > .0001), diagnosis of overt PMF (HR, 1.5l 95% CI, 1.1-2.0; P = .008) and HMR status (HR, 1.5; 95% CI, 1.2-2.1; P = .007). For LFS, only IPSS intermediate-2 (HR, 3.7; 95% CI, 1.8-7.9) and high-risk (HR, 9.0; 95% CI, 4.5-18.3; P = .001) category and HMR status (HR, 3.0; 95% CI, 1.6-5.7; P = .001) were significant. Disease Progression We then evaluated disease progression in the 2 patients’ cohorts. At the latest follow-up, 34.4% and 69.4% of pre-PMF and overt PMF patients, respectively, were scored as DIPSS intermediate-2 and high risk ( P < .0001) ( Table 3 ). At 3 and 5 years of follow-up, 8.0% and 14.0% of pre-PMF, and 20.5% and 31.4% of overt PMF patients, respectively, had progressed to higher-risk category ( P < .0001). The proportion of patients who acquired ≥1 of the individual DIPSS-Plus adverse variables (excluding age, and adverse cytogenetics for which we did not have information) was significantly greater in overt PMF than pre-PMF ( Table 3 ). The 3-year cumulative incidence of anemia was 29% in overt PMF vs 11% in pre-PMF (HR, 2.9; 95% CI, 2.0-4.3); leukocytosis, 10% vs 6.5% (HR, 2.2; 95% CI, 1.3-3.8); thrombocytopenia, 15% vs 6% (HR, 2.5; 95% CI, 1.5-4.3); ≥1% peripheral blood blasts, 21% vs 8% (HR, 2.7; 95% CI, 1.8-4.0); constitutional symptoms, 14% vs 5.5% (HR, 2.0; 95% CI, 1.2-3.3); transfusion dependency, 28% vs 12% (HR, 2.6; 95% CI, 1.8-3.8). Patients with absent fibrosis were less prone to develop anemia, transfusion dependency, thrombocytopenia, and ≥1% blasts in comparison with any grade of fibrosis, and the large majority of them remained in the lower DIPSS-plus categories (supplemental Table 6). Time to progression, considered as the time to acquisition of any 1 of the above prognostically adverse variables, was assessed by a time-dependent, competitive risk analysis (Figure 3A). Median time (range) to progression was 7.7 years (6.1-9.3 years) in overt PMF compared with 11.8 years (7.9-15.7 years) in pre-PMF ( P < .0001); the corresponding HR was 2.2 (95% CI, 1.5-3.1). Kaplan-Meier curves of event-free survival for each of the considered variables are shown in Figure 3B. Using pre-PMF as the reference category, the HR for acquisition of anemia in overt PMF was 2.9 (95% CI, 2.0-4.3), 2.2 for leukocytosis (95% CI, 1.3-3.8), 2.5 for thrombocytopenia (95% CI, 1.5-4.3), 2.7 for blasts ≥1% (95% CI, 1.8-4.0), 2.0 for symptoms (95% CI, 1.2-3.3), and 2.6 for transfusion dependence (95% CI, 1.8-3.8). Impact of Molecular Characteristics on Disease Progression We finally asked whether the molecular and cytogenetic abnormalities detected at diagnosis impacted on disease progression. Analysis of the 3-year cumulative incidence of acquisition of the individual DIPSS-Plus variables revealed that triple negativity was associated with higher rate of acquisition of anemia, transfusion dependency, and leukocytosis in both pre-PMF and overt PMF, plus thrombocytopenia in overt PMF (supplemental Table 7), whereas mutations in JAK2, MPL , and CALR were neutral. Remarkably, a HMR status was associated with statistically significant higher 3-year cumulative incidences of all of the adverse variables, except symptoms, in both cohorts compared with LMR category (supplemental Table 8). Discussion Discussion This analysis of a large series of patients with contemporary diagnosis of pre-PMF and overt PMF disclosed meaningful differences in clinical, hematologic, and molecular phenotype, and in outcome, thereby reinforcing the potential relevance of applying the 2016 revised WHO criteria in the clinical practice. The existence of pre-PMF distinct from ET and fibrotic overt PMF has been largely debated in the literature with regard to the reproducibility of criteria outside of pivotal studies based on centralized evaluation of diagnostic slides by a single WHO expert. In a number of reports with formal assessment of concordance degree among pathologists, the overall consensus ranged from 88% (best) to 53% (worst) (listed in supplemental Table 9). The current study was conducted in the spirit of a “real-life” approach where expert, local pathologists from 5 different tertiary centers with large accrual of myeloproliferative neoplasm patients independently formulated their diagnosis based on 2016 WHO criteria; then, we correlated histopathology with hematologic, clinical, and molecular findings. The primary aim was to assess whether stratification of patients in the 2 PMF categories, as required by modern WHO criteria, corresponded to any clinically meaningful difference that might pragmatically justify such distinction. When compared with overt PMF, patients with pre-PMF were generally females of younger age who showed a more pronounced myeloproliferative phenotype with higher leukocyte, hemoglobin, and platelet levels, whereas they less frequently had peripheral blood blasts, symptoms, and extensive splenomegaly. Conversely, overt PMF and pre-PMF did not differ regarding the driver mutations’ profile nor the variant allele frequency, whereas mutations included in the HMR category were enriched among overt PMF patients. At diagnosis, patients with pre-PMF were preferentially included in the lower IPSS risk categories, whereas 48.1% of overt MF were scored as intermediate-2 and high risk. Furthermore, patients with overt PMF had significantly shorter progression-free survival than pre-PMF. [20] Notably, OS and LFS were longer in pre-PMF than overt PMF, but significantly shortened in both categories compared with patients with ET. These findings stand in support of the importance of an accurate distinction between pre-PMF and ET, [12,23] as by the WHO criteria, particularly with regard to pre-PMF patients with absent fibrosis. In summary, differentiating between pre-PMF and overt PMF by adopting the 2016 revised WHO criteria proved to be clinically informative and prognostically relevant, although how this knowledge might inform a personalized therapeutic approach cannot be inferred based on this study and needs a prospectively followed series. Such prospective analyses might also include centralized evaluation of diagnostic slides to definitely assess the reproducibility of WHO criteria of pre-PMF. Results of this study also indicate that, in spite of the uniqueness of the individual diagnostic categories with regard to characteristics and outcome, the overlapping phenotype might support the hypothesis that the 2 diseases represent a continuum where unknown individual characteristics and/or germ line or somatic gene variants eventually affect disease presentation and progression. By analyzing the individual characteristics upon the degree of fibrosis, including absent fibrosis, there appears to be a gradient in most of the clinical and hematologic variables and, mostly relevant, outcome. These findings reinforce recent observations indicating that degree of BM fibrosis is prognostically informative. [24-28] One additional finding from this study concerns the appropriateness of a reappraisal of the current IPSS prognostic scores; in fact, these scores were originally developed using populations of PMF patients [18] that differed from the 2 categories currently identified by the 2016 revised WHO criteria. In this regard, we found that, although the IPSS score overall predicted survival, it largely failed to accurately separate intermediate-1 and intermediate-2, and intermediate-2 and high-risk patients, respectively, in pre-PMF and overt MF, as well as in the individual groups based on the grade of fibrosis. These observations may have importance in the settings of decision-making for stem cell transplantation, which is currently indicated in patients with intermediate-2 and high-risk PMF [29] ; based on our findings, pre-PMF patients with intermediate-2 disease, whose median survival was superimposable to intermediate-1 and projected at >10 years, might be inappropriately exposed to a risky procedure. Therefore, we suggest that these aspects be addressed in further studies. Furthermore, there might be speculation that more extensive mutation profiling, compared with the 5-gene panel of the HMR category used in this study, [16] might contribute to improved discrimination of patients at risk of premature death; this notwithstanding, it is noteworthy that the HMR status confirmed its predictive value in both pre-PMF and overt PMF. Of note, selected nondriver mutations are currently included in guidelines for referral to transplantation. [29,30] Concerning driver mutations, studies conducted in cohorts with 2008 WHO-defined PMF identified patients with triple negativity and presence of CALR type 1 mutation, respectively, as the worst and best category for survival; patients harboring JAK2 V617F, MPL W515, and CALR type 2 mutations showed intermediate survival. [15,22,31,32] In this study, we confirmed that CALR type 1 mutations represent the most favorable predictor of survival among the driver mutations; in pre-PMF, the negative impact of TN and the intermediate outcome associated with JAK2V617F and MPL W515 mutations were also confirmed, whereas in overt PMF, no significant differences among the 3 mutation profiles could be ascertained. As a whole, these findings should promote efforts to critically re-evaluate current scores and, eventually, develop separate risk scores for pre-PMF and overt PMF that include the most relevant clinical, molecular, and cytogenetic variables. In a multivariate analysis performed in this series, HMR mutations, unlike driver ones, maintained their independent prognostic value. In conclusion, in this “real-life” study of 661 molecularly annotated patients with a diagnosis of pre-PMF and overt PMF, according to the 2016 revised WHO criteria, we identified differences in patterns of presentation, survival, and disease progression, overall indicating that these criteria might help to separate clinically distinct categories of patients. Current results also suggest that accurate differentiation between pre-PMF and overt PMF is required for meaningful interpretation of results of clinical trials with novel therapeutic agents. ",
				"clientUrl": "/viewarticle/881383",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 0,
				"concept": ["Leukemia", "Cancer Diagnostics", "Hematology", "Tumor Pathology", "Myeloproliferative Disease", "Primary Myelofibrosis", "Myelofibrosis"],
				"leadSpecialtyId": 7,
				"leadSpecialty": "Hematology-Oncology",
				"allSpecialties": ["Hematology-Oncology", "Internal Medicine"],
				"contentGroup": "Journal Article",
				"origContentType": "Journal Article",
				"contentType": ["Journal Article"],
				"description": "Primary myelofibrosis can be characterized as prefibrotic or overt, with the latter having more pronounced disease manifestations, adverse mutations, and worse outcomes.",
				"legacyID": 881383,
				"pubDisplay": "Blood",
				"siteOn": 2003,
				"title": "Presentation and Outcome of Patients With 2016 WHO Diagnosis of Prefibrotic and Overt Primary Myelofibrosis",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/Blood-thumb.jpg"],
				"publicationDate": 1497502800000,
				"postingDate": 1497502800000,
				"_version_": 1573508875550720000,
				"last_index_date": 1500615001265
			}, {
				"id": "pdctm_0901c79180b71ab9",
				"activeCME": 1,
				"activityExpirationDate": 1526619600000,
				"authors": ["Colleen Curtis", " Aleksandra Mineyko", " Patricia Massicotte", " Michael Leaker", " Xiu Yan Jiang", " Amalia Floer", " Adam Kirton"],
				"body": "Abstract and Introduction Abstract and Introduction Abstract Perinatal stroke causes cerebral palsy and lifelong disability. Specific diseases are definable, but mechanisms are poorly understood. Evidence suggests possible associations between arterial perinatal stroke and prothrombotic disorders, but population-based, controlled, disease-specific studies are limited. Understanding thrombophilia in perinatal stroke informs pathogenesis models and clinical management. We conducted a population-based, prospective, case-control study to determine the association of specific perinatal stroke diseases with known thrombophilias. Children with idiopathic magnetic resonance imaging–classified neonatal arterial ischemic stroke (NAIS), arterial presumed perinatal ischemic stroke (APPIS), or fetal periventricular venous infarction (PVI) were recruited. Standardized thrombophilia evaluations were performed after 12 months of age on stroke cases and controls, including quantified proteins C and S, antithrombin, factors VIII/IX/XI, fibrinogen, lipoprotein(a), homocysteine, lupus anticoagulant, anticardiolipin antibodies and genotyping of factor V Leiden (FVL), factor II G20210A (FII), and methylenetetrahydrofolate reductase C677T. A total of 212 children were studied: 46 with NAIS, 34 with APPIS, 55 with PVI, and 77 controls (male, 53%; median age, 4.8 years). Of 14 parameters, no differences were observed in 12, including all common thrombophilias. Mean prothrombin time was shorter in arterial strokes ( P < .001). Rates of antiphospholipid antibodies were low, comparable to those in controls, and resolved on repeat testing. FVL and FII rates were comparable to population norms. Total number of possible abnormalities did not differ between cases and controls. Our prospective, population-based, controlled, disease-specific study suggests minimal association between perinatal stroke and thrombophilia. This does not exclude the possibility of disordered coagulation at the time of stroke but suggests testing in childhood is not indicated. Introduction Perinatal stroke is the leading cause of hemiparetic cerebral palsy and results in lifelong disability. [1] Disease-specific subtypes of perinatal stroke are now definable based on clinical presentation and neuroimaging including vascular distribution. [2,3] Most common are arterial ischemic strokes, but fetal venous infarcts also occur. There are many proposed risk factors, but pathogenesis remains unclear in most cases. [4] Study of these specific disease states is required to elucidate pathophysiological mechanisms if prevention strategies are to be realized. Neonatal arterial ischemic stroke (NAIS) presents acutely in the first days of life, typically with seizures. [3] Diffusion magnetic resonance imaging (MRI) confirms recent arterial infarction. Arterial presumed perinatal ischemic stroke (APPIS) presents later in childhood, typically with motor asymmetry at 4 to 6 months. [5,6] MRI shows remote arterial infarction, most often combined cortical and subcortical injuries in the middle cerebral artery territory indistinguishable from the chronic appearance of NAIS. Accordingly, NAIS and APPIS may represent the same disease, differing only in timing of symptomatic presentation. The pathogenesis of such arterial perinatal strokes is poorly understood. Case-control studies are limited, [7-10] and a recent meta-analysis [11] has methodological issues. Prevailing theory suggests many arterial perinatal strokes are thromboembolic events, possibly arising from the placenta. Most studies of thrombophilia in perinatal stroke have only included NAIS. Another common perinatal stroke disease is fetal periventricular venous infarction (PVI). PVI also presents later in infancy after term birth, typically with early hand preference and hemiparesis. [6] Modern neuroimaging has confirmed that PVI represents an in utero germinal matrix hemorrhage with secondary venous infarction of the periventricular white matter. [2,12-14] In the term infant presenting with hemiparesis, PVI is increasingly recognized. [12,14] Many risk factors have been identified for germinal matrix hemorrhage in preterm infants, but this fetal correlate has been less studied. The role of the coagulation system in germinal matrix hemorrhage and secondary venous infarction is unclear, regardless of gestational age. [15] Prothrombotic abnormalities have been associated with preterm PVI, but only small, uncontrolled studies exist in term PVI. [6] The role of prothrombotic abnormalities in perinatal stroke has been investigated previously but almost exclusively in NAIS populations. Studies have been limited by absence of controls, retrospective design, highly selected and modestly powered samples, inconsistent laboratory methods, and heterogeneous populations combining those with less specific cerebral palsy or perinatal stroke without specific, MRI-classified stroke disease states. [16] Studies in presumed perinatal stroke (APPIS, PVI) have been even more limited, [5,6,17,18] with no disease-specific, well-powered, case-control studies to date. A meta-analysis of thrombophilia in pediatric stroke was unable to examine perinatal populations, let alone each specific perinatal stroke disease in isolation. [19] A long list of known prothrombotic conditions have been investigated in perinatal stroke. These are summarized elsewhere [4,19] but include abnormal levels of coagulation factors such as protein C, protein S, and antithrombin; lipoprotein(a) [Lp(a)]; homocysteine; factors VII, IX and XI; and lupus anticoagulant and antiphospholipid antibodies (APAs). Commonly explored prothrombotic genetic changes include factor V Leiden (FVL), factor II G20210A (FII), and methylenetetrahydrofolate reductase C677T (MTHFR). These approaches are reasonable, based on substantial evidence of associations with other thrombotic diseases in adults and children. Disease-specific associations of prothrombotic disorders have been suggested for childhood ischemic stroke. [19] However, the same levels of evidence do not yet exist for children with perinatal stroke. In addition to the limitations noted is the known complexity of the human coagulation system and its dynamic evolution through conceptual and early postnatal development. [20,21] Understanding the role of thrombophilia in perinatal stroke carries multiple clinical implications. As possible risk factors, elucidating associations may help explain distinct pathophysiological mechanisms for arterial and venous subtypes of perinatal stroke. Although perinatal stroke recurrence is uncommon (< 1% to 2%), it has been associated with thrombophilia [22] and the issue of which, if any, child should be anticoagulated is often raised. Finally, the question of testing children with perinatal stroke for thrombophilia later in life has not been directly addressed. Implications include unnecessary anxiety for families, lack of informed treatment indications, accurate clinical best practice guidelines, and efficient health care resource use for the nearly 100 000 North American families currently affected by perinatal stroke. We conducted a population-based, prospective, single-center, case-control study of children with MRI-defined perinatal stroke diseases to explore associations with known prothrombotic conditions. Methods Methods Populations Patients with perinatal ischemic stroke were identified through the Alberta Perinatal Stroke Project. [23] Originating in 2008, this population-based registry systematically identified all children in southern Alberta (population ∼2.2 million, ∼26 000 live births per year), Canada, with perinatal stroke. Retrospectively (1998-2008), case ascertainment methods including exhaustive International Classification of Diseases, ninth and 10 revisions, code searching and medical record reviews identified all potential cases. Prospectively (2007-2015), children were identified at the time of NAIS, APPIS, or PVI diagnosis. Recruitment occurred by consultation to the Alberta Children’s Hospital Pediatric Stroke Service or referral to the Alberta Children’s Hospital Perinatal Stroke Clinic, where all participants were reviewed and examined by a stroke neurologist to confirm diagnosis and arrange definitive MRI if not already available. Patients were classified as NAIS, APPIS, or PVI based on clinical history and imaging results as described previously. [2] Inclusion criteria were: (1) MRI-confirmed ischemic perinatal stroke; (2) no identifiable high-likelihood etiology for stroke, such as congenital heart disease or bacterial meningitis; and (3) informed consent/assent. Control participants were recruited through an established healthy participant program. Children undergoing general anesthesia for routine elective procedures were screened preoperatively. Those without chronic medical conditions were contacted before procedure to confirm health and absence of any medications or first-degree relatives with clotting disorders. Controls were recruited randomly from eligible participants while maintaining a balance of age and sex comparable to the stroke group. At onset of anesthesia, a blood sample was collected and transported to the institutional special coagulation laboratory per protocol. Thrombophilia Evaluations Prothrombotic evaluations were conducted prospectively. Laboratory testing of prothrombotic conditions in perinatal stroke studies have been inconsistent, including different methodologies and timing during development. Because most evaluations are sensitive to these factors, a standardized approach was developed to optimize consistency in a population typically diagnosed between birth and 12 months. Blood draws were performed at 12 ± 2 months of age for all cases diagnosed in the first year of life. Those diagnosed at a later age were tested at the time of study enrollment. Genetic testing was performed on the same samples. Methods were approved by the institutional research ethics board. Prothrombotic outcomes were collected and measured according to standardized operating procedures. Peripheral blood was collected into vacutainer tubes (2.7 mL) containing 3.2% sodium citrate (0.105 mol/L; BD, Mississauga, Canada) and then centrifuged at room temperature for 15 minutes at 2800 RCF. The following tests were performed on an ACL TOP analyzer at the Special Coagulation Laboratory, Calgary Laboratory Services. Prothrombin time (international normalized ratio) and activated partial thromboplastin time were clot-based one-stage assays. Factor VIII, IX, and XI levels were activated partial thromboplastin time clot-based assays. Protein C test was performed on both clot-based and chromogenic-based assays. Quantitative free protein S tests were performed by latex ligand immunoassay. Protein S activity was measured by clot-based and/or chromogenic-based assays. Antithrombin quantitative test was performed by chromogenic-based assay. Fibrinogen was quantified using Clauss method. Lupus anticoagulants used a panel test including diluted Russell’s viper venom test screen, diluted Russell’s viper venom test confirmation test, and tissue thromboplastin inhibition test. Lp(a), homocysteine, and anticardiolipin antibody and β-glycoprotein tests were performed at the chemistry laboratory of Calgary Laboratory Services. Homocysteine levels were determined using a chemiluminescent microparticle immunoassay. Lp(a) was quantified using a particle-enhanced immunoturbidimetric assay (Roche Integra). An upper limit of normal of 0.30 g/L was also applied as the most commonly used risk threshold. Homocysteine was measured using a 1-step chemiluminescent microparticle immunoassay (Abbott Architect). APAs and β2 glycoprotein were measured using multiplex flow immunoassay Bio-Rad BioPlex 2200. Qualitative categorization of APAs as borderline or low was repeated a minimum of 8 weeks later. All cases were tested for the genetic variants FVL, FII G20210A, and MHTFR C677T. FVL and FII mutations were detected using heminested allele-specific polymerase chain reaction (PCR). The PCR assay was carried out on microliter volumes of whole, unfractionated EDTA or citrate anticoagulated blood specimens using nested, allele-specific primers in parallel reactions. The presence of allele-specific products for 1691G- or 1691A-containing sequence in addition to a constant fragment produced from the outer primer set was indicative of the patient genotype at the factor V 1691 locus. The MTHFR polymorphism analysis was conducted by PCR and restriction enzyme digestion (nonradioactive method). The PCR assay was carried out on purified DNA extracted from nucleated blood cells (MH 29.0), and the resulting amplified product was digested overnight with Hinf I restriction enzyme. The digested products were separated on thin polyacrylamide gels, and the pattern of fragments developed by staining with ethidium bromide and visualization with UV light. The genetic prothrombotic abnormalities of interest were already well characterized in the general population with studies having high power and ethnic diversity. Therefore, a literature search was performed in Medline for population-based investigations of mutations and variants in prothrombotic factors, including FVL, FII, and MTHFR. Studies were considered if they included populations that would be similar to our sample (North American, varied ethnicity) and specified the numbers of patients and allele frequencies. Analysis For continuous outcomes, mean values were compared between each stroke type and controls (analysis of variance, post hoc Tukey). Potential associations between age and continuous variables was tested (Pearson or Spearman), and group comparisons were corrected for age when present (analysis of covariance). Proportions of patients falling outside the normal range (defined as 5% to 95% of control values) were compared between stroke groups (χ 2 /Fisher’s exact test). Frequency of genetic abnormalities was compared between stroke groups (χ 2 /Fisher’s exact test) and the literature-based estimates of population prevalence ( z test). Analysis was repeated, grouping all arterial patients together (NAIS, APPIS). Analysis was performed using Statistical Package for the Social Sciences (version 19.0; SPSS Inc, Chicago, IL). An initial sample-size calculation based on clinically significant effect size of >20% incidence of thrombophilia in stroke cases, power of 90%, and type I error of 0.05 suggested a sample of 32 children per group. Results Results There were 182 children with confirmed perinatal stroke potentially meeting criteria: 72 with PVI (40%), 61 with NAIS (34%), and 49 with APPIS (27%). From this sample, 135 (74%; PVI, 55; NAIS, 46; APPIS, 34) were included in this analysis. Those excluded had a presumed alternative mechanism for their stroke (meningitis, congenital cardiac disease) or incomplete results, or the parents declined testing. The control population consisted of 77 participants, resulting in a total population of 212. There were no differences in age or sex between groups except among those with NAIS, in whom median age was lower. Participant characteristics are summarized in Table 1 . To establish reference ranges for our laboratory methods, control data were analyzed and summarized as shown in Table 2 . The means, standard errors, and 95% confidence intervals (CIs) are displayed for each coagulation parameter measured as a continuous variable. No age or sex differences were observed. Results were also similar to existing laboratory reference ranges (based on adults >16 years of age) and previously published values. [24] The results of all quantified prothrombotic measures are shown for stroke and control participants in Table 3 . Mean values, variances, and 95% CIs were comparable for most measures. This did not change when NAIS and APPIS were analyzed individually or collectively. Prothrombin time was significantly shorter in AIS (11.3 ± 0.1; 95% CI, 10.1-12.6) compared with controls (11.9 ± 0.1; 95% CI, 10.6-13.5; P < .001). The international normalized ratio was also higher in controls (1.10 ± 0.01; 95% CI, 1.0-1.2) compared with both stroke groups (1.00 ± 0.01; 95% CI, 0.9-1.1; P < .001). Two additional significant results were suggested on the initial analysis of variance without correction for multiple comparisons. However, neither was in the direction expected for thrombophilia, including a lower level of antithrombin and higher level of factor XI in controls compared with either stroke group. Using the ranges of normal established by the control sample, and considering the expected direction of abnormality associated with pathological thrombosis, the frequency of abnormalities was not different for stroke patients. This did not differ if NAIS and APPIS were analyzed individually or as a single group. These results are summarized in Table 4 . APAs were detected at low levels in 14 participants (7%) across all groups: anticardiolipin antibodies in 5 patients with PVI (borderline, 1; low positive, 4), 7 patients with AIS (borderline, 1; low, 5; moderate, 1), and 2 control participants (borderline, 1; low positive, 1). However, repeat testing at least 8 weeks later in 13 of the 14 participants with borderline or low levels revealed negative results in 11 and borderline in 2 (control, 1; PVI, 1). Lupus inhibitor was found in only 1 control participant. The results of the genetic analyses are shown in Table 5 . The prevalence of FVL heterozygosity was 10.7% in the PVI, 6.3% in the NAIS, and 8.1% in the APPIS groups. These proportions were not significantly different from one another. Rates for all arterial (NAIS, APPIS) were comparable to those for PVI. These rates did not differ from the estimated published North American population rate of 6%. [25] One child with PVI was homozygous for FVL, which was not distinguishable from chance against the extremely low population rate of 0.1%. [26] Factor II heterozygous mutation was found in 5.4% of PVI cases, which did not differ from 2.2% and 2.9% of patients with NAIS and APPIS, respectively. Compared with all arterial, the rate of factor II mutations was not higher in patients with PVI (5.4% vs 2.4%; P = .18). Compared with the published population value of 3.8%, [27] rates were comparable in NAIS, APPIS, and PVI ( P = .2). No difference was observed in the distribution of MTHFR genotypes between stroke subgroups. There were fewer patients with all arterial carrying the homozygous TT genotype compared with the population (9.1% vs 15%; P = .04). [28] No participants had elevated serum homocysteine. The mean homocysteine was 5.8 ± 0.27 umol/L in PVI, 6.7 ± 0.33 umol/L in APPIS, and 5.5 ± 0.19 umol/L in NAIS. In a sample of 32 healthy controls tested in the same laboratory, mean values, variance, and range were similar at 5.94 ± 0.25 umol/L. These values fell within our laboratory reference range for ages 16 to 49 years of 4.9 to 13.3 umol/L (males) and 4.1 to 9.1 umol/L (females). Associations between MTHFR and homocysteine demonstrated the expected trend, although this did not reach statistical significance (CC, 5.85 ± 0.22; CT, 6.06 ± 0.26; TT, 6.42 ± 0.59). Figure 1. Comparison by number of prothrombotic abnormalities. Relative proportions of participants having each of none through 6 abnormalities are shown by stroke group or controls. Most participants had no abnormalities. No difference was found between stroke groups and controls regardless of number of abnormalities. Figure 1. The number of abnormal test results did not differ between stroke subtypes and controls (Figure 1). No abnormalities were detected in 41 control participants (53%), 33 patients with PVI (60%), and 48 patients with AIS (60%; NAIS, 25; APPIS, 23). One abnormality was found in 26 controls (34%), 16 patients with PVI (29%), and 18 patients with AIS (23%). Five or 6 abnormalities were detected in 1 each of the control, PVI, and AIS groups. Discussion Discussion Our results suggest that patients with perinatal stroke undergoing thrombophilia investigations in childhood demonstrate minimal risk of harboring a prothrombotic disorder compared with the general population. Our findings disagree with those of previous studies, but our methodology carries substantial additional strengths, including specific, MRI-classified perinatal stroke disease states; prospective, case-control data within the same laboratory; and a well-powered, population-based sample. Perhaps the most compelling association between thrombophilia and perinatal stroke previously described is that of FVL. Being a commonly performed genetic test with established population prevalence makes previous reports of much higher than expected rates seem significant. [29-32] As a constant genetic factor present from birth, FVL also avoids potentially complicating, confounding issues of neonatal versus childhood testing and developmental hemostasis. However, our results demonstrated rates of FVL (as well as prothrombin gene mutations) comparable to those in the general population. Prevalence among 4047 participants in the Physician’s Health Survey and Women’s Health Study with no history of thrombosis varied from 0.45% in Asian Americans to 5.27% in whites, with a pooled frequency of 3.7%. [25] Although our results cannot refute all previous studies, the clinical significance of FVL heterozygosity should also be considered. With >95% of such individuals never incurring a serious thrombotic disease during their lifetime, the benefits of testing children with perinatal stroke is questionable, even if rates are slightly increased. Additional considerations exist for the contrast between our results and those of previous studies. The possibility of selection bias can be considered, with many previous positive studies coming from specialized thrombosis centers where the advantages of methodological and other expertise may be complicated by referral patterns, leading to higher rates of thrombophilia. Examination of the limited case-control studies to date supports this possibility, with nearly 1 in 4 so-called normal participants having at least 1 prothrombotic abnormality. [33] Second, many previous studies used reference ranges or cutoffs established elsewhere. For example, many studies of Lp(a) used a cutoff of >0.3 mg/dL. [34,35] In contrast, our results found that the normal range in controls extended far above this number, with no differences observed between cases and controls. Finally, another highly powered study of perinatal stroke thrombophilia submitted for publication also describes a similar lack of association between known thrombophilias and perinatal stroke (L. Lehman, personal communication, 11 October 2016). The MTHFR story also merits consideration. This common genotype has been repeatedly associated with thrombosis over decades, including common descriptions in perinatal stroke. [4] MTHFR prevalence varies among ethnic groups, from 8% to 30% for the TT genotype; in >1000 newborns, the North American genotype distribution was 57%, 37%, and 15% for CC, CT, and TT genotypes, respectively. [36] The association of MTHFR mutations with stroke and thrombosis not only is inconsistent but has virtually been disproven to the point of new guidelines suggesting testing is no longer warranted. [37] The predominance of this so-called genetic thrombophilia in the literature for so long across so many studies may highlight the complexities of defining such relationships and the high risk of false-positive associations. The potential association between perinatal stroke and APAs is also becoming clearer. Although multiple studies have suggested this association, [5,22,29,38-40] there have been no well-powered, population-based, case-control investigations. Importantly, none has confirmed that positive findings are both strong and persistent over time. The most common cause of a borderline or low positive test is probably intercurrent illness. It has clearly been shown in recent meta-analyses that only such persistently abnormal positivity is associated with incident thromboembolic disease in children. [41] A recent prospective study followed 12 of 62 children with NAIS or neonatal cerebral sinus venous thrombosis who had persistently positive acute APAs. [42] Followed with serial testing for a median of 3.5 years, many were anticoagulated, but 10 of 12 demonstrated normalization of APA status, and there were no recurrences. In contrast, our study, which included only those children with persistent, significant APA positivity, found very low prevalence rates and no association with specific perinatal stroke disease states. The role of maternal APAs is less clear; however, the few studies suggesting an association [29,43-47] have the same limitations described earlier in this section, and the single best acute case-control study in NAIS found no association with APA. [33] That maternal APA positivity has been disassociated from infant positivity in NAIS, [42] and that it is not readily apparent how maternal thrombophilia would lead to cerebral thromboembolism in the fetus or newborn, further calls into question the relevance of maternal APA status. With known risks of APA syndrome and available treatments, this issue is of great clinical relevance. However, the body of evidence and our new results here suggest APAs are unlikely to influence the health of children who have experienced a perinatal stroke in the past. Despite accounting for a majority of perinatal stroke cases, presumed perinatal stroke has been relatively neglected in the literature, with no case-control studies to date. In fact, most early studies did not even specify between perinatal stroke types. The one exception was an uncontrolled Turkish study of 35 participants suggesting a high rate of thrombophilia. [18] However, the most common finding was MTFHR, whereas other more legitimate abnormalities were uncommon. Our study is the first to add MRI-confirmed, disease-specific, population-based, case-control data. Testing nearly 90 cases of presumed perinatal stroke compared with controls within the same laboratory, we found essentially no differences. We believe this provides the best evidence to date and suggests that childhood thrombophilia is uncommon in presumed perinatal stroke. The lack of association we observed between prothrombotic abnormalities and perinatal stroke does not preclude a role for disordered coagulation in the pathogenesis of perinatal stroke. Could acute changes be more important? One of the best acute NAIS studies to date prospectively performed a thrombophilia panel similar to ours in 91 consecutive term-born cases matched 2:1 to healthy controls. [33] Important considerations are that acutely ill neonates were not exclude,d including those with asphyxia and infections. Blood was collected between 3 weeks and 6 months of age (controls were from 6-16 weeks of age). Multiple moderately powered case-control studies of clinical variables associated with NAIS have failed to define consistent associations supportive of causation. [7-10] They have agreed, however, that multifactorial pathogenesis is likely often required and that thromboembolism is almost certainly the culprit in arterial perinatal stroke. Placental disease leading to fetal cerebral embolism is a leading candidate mechanism, supported by associations with placental disease, common bilateral lesions without cardiac abnormality, and virtually no recurrence risk (<1% to 2%). [4,48] A low-flow vascular bed prone to thrombosis such as an inflamed placenta in chorioamnionitis could certainly theoretically interact with a neonatal thrombotic state to lead to perinatal stroke. Although less studied, abnormal thrombosis may also be associated with PVI mechanisms. [15] Such acute or transient alterations in thrombotic state are also supported by previous reports of acute protein C and S defects typically resolving at follow-up in children with NAIS. [33] Our results therefore do not alter the strong suspicion of acutely disturbed thrombosis in perinatal stroke. Additional limitations are acknowledged. We did not test the mothers of children, although even studies performed acutely have shown inconsistent results, [29,44] with potential abnormalities not persisting to the chronic phase. [42] We did not explore previous suggestions of association between thrombophilia and adverse outcome, primarily for lack of recurrence in our population and no other rationale to associate blood clotting with outcome. [17,49] Several recently described thrombophilias potentially associated with stroke in children were not included in our panel, including plasminogen activator inhibitor-1 4G6755G, ADAMTS13, and plasma glutathione peroxidase. [50-52] Importantly, our study of specific, idiopathic perinatal stroke diseases does not exclude possible associations with other diseases (eg, cerebral sinovenous thrombosis) or major risk factors such as congenital heart disease. Our results carry clinical implications. With minimal association and virtually no risk of stroke recurrence, we suggest that routine testing in childhood is not required. Not only is there little if any apparent benefit, but there may also be substantial risk of harm to children and their families. Completing ≥15 tests will most often lead to at least 1 seemingly abnormal result. This in turn may lead to unnecessary additional testing and referrals to specialists, with implications for child and family anxiety as well as health care resource use. These same issues have been addressed in adult stroke, [53] with conclusions similar to ours: “If there is an association between thrombophilia and arterial stroke, then it is a weak one… The consequences of ordering these tests and attributing causality to an arterial event can result in significant costs to the health care system and pose a potential risk to patients, because this may lead to inappropriate use of long-term oral anticoagulants, exposing patients to harm without a clearly defined benefit.” We have not addressed the role of acute testing. However, with interpretation being complex, few if any clear indications for anticoagulation or other alterations in early management, and almost no risk of recurrence, the utility of acute testing is questionable. We have also not addressed specific circumstances such as a strong family history of pathological thrombosis. In conclusion, thrombophilia in children with ischemic perinatal stroke is rare, with rates approximating those in the normal population, and routine testing in childhood is not indicated. ",
				"clientUrl": "/viewarticle/879944",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 477,
				"leadConcept": "Cerebrovascular Accident (CVA)",
				"concept": ["Thrombosis", "Hematology", "Neonatal Medicine", "Ischemic Stroke"],
				"leadSpecialtyId": 7,
				"leadSpecialty": "Hematology-Oncology",
				"allSpecialties": ["Hematology-Oncology", "Pediatrics", "Neurology & Neurosurgery"],
				"contentGroup": "Journal Article",
				"origContentType": "Journal Article",
				"contentType": ["Journal Article"],
				"description": "In children with perinatal stroke, rates of thrombophilia are similar to those in the normal population, and routine testing in childhood is not indicated.",
				"legacyID": 879944,
				"pubDisplay": "Blood",
				"siteOn": 2003,
				"title": "Thrombophilia Risk Is Not Increased in Children After Perinatal Stroke",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/Blood-thumb.jpg"],
				"publicationDate": 1495083600000,
				"postingDate": 1495083600000,
				"_version_": 1573508880883777536,
				"last_index_date": 1500615006348
			}, {
				"id": "pdctm_0901c79180add0c3",
				"activeCME": 1,
				"activityExpirationDate": 1516338000000,
				"authors": ["Eli Muchtar", " Hila Magen", " Morie A. Gertz"],
				"body": "Abstract and Introduction Abstract and Introduction Abstract Cryoglobulinemia is a distinct entity characterized by the presence of cryoglobulins in the serum. Cryoglobulins differ in their composition, which has an impact on the clinical presentation and the underlying disease that triggers cryoglobulin formation. Cryoglobulinemia is categorized into two main subgroups: type I, which is seen exclusively in clonal hematologic diseases, and type II/III, which is called mixed cryoglobulinemia and is seen in hepatitis C virus infection and systemic diseases such as B-cell lineage hematologic malignancies and connective tissue disorders. Clinical presentation is broad and varies between types but includes arthralgia, purpura, skin ulcers, glomerulonephritis, and peripheral neuropathy. Life-threatening manifestations can develop in a small proportion of patients. A full evaluation for the underlying cause is required, because each type requires a different kind of treatment, which should be tailored on the basis of disease severity, underlying disease, and prior therapies. Relapses can be frequent and can result in significant morbidity and cumulative organ impairment. We explore the spectrum of this heterogeneous disease by discussing the disease characteristics of 5 different patients. Introduction Cryoglobulinemia is a clinical disorder characterized by the presence of cryoglobulins in the serum. Cryoglobulins are immunoglobulins that precipitate in vitro at temperatures below normal body temperature (<37°C) and redissolve upon rewarming. This observation was first reported in 1933 in a patient with multiple myeloma. [1] The term “cryoglobulin” was coined in 1947, and at that time, cryoglobulins were found to be globulins that appeared in various diseases. [2] Cryoglobulinemia may be asymptomatic without end-organ damage and is sometimes discovered as an incidental laboratory finding. The term cryoglobulinemic vasculitis is often used to distinguish the asymptomatic presence of cryoglobulins from cryoglobulins that cause end-organ damage by precipitating in small- to medium-size blood vessels. Classification of cryoglobulinemia is based on a system developed more than 40 years ago. It has the advantage of correlating with pathogenicity and clinical manifestations, which differ among types. [3] In type I cryoglobulinemia, the cryoglobulins are monoclonal immunoglobulins (Ig’s), usually of the IgG or IgM isotypes and rarely IgA or free immunoglobulin light chains. [4] Type I cryoglobulinemia develops in the setting of protein-secreting monoclonal gammopathies. Monoclonal gammopathy of undetermined significance (MGUS) is seen in ∼40% of patients, and the remaining 60% have an overt malignancy of B-cell lineage (eg, multiple myeloma [MM], Waldenström macroglobulinemia [WM], or chronic lymphocytic leukemia [CLL]). [5,6] Type I cryoglobulin levels do not differ among patients with MGUS and those with B-cell malignancies. [6] Therefore, the qualitative characteristics of the cryoglobulins play a greater role in disease pathogenesis than the cryoglobulin burden. In type II cryoglobulinemia, the cryoglobulins are composed of a mix of monoclonal IgM with rheumatoid factor (RF) activity and polyclonal IgG. This is usually associated with hepatitis C virus (HCV) infection in up to 90% of patients. [7] There are geographic variations, and higher rates of HCV infection are seen in the Mediterranean region. Other causes of type II cryoglobulinemia include other infections (mainly HIV and hepatitis B virus [HBV]), connective tissue diseases (CTDs), and lymphoproliferative disorders. Approximately 10% of patients have no identifiable cause (termed essential mixed cryoglobulinemia). [8] Type III is characterized by polyclonal IgM with RF activity and polyclonal IgG. This type is seen in CTDs or secondary to infection (mainly HCV). Overall, cryoglobulins in mixed cryoglobulinemia result from a B-cell lymphoproliferative process in the setting of persistent immune activation triggered by chronic infection, autoimmune disease, or an unknown cause. Pathogenesis Pathogenesis Cryoprecipitation The process of cryoprecipitation is not entirely understood and probably differs between type I and type II/III. In type I, the monoclonal component undergoes crystallization and aggregation, which is dependent on temperature and concentration. [9] Although the definition of cryoglobulins is precipitation at cold temperatures, this process can occur at room temperature at high cryoglobulin concentrations. [2] This probably explains why distal extremities (lower temperatures) and kidneys (increase in concentration as a result of ultrafiltration) are major sites of pathology. In type II/III cryoglobulinemia, cryoprecipitation takes place in the setting of immune complex formation between polyclonal IgG and IgM with RF activity and complement fixation. Cryoprecipitation cannot be induced by the IgM or IgG components separately and requires specific antigen-avidity IgG molecules. [10] This underscores the unique properties of cryoglobulins and explains the high incidence of HCV as a cause. Figure 1. Schematic illustration of vascular occlusion in type I cryoglobulinemia, demonstrating glomerular intracapillary thrombi. Figure 1. Tissue Injury The mechanism of cryoglobulin pathogenicity is best described for HCV-associated cryoglobulinemia. [11] HCV drives a clonal B-cell expansion, which secretes a monoclonal IgM that binds to polyclonal IgG molecules, which defines a RF. The IgM interacts with anti-HCV IgG to form immune complexes. These immune complexes bind via a C1q to C1q receptors receptor on endothelial cells, which promotes inflammatory cell recruitment and produces vasculitis. In contrast, the underlying pathogenesis of cryoglobulins in type I is small blood vessel occlusion with minimal inflammatory response (Figure 1). Diagnosis and Laboratory Evaluation The diagnosis of cryoglobulinemia is based on typical clinical manifestations in the presence of cryoglobulins in the serum. False-negative results may occur as a result of improper sample handling. Samples should be transferred and centrifuged at 37°C to avoid precipitation before serum extraction. In type I, precipitation at 1 to 4°C usually occurs within hours; samples should be stored for 7 days because precipitation can be delayed in the mixed types. If the test is negative for cryoglobulin and the index of suspicion remains high, it is appropriate to repeat the test after contacting the laboratory to ensure that the sample has been handled appropriately. At least 5 mL of sample should be obtained to increase diagnostic yield because trace levels of cryoglobulins can be clinically significant. When cryoglobulins are detected, measurement of the cryocrit (ie, the relative volume of the precipitate as a percentage of the total serum volume) should be reported if possible. The cryocrit level is higher in type I and the lowest in type III [12] (can be more than 50% in type I and is usually less than 5% in type II/III). Correlation between the cryocrit and disease manifestations is poor, [13,14] although higher cryocrit has been reported to increase the likelihood of symptomatic disease. [8] The cryocrit was prognostic in a few studies. [15,16] Overall, cryocrit use should be reserved for diagnosis because there is a poor correlation between the cryocrit and the response to treatment. After cryoprecipitation, the precipitate is washed in a cold buffer and dissolved in a warm solution; electrophoresis and immunofixation are then performed to type the cryoglobulins. Immunofixation may not be feasible if the concentration of cryoglobulins is low. RF and complement studies (C3, C4, CH 50 ) are part of the evaluation. RF is increased and complement (mainly C4) is decreased in the mixed types but can also be abnormal in type I. [6,17] These serologic abnormalities have led to a misdiagnosis of rheumatoid vasculitis because of failure to consider cryoglobulinemia. These parameters do not correlate well with disease activity but can be used to monitor the response to therapy. [18] Comparison of clinical manifestations and laboratory findings between type I and mixed cryoglobulinemia is presented in Table 1 . Cryoglobulinemia and Hematologic Diseases Hematologic cancers represent less than one quarter of all cryoglobulinemia cases. Type I cryoglobulinemia occurs mainly in B-cell malignancies with predominant protein secretion, including WM, MM, CLL, and the premalignant state MGUS. In contrast, type II cryoglobulinemia is seen more often in patients with WM or other B-cell lymphomas. Clinical Manifestation Most patients with circulating cryoglobulins remain asymptomatic and do not require immediate intervention. Signs and symptoms depend on the cryoglobulin type. Case 1: Type I Cryoglobulinemia Case 1: Type I Cryoglobulinemia A 40-year-old previously healthy man was seen in the emergency room for intractable epistaxis. He reported having a week of intermittent bleeding that was self-limiting but then became uncontrolled. The patient also reported several months of increasing fatigue and spontaneous bruises on his lower extremities. On examination, the patient appeared pale with active bleeding from both nostrils without an obvious focus. Livedo reticularis in both lower extremities and confluent hematomas were also noted. Laboratory evaluation revealed hemoglobin of 7.8 g/dL, normal platelet count, and normal coagulation studies. Serum total protein was increased and led to identification of an IgM-κ monoclonal protein of 5.7 g/dL with cryoglobulins precipitated at 4°C after several hours. Serum viscosity was increased to 4.8 centipoise, and funduscopic examination revealed asymptomatic retinal bleeding. Urgent plasma exchange was initiated, and the patient experienced symptom relief after 2 exchanges. Questions What are the hallmark manifestations of type I cryoglobulinemia? How should a patient with type I cryoglobulinemia be managed? Clinical Manifestations of Type I Cryoglobulinemia Figure 2. Skin necrosis in cryoglobulinemia. (A) Three skin ulcers at the anterolateral dorsum of the left foot in a patient with newly diagnosed WM-associated mixed cryoglobulinemia. Note that the 2 large ulcers are full skin thickness with minimal surrounding inflammatory response and no tendon or bone exposure. Prophylactic antibiotics were initiated to prevent serious infection. (B) The ulcers healed within 3 months from initiation of definitive therapy for WM. Figure 2. Signs and symptoms are generally associated with vascular occlusion by the cryoprecipitate, although small-vessel vasculitis features may also be seen (eg, purpura, glomerulonephritis, neuropathy). Two studies (64 patients each) reported on the clinical manifestations in type I cryoglobulinemia. [5,6] Skin manifestations were the most common and were observed in 69% to 86% of patients. These manifestations include purpura, livedo reticularis, Raynaud's phenomenon, acrocyanosis, skin necrosis, ulcers and, infrequently, digital gangrene. Cutaneous manifestations are often confined to acral sites (distal limbs, nose, and ears) and can be triggered by cold exposure. Skin necrosis (Figure 2) is evident in approximately one third of patients and is mainly seen in the lower extremities in the supramalleolar areas. These ulcers do not heal easily because of impaired blood supply, they put patients at significant risk for sepsis, and at times require amputation. Extracutaneous disease includes peripheral neuropathy in 19% to 44% of patients, arthralgia in 28%, and renal disease in approximately 30%. Painful peripheral neuropathy is usually confined to the lower extremities with predominant sensory impairment, but motor involvement can also be seen. Renal involvement presents as proteinuria, microscopic hematuria, increased creatinine, and/or hypertension and is more common in IgG than IgM cryoglobulinemia. [5] Most renal biopsies show membranoproliferative glomerulonephritis (MPGN) with immune cell infiltration, glomerular thrombi, and microtubular deposits composed of the cryoglobulin aggregates (Figure 3). When the cryocrit is high, hyperviscosity syndrome may ensue. Symptoms suggestive of hyperviscosity syndrome include oronasal bleeding, blurred vision, sudden deafness, headache, confusion, and heart failure as a result of plasma volume expansion. Measurement of serum viscosity may be helpful in establishing the diagnosis because symptoms of hyperviscosity rarely appear when the viscosity is below 4.0 centipoise (normal level, ≤1.5 centipoise). Management of Type I Cryoglobulinemia Figure 3. Cryoglobulinemic glomerulonephritis. The glomerulus shows global occlusion of peripheral capillary lumina by numerous infiltrating monocytes. Segmental intracapillary pink-staining immune thrombi (arrows), likely representing cryoglobulin deposits, are seen. There is widespread duplication of the glomerular basement membrane with associated cellular interposition (silver stain). Original magnification ×400. Photo courtesy of Samih Nasr, Mayo Clinic, Rochester, MN. Figure 3. Treatment is reserved for symptomatic disease and is directed against the underlying disorder. Complete hematologic evaluation includes bone marrow aspiration and/or biopsy and appropriate imaging studies. High-grade evidence regarding the appropriate approach to treatment for the underlying disease is limited because the incidence is low. Thus, recommendations are mostly expert opinion, based on the best available data. In patients with MM, treatment options follow MM consensus recommendations. In patients with renal failure, a bortezomib-based regimen is warranted, whereas in patients with neuropathy, lenalidomide-based treatment is a reasonable first choice. Before using autologous stem cell transplant, possible organ damage caused by the cryoglobulinemia should be considered. In patients with WM-associated cryoglobulinemia, the use of bortezomib as primary therapy is recommended by the International Workshops on Waldenström’s Macroglobulinemia. [19] Rituximab (monoclonal anti-CD20 antibody) as an initial therapy may cause IgM flare and development of hyperviscosity [20] ; rituximab can be incorporated after an initial response to treatment has been achieved. Plasma exchange can be used to prevent IgM flare in patients treated with rituximab who have high levels of IgM (above 4 g/dL). Ibrutinib is emerging as an active agent in the management of WM, [21] and although no data are available on its use in WM-associated cryoglobulinemia, this therapeutic option may be a legitimate consideration while waiting for clinical data to emerge. In patients with symptomatic hyperviscosity, plasma exchange is warranted but should always parallel definitive cytoreductive therapy. Patients with MGUS have a lower tumor burden, and lower-intensity treatment can initially be attempted. Among 23 patients with MGUS-related type I cryoglobulinemia, initial therapy consisted of single-agent prednisone at a median dose of 60 mg/day. [6] Response, defined by improvement in baseline clinical manifestations, was seen in 74% of patients, although half the responders relapsed and required a second line of therapy. Rituximab should be limited to MGUS patients with IgM isotype or when a CD20-positive B-cell clone is detected. [5] It is imperative to educate patients on avoiding exposure to the cold by wearing gloves when using the freezer or refrigerator, wearing warm clothes in air-conditioned facilities, and relocating to a warmer climate during the winter months. Foot and leg care is important to prevent wound complications. Diabetic foot care guidelines can be followed for this purpose (eg, checking the feet every day, wearing shoes and socks at all times, and trimming toenails gently). Case 2: Noninfectious Mixed Cryoglobulinemia Case 2: Noninfectious Mixed Cryoglobulinemia A 55-year-old previously healthy man first noticed decreased tolerance for exercise during a 500-mile bike ride. Subsequently, lower extremity edema developed and 2 skin ulcers were noted over the left anterolateral aspect of the dorsal foot (Figure 2A). Creatinine was 1.4 mg/dL, and 2.2 g of protein (predominantly albumin) was seen in a 24-hour urine collection. A renal biopsy demonstrated MPGN. Immunofluorescence staining was positive for IgM, κ light chain and C3. Congo red stain was negative for amyloid deposits. Serum electrophoresis and immunofixation showed the presence of an IgM-κ band as well as a cryocrit of 9%. Serology was negative for double-stranded DNA and positive for RF activity (915 IU/mL [normal, <15 IU/mL]). Complement tests demonstrated reduced total hemolytic complement assay (CH50), markedly reduced C4 (<2 mg/dL [normal, 14-40 mg/dL]), and a slight reduction in C3 (67 mg/dL [normal, 75-175 mg/dL]). HBV and HCV panels were negative. Bone marrow examination revealed 25% infiltration by a mix of κ-restricted CD20-positive lymphoid cells, lymphoplasmacytic cells, and plasma cells. The diagnosis was WM-associated mixed cryoglobulinemia, and the patient was treated with bendamustine-rituximab for 6 cycles. He achieved a very good partial response to treatment, the proteinuria fully resolved, and the foot ulcers healed (Figure 2B). Questions What are the clinical manifestations of mixed cryoglobulinemia? What are the treatment options for noninfectious mixed cryoglobulinemia? Clinical Manifestations of Mixed Cryoglobulinemia Mixed cryoglobulinemia, compared with type I cryoglobulinemia, is more often associated with constitutional symptoms such as fever, weakness, myalgia/arthralgia, and anorexia reflecting an immune complex disorder. The disease course is often chronic with flares followed by symptom resolution. The triad of purpura, arthralgia, and weakness (Meltzer’s triad) [22] is well known but is seen in only one third of patients. [12] Purpura is the most common manifestation, is seen in up to 90% of patients, and is a key feature of the diagnosis. [10] It can be transient or persistent. Cold exposure can trigger a purpura flare, but more common triggers are protracted standing, exercise, depilation, drugs, and infections. [3,23] Purpura usually involves the legs (gravitational) but can extend to the torso and upper extremities, can be isolated or can accompany a more widespread vasculitis, including livedo reticularis and skin ulcers. Histopathologic examination of the purpuric lesions reveals leukocytoclastic vasculitis with fibrinoid necrosis. Arthralgia is common in elbows, wrists, and knees, whereas arthritis with overt joint effusion is seen only in a small proportion of patients. [24] Renal disease and neuropathy are similar to those seen in type I, although type I is more likely to demonstrate small vessel obstruction by cryoglobulin aggregates. [25] Involvement of organs other than the kidneys is rare but when present, it almost exclusively points to mixed cryoglobulinemia. Dyspnea and dry cough can be signs of pulmonary involvement in the form of fibrosis or infiltrates that result from organizing pneumonia or alveolar hemorrhage. [26,27] Gastrointestinal (GI) involvement should be considered in patients with cryoglobulinemia who present with acute abdominal pain and/or GI bleeding as a sign of intestinal vasculitis and ischemia with risk of perforation. [28] Central nervous system manifestations of cryoglobulinemia are usually in the form of ischemic stroke, rarely as confusion. Heart involvement is rare, with the main manifestation being myocardial ischemia and dilated cardiomyopathy. [29] In a cohort of 209 patients with cryoglobulinemia, 14% had life-threatening involvement defined by acute renal failure, intestinal ischemia, pulmonary hemorrhage, and/or central nervous system involvement. [30] A life-threatening event was the initial presentation in 59% of patients. Compared with patients with more subtle symptoms, life-threatening involvement was associated with a higher frequency of fever, type II cryoglobulinemia, higher cryocrit, and a low C3. Mortality was 100% in patients with GI involvement and pulmonary hemorrhage. Figure 4. Management algorithm for non-infectious mixed cryoglobulinemia. CNS, central nervous system; CTX, cyclophosphamide; GN, glomerulonephritis; NSAIDS, nonsteroidal anti-inflammatory drugs; RPGN, rapidly progressive glomerulonephritis. Figure 4. Treatment Options for Noninfectious Mixed Cryoglobulinemia Given the rarity of non-HCV mixed cryoglobulinemia, it is challenging to provide evidence-based treatment recommendations. Moreover, treatment of noninfectious cryoglobulinemia is provided by both hematologists and rheumatologists, and treatment philosophies may differ between disciplines. When a treatment plan is being considered, there are several general principles to follow, as shown in Figure 4. Treatment of the underlying disease is not always feasible when a cause has not been identified. In patients with overt hematologic malignancy, we prefer to treat the malignancy and modify the treatment according to disease extent and organ dysfunction. Patients with severe or life-threatening manifestations need urgent intervention to suppress immune complex formation. This is accomplished with immunosuppressive therapy (IST), which is used in other systemic vasculitis. IST is primarily based on high-dose corticosteroids, cyclophosphamide, rituximab, and plasmapheresis. IST is intended to halt end-organ damage, and once the treatment goal has been achieved, the dose should be tapered to the lowest possible dose and should be discontinued, if possible. Rituximab, as a B-cell depletion agent, constitutes a major element in the current paradigm of the immunosuppressive approach. Four weekly doses of 375 mg/m 2 are usually given. [31] The largest data set on the use of rituximab in noninfectious mixed cryoglobulinemia comes from a Cryovac multicenter survey that reported on 242 patients. The use of rituximab in combination with corticosteroids achieved the greatest benefit in terms of clinical response, renal response, and immunologic response (ie, >50% decrease in the baseline cryoglobulin level and/or a >50% increase in serum C4). [32] This combination was more efficacious than corticosteroids alone or corticosteroids in combination with an alkylator. However, patients treated with rituximab and corticosteroids experienced a ninefold increase in severe infections (primarily when the prednisone dose was >50 mg/d), with no adverse effect on survival. Alkylators, mainly cyclophosphamide (2 mg/kg orally once per day or a once-per-month intravenous pulse of 500-750 mg/m 2 ), remain a valid option, because data from randomized controlled trials comparing rituximab to alkylators in the noninfectious setting are limited. [33] The fludarabine-cyclophosphamide-rituximab regimen was shown to be active in 7 patients with refractory cryoglobulinemia associated with lymphoma. [34] In life- or organ-threatening events, cyclophosphamide can be used in conjunction with pulse corticosteroids (intravenous methylprednisolone 500-1000 mg for 3 days followed by a prednisone taper). A response to plasma exchange in mixed cryoglobulinemia is seen in 70% to 80% of patients, [35] and plasma exchange is a rational therapeutic option with severe disease manifestations (MPGN, leg ulcers) or in the case of life-threatening events such as pulmonary hemorrhage or intestinal vasculitis. The exchange solution should be warmed to body temperature to avoid cryoglobulin precipitation. [36] If a response is achieved, we usually schedule close follow-up visits once every 3 months, because relapses frequently occur. Follow-up visits can be scheduled for two times per year if remission is maintained for more than 2 years. During follow-up visits, detailed interval history and careful physical examination are the key components in assessing remission status. In addition, our routine laboratory evaluation at each visit includes complete blood count, chemistry panel, cryoglobulin measurement (and monoclonal protein measurement if it was present at diagnosis), RF and complement measurements if they were abnormal at presentation, urinalysis, and 24-hour urine collection for proteinuria. It is also imperative to assess for infections in this population and adhere to recommended vaccinations for the immunocompromised population. Monitoring for malignancies, particularly hepatocellular carcinoma in patients with chronic viral hepatitis and hematologic malignancies in patients with MGUS or CTDs, should be performed. [37-39] Case 3: Relapsed Cryoglobulinemia Case 3: Relapsed Cryoglobulinemia A 62-year-old woman was diagnosed with type II non-HCV cryoglobulinemia affecting the kidneys and skin. A small clone of CD20-positive κ-restricted lymphocytes was seen in a bone marrow biopsy. She was successfully treated with rituximab and prednisone and achieved complete resolution of her symptoms with reduction in the cryocrit >80%. She relapsed after 2 years off treatment, with an increase in urine protein (>1 g/day) and leg purpura. Questions What is the natural course of mixed cryoglobulinemia? What are the treatment options for disease recurrence and/or progression? Little data are available on the rate of progression or relapse over the disease course. In a study of 47 treated patients with mixed cryoglobulinemia, an average of 3.8 treatments per patient were given over a median follow-up of 3.2 years, [13] emphasizing the relapsing nature of the disease. Moreover, many patients have underlying indolent clonal hematologic disease (eg, indolent lymphoma) or CTD, which have frequent relapses and may contribute to the relapsing-remitting nature of mixed cryoglobulinemia. Noninfectious mixed cryoglobulinemia is associated with a 10-year survival of 79%, similar to the survival among patients with mixed cryoglobulinemia associated with HCV (10-year survival, 75%). [40] The leading cause of death in this population is severe infections, which account for half the deaths. More than 80% of the infection-related deaths occurred during the induction phase of treatment at a median of 50 days from initiation. Nineteen percent of the deaths were the result of vasculitis flares, predominantly renal. In comparison, the leading causes of death in HCV-associated cryoglobulinemia are infections (35%), end-stage liver disease (30%), and end-organ damage resulting from vasculitis (17%). [41] Treatment at progression should follow the outline for initial treatment, with adjustments according to the nature of the progression. If initial treatment was successful with durable response (>1 year), that regimen can be repeated. Otherwise, an alternative regimen would be appropriate. It is also appropriate to re-stage the underlying disease because patients with MGUS or CTD can progress to overt hematologic malignancy, which can have an impact on the choice of treatment. Case 4: HCV-associated (Infectious) Mixed Cryoglobulinemia Case 4: HCV-associated (Infectious) Mixed Cryoglobulinemia A 55-year-old woman HCV carrier developed weakness and arthralgia over several months. Muscle weakness was accompanied by a painful burning sensation in her lower extremities, which prompted further investigation. On examination, symmetrically distributed palpable purpura were observed in the lower extremities. Muscle strength was 4/5 in the lower extremities and preserved in the upper extremities. Tendon reflexes were absent at the ankles bilaterally and reduced at the knee. Cryoglobulins were detected in the serum with an IgM-κ monoclonal protein and 3% cryocrit. RF activity was increased (765 IU/mL), and C4 was below normal (5.4 mg/dL). Creatinine was 1.3 mg/dL, and urinalysis demonstrated microscopic hematuria and proteinuria (1.5 g/24 hours). HCV polymerase chain reaction demonstrated the presence of viral RNA genotype 1a. The patient initiated treatment with rituximab and prednisone followed by ribavirin and peg-interferon. Questions What are the treatment options for infection-associated mixed cryoglobulinemia? Does rituximab have a role and is it safe in virus-associated mixed cryoglobulinemia? The principles of infectious-associated mixed cryoglobulinemia follow those used for noninfectious mixed cryoglobulinemia (Figure 5). Patients with HCV-associated severe cryoglobulinemia are usually offered IST followed by combination antiviral therapy. Gradual introduction of treatment aims to avoid cumulative toxicities. [42] In our patient, glomerulonephritis and sensorimotor neuropathy indicated severe disease, and IST is the preferred initial treatment to halt immune complex–mediated organ damage. The choice of antiviral treatment should be made according to current guidelines, [43-46] because the presence of cryoglobulinemia does not have an impact on the choice of antiviral therapy. Direct-acting antiviral agents (DAAs) are more potent than the pegylated interferon-ribavirin combination, are given orally, for a shorter duration with a better safely profile. [47] This may be relevant because patients with mixed cryoglobulinemia are often anemic and/or have renal impairment, which complicates the use of ribavirin in these patients, whereas DAAs can safely be given to most patients with renal and hepatic impairment. [48] Although clinical improvement can occur even without achieving HCV RNA clearance (sustained virologic response [SVR]), patients who achieved SVR were more likely to have improvement in their disease manifestations. [49,50] The presence of cryoglobulinemia (with or without symptoms) in HCV patients was an independent negative predictor for attaining SVR in patients treated with pegylated interferon-ribavirin combination. [50] Data on the use of DAAs in mixed cryoglobulinemia are emerging with encouraging results. [51-54] Figure 5. Management algorithm for infectious mixed cryoglobulinemia. Figure 5. Rituximab was shown to be effective in HCV-associated cryoglobulinemia. In a prospective cohort study, the addition of rituximab to pegylated interferon-ribavirin resulted in a shorter time to response and better renal response and cryoglobulin clearance, although the rate and depth of clinical response and the relapse rate were similar between study arms. Two randomized trials evaluated rituximab in mixed cryoglobulinemia, mostly in the setting of HCV. In the first trial, 2 doses of rituximab 1 g/m 2 days 1 and 14 were compared with other IST therapies in patients for whom anti-HCV therapy failed or who could not tolerate it. At 12 months, a treatment-free status was more likely in the rituximab arm. Organ improvement was better with rituximab, predominantly for skin and renal involvement. [33] The second trial (with a similar design) evaluated rituximab (375 mg/m 2 , 4 weekly doses) compared with other IST therapies. At 6 months, the remission rate was 83% in the rituximab arm compared with 8% in the control arm. [55] Data on the therapeutic approach in non-HCV infectious cryoglobulinemia are limited, given the rarity of this disease. A review of 45 patients with non-HCV infectious cryoglobulinemia suggests that disease management in this case is somewhat different than that outlined for HCV-associated cryoglobulinemia [56] (Figure 5). Patients who received appropriate anti-infective therapies (antiviral or antibacterial) were more likely to achieve a sustained response, even in the absence of IST. The use of IST alone (including corticosteroids alone) in these patients resulted in a poor response to therapy. And finally, in refractory cases, the use of targeted anti-infective agents in combination with IST may overcome refractoriness to either agent alone. Concomitant anti-infective treatment in non-HCV cases relies on the fact that rituximab is associated with reactivation of HBV [57-59] and HIV [60,61] in the untreated state. Therefore, rituximab (as well as other forms of IST) should be given only to patients who are receiving concomitant anti-HBV and/or anti-HIV therapies. In contrast, there is evidence suggesting that rituximab does not have an impact on HCV replication, [55,62,63] although there are reports indicating an increase in HCV RNA in the serum after rituximab administration, albeit without adverse clinical consequences. [64,65] Case 5: Asymptomatic Cryoglobulinemia Case 5: Asymptomatic Cryoglobulinemia A 55-year-old woman was diagnosed with CLL after being evaluated for an increased white blood cell count during her annual physical examination. She was asymptomatic without an indication for treatment and was put on observation. Two years after the diagnosis, cryoglobulins were found in her serum. Immunofixation of the cryoglobulins revealed a monoclonal IgG-κ. She had no cryoglobulinemia-related symptoms. Questions What is the frequency of cryoglobulinemia without associated symptoms? When is it appropriate to screen for cryoglobulins? Cryoglobulins can be detected in the sera of healthy people but usually at a very low concentration. [66,67] The prevalence of circulating cryoglobulins in the HCV-infected population is close to 50%, [68] but only 15% of people in that group show clinical signs of cryoglobulinemia. [69] The prevalence of circulating cryoglobulins in hematologic and rheumatologic diseases is likely underreported. In a study that assessed type I cryoglobulins from a laboratory database, 227 patients had circulating type I cryoglobulins, but only 36 patients (16%) had symptomatic disease. [17] Several clinical findings should prompt evaluation for cryoglobulinemia ( Table 2 ). Summary Summary In conclusion, cryoglobulinemia is a rare clinical entity. Awareness of its clinical spectrum is important, because diagnosis is facilitated by the demonstration of cryoglobulins in the serum. Treatment is challenging, given the end-organ damage and frequent relapses. Currently all treatment options are designed to either treat the underlying disease or to provide immunosuppression, without any emerging disease-specific interventions. Because cryoglobulinemia is a heterogeneous disease in its manifestations and causation, it is difficult to propose uniform management guidelines, although there are similarities in management approaches, as outlined earlier. There is a lack of good-quality data, especially for the less common cryoglobulinemia subtypes. Among the open questions are the components of treatment and their sequence within each subtype and the duration of treatment that will produce a sustained remission, especially in light of short remissions. Data from large cohorts of patients from nationwide or even multinational registries are a key component in trying to sort out the important principles of therapy. ",
				"clientUrl": "/viewarticle/874381",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 0,
				"concept": ["Connective Tissue Disease", "Multiple Myeloma", "Hematologic Complications of HIV", "Immunoglobulin A (IgA)", "Immunoglobulin G (IgG)", "Immunosuppressive Therapy", "Hepatitis B Virus (HBV)", "Hepatitis C Virus (HCV)", "Monoclonal Antibody", "Hematological Disorders", "Cryoglobulinemia", "Waldenstrom Hypergammaglobulinemia"],
				"leadSpecialtyId": 7,
				"leadSpecialty": "Hematology-Oncology",
				"allSpecialties": ["Hematology-Oncology", "Internal Medicine", "Rheumatology", "Family Medicine/Primary Care", "Nephrology"],
				"contentGroup": "Journal Article",
				"origContentType": "Journal Article",
				"contentType": ["Journal Article"],
				"description": "Treatment of cryoglobulinemia, which ranges from asymptomatic to life-threatening disease, is challenging because of end-organ damage, frequent relapses, and lack of consensus guidelines.",
				"legacyID": 874381,
				"pubDisplay": "Blood",
				"siteOn": 2003,
				"title": "How I Treat Cryoglobulinemia",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/Blood-thumb.jpg"],
				"publicationDate": 1484802000000,
				"postingDate": 1484802000000,
				"_version_": 1573508875326324736,
				"last_index_date": 1500615001049
			}, {
				"id": "pdctm_0901c79180a2834d",
				"activeCME": 1,
				"activityExpirationDate": 1503032400000,
				"authors": ["Julie A.E. Irving", " Amir Enshaei", " Catriona A. Parker", " Rosemary Sutton", " Roland P. Kuiper", " Amy Erhorn", " Lynne Minto", " Nicola C. Venn", " Tamara Law", " Jiangyan Yu", " Claire Schwab", " Rosanna Davies", " Elizabeth Matheson", " Alysia Davies", " Edwin Sonneveld", " Monique L. den Boer", " Sharon B. Love", " Christine J. Harrison", " Peter M. Hoogerbrugge", " Tamas Revesz", " Vaskar Saha", " Anthony V. Moorman"],
				"body": "Abstract and Introduction Abstract and Introduction Abstract Somatic genetic abnormalities are initiators and drivers of disease and have proven clinical utility at initial diagnosis. However, the genetic landscape and its clinical utility at relapse are less well understood and have not been studied comprehensively. We analyzed cytogenetic data from 427 children with relapsed B-cell precursor ALL treated on the international trial, ALLR3. Also we screened 238 patients with a marrow relapse for selected copy number alterations (CNAs) and mutations. Cytogenetic risk groups were predictive of outcome postrelapse and survival rates at 5 years for patients with good, intermediate-, and high-risk cytogenetics were 68%, 47%, and 26%, respectively ( P < .001). TP53 alterations and NR3C1 / BTG1 deletions were associated with a higher risk of progression: hazard ratio 2.36 (95% confidence interval, 1.51-3.70, P < .001) and 2.15 (1.32-3.48, P = .002). NRAS mutations were associated with an increased risk of progression among standard-risk patients with high hyperdiploidy: 3.17 (1.15-8.71, P = .026). Patients classified clinically as standard and high risk had distinct genetic profiles. The outcome of clinical standard-risk patients with high-risk cytogenetics was equivalent to clinical high-risk patients. Screening patients at relapse for key genetic abnormalities will enable the integration of genetic and clinical risk factors to improve patient stratification and outcome. This study is registered at www.clinicaltrials.org as #ISCRTN45724312. Introduction Acute lymphoblastic leukemia (ALL) is a heterogeneous disease at the genetic level, and the spectrum of somatic aberrations range from chromosomal abnormalities to submicroscopic copy number alterations (CNAs) and sequence mutations. [1] In pediatric ALL, chromosomal abnormalities and CNA define subgroups associated with risk of relapse and death. [2,3] High-risk chromosomal abnormalities are used to risk-stratify treatment, ensuring patients receive the most appropriate intensity of chemotherapy. [4] Although genetic abnormalities are prognostic biomarkers of outcome at initial diagnosis, their clinical applicability after relapse has rarely been studied systemically within the context of a large clinical trial. Currently, 3 parameters define risk groups at relapse: (1) duration of first remission (CR1); (2) site of relapse; and (3) immunophenotype. [5] Shorter CR1, T-ALL, and marrow involvement are associated with poor outcome postrelapse. [5] In contrast, patients who have late or isolated extra-medullary relapses have better outcomes. [5] Studies investigating the genetic profile of relapse samples have identified important similarities and differences with the matched diagnostic sample. Primary genetic abnormalities that define distinct subtypes, including ETV6-RUNX1 , KMT2A ( MLL ) translocations, TCF3-PBX1 , and high hyperdiploidy (HeH), are stable between diagnosis and relapse. [6,7] In contrast, cooperating or secondary aberrations are lost, enriched, or gained as the leukemia evolves under the selection pressure of frontline chemotherapy and the surviving subclones expand, resulting in relapse. [8-11] Several abnormalities are more prevalent at relapse (eg, TP53 [12] and NR3C1 [8,13] alterations). Recent studies suggest that some genetic abnormalities (eg, IKZF1 , TP53 , KRAS abnormalities) are prognostic biomarkers that can refine current risk stratification algorithms. [10,12,14] These biomarkers need independent validation to ensure they are disease-specific, rather than trial-dependent. The aims of this study were to determine (1) the spectrum and frequency of chromosomal abnormalities, CNA, and sequence mutations among patients with relapsed B-cell precursor ALL (BCP-ALL); (2) the prognostic relevance of individual genetic abnormalities and predefined cytogenetic and CNA risk groups for predicting outcome after first relapse; and (3) whether the current clinical risk algorithm used to stratify relapsed ALL patients can be improved through the integration of genetic biomarkers. Methods Methods Patients Between January 2003 and October 2013, 449 children aged 1 to 18 years from the United Kingdom, Ireland, The Netherlands, Australia, and New Zealand diagnosed with relapsed BCP-ALL were enrolled on the ALLR3 trial (Figure 1). [15] The study was approved by the relevant institutional ethics committee(s) and written informed consent was obtained for each patient from parents, legal guardians, or the patients themselves. [15] Procedures Detailed treatment protocols and the main trial results have been published. [15-17] An outline of the risk stratification algorithm and treatment is provided in supplemental Figure 1 and supplemental Table 1, available on the Blood Web site. An initial randomization during induction between idarubicin and mitoxantrone was stopped in favor of mitoxantrone. [15] Patients were classified as standard, intermediate, or high risk (supplemental Figure 1). Patients with late (>6 months after stopping frontline therapy) isolated extra-medullary (EM) relapses were classified as standard risk (SR). Intermediate risk (IR) comprised BCP-ALL patients with late relapses involving the bone marrow (BM) or early (<6 months from stopping frontline therapy) isolated EM and combined relapses, as well as T-ALL patients with early isolated EM relapses. All remaining patients were classified as high risk (HR) and included: (1) patients with a very early relapse (<18 months from initial diagnosis); (2) T-ALL relapses involving the marrow; and (3) BCP-ALL patients with an early isolated BM relapse. HR patients were eligible for an allogenic stem cell transplant (SCT), and a small cohort (n = 44) received clorafabine. Patients were evaluated for minimal residual disease (MRD) by real-time quantitative polymerase chain reaction (qPCR) analysis of immunoglobulin and T-cell receptor gene rearrangements. [18] IR patients with a late marrow relapse or an early combined relapse who had MRD levels ≥1 × 10 −4 at the end of induction were eligible for an allogenic SCT. IR patients with MRD levels <1 × 10 −4 at end of induction and SR patients with isolated extramedullary relapses received chemotherapy. Patients with extramedullary disease who were not transplanted also received radiotherapy. Only 26 BCP-ALL patients were classified as SR, and none were assessed for CNA or mutations because, by definition, there was no marrow involvement. In keeping with the current international relapsed ALL trial, we combined SR and IR, and throughout this manuscript they are referred to as “SR.” Routine cytogenetic and fluorescence in situ hybridization (FISH) testing at diagnosis and/or relapse was used to classify patients into 3 previously defined mutually exclusive cytogenetic risk groups: (1) good risk— ETV6-RUNX1 and HeH (CYTO-GR); (2) intermediate risk— TCF3-PBX1 , IGH translocations, B-other (none of these established abnormalities) (CYTO-IR); and (3) high risk— BCR-ABL1 , KMT2A translocations, near haploidy, low hypodiploidy iAMP21, TCF3-HLF (CYTO-HR) [3] (supplemental Figure 2). None of the 245 patients tested at both diagnosis and the time of marrow relapse was discordant for these classifying chromosomal abnormalities. Figure 1. CONSORT diagram depicting the patient cohorts used in this study with their key demographic and clinical features. “Age” refers to the mean age at relapse in years. *Material not available. E, early; F, female; HR, clinical high risk; L, late; M, male; VE, very early. Figure 1. The copy number and mutational status of key genes were tested using DNA extracted from marrow relapse samples, which comprised ≥20% blasts derived from representative patient cohorts (Figure 1). The copy number status of IKZF1 , CDKN2A/B , PAX5 , EBF1 , ETV6 , BTG1 , RB1 , and PAR1 were determined using the SALSA multiplex ligation-dependent probe amplification (MLPA) kit P335 (MRC Holland, The Netherlands). [19] The copy number status of these 8 loci was used to classify patients into predefined CNA profiles [2] (supplemental Figure 2). NR3C1 copy number status was determined using TaqMan Copy Number Assays using primer and probe sets directed to NR3C1 (intron 4) and 2 references genes (ribonuclease P RNA component H1 [14q11.2] and telomerase reverse transcription [5q15.33]). NR3C1 deletions were confirmed by FISH using probes generated from the BAC clones (RP11-138C1 [5p13.1] and RP11-278J6 [5q31.3]), where suitable material was available. Key exons of TP53 , NRAS , KRAS , PTPN11 , FLT3 , and CBL genes were assessed for mutations by denaturing high-performance liquid chromatography and Sanger or next-generation sequencing (supplemental Tables 2 and 3). [10,12] Germline material was available for 10 patients harboring PTPN11 (n = 7), KRAS (n = 2), and TP53 (n = 3) mutations; all mutations were confirmed to be somatic. Statistical Analysis Survival analysis considered 2 end points—progression-free (PFS) and overall survival (OS). [15] PFS was calculated as the time from first relapse, using the date of registration onto ALLR3, until reinduction failure, second relapse, second malignancy, or death, censoring at last contact. OS was defined as time from first relapse to death, censoring at last contact. The median follow-up time for patients without an event was 4.3 years. Survival rates were calculated using Kaplan-Meier methods. The risk associated with the presence of each genetic abnormality was determined using a binary variable in univariate or multivariate Cox regression models. The prognostic impact of cytogenetic risk group was also assessed using a Cox regression model using 3-way categorical variable comparing CYTO-GR and CYTO-HR with CYTO-IR. Other comparisons were performed using the χ 2 or Fisher exact test as appropriate. All analyses were performed using Intercooled Stata 13.0 (Stata Corporation, USA). Results Results Spectrum and Frequency of Chromosomal Abnormalities, Gene Mutations, and CNA A total of 427 of 449 (95%) patients with relapsed BCP-ALL had successful cytogenetic/FISH analysis at initial diagnosis or relapse. The spectrum of chromosomal abnormalities observed was similar to that seen at initial diagnosis, but the proportions were different (supplemental Figure 3). Patients were classified into predefined cytogenetic risk groups (supplemental Figure 2), which have been validated in consecutive frontline treatments protocols. [2,3] The distribution of relapsed patients across the 3 risk groups was: CYTO-GR (48%), CYTO-IR (38%), and CYTO-HR (13%). The frequency of ETV6-RUNX1 and HeH was lower among these relapsed patients compared with newly diagnosed patients treated on ALL97 [3] : 83 of 427 (19%) vs 368 of 1451 (25%), P = .012; and 124 of 427 (29%) vs 562 of 1486 (38%), P = .001. In contrast, after the exclusion of BCR-ABL1 patients, there was a higher proportion of CYTO-HR patients among ALLR3 patients compared with the frontline trial ALL97: 55 of 425 (13%) vs 124 of 1505 (8%), P = .004. Figure 2. Progression-free and overall survival of relapsed B-cell precursor ALL patients stratified by cytogenetic risk and clinical risk group. Kaplan-Meier survival graphs depicting the PFS and OS of relapsed childhood. Patients with ALL treated on ALLR3 and stratified by cytogenetic risk group. Figure 2. We screened 190 to 222 patients for CNAs and sequence mutations affecting 15 genes (Figure 1; supplemental Table 4). The frequency of secondary abnormalities ranged from 1% to 41%, with the most prevalent aberrations targeting CDKN2A/B (41%), IKZF1 (23%), and PAX5 (20%). Among 173 patients successfully tested for all 15 aberrations, 80% harbored ≥1 abnormality: 1 (29%), 2 (24%), 3 (16%), and 4+ (10%) abnormalities. The secondary abnormalities were not distributed evenly across cytogenetic risk groups or individual abnormalities ( Table 1 ). Overall, the frequencies of individual CNA and mutations and their correlation with chromosomal abnormalities strongly reflected the genomic landscape observed at diagnosis. [20-22] IKZF1 and CDKN2A/B deletions were associated with B-other ALL and were less prevalent among CYTO-GR patients. ETV6 deletions were associated with ETV6-RUNX1 and iAMP21. TP53 mutation/loss was more frequent among CYTO-HR (35% vs 8%, P < .001) and clinical HR patients (25% vs 7%, P < .001). NRAS mutations were associated with HeH (14/62 [23%] vs 12/149 [8%], P = .003). Specific secondary abnormalities rarely coexisted more often than chance would predict (supplemental Figure 4). Deletions/mutations of CDKN2A/B - PAX5 , CDKN2A/B – KRAS , and PAX5 – IKZF1 were more common than expected, and the majority of patients with each pair had B-other ALL (64%, 56%, and 85%, respectively), which is in line with the distribution of individual CNA and mutations by chromosomal abnormality ( Table 1 ). Association between clinical parameters and CNA/mutations were rare (supplemental Table 4) but IKZF1 -deleted patients were older (median, 12.2 vs 8.7 years, P = .004) and NRAS/KRAS -mutated patients were younger (median, 7.4 vs 10.5 years, P = .002) compared with other patients. Clinical Relevance of Chromosomal Abnormalities, Gene Mutations, and CNA The clinical and outcome features of ETV6-RUNX1 and HeH patients were similar with OS rates 67% (49-80) and 68% (54-79), respectively (supplemental Table 3). These chromosomal abnormalities define the GR-CYTO group and, collectively, they had a superior outcome postrelapse compared with other patients ( Table 2 ; Figure 2A-B). Although all CYTO-HR patients had a poor outcome, there were demographic and clinical differences by individual abnormality ( Table 2 ). Patients with KMT2A translocations were <10 years old at relapse and 87% had a very early or early relapse. In contrast, iAMP21 patients were older, and 11 of 19 (58%) had relapsed late. Hence, the majority of KMT2A patients (74%) were classified as HR, whereas the majority of iAMP21 patients were classified as SR (84%). Although both sets of patients had a high second relapse rate (44% and 31%, respectively), iAMP21 patients had a lower OS rate (16% vs 42%), despite similar proportions having a transplant—12/23 KMT2A patients and 12/19 iAMP21 patients. There was evidence of outcome heterogeneity within the CYTO-IR group. Among 9 patients with TCF3-PBX1 , 8 relapsed within 2.5 years of initial diagnosis. All 7 TCF3-PBX1 patients who had a marrow relapse died, whereas 2 patients with an isolated central nervous system (CNS) relapse remain alive 3+ years post-relapse. TCF3-PBX1 patients had an increased risk of second event and death compared with other patients: hazard ratios—PFS 2.85 (95% confidence interval [CI], 1.34-6.06), P = .007 and OS 3.30 (1.55-7.05), P = .002. Ten patients harbored an IGH translocation and were older than other patients (median, 16 vs 9 years, P < .001). Even though the majority (6/10) had late relapses, postrelapse outcomes were poor with an increased risk of second event and death: hazard ratio PFS 2.05 (0.96-4.35), P = .06 and OS 2.48 (1.16-5.29), P = .019. Interestingly, only 2 of 10 IGH translocation patients suffered a second relapse, so this poor outcome was driven by treatment-related mortality. Univariate analysis revealed that only TP53 alterations, NR3C1 and BTG1 deletions, were significantly associated with outcome (supplemental Table 4). Patients with a TP53 alteration were more likely to have had a very early relapse and hence be classified and treated as HR. Although their initial response was not poorer than other cases, they did have a higher relapse rate (52%) and consequently a higher hazard ratio for PFS and OS: 2.36 (1.51-3.70), P < .001; and 2.56 (1.61-4.06), P < .001. NR3C1 and BTG1 deletions were linked with induction failure/death, second relapse, and OS. Because both genes are implicated in resistance to glucocorticoids and the deletions are mutually exclusive, we also considered the effect of the deletions together: hazard ratios for PFS and OS were 2.15 (1.32-3.48), P = .002, and 1.91 (1.13-3.22), P = .015. Patients with a NRAS mutation appeared to have lower PFS and OS rates as well as higher rates of induction failure and second relapse, but this did not reach statistical significance. We have previously shown that the prognostic impact of CNA at initial diagnosis was strongest when combined into a profile rather than individually (supplemental Figure 2). [2] Applying the same criteria to CNA data generated at relapse identified that 58% patients harbored an IR/PR CNA profile, which was higher than in the original diagnostic ALL97 cohort (39%). [2] Patients with an IR/PR CNA profile were older but did not have an inferior outcome (supplemental Table 4). Refining the Risk Classification by Integrating Genetic and Clinical Risk Factors The current international trial for children with relapsed ALL—IntReALL2010—comprises 2 separate protocols, one for clinically defined SR patients and one for HR patients. Therefore, we reexamined the prognostic effect of genetic factors within clinical SR and HR groups to identify: (1) SR patients who have a poor outcome and may benefit from HR therapy, (2) HR patients who have a dismal outcome and maybe benefit from experimental therapy, and (3) HR patients with a good outcome who may be spared HR therapy. The cytogenetic, CNA, and mutational profile of SR and HR patients was distinctive (Figure 3). SR patients were enriched for ETV6-RUNX1 , HeH, ETV6 and RB1 deletions, and PTPN11 mutations. In contrast, TCF3-PBX1 , KMT2A translocations, haploidy, low hypodiploidy, TCF3-HLF , TP53 alterations, and NR3C1 deletions were more frequent among HR patients. CDKN2A/B , IKZF1 , PAX5 , and KRAS alterations were equally prevalent among SR and HR patients. Figure 3. Cytogenetic, copy number, and mutational profile of relapsed acute lymphoblastic leukemia patients stratified by clinical risk group. Frequency of individual chromosomal abnormalities, copy number alterations and sequence mutations among clinical standard and high-risk B-cell precursor ALL patients treated in ALLR3. * P < .05; ** P < .01. Figure 3. Among clinical SR patients, those with CYTO-GR and CYTO-HR had superior or inferior risks of progression/death compared with CYTO-IR patients ( Table 3 ). The most prevalent secondary abnormalities among SR patients were deletions or alterations of CDKN2A/B , IKZF1 , and PAX5 , but were not associated with response or outcome. SR patients with a TP53 alteration had an inferior outcome; in particular, an increased risk of death: OS hazard ratio 2.56 (95% CI, 1.61-4.06), P < .001. SR patients with an NR3C1 deletion had a borderline adverse outcome, and combining NR3C1 and BTG1 deletions did reveal an increased risk of death: hazard ratio 1.91 (95% CI, 1.13-3.22), P = .015. Correlations between the primary chromosomal subgroup and the prevalence of specific secondary abnormalities raise the prospect of pleiotropic effects ( Table 1 ). B-other ALL is enriched for CDKN2A/B , IKZF1 , and PAX5 alterations, but their presence was not associated with outcome among SR patients. Similarly, the good outcome of ETV6-RUNX1 and HeH was not adversely affected by ETV6 deletions and PTPN11 mutations (data not shown). However, the presence of NRAS mutations was associated with an increased risk of progression/death among SR HeH patients: hazard ratio 3.17 (95% CI, 1.15-8.71), P = .026, and 3.41 (95% CI, 1.11-10.43), P = .032. The 5-year PFS and OS rates for the 10 SR patients with HeH and an NRAS mutation were 32% (6-63) and 26% (1-65). Among SR patients, the prognostic effect of MRD was borderline (supplemental Table 5) and did not correlate with the presence of specific genetic abnormalities ( Table 3 ). A multivariate Cox regression model with variables for both MRD and high-risk genetics suggests both factors are associated with a higher risk of second relapse or death; however, neither reached statistical significance. (supplemental Table 5). The outcome of HR patients was universally poor and none of the genetic alterations was associated with a superior outcome (supplemental Table 6). However, none of the HR patients with a TP53 alteration survived 3 years, and the hazard ratio for risk of death was 2.56 (95% CI, 1.61-4.06), P < .001. Although the number of patients is small, the poor outcome appeared to be largely driven by a higher rate of second relapse. Nine of these 16 (56%) were CYTO-HR patients, 5 were CYTO-IR, and 2 CYTO-GR. HR patients with a NR3C1 or BTG1 deletion had an inferior outcome with an increased risk of progression: hazard ratio 3.40 (95% CI, 1.70-6.80), P = .001. Interestingly, 8 of 12 HR patients with NR3C1/BTG1 deletions failed or died during induction. Discussion Discussion This cohort represents the largest and most comprehensive genetic study of relapsed childhood BCP-ALL. Our previous studies have reported convincing evidence for the prognostic relevance of genetic aberrations at initial presentation. [2,3] Here we provide compelling evidence that genetic biomarkers are important at predicting outcome in the relapse setting. The cytogenetic classification system, defined in our previous study, identified 3 risk groups with differential outcome; especially among SR patients. Observations from this study mirror those from initial disease presentation [3] and argue for the prospective genetic stratification of patients. CYTO-HR patients had a uniformly poor outcome, with high rates of induction failure/death and second relapse and may benefit from alternative therapeutic strategies. The 5-year PFS and OS rates for SR patients with CYTO-HR were 25% (95% CI, 8%-46%) and 29% (95% CI, 9%-52%) (Figure 2), which are almost identical to HR patients overall ( Table 2 ) and not different from CYTO-HR patients classified as HR ( Table 4 ; Figure 2). Although there were differences between CYTO-HR patients classified as SR and HR—most notably the distribution of iAMP21 and KMT2A translocations—this did not translate into a survival difference. Nearly two thirds of SR patients with CYTO-HR had iAMP21 and their OS at 5 years was just 20% ( Table 3 ). Despite the size of this study, we were limited in our ability to factor in the effect of MRD and treatment. Our analysis suggests that both postinduction MRD and genetics will be important risk factors in determining outcome in SR patients. This is the first study of relapsed ALL that has been able to examine the prognostic effect of CYTO-HR abnormalities by clinical risk group. Our data indicate that all CYTO-HR patients should be treated on future HR protocols regardless of clinical risk stratification. Even though ETV6-RUNX1 and HeH are established good prognostic markers, they still accounted for ∼50% of BCP-ALL patients treated in ALLR3. This high incidence reflects both their prevalence at initial diagnosis and the fact that recruitment started in 2003 and hence captured “good risk” patients suffering late relapses from earlier protocols. The outcome of SR patients with CYTO-GR was >70%. Although ETV6-RUNX1 and HeH were rare among HR patients, they did have a poor outcome. One possible explanation for the poor outcome of HR HeH patients is the presence of RAS pathway mutations. The frequency of RAS mutations among HeH patients at diagnosis is higher compared with other subgroups. [22,23] This study and the BFM study [10] confirm that this association prevails at relapse. SR patients with HeH and an NRAS mutation had a threefold increased risk of death. In the HR group, 6 of 10 HeH patients had a NRAS/KRAS mutation and 5 have died. A recent BFM ALL-REZ 2002 study has reported that RAS pathway mutations can influence outcome. [10] Moreover, it has recently been suggested that HeH clones are susceptible to RAS mutations, and specific combinations (eg, KRAS and CREBBP ) might cooperate to drive relapse. [24] Within the CYTO-IR subgroup, TCF3-PBX1 and IGH translocations were associated with a poor outcome. The prognostic impact of TCF3-PBX1 at initial diagnosis appears to be protocol-dependent, with historic studies reporting inconsistent results and recent intensive protocols achieving better outcomes. [1,3,25] This study indicates that if TCF3-PBX1 patients do relapse, they tend to relapse very early and have a poor response to treatment. In contrast to the St. Jude’s group, [25] we did not observe an association between TCF3-PBX1 and CNS relapse. The association of IGH translocations with age and poor outcome is consistent with our previous observations. [17,26] Secondary abnormalities can be acquired, lost, or enriched between initial diagnosis and marrow relapse. [8,9,12,27] Therefore, it is not surprising that the CNA risk profile proposed at initial diagnosis was not predictive of outcome when applied at relapse. [2] The incidence of IKZF1 deletions was similar among SR and HR patients, but was not prognostic in either group or overall. The ALL-REZ BFM 2002 trial reported a negative prognostic impact of IKZF1 deletions at relapse. [14] Although the 2 studies used the same detection strategy, there were differences in the composition of the cohorts: (1) the BFM study included more patients with BCR-ABL1 or Down syndrome (13/204 [6%] vs 4/224 [2%], P = .02); (2) the proportion of very early relapses was lower in ALLR3 overall (10% vs 18%, P = .005) and among IKZF1 -deleted patients (8% vs 26%, P = .02). Hence, IKZF1 -deleted patients in the BFM study were more likely to be associated with HR clinical risk factors, most notably shorter CR1 duration. This observation further supports the idea that the prognostic effect of IKZF1 deletions is context-dependent. [28-30] Our analysis revealed that TP53 alterations were significantly more prevalent in the HR group but associated with an inferior outcome in both the SR and HR groups. Indeed within the HR group, none of the patients with a TP53 alteration survived. TP53 mutations and 17p13 deletions occurred at an increased frequency in the CYTO-HR groups at initial diagnosis [31,32] and have been linked with a poor outcome at relapse. [12] The overall frequency of TP53 alterations was similar in the ALLR3 and BFM cohorts (12%), as was the frequency of TP53 loss (9%); despite the use of different detection strategies (MLPA vs cytogenetics). The frequency of TP53 mutations was lower in the ALLR3 study (3% vs 8%, P = .02), which led to a lower number of ALLR3 cases harboring a defect in both TP53 alleles (ie, a double-hit [9 vs 3 cases]). Recent studies have demonstrated a strong correlation between TP53 mutations and selected cytogenetic subgroups, namely low hypodiploidy and MYC translocations. [31,32] In this study, only one TP53 mutated case was found along with low hypodiploidy, whereas the remainder had various chromosomal abnormalities—HeH, ETV6-RUNX1 , TCF3-PBX1 , KMT2A , and B-other. This observation mirrored the BFM study, [12] suggesting the distribution of TP53 mutations at relapse is different from initial diagnosis. Loss of NR3C1 and BTG1 has been implicated in resistance to glucocorticoids, which is a key component of ALL therapy. [33-35] NR3C1/BTG1 deletions were present in 12% of cases but were more common among cytogenetic and clinical high-risk patients. The deletions were associated with an inferior outcome in both SR and HR groups, but the effect appeared strongest in the HR group, where it correlated with a high rate of induction failure and death. These observations are consistent with the results of a recent BFM study showing an association between NR3C1 deletion and poor outcome in relapsed ETV6-RUNX1 ALL. [36] Further studies are required to establish whether this poor outcome is linked directly to glucocorticoid resistance or whether it is part of a broader drug resistance profile. One third of relapsed patients harbored a mutation in the RAS signaling pathway, with KRAS and NRAS mutations being the most prevalent (12% cases each). The incidence and distribution of RAS pathway mutations (88% G12/13 mutations; supplemental Table 3) was consistent with that observed by the BFM group. [10] The BFM study suggested that KRAS mutations were stronger predictors of outcome, whereas our study implicated NRAS mutations especially in SR patients with HeH. It is not yet known whether KRAS and NRAS mutations have different functional consequences, and taken together, these 2 studies suggest that NRAS/KRAS mutations confer significant chemoresistant properties to the relapse clone. The in vitro and in vivo evidence that NRAS - and KRAS -mutated clones were sensitive to the MEK inhibitors selumetinib and trametinib, provides a potential targeted therapy strategy for this subset of patients. [10,11] The outcome of patients with relapsed ALL remains unsatisfactory. Current risk stratification in BCP-ALL is based primarily on CR1 duration. The integration of genetic data into the current risk classification indicates that SR patients with CYTO-HR have a very poor outcome and therefore require alternative treatment. Furthermore, our data suggest that many patients with CYTO-GR are still chemosensitive. A combination of clinical and genetic risk factors could therefore be used to define a subgroup of relapsed patients that may be spared SCT. We have confirmed the adverse effect of TP53 alteration reported by a BFM study [12] and provide evidence that the poor outcome associated with NR3C1 deletions extends beyond ETV6-RUNX1 . [36] In conclusion, the screening of patients at relapse for key genetic abnormalities will enable the integration of genetic and clinical risk factors to improve patient stratification and outcome. ",
				"clientUrl": "/viewarticle/867431",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 5005273,
				"leadConcept": "Acute Leukemia",
				"concept": ["Acute Lymphoblastic Leukemia", "Pediatric Oncology", "Hematology", "Tumor Pathology", "Tumor Genetics", "Pure B-Cell Disorders", "Biomarker", "Prognosis"],
				"leadSpecialtyId": 7,
				"leadSpecialty": "Hematology-Oncology",
				"allSpecialties": ["Hematology-Oncology", "Pediatrics", "Pathology & Lab Medicine"],
				"contentGroup": "Journal Article",
				"origContentType": "Journal Article",
				"contentType": ["Journal Article"],
				"description": "In relapsed childhood B-cell precursor acute lymphoblastic leukemia, integrating genetic and clinical risk factors improves prognostication.",
				"legacyID": 867431,
				"pubDisplay": "Blood",
				"siteOn": 2003,
				"title": "Integration of Genetic and Clinical Risk Factors Improves Prognostication in Relapsed Childhood B-cell Precursor Acute Lymphoblastic Leukemia",
				"suppressComment": "F",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/Blood-thumb.jpg"],
				"publicationDate": 1471496400000,
				"postingDate": 1471496400000,
				"_version_": 1573508877870170112,
				"last_index_date": 1500615003482
			}, {
				"id": "pdctm_0901c79180b1b7f6",
				"activeCME": 1,
				"activityExpirationDate": 1521954000000,
				"authors": ["Sandra Burke"],
				"body": "Welcome Slide 1. Slide 1. Updates to Managing Diabetes in the Long-Term Care Setting 3 2016 ADA Position Statement Slide 2. Slide 2. Managing Diabetes in Long-Term Care and Skilled Nursing Facilities: 2016 ADA Position Statement Normal age-related physiologic changes put older adults at high risk for type 2 diabetes, the most common type of diabetes in the elderly [1] According to the Centers for Disease Control and Prevention, 25.9% of the older adult population has diabetes [2] American Diabetes Association published its first ever position statement on managing diabetes in long-term care (LTC) in 2016 [3] Challenges and Goals in LTC Facilities Slide 3. Slide 3. Challenges of LTC Facilities [3] Older adults with diabetes are more likely to have functional disabilities, hypertension, heart disease, stroke, and premature death than older adults without diabetes Older adults with diabetes are more likely to experience geriatric syndromes, specifically, pain, polypharmacy, cognitive impairment, urinary incontinence, and falls Staff have varying levels of knowledge, skill, and abilities in working with residents who have long-standing diabetes In LTC, residents are assessed once every 60 days Slide 4. Slide 4. Goal 1: Know Your Targets [3] Glucose target levels need to be individualized, and are dependent on a number of factors: Age, life expectancy, cognitive status, functional ability (including level of frailty), comorbid conditions, and diabetes complications Blood glucose levels less than 100 mg/dL are not desirable in frail, older adults Slide 5. Slide 5. Goal #2: Liberalize the Diet [3,4] There is no such thing as a diabetic diet anymore Slide 6. Slide 6. Goal #3: Avoid Sliding Scale Insulin [3,5] Clinical staff and prescribers should consider developing standardized practices for converting residents from sliding scale insulin to scheduled insulin therapy 4 Interpreting Blood Glucose Logs Slide 7. Slide 7. Role of Blood Glucose Monitoring: Frequent Monitoring -- Look for Patterns One purpose of frequent blood glucose monitoring is to look for patterns A blood glucose log, or flow sheet, can be used by LTC staff, including nurses, pharmacists, and dietitians, to examine for patterns or incidences of hypo/hyperglycemia Slide 8. Slide 8. Role of Blood Glucose Monitoring: Check for Stability/Glucose Variability Another purpose of blood glucose monitoring is to check for stability or variability in blood glucose values Factors that can lead to variability in blood glucose include changes in carbohydrate intake, changes in physical activity, aging, and progression of the disease Slide 9. Slide 9. Role of Blood Glucose Monitoring: Spot-Check – All Values in Target Range Another role of blood glucose monitoring is to spot-check Less frequent blood glucose monitoring may be appropriate for a resident without symptoms of hypoglycemia or hyperglycemia whose appetite and blood glucose values are stable Slide 10. Slide 10. Role of Blood Glucose Monitoring: Identify Hypoglycemia One very important role of blood glucose monitoring is to identify hypoglycemia Older adults do not always have typical symptoms of hypoglycemia Symptoms in LTC residents with diabetes may be confusion, dizziness, and/or delirium Use finger stick glucose to confirm all suspected hypoglycemia episodes Blood glucose logs can be used to change/modify therapy 5 Summary Slide 11. Slide 11. Summary [3,6] Slide 12. Slide 12. Thank you for participating in this activity. This content has been condensed for improved clarity. ",
				"clientUrl": "/viewarticle/876732",
				"creditType": ["Nurse CE"],
				"cmeFlag": "CE",
				"leadConceptId": 1069,
				"leadConcept": "Type 2 Diabetes Mellitus",
				"concept": ["Diabetes Mellitus", "Hyperglycemia", "Hypoglycemia", "Nursing Homes", "Disease Management", "Geriatrics", "Clinical Guidelines", "Treatment Guidelines", "Long-Term Care", "Diet", "Geriatric Nursing", "Insulin Therapy", "Public Health Nursing", "Blood Glucose Test", "Disease Surveillance"],
				"leadSpecialtyId": 24,
				"leadSpecialty": "Nursing",
				"allSpecialties": ["Nursing", "Medscape Today", "Diabetes & Endocrinology", "Family Medicine/Primary Care", "Public Health & Prevention"],
				"origContentType": "Commentary",
				"contentType": ["Expert Commentary"],
				"description": "In this audio commentary, Sandra Burke, PhD, RN, highlights the purpose and utility of the 2016 ADA guidelines for managing diabetes in LTCFs.",
				"legacyID": 876732,
				"mediaFlag": "2",
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Updates to Managing Diabetes in the Long-Term Care Setting",
				"suppressComment": "T",
				"creditsAvailable": ["Nurses:ANCC Contact Hour(s):0.25"],
				"maxCredits": [0.25],
				"multimedia": ["/thumbnail_library/876732.jpg"],
				"publicationDate": 1490418000000,
				"postingDate": 1490418000000,
				"_version_": 1573508882730319872,
				"last_index_date": 1500615008100
			}, {
				"id": "pdctm_0901c79180a7c8ea",
				"activeCME": 1,
				"activityExpirationDate": 1509685200000,
				"authors": ["News Author: Larry Hand \nCME Author: Charles P. Vega"],
				"body": "Clinical Context High blood pressure is a highly common finding in the United States, affecting tens of millions of US adults. However, the best practice for the management of high blood pressure remains controversial. The authors of the current study provide a background in the debate over hypertension management. Research from epidemiologic studies suggests a continuous rise in the risk for cardiovascular events among adults as the systolic blood pressure increases past 115 mm Hg. However, the results from clinical trials have been less supportive of systolic blood pressure targets less than 130 mm Hg. Nonetheless, the data remain conflicting. The Systolic Blood Pressure Intervention Trial (SPRINT) randomly assigned adults with a high risk for cardiovascular events to a target systolic blood pressure of less than 140 mm Hg (standard therapy) or 120 mm Hg (intensive therapy). The intensive therapy cohort experienced a 25% reduction in the risk for incident cardiovascular events, as well as a reduction in mortality. Importantly, SPRINT excluded adults with a history of diabetes. These results were contradicted in the Heart Outcomes Prevention Evaluation - 3 (HOPE-3). A less intensive approach of reducing blood pressure among adults with an intermediate risk for cardiovascular events failed to improve the main study outcome of macrovascular events. What are the broad public health implications of the controversy in blood pressure management? How do individual clinicians use this disparate data to guide patient care? The current study by Navar and colleagues evaluates these issues. Study Synopsis and Perspective Clinicians should consider a person's cardiovascular disease risk factors in addition to blood pressure and not rely on clinical-trial data in diagnosing and treating hypertension, according to new research. [1] \"Most patients with a systolic blood pressure between 120 and139 mm Hg are not at high risk for CVD [cardiovascular disease]. However, rigorously applying clinical-trial criteria would miss a large number of high-risk patients who do fall into this gray area,\" first author Dr Ann Marie Navar (Duke Clinical Research Institute, Durham, NC) told heart wire from Medscape. \"Similar to how we approach treatment of cholesterol, clinicians should consider CVD risk when determining a treatment strategy for hypertension,\" she said. Navar and colleagues assessed how two recent clinical trials, SPRINT and HOPE-3, relate to treating everyday patients. [2][3] SPRINT demonstrated that aggressive treatment of hypertension has a significant benefit, [4] but HOPE-3 found no consistent benefit from such an approach. [5] Their results were published online September 7, 2016, in JAMA Cardiology . The researchers analyzed data on 14,142 adults 20 to 79 years old who participated in the 2007-2012 National Health and Nutrition Examination Survey (NHANES). They estimated the number and characteristics of adults with systolic blood pressure of at least 120 mm Hg, then estimated who might require treatment or treatment intensification if clinical-trial or risk-based criteria were applied. They estimated that 53.3 million untreated and 19.8 million treated US adults have a systolic blood pressure that falls within the 120- to 139-mm Hg diagnostic and treatment gray zone. A small proportion would have been eligible for SPRINT or HOPE-3. Further, they calculated that even for persons with prior or at high risk for cardiovascular disease, few would have been eligible for SPRINT (27% treated and 21.9% untreated) or HOPE-3 (10.6% treated and 2.1% untreated). \"A substantial number of adults in the US have a systolic blood pressure between 120 and 139 mm Hg but would not have qualified for SPRINT or HOPE-3,\" Navar told heartwire . The researchers conclude in their analysis, \"Further trial data will ideally clarify how, when, and whom to treat more intensely. In the interim, we propose a diagnosis-based approach that takes into consideration not only a person's BP [blood pressure] but also the overall CVD risk.\" Navar elaborated, \"First, patients with prior CVD are automatically considered high risk. For the primary-prevention group, the SPRINT trial used the Framingham risk calculator, although the new pooled cohort equations may be more generalizable to the population. Both calculators use a combination of age, sex, blood pressure, cholesterol, diabetes status, and smoking status. These calculators are a good starting point, but clinicians may also want to consider other risk factors, including family history, obesity, coronary artery calcium, and physical activity.\" In an accompanying commentary, [6] Dr Paul K Whelton (Tulane University School of Public Health and Tropical Medicine, New Orleans, LA), a SPRINT investigator, and colleagues wrote that the two clinical trials were fundamentally different in design and geographically and demographically. \"The central message is more intensive treatment in SPRINT provides a very dramatic benefit. Many practitioners are more attentive to their efforts to lower blood pressure,\" Whelton told heartwire . \"I hope that out of this we will get back to a more forthright discussion of how we measure blood pressure in medical practice.\" Drs Salim Yusuf and Eva Lonn (McMaster University, Hamilton, ON), HOPE-3 investigators, also co-wrote an accompanying commentary. [7] Yusuf told heartwire , \"I don't think the SPRINT approach is applicable to the majority of centers even in the Western countries like Canada and the US. \"The real message is if blood pressure is elevated treat it with an approach that is appropriate to your resource level. If you want the blood pressure way down, do so only if you have a lot of staffing and you're willing to monitor the patient carefully. It's a fair approach, but the issue is how applicable it is to the majority of people with hypertension,\" he said. How Low to Go? In another study, published online August 30, 2016, [8] Dr Philippe Gabriel Steg (Hospital Bichet, Paris, France) and colleagues analyzed data on 22,672 patients with stable coronary artery disease and treated for hypertension in routine clinical practice. They found that for this subpopulation, systolic blood pressure below 120 mm Hg and diastolic blood pressure of less than 70 mm Hg were associated with adverse cardiovascular outcomes, including mortality. \"Our study is observational and cannot compare with prospective randomized intervention trials, which are needed to guide therapy,\" Steg told heartwire . \"Our results are, however, not contradictory with those of SPRINT because we used 'casual office blood pressure,' whereas they used a 'perfect' rest measurement, which has less variability. Casual office BP can overestimate 'real' BP by up to 15 mm Hg. Therefore, 120 mm Hg in the SPRINT trial may correspond to 125, 130, or even 135 mm Hg in routine clinical practice, where clinicians use casual measurements,\" he said. \"Our results apply to a specific subset of hypertensive patients: those with stable coronary artery disease. I would not dare extend our results to other types of patients with hypertension,\" he said. Dr Navar discloses receiving research funding from Sanofi and Regeneron; disclosures for the coauthors are listed in the original article. Dr Whelton and coauthors have disclosed no relevant financial relationships. Drs Yusuf and Lonn were principal investigators of the HOPE-3 trial, which was funded by AstraZeneca and the Canadian Institutes of Health Research. Dr Lonn discloses receiving research support from AstraZeneca, Amgen, Bayer, GlaxoSmithKline, Eli Lilly, and Sanofi; consulting and/or lecture honoraria from Amgen, Sanofi, and Novartis; and travel support from Sanofi. Dr Yusuf discloses receiving research support from Boehringer Ingelheim, AstraZeneca, Bayer, Merck, Bristol-Myers Squibb, Cadila, and Novartis and honoraria and travel expenses from Bayer. Dr Steg discloses receiving grants, personal fees, and nonfinancial support from Servier during the conduct of the study; personal fees from Amarin, AstraZeneca, Bayer, Boehringer Ingelheim, Bristol Myers-Squibb, Daiichi-Sankyo, GlaxoSmithKline, Lilly, Merck Sharpe Dohme, Novartis, Pfizer, Roche, Medtronic, Servier, Janssen, CSL Behring, and Regeneron; grants and personal fees from Sanofi; and personal fees and nonfinancial support from the Medicines Company outside the submitted work. Disclosures for the coauthors are listed in the original article. Study Highlights Research data were drawn from adults between 20 and 80 years old who underwent a health evaluation as part of NHANES between 2007 and 2012. Systolic blood pressure was measured and averaged across 3 readings. Antihypertensive use was determined by patient self-report. Resistant hypertension was defined as the use of 3 different antihypertensive medications, including a diuretic. Researchers calculated 10-year risks for cardiovascular disease based on participant data. Participants with a 10-year risk of 15% or more were considered as having a high risk for cardiovascular disease. Researchers extrapolated data from their sample to the larger US adult population. The focus of the study was the epidemiology of hypertension and the number of adults that would qualify for the SPRINT and HOPE-3 studies. The study sample included 14,142 adults, 50.5% of whom were women. The average age of the participants was 45.9 years. 6.1% of adults were found to have untreated hypertension (systolic blood pressure ≥140 mm Hg and not receiving treatment). An estimated 25.8% of participants had a systolic blood pressure between 120 and 139 mm Hg. 21.6% of participants received at least 1 antihypertensive medication, and 5.4% had a systolic blood pressure in excess of 140 mm Hg despite treatment. An estimated 21.9% of patients with poorly controlled hypertension were taking 3 or more antihypertensive drugs. 9.6% of participants had a systolic blood pressure between 120 and 139 mm Hg while receiving treatment with antihypertensive drugs. Among participants with an untreated systolic blood pressure between 120 and 139 mm Hg, only 10.8% had a high risk for cardiovascular disease. This rate rose to 36.3% among adults with an untreated systolic blood pressure above 140 mm Hg. The prevalence of high cardiovascular risk was generally higher among adults with treated hypertension. Only 5.4% of adults with an untreated systolic blood pressure between 120 and 139 mm Hg would have been eligible for SPRINT, and 4.4% would have been eligible for HOPE-3. If a new target systolic blood pressure of 120 mm Hg or less was established for patients with high cardiovascular risk or previous cardiovascular disease, an additional 3.2% of adults (6.6 million people) would require treatment intensification, and 27.2% of additional adults would have resistant hypertension. The authors conclude by advocating for a risk-based strategy to treat hypertension, with a focus on the patient's overall cardiovascular risk profile vs the blood pressure value alone. Clinical Implications Epidemiologic data suggest a continuous rise in the risk for cardiovascular events when systolic blood pressure increases above 115 mm Hg, but data from clinical trials do not consistently support lower blood pressure targets. Results from SPRINT suggest better outcomes with a target systolic blood pressure of less than 120 mm Hg among high-risk adults, but results from HOPE-3 contradict these data. The current study by Navar and colleagues finds that elevated blood pressure is very common among US adults, yet only a small minority of adults would have qualified for the entrance criteria for SPRINT. The authors conclude by advocating for a risk-based strategy to treat hypertension, with a focus on the patient's overall cardiovascular risk profile vs the blood pressure value alone. Implications for the Healthcare Team: The current study confirms the high prevalence of elevated blood pressure in the United States. The evaluation of each patient's cardiovascular risk requires data synthesis, and the healthcare team should have this information readily available when faced with treatment decisions. CME Test 3 ",
				"clientUrl": "/viewarticle/870664",
				"creditType": ["CME", "Nurse CE", "Pharmacist CE", "ABIM MOC"],
				"cmeFlag": "CME / ABIM MOC / CE",
				"leadConceptId": 281,
				"leadConcept": "Hypertension",
				"concept": ["Controlled Hypertension", "Hypertensive Cardiovascular Disease", "Increased Blood Pressure", "Cardiovascular disease (CVD)", "Coronary Artery Disease (CAD)", "Cardiovascular Risk Management", "Cardiovascular Nursing", "Antihypertensive Agents", "Public Health Nursing", "Guidelines for Hypertension", "Primary and Secondary Prevention of Coronary Artery Disease", "Coronary Heart Disease Risk Factors"],
				"leadSpecialtyId": 2,
				"leadSpecialty": "Cardiology",
				"allSpecialties": ["Cardiology", "Medscape Today", "Internal Medicine", "Diabetes & Endocrinology", "Nursing", "Pharmacist", "Family Medicine/Primary Care", "Public Health & Prevention"],
				"contentGroup": "Clinical Review",
				"origContentType": "Clinical Brief",
				"contentType": ["News"],
				"description": "Is there a best practice for the management of hypertension? A new data analysis explores the options, suggesting that cardiovascular risk be considered.",
				"legacyID": 870664,
				"pubDisplay": "Heartwire CME",
				"siteOn": 2003,
				"title": "Treat the Risk, Not Just the Numbers, for Hypertension",
				"suppressComment": "T",
				"creditsAvailable": ["PhysiciansFamily Physicians:AMA PRA Category 1 Credit(s)™AAFP Prescribed credit(s):0.25", "US Physicians:Points for ABIM MOC:0.25", "Nurses:ANCC Contact Hour(s):0.25", "Pharmacists:Knowledge-based ACPE:0.25", "Physicians:AMA PRA Category 1 Credit(s)™:0.25"],
				"maxCredits": [0.25],
				"publicationDate": 1478149200000,
				"postingDate": 1478149200000,
				"_version_": 1573508891790016512,
				"last_index_date": 1500615016738
			}, {
				"id": "pdctm_0901c79180b51eb3",
				"activeCME": 1,
				"activityExpirationDate": 1529125200000,
				"authors": ["Davida F. Kruger"],
				"body": "Educational Impact Challenge Assess your clinical knowledge by completing this brief survey. Answering these questions again after the activity will allow you to see what you learned and to compare your answers with those of your peers. 3 The Increasing Role of Continuous Glucose Monitoring Continuous glucose monitoring (CGM) is available for both professional and personal use. During the past 10 years, significant advances have been made in CGM. Clinicians have become comfortable with patients' self-monitoring of blood glucose (SMBG) as a standard of patient care; however, SMBG can give information on only 1 point in time. SMBG does not provide sufficient data points to allow the patient or the healthcare provider (HCP) to know when patients are hypoglycemic or hyperglycemic. [1] It is difficult to get any blood glucose data when the patient is sleeping; these are often data that are needed to keep the patient safe and to help patients get to treatment goal. In addition, most insurance companies will pay for only 2 blood glucose strips a day. It is then up to the HCP to document the need for additional test strips and to make the case on behalf of the patient for more blood glucose test strips. Even with additional test strips, most patients are not able to test more often than 4 to 7 times per day. As such, during a 24-hour period, 4 to 7 data points do not provide an accurate picture of what is needed to adequately help patients control their diabetes and to keep them from experiencing either hypoglycemia or hyperglycemia. Too many patients are having dangerously low blood glucose levels and are unable to detect these levels. In 2017, CGM technology is more accurate than it has ever been. The use of professional CGM in clinical practice allows the HCP to use the data to visualize the patient's blood glucose levels continuously during a 24-hour period. Initially, the healthcare community believed that CGM would be used only for patients who had type 1 diabetes. In reality, patients who have type 2 diabetes have many of the same issues as patients with type 1 diabetes, including not being able to detect low blood glucose levels and wide variability in their blood glucose levels. Patients with type 2 diabetes are taking multiple injections of insulin and using insulin pumps; they are at risk for hypoglycemia. Examples of patients with both type 1 and type 2 diabetes who would benefit from professional CGM include but certainly is not limited to: individuals who are not achieving treatment goals, individuals who are achieving treatment goals and there is a concern they may be having undetected low blood glucose, individuals who report low blood glucose they are unable to detect, insulin requiring patients, patients who may be checking blood glucose 2-4 times daily and more data is needed to make quality decisions, and patients who wish to own personal CGM. [2,3] There are many other reasons to use professional CGM in clinical practice in both individuals with type 1 and type 2 diabetes including helping to help guide the clinician in assisting the patient with their diabetes care and for the patient to better understand what happens to their blood glucose continuously over the period of time they wear CGM. From time to time we have patients that do not wish to wear a device; typically these are patients who do not want to own personal CGM. Although professional CGM is worn over a short period of time, it allows the patient and the health care provider to obtain thousands of blood glucose data to assist in the management of their diabetes. Patients are usually willing to wear a CGM for this time frame and learn so much from the data. Many of the barriers to the use of CGM are created by the HCP. [4] If the HCP is not comfortable with what CGM is, the value it brings to his or her practice, and how to interpret the data, the HCP may not offer it to the patients in his or her practice. HCPs may also falsely believe that the use of CGM is limited to patients with type 1 diabetes. Another limitation is lack of insurance coverage or the belief that CGM is not covered by insurance. It has been our experience that professional use CGM in patients with type 1 or type 2 diabetes is covered regardless of the insurance provider, including Medicare and Medicaid. In 2017, Medicare is providing coverage for professional CGM based on their guidelines. [5] Patient Education and Introduction to CGM In our practice, we have patients try professional CGM before moving them to personal CGM. We want them to understand what CGM is and what it is not. It is our starting point for educating the patient. All patients owning personal CGM devices are required to attend an educational class once they have been their device in hand. We want patients to be successful with the use of CGM and to benefit from all the device offers. The class instructor will walk patients through how to insert their sensor, discuss skin care, provide tricks to keep the sensor in place, and teach them when to change the sensor, and how to calibrate. Most importantly, we want the patient to own the data that the CGM provides. We want the patient to use the CGM data on a day-to-day basis, to use the trends arrows to help with the use of insulin and the treatment of low blood glucose levels. For the big picture, we ask patients to download the data and look at their weekly trends to see if adjustments need to be made to their overall diabetes management. Our patients have an opportunity to share these data if they want one of the HCPs to help make changes in their diabetes management between visits. At clinic visits, data are reviewed and used to assist patients to better understand how to manage their diabetes. Based on the data, we can help patients understand how to adjust their medication or how to treat a low blood glucose reading. To give an example of how personal CGM devices work, if a patient has a blood glucose level of 200 mg/dL with a downward arrow showing on the device, then that patient should not take extra insulin. If the blood glucose level is 200 mg/dL with an upward arrow showing on the device, then it is suggested that the patient correct the blood glucose level with the use of additional insulin. Research has shown that patients are more comfortable following the arrows and are more likely to correct low blood glucose levels without overcorrecting because they can see what is happening to their blood glucose levels. [6] In my clinical practice, I tell patients to look on their CGM device not only at the day-to-day data but also, once a week, at a week's worth of data so that the patients can see trends occurring over time. The Development of the Ambulatory Glucose Profile A CGM user can download the CGM device, similar to blood glucose monitoring devices, to show glucose readings and create reports. Each device provides the data through the use of different formats and graphs. Therefore, when an HCP is looking at the data, he or she has to recognize what device was used and interpret the data based on how it is presented. This can get tricky in a busy practice. The ambulatory glucose profile (AGP) is a program developed as a standard way of looking at the data provided by a continuous glucose monitor or blood glucose monitor. [7] The result is like an electrocardiogram; regardless of the manufacturer of the electrocardiograph, the printouts from each electrocardiogram are identical in format. The AGP enables downloading of the data from any blood glucose meter or any continuous glucose monitor into its system, and the output is a standardized report. The present CGM devices provide data that, in many instances, are more accurate than data from fingerstick measurements. The recent study REPLACE-BG compared CGM data with fingerstick data. [8] The results were sufficiently compelling that the US Food and Drug Administration approved the Dexcom G5 CGM device to be used instead of fingerstick devices to dose insulin. [9] Interpreting an AGP Report A standard AGP report of CGM is one page and includes 3 parts; the top part is a statistical summary (Figure). [7] This section provides glucose exposure information, variability data, and percentage of values in the target range. Next is a visual display, which provides modal day, created from the data collected, with 14 days of CGM data being best, if possible. An algorithm applied to the data generates the 5 curves of the AGP. The median blood glucose level is represented by the orange line, the 25th and 75th percentiles of the glucose levels are shown as the solid blue lines, and the 10th and 90th percentiles of the glucose levels are indicated by the dotted lines and are the outlier values. At the bottom of the report is the daily view, which is a thumbnail view of the glucose profile of each day. You can see the actual values if you hover it, but what you really want is to obtain the big picture. If you see episodes of hypoglycemia, then you can go back to the individual day or days and see whether the patient was having hypoglycemia on 1 or multiple days. This information will help you better understand how to adjust the patient's activity levels, food intake, and medications. Figure. An Example of a Standard AGP Report [7] 1500 1125 Presently AGP is used in the download reports of the Free Style Libre Pro (professional CGM) and the Ping/Vibe insulin pumps. Other CGM and pump companies are looking at utilization of this report as well. The goal moving forward would be for each company to have this as part or all of their download programs. The American College of Clinical Endocrinologists (ACCE) are working with each of the companies to move them to providing AGP as a standardized report for all downloads. Improving Time Management in Busy Practice Settings and the Role of the Nurse The CGM device provides accurate data in easy-to-interpret graphs that allow the HCP to be more efficient and effective in the care provided. In our clinical practice, we have more than 900 patients wear personal CGM devices. Rather than having to scroll through a blood glucose meter, look at a blood glucose diary, or download data from a blood glucose meter, all of which provide information on only a few points in time, when a patient wears a CGM device, an HCP can quickly download the data and see what has happened to that patient during the past 7 to 14 days continuously. The nurse is in a prime role to be able to use CGM to help his or her patients manage their diabetes. If a patient is performing only several blood glucose checks daily, it limits the feedback that can be provided to the patient. For patients wearing a CGM device, the data provided in addition to patients' responses to questions about food, food, activity, timing of medication, work scheduled, and stress allow HCPs to educate patients and inform them on how their nutrition and activities affect their blood glucose levels. Very often, patients do not know they are having low blood glucose. This is a prime opportunity for the HCP to look at the data, see if there is any pattern or problems with low blood glucose, and help ascertain what is causing the low blood glucose. The HCP can then educate the patient about the treatment of hypoglycemia, prevention of hypoglycemia, and adjustment of medication. Conclusion Personally, I cannot imagine practicing without the use and support of CGM. For the appropriate patients, using a CGM device provides them the opportunity to self-monitor their diabetes. Once the HCP learns how to use CGM, he or she will see how easy it is to incorporate into their practice. The nurse is in a prime place in health care to be the one to champion CGM and the use of AGP and to move this concept forward. Nurses spend time with the patients and educate the patients. CGM provides a picture of what is occurring during a 1-2-week period, providing 2000-3000 blood glucose values. The AGP produces easy-to-read charts and graphs for both the patient and the nurse to use to help with education and support of the patient. For the nurse to be able to incorporate the AGP into patient education is an amazing opportunity. Educational Impact Challenge What did you learn from this activity? Please click on the \"Next\" button to proceed to a brief survey to see how your knowledge improved after the education. You can also see how your answers compare with those of your peers. Educational Impact Challenge 4 ",
				"clientUrl": "/viewarticle/878707",
				"creditType": ["Nurse CE"],
				"cmeFlag": "CE",
				"leadConceptId": 1069,
				"leadConcept": "Type 2 Diabetes Mellitus",
				"concept": ["Diabetes Mellitus", "Type 1 Diabetes Mellitus", "Hyperglycemia", "Hypoglycemia", "Health Education and Counseling", "Disease Management", "Nursing Education", "Blood Glucose Test", "Glycemic Index", "Patient Assessment"],
				"leadSpecialtyId": 22,
				"leadSpecialty": "Diabetes & Endocrinology",
				"allSpecialties": ["Diabetes & Endocrinology", "Pediatrics", "Medscape Today", "Nursing", "Family Medicine/Primary Care"],
				"origContentType": "Commentary",
				"contentType": ["Expert Commentary"],
				"description": "Davida Kruger reviews the role of continuous glucose monitoring and the ambulatory glucose profile in diabetes management. ",
				"legacyID": 878707,
				"mediaFlag": "2",
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "The Nurse's Role in Glucose Monitoring and Data Interpretation",
				"suppressComment": "T",
				"creditsAvailable": ["Nurses:ANCC Contact Hour(s):0.25"],
				"maxCredits": [0.25],
				"multimedia": ["/thumbnail_library/878707.jpg"],
				"publicationDate": 1497589200000,
				"postingDate": 1497589200000,
				"_version_": 1573508896746635264,
				"last_index_date": 1500615021464
			}, {
				"id": "pdctm_0901c79180b11e47",
				"activeCME": 1,
				"activityExpirationDate": 1519966800000,
				"authors": ["News Author: Marcia Frellick", " CME Author: Laurie Barclay"],
				"body": "Clinical Context In the United States, hypertension is associated with significant healthcare costs and morbidity and is very common, with an overall prevalence of 29.0%, increasing to 64.9% among adults 60 years and older. Appropriate management lowers risks for cardiovascular, renal, and cerebrovascular disease and death. Particularly for adults 60 years and older, however, identifying optimal blood pressure targets is controversial. A new guideline jointly developed by the American College of Physicians (ACP) and the American Academy of Family Physicians (AAFP) offers evidence-based clinical recommendations regarding the benefits and harms of higher vs lower blood pressure targets for hypertension in adults 60 years and older. It is intended for all clinicians caring for adults 60 years and older with hypertension. Synopsis and Perspective The ACP and AAFP have released a joint practice guideline on systolic blood pressure targets for people 60 years and older with hypertension. The guidance calls for physicians to start treatment for patients who have a persistent systolic blood pressure at or above 150 mm Hg to achieve a target of less than 150 mm Hg to reduce the risks for stroke, cardiac events, and death. The recommendation was rated strong, with high-quality evidence. \"The evidence showed that any additional benefit from aggressive blood pressure control is small, with a lower magnitude of benefit and inconsistent results across outcomes,\" ACP's President Nitin S. Damle, MD, said in a news release. However, in some cases, a lower systolic target should be considered, according to the guidelines. If patients have a history of stroke or transient ischemic attack or have high cardiovascular risk, physicians should consider starting or increasing drug therapy to achieve systolic blood pressure of less than 140 mm Hg to reduce the risks for stroke and cardiac events. The authors note, however, that this recommendation was rated weak, with moderate-quality evidence. High cardiovascular risk generally includes patients with diabetes, vascular disease, metabolic syndrome, or chronic kidney disease, as well as older adults. The guidelines also emphasize that cost burden for patients should be considered in any treatment discussions. \"When prescribing drug therapy, clinicians should select generic formulations over brand-name drugs, which have similar efficacy, reduced cost, and therefore better adherence,\" they write. In addition, the guidelines stress that clinicians should periodically discuss the potential benefits and harms of specific blood pressure targets with the patient. The full guidelines, written by Amir Qaseem, MD, PhD, head of the ACP guidelines committee, and colleagues, were published online January 17 in the Annals of Internal Medicine . [1] A guideline summary will be published in the March/April 2017 issue of the Annals of Family Medicine . Lower Targets Also Have Risks In a supporting evidence review, [2] Jessica Weiss, MD, MCR, from the Portland Veterans Affairs Medical Center in Portland, Oregon, and colleagues warn that the benefits of a lower threshold (<140/90 mm Hg) should be weighed against risk. \"Tighter control may prevent, on average, roughly 10 to 20 events for every 1000 high-risk patients treated over 5 years across a population,\" they write. However, the tradeoff may be higher costs and greater risks for hypotension and syncope. \"On the other hand, we found that lower targets are unlikely to increase the risk for dementia, fractures, and falls or reduce quality of life,\" Dr Weiss and colleagues write. Most of the support for treatment targets of less than 140 mm Hg comes from a single trial that had a target of less than 120 mm Hg, the reviewers note. The Systolic Blood Pressure Intervention Trial (SPRINT), as previously reported by heartwire from Medscape, [3] compared benefit of a systolic target of less than 120 mm Hg vs less than 140 mm Hg and found substantial reductions in cardiac events and deaths with tighter control. However, the Action to Control Cardiovascular Risk in Diabetes (ACCORD) trial, which tested the same targets, did not show similar benefits. When SPRINT data were removed from the analysis, the effects on mortality were reduced and the effects on cardiovascular events were no longer significant, Dr Weiss and colleagues write. The guidelines mention \"white coat\" syndrome, which can skew blood pressure readings. Before changing any treatment plan, the authors urge physicians to ensure they are getting the most accurate numbers across time. ACP and AAFP did not have enough evidence to make recommendations regarding diastolic blood pressure targets. Substantial Improvements in Morbidity Possible In an accompanying editorial, [4] Michael Pignone, MD, MPH, from the Department of Medicine, University of Texas Dell Medical School in Austin, and Anthony J. Viera, MD, MPH, from the Department of Family Medicine, University of North Carolina in Chapel Hill, write that improving blood pressure control in this patient group has the potential to substantially reduce morbidity and mortality. They note that 65% of US adults 60 years and older have hypertension, and only approximately half (52.5%) have controlled blood pressure levels (defined as <140/90 mm Hg). \"Over 15% of persons with hypertension are unaware of their condition,\" they write. With the publication of the new ACP/AAFP guidelines, they say physicians who want to implement high-value prevention programs should take the following steps: offer accurate blood pressure measurement taken by a well-trained staff and offer training in home or ambulatory monitoring; routinely assess cardiovascular risk in patients older than 40 years and in some younger patients with prominent risk factors; train providers in shared decision making for the treatment of high blood pressure; create a registry to track patients with hypertension; and use additional nonvisit follow-up measures for patients with moderate to severe hypertension. \"Such programs, when implemented, have been associated with large improvements in blood pressure control and have the potential to significantly reduce hypertension-related morbidity and mortality, particularly in older adults,\" the editorialists write. The US Department of Veterans Affairs provided funding for the evidence review. The authors and editorialists have disclosed no relevant financial relationships. Ann Intern Med . Published online January 17, 2017. Review/Guideline Highlights A search of EMBASE, Cochrane Database of Systematic Reviews, MEDLINE, and ClinicalTrials.gov through January 2015 (MEDLINE through September 2016) identified 21 randomized controlled trials for primary outcomes of hypertensive treatment and 3 observational studies evaluating harms only. All-cause mortality, morbidity and mortality associated with stroke, major cardiac events (fatal/nonfatal myocardial infarction, sudden cardiac death), and harms were endpoints for systematic review. 9 trials had high-strength evidence that controlling blood pressure to less than 150/90 mm Hg lowers mortality (relative risk [RR], 0.90; 95% confidence interval [CI], 0.83-0.98), cardiac events (RR, 0.77; 95% CI, 0.68-0.89), and stroke (RR, 0.74; 95% CI, 0.65-0.84). Low- to moderate-strength evidence from 6 trials suggests that lower blood pressure targets (≤140/85 mm Hg) are linked with marginally significant reductions in cardiac events (RR, 0.82; 95% CI, 0.64-1.00) and stroke (RR, 0.79; 95% CI, 0.59-0.99) and a nonsignificant trend to lower mortality (RR, 0.86; 95% CI, 0.69-1.06). Lower blood pressure targets are not associated with increased falls or cognitive impairment, based on low- to moderate-strength evidence. Data are limited regarding frail elderly and the impact of multiple morbidities. On the basis of these findings, the reviewers concluded that in older adults with hypertension, treatment to at least current blood pressure guideline standards (<150/90 mm Hg) substantially improves health outcomes. However, evidence is less consistent that lower blood pressure targets benefit high-risk patients, and mostly comes from a single trial with systolic blood pressure target of less than 120 mm Hg. Although lower blood pressure targets were not associated with increased falls or cognitive decline, they did result in hypotension, syncope, and greater medication burden. On the basis of this systematic review, specific ACP/AAFP recommendations include the following: To lower risks for mortality, stroke, and cardiac events, clinicians should begin treatment in adults 60 years and older with systolic blood pressure persistently 150 mm Hg or higher to achieve a target systolic blood pressure of less than 150 mm Hg (strong recommendation, high-quality evidence). To lower the risk for recurrent stroke, clinicians should consider starting or intensifying pharmacologic treatment in adults 60 years and older with a history of stroke or transient ischemic attack to achieve a target systolic blood pressure of less than 140 mm Hg (weak recommendation, moderate-quality evidence). To lower the risk for stroke or cardiac events, clinicians should consider, based on individualized evaluation, starting or intensifying pharmacotherapy in some adults 60 years and older at high cardiovascular risk because of age, diabetes, vascular disease, metabolic syndrome, or chronic kidney disease. The target should be a systolic blood pressure of less than 140 mm Hg (weak recommendation, low-quality evidence). For all of these recommendations, treatment goals should be based on periodic discussions of benefits, harms, and cost burden of specific blood pressure targets. Generic formulations are preferred to brand-name drugs because of similar efficacy and lower cost, resulting in better adherence. An accompanying editorial recommends high-value prevention programs, which have been shown to improve blood pressure control and may significantly lower hypertension-related morbidity and mortality, especially in older adults. Such programs should include the following: accurate blood pressure measurement by well-trained staff; training in home or ambulatory monitoring; routine cardiovascular determination for patients older than 40 years and in younger patients with prominent risk factors; clinician training on shared decision making for hypertension treatment; hypertension registry; and additional nonvisit follow-up interventions for moderate to severe hypertension. Clinical Implications In older adults, treatment to at least current blood pressure guideline standards (<150/90 mm Hg) substantially improves health outcomes, based on a systematic review. To lower the risks for mortality, stroke, and cardiac events, a new ACP/AAFP guideline recommends that clinicians begin treatment in adults 60 years and older with systolic blood pressure persistently 150 mm Hg or higher to achieve a target systolic blood pressure of less than 150 mm Hg (strong recommendation, high-quality evidence). Implications for the Healthcare Team: Members of the healthcare team should be aware that high-value prevention programs have been shown to improve blood pressure control and may significantly lower hypertension-related morbidity and mortality, especially in older adults. CME Test 3 ",
				"clientUrl": "/viewarticle/876284",
				"creditType": ["CME", "Nurse CE", "Pharmacist CE", "ABIM MOC"],
				"cmeFlag": "CME / ABIM MOC / CE",
				"leadConceptId": 281,
				"leadConcept": "Hypertension",
				"concept": ["Hypertensive Cardiovascular Disease", "Cardiovascular disease (CVD)", "Coronary Artery Disease (CAD)", "Geriatrics", "Cardiovascular Risk Management", "Clinical Guidelines", "Treatment Guidelines", "Clinical Pharmacology", "Meta-Analysis", "Cardiovascular Nursing", "Geriatric Nursing", "Public Health Nursing", "Guidelines for Hypertension", "Primary and Secondary Prevention of Coronary Artery Disease", "Coronary Heart Disease Risk Factors"],
				"leadSpecialtyId": 2,
				"leadSpecialty": "Cardiology",
				"allSpecialties": ["Cardiology", "Medscape Today", "Internal Medicine", "Nursing", "Pharmacist", "Family Medicine/Primary Care", "Public Health & Prevention"],
				"contentGroup": "Clinical Review",
				"origContentType": "Clinical Brief",
				"contentType": ["News"],
				"description": "A new guideline from the American College of Physicians and American Academy of Family Physicians recommends treatment in adults 60 years and older with systolic blood pressure at or above 150 mm Hg.",
				"legacyID": 876284,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "ACP Releases Updated Hypertension Guidelines",
				"suppressComment": "T",
				"creditsAvailable": ["PhysiciansFamily Physicians:AMA PRA Category 1 Credit(s)™AAFP Prescribed credit(s):0.25", "US Physicians:Points for ABIM MOC:0.25", "Nurses:ANCC Contact Hour(s):0.25", "Pharmacists:Knowledge-based ACPE:0.25", "Physicians:AMA PRA Category 1 Credit(s)™:0.25"],
				"maxCredits": [0.25],
				"publicationDate": 1488430800000,
				"postingDate": 1488430800000,
				"_version_": 1573508878991097856,
				"last_index_date": 1500615004537
			}, {
				"id": "pdctm_0901c79180a6aed2",
				"activeCME": 1,
				"activityExpirationDate": 1507784400000,
				"authors": ["Meghan B. Brennan", " Barbara L. Herwaldt", " James J. Kazmierczak", " John W. Weiss", " Christina L. Klein", " Catherine P. Leith", " Rong He", " Matthew J. Oberley", " Laura Tonnetti", " Patricia P. Wilkins", " Gregory M. Gauthier"],
				"body": "Abstract and Introduction Abstract and Introduction Abstract Babesia microti , an intraerythrocytic parasite, is tickborne in nature. In contrast to transmission by blood transfusion, which has been well documented, transmission associated with solid organ transplantation has not been reported. We describe parasitologically confirmed cases of babesiosis diagnosed ≈8 weeks posttransplantation in 2 recipients of renal allografts from an organ donor who was multiply transfused on the day he died from traumatic injuries. The organ donor and recipients had no identified risk factors for tickborne infection. Antibodies against B. microti parasites were not detected by serologic testing of archived pretransplant specimens. However, 1 of the organ donor's blood donors was seropositive when tested postdonation and had risk factors for tick exposure. The organ donor probably served as a conduit of Babesia parasites from the seropositive blood donor to both kidney recipients. Babesiosis should be included in the differential diagnosis of unexplained fever and hemolytic anemia after blood transfusion or organ transplantation. Introduction Babesia microti , an intraerythrocytic parasite, is the most common cause of human babesiosis in the United States and is endemic to the Northeast and upper Midwest regions, including parts of Wisconsin and Minnesota. [1-4] B. microti infection can range from asymptomatic to severe. Common manifestations include hemolytic anemia and nonspecific influenza-like symptoms. [2] Persons who are asplenic, elderly, or immunocompromised are at increased risk for symptomatic infection and for severe complications, such as multiorgan dysfunction and death. [5] The primary route of transmission of B. microti parasites is by the bite of an infected Ixodes scapularis tick. [6] Transmission of Babesia parasites by blood transfusion also is well-documented. [7-11] In contrast, transmission associated with solid organ transplantation has not been reported. We investigated 2 cases of babesiosis for which transmission probably occurred when renal allografts were transplanted from a multiply transfused organ donor. Materials and Methods Materials and Methods Diagnosis of babesiosis in 2 persons who received kidney transplants from the same donor prompted multifaceted, collaborative investigations, which were conducted by the authors and acknowledged persons and agencies (e.g., transplant, transfusion, and public health organizations). The Organ Procurement Organization (Madison, WI, USA) identified the disposition of all organs and tissues recovered from the organ donor and notified the United Network for Organ Sharing (Richmond, VA, USA) about the possibility of donor-derived transmission. Only kidneys and corneas had been transplanted; the bilateral iliac arteries and veins had been recovered but discarded 14 days later, whereas the liver and other tissues that had been donated for research were embargoed. Medical and transfusion records of the organ donor and transplant recipients were reviewed, as were procedures and records for organ/tissue recovery, handling, and transplantation. The transplant recipients, the seropositive blood donor identified in the transfusion investigation, and surrogates for the organ donor were interviewed regarding risk factors for and potential clinical manifestations of Babesia infection. Specimens from the transplant recipients, the organ donor, and the organ donor's blood donors were tested for evidence of Babesia infection. Evaluations of the transplant recipients included light microscopy of Giemsa- or Wright-stained thick and thin blood smears for Babesia parasites. The Centers for Disease Control and Prevention (CDC; Atlanta, GA, USA) conducted reference diagnostic testing of specimens from transplant recipients and organ donor. CDC also conducted serologic testing by using an indirect fluorescent antibody (IFA) assay for total immunoglobulin against B. microti antigens. [12] Serum and plasma specimens were tested in serial 4-fold dilutions, and a reciprocal dilution titer of 64 was considered positive. CDC conducted PCR analysis of whole-blood specimens from the transplant recipients by using primers specific for the B. microti 18S rRNA gene [13] and a previously described 2-step nested PCR. [7] CDC also conducted B. microti PCR analysis of fresh-frozen hepatic tissue from the organ donor. No fresh-frozen renal tissue or whole-blood specimens from the organ donor were available for testing. However, paraffin-embedded, pretransplantation specimens from both kidneys were available and were tested by using a B. microti immunohistochemical (IHC) assay; [14] CDC also conducted IHC testing of hepatic tissue. The American Red Cross obtained blood/serum specimens from all 33 blood donors who had contributed components transfused into the organ donor. No segments or components from original donor units were available for testing. The American Red Cross tested postdonation specimens by using a B. microti IFA assay for IgG and a B. microti real-time PCR. IFA testing was conducted with serial 2-fold dilutions of samples. Case Reports Case Reports Renal Transplant Recipients In late August 2008, two men with end-stage diabetic nephropathy (a 65-year-old Wisconsin resident [patient A; the index case-patient] and a 41-year-old Iowa resident [patient B]) received renal allografts from the same deceased donor at the University of Wisconsin Hospital and Clinics (UWHC; Madison, WI, USA). Different surgeons in separate operating rooms transplanted the kidneys. Both patients received induction immunosuppressive therapy with basiliximab and maintenance therapy with prednisone, mycophenolate mofetil, and tacrolimus. During the previous year and peritransplant period, neither patient lived or traveled in babesiosis-endemic regions, which in the Midwest, included parts of Minnesota and Wisconsin but not Iowa ( Table ), and they did not receive blood transfusions. Figure 1. Timelines showing key clinical and laboratory events for 2 renal transplant recipients (patients A and B) infected with Babesia microti parasites, Wisconsin, USA, 2008. Trauma, transfusions, death, and organ procurement for the organ donor all occurred on the same day in late August 2008. NPF, no parasites were found by examination of thick and thin blood smears. Both patients showed seroconversion and development of parasitologically confirmed cases of babesiosis, which were diagnosed ≈8 weeks posttransplantation ( Table ; Figure 1). At the request of the transplant physicians, both patients were evaluated by the same UWHC infectious disease specialists. After babesiosis was diagnosed, doses of immunosuppressive medications were decreased and each patient received a 6-week course of oral antimicrobial drug therapy: atovaquone (750 mg, 2×/d for 6 wks) plus azithromycin (1,000 mg, 1×/d for 2 wks, followed by 600 mg, 1×/d for 4 wks). During therapy, symptoms resolved, laboratory parameters returned to reference ranges or values, and Babesia parasite DNA became undetectable ( Table ; Figure 1). Patient A On October 2, 2008 (≈5 weeks posttransplantation), during a routine follow-up appointment at the UWHC Transplant Clinic, the wife of patient A mentioned that he had a lack of energy and decreased appetite (onset date not specified). At that clinic visit, his hematocrit was 37%, which approximated his baseline value posttransplantation. On October 8, he was admitted to the UWHC, as planned, to have his peritoneal dialysis catheter removed the next day. However, at admission, he unexpectedly was found to have a temperature of 39.4°C. His hematocrit values were 33% and 28% on October 8 and 9, respectively. Removal of the catheter was postponed until October 10, and he was discharged after the procedure. Cultures of the catheter tip, blood, and urine specimens were negative for bacterial growth. He was treated empirically with piperacillin/tazobactam during his 2-day hospitalization, followed by a 7-day outpatient course of ciprofloxacin. Figure 2. Wright-stained peripheral blood smear from patient A (index case-patient), a renal transplant recipient infected with Babesia microti parasites, Wisconsin, USA, 2008. The smear shows intraerythrocytic Babesia parasites, a ring form (black arrow), and a Maltese cross or tetrad form (red arrow), which is pathognomonic for babesiosis. Scale bar indicates 10 μm. On October 16 (day 6 of ciprofloxacin therapy), his wife called the transplant coordinator to report that he had a low-grade temperature (37.5°C) and a 2-day history of drenching sweats. An appointment in the Transplant Clinic was scheduled for October 20 to evaluate his symptoms. During the appointment, he reported a several-day history of darkening urine and progressive fatigue since his previous hospitalization. Per routine for clinic visits, a complete blood count was determined. His hematocrit had decreased to 21% ( Table ). Because platelet clumping was detected by using an automated hematology analyzer, a blood smear was reviewed manually: intraerythrocytic Babesia parasites were visualized at a parasitemia level of 8% ( Table ; Figure 2). On the same day (October 20), he was admitted to the UWHC, evaluated by the Infectious Disease Service, and began treatment with azithromycin plus atovaquone ( Table ; Figure 1). Within 48 hours of initiating therapy, his appetite and exercise tolerance increased, and his parasitemia level decreased to <5%. Patient B During October 4–9, patient B was hospitalized in Iowa for evaluation of epigastric discomfort, dyspepsia, nausea, and low-grade fever of unclear etiology. His hemoglobin level was 12.1 g/dL. Computed tomography (CT) imaging of his abdomen and pelvis was unremarkable except for enlargement of the pancreatic head (amylase and lipase values were within reference ranges). While hospitalized, he was treated empirically with metronidazole and levofloxacin; a 7-day outpatient course of ciprofloxacin therapy was prescribed. Figure 3. Computed tomography (CT) scan of the abdomen of patient B, a renal transplant recipient infected with Babesia microti parasites, Wisconsin, USA, 2008. Taken on November 5, the scan shows a splenic infarction (white arrow) that had not been visualized on a CT scan on October 5. Although the cause of the splenic infarction was not determined, the infarction might have been a complication of babesiosis, as reported for other patients. 16,17 On October 23, during a routine follow-up appointment in the UWHC Transplant Clinic, he was afebrile but, on prompting, recalled a transient fever (38°C) ≈1 week earlier. In addition, he reported a several-week history of left upper quadrant pain. At examination, he had tenderness to deep palpation of the left upper quadrant, which worsened with deep inspiration. A manual (nonautomated) review of a blood smear was requested explicitly, prompted by diagnosis of the case of babesiosis in patient A 3 days earlier. Intraerythrocytic Babesia parasites also were observed on the blood smear for patient B; the parasitemia level was 1%. His hemoglobin level was 11 g/dL, and his hematocrit was 35%. On the same day, he was evaluated in the UWHC Infectious Disease Clinic and began outpatient therapy with atovaquone plus azithromycin. To evaluate his abdominal pain, CT of the abdomen and pelvis was performed on an outpatient basis (November 5); it showed a splenic infarction (Figure 3), which was not detected by CT in early October. During the course of antimicrobial drug therapy, his abdominal pain and constitutional symptoms resolved. Organ Donor The organ donor was a 22-year-old man who was a resident of an urban area of Wisconsin to which babesiosis was not endemic. According to his relatives and primary care physician, he had been in good health and did not have any potentially relevant travel or clinical manifestations during the previous year. His only known risk factor for exposure to Babesia parasites was receipt of multiple blood transfusions during resuscitation attempts on the day he died from unintentional trauma. Although an autopsy was not performed, a limited number of plasma, serum, and tissue specimens were available for Babesia testing. Antibodies against B. microti parasites were not detected by retrospective serologic testing of a pretransfusion plasma specimen and 2 posttransfusion serum specimens (IFA titer ≤8). Tissue sections from both kidneys had negative IHC results. IHC testing of hepatic tissue showed a few rare foci of suspicious staining but no definitive evidence of Babesia parasites, and hepatic tissue showed negative results by PCR. The cornea recipients were contacted, and blood specimens collected ≈3–4 months posttransplantation were tested for evidence of Babesia infection. Specimens showed negative results for PCR and IFA analysis, and no parasites were found on blood smears. Transfusion Investigation During resuscitation attempts, the organ donor received 20 cellular blood components (19 units of erythrocytes and 1 unit of apheresis platelets) and 13 plasma units. Only 1 of the 33 donors, a 52-year-old man, had evidence of B. microti infection. Specimens available for testing were collected 88 and 151 days postdonation and had IFA titers of 256 and 128, respectively; both specimens showed negative results by PCR. The seropositive blood donor was the source of 1 of the organ donor's last erythrocyte transfusions, which was transfused 15 days postdonation. This blood donor lived in a babesiosis-endemic area of Minnesota (Washington County) and had camped in disease-endemic areas in northern Wisconsin (Ashland County) in May 2008 and in northern Minnesota (Saint Louis County) in July 2008. During the retrospective investigation, he recalled a fever (39.4°C), chills, and diaphoresis, which lasted ≈36 hours, during the first week of June. Although he did not recall any tick bites, his wife reportedly had found a tick on his body (timing and other details not specified). No cellular components from his donation in August were transfused to other patients. After he was found to be seropositive, he was deferred indefinitely from future blood donations. However, he already had donated blood in the interim (in September 2008), and apheresis platelets from the donation had been transfused. A specimen obtained ≈2 months posttransfusion from the platelet recipient was tested in a commercial laboratory and showed negative B. microti IFA and PCR results. Discussion Discussion We investigated parasitologically confirmed cases of babesiosis in 2 recipients of renal allografts from an organ donor whose only known risk factor for exposure to Babesia parasites was the receipt of multiple blood transfusions on the day he died. The organ donor and the kidney recipients did not have antibodies against B. microti parasites detected by retrospective testing of pretransplantation specimens. However, 1 of the organ donor's blood donors was seropositive when tested postdonation and had risk factors for tick exposure. The most likely scenario is that the kidney donor served as a conduit of Babesia parasites from this blood donor to the kidney recipients (i.e., the blood donor became infected by tickborne transmission, secondary transmission occurred by erythrocyte transfusion, and tertiary transmission occurred by organ transplantation). The possibility that the kidney recipients became infected independently is remote: they did not live, travel, or receive medical care in any known babesiosis-endemic areas in the Midwest or elsewhere; they did not receive any transfusions; and they showed seroconversion posttransplantation, despite being immunosuppressed. Although no subtyping tools are available to establish that the patients were infected with the same B. microti strain, they almost assuredly became infected from the same source at approximately the same time. Previous reports have described organ transplant recipients who became infected with Babesia parasites by tickborne- or transfusion-associated transmission in the peritransplant period or thereafter. [10,18-22] Transplantation-associated transmission of B. microti parasites, which are not known to have an exoerythrocytic tissue phase, has not been described, nor has the occurrence of 3 consecutive routes of transmission (vector, transfusion, and transplantation), which has been reported for West Nile virus. [23,24] The plausibility of transplantation-associated transmission of B. microti parasites, in the context of residual parasites in the renal vasculature/fluids after flushing the organs, is supported in part by data from other contexts (e.g., transfusion-associated cases) that suggest low inocula of the parasite can cause infection. [10,25] Although we do not have proof that the blood donor was infected when he donated blood or have laboratory evidence that the organ donor briefly harbored the parasite, the negative PCR results for the postdonation specimens from the blood donor and the negative PCR and IHC results for the available posttransfusion specimens from the organ donor are not helpful; only positive results would have been informative. Although other transmission scenarios seem much less probable, the cases of babesiosis in the kidney recipients we report would be noteworthy even if the organ donor recently had acquired the parasite from a tick (i.e., was in the early window period of infection, despite his lack of known risk factors for tickborne transmission). Diagnosis of babesiosis in the kidney recipients prompted multiagency investigations of the organ donor and his blood donors. However, the cases of babesiosis in the recipients could have been easily missed, which highlights the possibility that other transplantation-associated cases have occurred but were not diagnosed or investigated. For patient A (index case-patient), babesiosis was diagnosed because of the serendipitous finding of parasites on a blood smear that was examined manually because of platelet clumping. His lack of risk factors for tickborne transmission and the possibility of donor-derived infection led to prompt evaluation of patient B. At the time of diagnosis, illness in patient B was milder (lower-level parasitemia, minimal anemia, and transient fever) than that in patient A, even though the 2 patients received similar immunosuppressive regimens. Babesiosis can be persistent, relapsing, or life threatening in immunocompromised patients. [18,19,22,26-28] Optimal therapy for babesiosis in patients who have received an organ transplant or have impaired immunity for other reasons is not well established and might depend on multiple factors; a uniform recommendation might not be applicable to such a heterogeneous population. In immunocompetent persons, the typical duration of antimicrobial drug therapy for babesiosis is 7–10 days. [6] We decided to treat both kidney recipients for 6 weeks on the basis of retrospective data for immunosuppressed patients that suggest the likelihood of cure is higher if combination antimicrobial drug therapy is administered for ≥6 weeks, including 2 weeks after Babesia parasites are no longer detected on blood smears. [27] We gave the patients atovaquone plus azithromycin rather than clindamycin plus quinine (the standard of care for severely ill patients [6,29] ) to minimize the likelihood of toxicity during their 6-week treatment courses. In addition, we decreased the doses of their immunosuppressive medications. Both patients tolerated and responded well to the antimicrobial treatment, without documented relapses. However, clinicians should be aware that clinical resistance reportedly developed in several immunosuppressed patients treated for prolonged periods with atovaquone plus azithromycin; [28] whether particulars of those patients' treatment regimens (e.g., antimicrobial drug dosing) contributed to development of clinical resistance is not known. [28,30] The cases of babesiosis we describe not only underscore the plausibility and likelihood of transmission by organ transplantation, but also highlight the emerging role of transfusion-associated babesiosis. For the 3-decade period of 1979 (the year the first known transfusion case occurred) through 2009, a total of 159 transfusion-associated cases of B. microti infection were identified in the United States, most (77%) of which occurred during 2000-2009. [10] Asymptomatic persons can fulfill all of the criteria for donating blood despite having low-level parasitemia sufficient to cause infection in a transfusion recipient. [10] To date, no Babesia tests for screening US blood donors have been licensed by the Food and Drug Administration, and no pathogen-reduction technologies for cellular blood components have been approved. [31-35] However, the Blood Products Advisory Committee of the Food and Drug Administration that was convened on May 13, 2015, supported the concepts of year-round B. microti serologic testing of all US blood donors and of B. microti nucleic acid-based testing of donors in selected states (details remain to be determined). [36] Because of donor travels and shipments/distributions of blood components, transmission by transfusion is not limited to babesiosis-endemic foci. [10] For example, the seropositive erythrocyte donor we identified had donated blood in a babesiosis-endemic area of Minnesota. This blood was then transported to and transfused in an area of Wisconsin to which babesiosis was not endemic. As we described, unrecognized tickborne transmission of Babesia parasites to the blood donor probably led to transmission by transfusion to the organ donor and subsequent transmission by organ transplantation to both kidney recipients. Clinicians should include babesiosis in the differential diagnosis of unexplained fever and hemolytic anemia after blood transfusion or organ transplantation, even in regions to which babesiosis is not endemic. Suspected cases of iatrogenic transmission should be reported to state and local public health authorities. In addition, cases that might be transfusion or transplantation associated should be reported to the pertinent blood center and organ procurement organization, respectively. ",
				"clientUrl": "/viewarticle/869734",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 0,
				"concept": ["Hemolytic Anemia", "Organ Transplantation", "Kidney Transplantation", "Tick-Borne Diseases", "Babesiosis", "Posttransplantation Infection", "Blood Transfusion"],
				"leadSpecialtyId": 3,
				"leadSpecialty": "Infectious Diseases",
				"allSpecialties": ["Infectious Diseases", "Hematology-Oncology", "Transplantation"],
				"contentGroup": "Journal Article",
				"origContentType": "Journal Article",
				"contentType": ["Journal Article"],
				"description": "Clinicians should consider babesiosis in the differential diagnosis of unexplained fever and hemolytic anemia after transfusion or organ transplantation.",
				"legacyID": 869734,
				"pubDisplay": "Emerging Infectious Diseases CME",
				"siteOn": 2003,
				"title": "Transmission of Babesia microti Parasites by Solid Organ Transplantation",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/EmergInfectDis-thumb.jpg"],
				"publicationDate": 1477976400000,
				"postingDate": 1476248400000,
				"_version_": 1573508886514630656,
				"last_index_date": 1500615011715
			}, {
				"id": "pdctm_0901c79180b11e48",
				"activeCME": 1,
				"activityExpirationDate": 1520053200000,
				"authors": ["News Author: Deborah Brauser", "   CME Author: Charles P. Vega"],
				"body": "Clinical Context Distinguishing between Parkinson disease (PD) and atypical parkinsonian disorders (APDs) --which include multiple system atrophy, progressive supranuclear palsy, and corticobasal degeneration -- can be challenging even for experienced clinicians, particularly at the early stages of disease. The authors of the current study note that concentrations of neurofilament light chain (NfL) protein in the cerebrospinal fluid (CSF) can aid in the identification of PD vs APDs. The source of NfL is large myelinated axons, and NfL levels may be elevated in acute conditions such as stroke and traumatic brain injury. NfL levels are also increased in chronic conditions such as amyotrophic lateral sclerosis and frontotemporal dementia. Although NfL levels in the CSF may be increased in APDs, they are generally not elevated among patients with PD. This reflects the greater degree of axonal degeneration in APDs vs PD. However, NfL generally does not help discriminate between different disease states of APDs. Patients are often reticent to undergo lumbar puncture to assess CSF levels of NfL. The current study by Hansson and colleagues assesses the potential value of a blood-based assay for NfL among patients with PD, APDs, and healthy control participants. Study Synopsis and Perspective Testing blood samples for NfL protein levels may help differentiate PD from APDs, new research suggests. Analysis of more than 500 total participants among 3 cohorts showed that blood NfL levels increased significantly in all subgroups with APDs -- including those with progressive supranuclear palsy, multiple system atrophy, and corticobasal syndrome -- compared with healthy volunteers or those with standard PD. The blood test had a specificity of 90% to 91% in distinguishing between PD and APDs in 2 of the cohorts and of 80% in the cohort comprising only those with disease duration of 3 years or less. In addition, \"I was somewhat surprised that the diagnostic accuracy of NfL in blood was just as good as when analyzing NfL in ...CSF,\" lead author Oskar Hansson, MD, PhD, professor of neurology at Lund University, Lund, Sweden, told Medscape Medical News . Dr Hansson added that although rare, ADPs usually progress much faster than PD and have more disabling symptoms, so providing the correct diagnosis is important for determining a patient's future needs. \"If the blood levels of NfL are increased in a certain patient with parkinsonism, then the results could be interpreted as a 'red flag,'\" he said. However, this type of test \"is only one piece of the puzzle,\" Dr Hansson noted. \"The neurological examination, patient history, and brain imaging will still be very important.\" The findings were published online February 8 in Neurology . \"Overlapping Symptomatology\" The investigators note that differentiating between PD and APDs \"is often difficult due to the overlapping symptomatology, especially during the early stages of the disease course.\" Past studies have shown increased CSF concentration of NfL in APDs but not in PD. \"However, lumbar puncture is not easily implemented in the primary care setting and may [have] patients feel apprehensive about [it], reducing the clinical usefulness of these findings,\" they write. \"It's important that patients with parkinsonism are correctly diagnosed,\" added Dr Hansson. \"Most with APD do not respond well to dopamine-targeting medications, and many...need to be handled by a team of movement disorder specialists.\" The current study included 3 prospective cohorts. All 3 included patients with PD, progressive supranuclear palsy, corticobasal syndrome, and multiple system atrophy. Only the Lund cohort and the London cohort also had healthy volunteers, whereas all of the patients in the third cohort had the disease for less than 4 years. Table 1. Number of Patients by Condition in Each Cohort Cohort PD MSA PSP CBS Healthy Volunteers Lund (n=278) 171 30 19 5 53 London (n=117) 20 30 29 12 26 Early disease (n=109) 53 28 22 6 0 CBS=corticobasal syndrome; MSA=multiple system atrophy; PD=Parkinson disease; PSP=progressive supranuclear palsy. \"Blood NfL concentration was measured using an ultrasensitive single molecule array ... method,\" report the researchers. In the Lund and London cohorts, blood NfL levels correlated significantly with CSF NfL levels (both, P <.001). Both cohorts showed that those with any of the APDs had significantly greater levels of blood NfL than did the healthy volunteers (all comparisons, P <.001). There were also significantly greater levels of blood NfL in patients with any APD vs those with PD in all 3 cohorts (all comparisons, P ≤.001). These differences remained significant in both the Lund and London cohorts even after controlling for disease duration. It is interesting to note that the London cohort alone showed that blood NfL levels were significantly greater in the patients with PD compared with the healthy volunteers ( P =.01). However, \"the levels were far below those observed in patients with APD,\" note the investigators. In all 3 cohorts, blood NfL showed high accuracy in distinguishing PD from APDs. Table 2. Accuracy in Distinguishing Between PD and APDs with Blood NfL Cohort Area Under Curve (95% CI) Specificity (%) Sensitivity (%) Lund 0.91 (0.87-0.95) 91 82 London 0.85 (0.72-0.98) 90 80 Early disease 0.81 (0.73-0.90) 80 70 APDs=atypical parkinsonian disorders; CI=confidence interval; NfL=neurofilament light chain protein; PD=Parkinson disease. The investigators note that the study provides class III evidence on the discriminatory abilities of blood NfL tests. One of its limitations, though, is that it cannot differentiate between the different types of APDs. Still, the \"easily accessible biomarker of axonal degeneration may improve the diagnostic workup of patients with parkinsonian symptoms in specialized clinics as well as in primary care settings,\" they write. Larger Studies, New Protocols Needed James Beck, PhD, vice president of scientific affairs at the Parkinson's Disease Foundation, a division of the Parkinson's Foundation, told Medscape Medical News that this study was \"an interesting take\" on a way to determine parkinsonism, which can be \"notoriously difficult to separate out.\" \"Having a test which might one day be able to do that could be really useful,\" said Dr Beck, who is also an adjunct professor at the New York University School of Medicine. He was not involved with this research. \"Early on, these diseases can look very similar when they present to clinicians. So having something that would be more accurate than just waiting would be a real benefit to this patient population.\" When asked if he believed these findings, which were in patients in Sweden and the United Kingdom, might be generalizable to other countries, Dr Beck said, \"I think they will be at some point.\" He noted that this test is still in its early days, the test needs to be assessed in a larger group, and standardized protocols would be needed \"so that it can be done anywhere in the world.\" \"Diagnostic tests are like baking. You need to be very precise in how you do it so that it can be repeatable from place to place. And that's often been the downfall for many tests such as this,\" said Dr Beck. \"If it's not done consistently, the results can be confusing or even contradictory to each other.\" If all of these technical issues are resolved, \"I think this could be a useful aid to clinicians,\" he concluded. The study was supported by the European Research Council, the Swedish Research Council, the Parkinson Foundation of Sweden, the Swedish Brain Foundation, the Knut and Alice Wallenberg Foundation, the Torsten Soderberg Foundation at the Royal Swedish Academy of Sciences, and the Swedish Federal Government \"under the ALF Agreement.\" Dr Hansson has disclosed no relevant financial relationships. Disclosures for the coauthors are detailed in the original study. Neurology . Published online February 8, 2016. [1] Study Highlights Researchers tested their hypothesis that serum NfL levels might discriminate between PD and APD among 2 cohorts of patients with PD, APDs, and no neurologic illness, along with another cohort of patients with PD or APDs of less than 3 years' duration. Participants underwent blood and CSF testing for NfL. One of the study cohorts also completed magnetic resonance imaging (MRI) of the brain. The main study outcome was a comparison of blood NfL levels among adults with PD and APDs. Researchers also evaluated the correlation between blood and CSF levels of NfL and whether serum NfL levels changed based on disease duration or severity. There were 543 participants in the 2 cohorts comparing patients with PD, those with APDs, and healthy control volunteers. 109 participants comprised the early disease cohort with PD or APD. The mean age of participants was slightly older than 65 years, and most participants were men. Blood levels of NfL increased with age, and they correlated very well with CSF levels of NfL. Blood levels of NfL were clearly elevated in the APD group compared with the PD and healthy control groups. In the early disease cohort, NfL levels were higher among participants with APDs vs those with PD. In the first cohort (Lund), the area under the curve in comparing levels of blood NfL vs CSF NfL was 0.91 (95% confidence interval [CI], 0.87-0.95). Blood NfL carried a sensitivity of 82% and a specificity of 91% in discriminating between PD and APDs. In the second cohort (London), the area under the curve in comparing levels of blood NfL vs CSF NfL was 0.85 (95% CI, 0.72-0.98). Blood NfL carried a sensitivity of 80% and a specificity of 90% in discriminating between PD and APDs. In the early disease cohort, the area under the curve in comparing levels of blood NfL vs CSF NfL was 0.81 (95% CI, 0.73-0.90). Blood NfL carried a specificity of 80% and a sensitivity of 70% in discriminating between PD and APDs. Longer disease duration and more severe symptoms of PD and APDs correlated with higher blood levels of NfL in one cohort, but not the other two. There was also not a clear correlation between NfL levels and white matter changes on MRI. Clinical Implications NfL levels may be increased in cases of APDs, stroke, frontotemporal dementia, and amyotrophic lateral sclerosis, but the levels are not increased among patients with PD. The current study by Hansson and colleagues finds that blood levels of NfL correlate well with CSF levels. Blood NfL may be helpful in discriminating PD from APDs, even at an early stage of disease. Implications for the Healthcare Team: Multiple tools are available to help discriminate PD from APDs, beginning with the clinical examination and with the use of MRI and fluorodeoxyglucose positron emission tomography. The availability of a blood test for NfL could improve diagnostic accuracy and efficiency and thus expedite correct care for the patient. CME Test 3 ",
				"clientUrl": "/viewarticle/876285",
				"creditType": ["CME", "Nurse CE"],
				"cmeFlag": "CME / CE",
				"leadConceptId": 907,
				"leadConcept": "Parkinson Disease",
				"concept": ["Movement Disorder", "Parkinsonian", "Geriatrics", "Multiple System Atrophy (MSA)", "Neurodegenerative Diseases", "Laboratory Diagnosis", "Geriatric Nursing", "Parkinson-Plus Syndrome", "Progressive Supranuclear Palsy", "Biomarker", "Corticobasal syndrome (CBS)"],
				"leadSpecialtyId": 26,
				"leadSpecialty": "Neurology & Neurosurgery",
				"allSpecialties": ["Neurology & Neurosurgery", "Medscape Today", "Internal Medicine", "Nursing", "Family Medicine/Primary Care", "Pathology & Lab Medicine"],
				"contentGroup": "Clinical Review",
				"origContentType": "Clinical Brief",
				"contentType": ["News"],
				"description": "A new blood biomarker is helpful in discriminating between Parkinson disease and atypical parkinsonian disorders.",
				"legacyID": 876285,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Blood Test Can Improve Parkinson Disease Diagnosis",
				"suppressComment": "T",
				"creditsAvailable": ["PhysiciansFamily Physicians:AMA PRA Category 1 Credit(s)™AAFP Prescribed credit(s):0.25", "Nurses:ANCC Contact Hour(s):0.25", "Physicians:AMA PRA Category 1 Credit(s)™:0.25"],
				"maxCredits": [0.25],
				"publicationDate": 1488517200000,
				"postingDate": 1488517200000,
				"_version_": 1573508887516020736,
				"last_index_date": 1500615012669
			}, {
				"id": "pdctm_0901c79180a7c9f0",
				"activeCME": 1,
				"activityExpirationDate": 1511326800000,
				"authors": ["News Author: Sue Hughes \nCME Author: Laurie Barclay"],
				"body": "Clinical Context Dementia is a major, growing public health problem, and cardiovascular risk factors and conditions are also highly prevalent. The American Heart Association (AHA) has previously addressed the role of vascular risk factors in cognitive impairment, but has now critically reviewed current evidence regarding the association of cognitive function with hypertension. The goal of the present AHA statement is to examine the contribution of chronic arterial hypertension to age-related cognitive dysfunction. It aims to inform healthcare professionals regarding recent advances, as well as to highlight remaining questions and guide future research. Study Synopsis and Perspective High blood pressure is a major risk factor for vascular cognitive impairment and is emerging as a potential risk factor for Alzheimer's disease, concludes a new statement from the AHA. \"We know treating blood pressure is important for reducing cardiovascular events,\" chair of the writing committee Costantino Iadecola, MD, from the Brain and Mind Research Institute at Weill Cornell Medicine, New York City, commented to Medscape Medical News . \"The relationship to dementia is not fully established, but putting all the data together on the issue, it does appear that increased blood pressure in midlife is bad for the brain.\" He added, \"Epidemiological studies suggest that treating blood pressure in midlife should have a positive effect on cognitive impairment later in life. But this has not yet been proven definitively.\" Dr Iadecola emphasized the need for prospective randomized trials to determine the exact relationship between blood pressure and dementia, and whether lowering blood pressure can protect against later dementia. One such trial, SPRINT MIND, is expected to report next year. \"Until then, we should treat blood pressure judiciously on a patient-by-patient basis,\" he concluded. The statement was published online October 10 in Hypertension . [1] As background, Dr Iadecola explained that as both hypertension and dementia were very common disorders, and it is known that chronic arterial hypertension is linked to vascular cognitive impairment, \"we thought it was timely to conduct a comprehensive review of the literature on the issue of hypertension and dementia, including Alzheimer's. The present statement therefore seeks to provide an appraisal of the contribution of hypertension to age-related cognitive dysfunction.\" \"The evidence suggests a very strong link between hypertension during midlife (age 50 - 60) and dementia later in life (age 80 plus). And this is for Alzheimer's as well as vascular dementia.\" He noted that although this has been suggested before in individual reports, this is the first time all the evidence has been reviewed so comprehensively. In addition, trials have not looked at each individual age groups, and most studies have been retrospective. \"Many of the individual studies are difficult to interpret because they have not used cognition as a primary endpoint; it has generally been a secondary endpoint, and different definitions have been used,\" he said. Dr Iadecola was not in favor of recommending a single value for the optimal blood pressure for the whole of life. \"This probably changes with age,\" he said. \"In the elderly, we think a slightly higher blood pressure may be beneficial, as when carotid stenosis starts to develop, then you need a higher pressure to push blood through the brain. A pressure of 120/80 may be too low for someone with severe cerebrovascular disease. So I think the ideal blood pressure needs to be personalized.\" He said he finds it \"bizarre\" that \"in the age of precision medicine, when we are sequencing genes to personalize medical care, something as simple as blood pressure is still viewed as a 1-size-fits-all.\" In the statement, the authors note that hypertension disrupts the structure of cerebral blood vessels, promotes atherosclerosis, and impairs vital cerebrovascular regulatory mechanisms. These vascular changes increase the susceptibility of the brain to ischemic injury, especially in vulnerable white matter regions critical for cognitive function, and may promote Alzheimer's pathology. The evidence to date points strongly to a deleterious influence of midlife hypertension on cognitive function in midlife and late life. Executive function and processing speed seem to be the cognitive domains most affected, but memory can also be impaired, they report. On the subject of aging, they say: \"Although the data are not conclusive, there is evidence of an association between higher late-life [blood pressure] and better cognition, highlighting the complexities of recommending uniform levels of [blood pressure] across the life course.\" In addition to aging, other factors that may affect the relationship of hypertension in cognitive decline are given as menopausal status, APOE ε4 genotype, insulin resistance, and systemic inflammation. The statement says that the effects of hypertension treatment on cognitive function is less clear. \"[E]vidence from randomized, double-blind, clinical trials that treatment of high [blood pressure] at any stage over the life course improves cognition is far from conclusive.\" On Alzheimer's disease, it states: \"An intriguing relationship has emerged between hypertension and [Alzheimer's], raising the prospect that a chronic elevation in [blood pressure] aggravates [Alzheimer's] pathology, contributing to dementia. These findings are critically important because they raise the possibility that treatment of hypertension may also contribute to reduce the development or progression of [Alzheimer's]. Because no evidence-based recommendations can be made at this time, treatment of high [blood pressure] in midlife and judicious use of antihypertensives in late life, taking into account cerebrovascular status and comorbidities, seem justified,\" the authors conclude. Full conflict-of-interest information is available on the journal's website. Study Highlights Vascular dementia is a form of age-related dementia caused by cerebrovascular factors. Chronic arterial hypertension is a known risk factor for vascular dementia, as well as for Alzheimer's disease, but mechanisms underlying the associations are still unclear. A multidisciplinary team of experts reviewed pertinent literature and summarized available data. Hypertension disrupts cerebral vasculature structure and function, causing ischemic damage to white matter regions underlying cognitive function. Related mechanisms include development of atherosclerosis and impairment of cerebrovascular regulation. Hypertension-induced amyloid production and deposition may also promote Alzheimer's pathology, and whole brain and hippocampal atrophy over time are also likely to reduce brain processing power. Underlying cellular and molecular mechanisms are incompletely understood, although oxidative stress may be involved. Evidence is strong for a harmful effect of midlife (age 50-60 years) hypertension on late-life (age ≥80 years) cognitive function and risk for Alzheimer's/vascular dementia, but weaker for the cognitive effect of late-life hypertension. Affected cognitive domains include executive function and processing speed, and sometimes memory. Hypertension appears to have a cumulative effect on cerebrovascular damage, according to observational studies. The effect of antihypertensive treatment on cognition is inconclusive, according to evidence from randomized, double-blind, clinical trials, because of difficulties in conducting decades-long longitudinal studies, lack of appropriate and uniform cognitive outcomes across trials, and the complex associations of hypertension with ethnicity, age, sex, and cerebrovascular risk factors. Findings of the SPRINT-MIND trial are forthcoming and may help answer questions regarding the potential role of antihypertensive treatment on preventing cognitive impairment. On the basis of their findings, the AHA group concluded that data were insufficient for evidence-based recommendations. They note that careful, patient-specific hypertension treatment, considering care goals, age, menopause, APOE ε4 genotype, metabolic traits, insulin resistance, systemic inflammation, and comorbidities, is warranted to protect vascular health, and therefore brain health. Optimal blood pressure most likely changes with age, and may need to be slightly higher when carotid stenosis begins to develop. Despite the relative safety and availability of antihypertensive drugs, it is still unclear how best to use them over the life course, based on patient-specific characteristics. It is also still unknown whether specific drug classes offer cognitive benefits beyond BP reduction. Better understanding of the cellular and molecular pathology of the cerebrovascular tree and associated cells, and development and use of new imaging tools, biomarkers, and genomic-proteomic approaches in clinical trials, should help resolve these uncertainties and develop new treatments. Clinical Implications Evidence is strong for a harmful effect of midlife hypertension on late-life cognitive function and dementia risk, but weaker for the cognitive effect of late-life hypertension, according to an AHA statement. Data regarding the effects of blood pressure treatment on dementia risk were insufficient for the AHA group to make evidence-based recommendations. Implications for the Healthcare Team: Careful, patient-specific hypertension treatment is warranted to protect vascular health, and therefore brain health. CME Test 3 ",
				"clientUrl": "/viewarticle/870678",
				"creditType": ["CME", "Nurse CE", "ABIM MOC"],
				"cmeFlag": "CME / ABIM MOC / CE",
				"leadConceptId": 281,
				"leadConcept": "Hypertension",
				"concept": ["Dementia", "Alzheimer Disease"],
				"leadSpecialtyId": 2,
				"leadSpecialty": "Cardiology",
				"allSpecialties": ["Cardiology", "Psychiatry", "Medscape Today", "Internal Medicine", "Nursing", "Neurology & Neurosurgery", "Family Medicine/Primary Care", "Public Health & Prevention"],
				"contentGroup": "Clinical Review",
				"origContentType": "Clinical Brief",
				"contentType": ["News"],
				"description": "The AHA notes strong evidence for a harmful effect of midlife hypertension on late-life cognition, but cannot make evidence-based recommendations on treating hypertension to lower dementia risk.",
				"legacyID": 870678,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "AHA: Relationship Between Hypertension, Cognitive Function",
				"suppressComment": "T",
				"creditsAvailable": ["PhysiciansFamily Physicians:AMA PRA Category 1 Credit(s)™AAFP Prescribed credit(s):0.25", "US Physicians:Points for ABIM MOC:0.25", "Nurses:ANCC Contact Hour(s):0.25", "Physicians:AMA PRA Category 1 Credit(s)™:0.25"],
				"maxCredits": [0.25],
				"publicationDate": 1479790800000,
				"postingDate": 1479790800000,
				"_version_": 1573508880954032128,
				"last_index_date": 1500615006406
			}, {
				"id": "pdctm_0901c79180aa8e79",
				"activeCME": 1,
				"activityExpirationDate": 1512104400000,
				"authors": ["News Author: Pauline Anderson \nCME Author: Charles P. Vega"],
				"body": "Clinical Context Autonomic dysfunction is one of the physical signs of mental health disorders, and the authors of the current study provide a brief review of previous research into this topic. In particular, adults with psychiatric illness such as depression, anxiety disorders, and schizophrenia have reduced parasympathetic activity, which is most apparent during periods of rest. The physical sign most clearly associated with these disorders is reduced beat-to-beat variability in heart rate. The relevance of other vital signs in their relationship to mental health disorders is less clear. Some limited research has found higher average resting heart rate (RHR) levels among patients with several different psychiatric diagnoses, but the evidence is limited. Meanwhile, research investigating trends in blood pressure values among patients with psychiatric illness has produced variable results. There are few studies regarding whether autonomic activity may help identify individuals at risk for incident mental health disorders. The current study by Latvala and colleagues addresses this issue. Study Synopsis and Perspective An elevated RHR and high blood pressure in male adolescents are linked to an increased risk for certain psychiatric disorders, particularly obsessive-compulsive disorder (OCD), later in life, new research suggests. The study, conducted by investigators at the University of Helsinki, Helsinki, Finland, and the Karolinska Institute, Stockholm, Sweden, also showed that lower RHR and blood pressure were associated with subsequent diagnoses of substance abuse disorders and violent criminal behavior. The results suggest that altered cardiac autosomal activity may represent an early marker of psychiatric disorders in men, said lead author Antti Latvala, PhD. \"This study provides new evidence for the role of autonomic nervous system functioning underlying some psychiatric disorders. Previous studies showed some autonomic abnormalities related to various psychiatric disorders, but none of them actually systematically studied several different disorders or looked at the predictive associations,\" Dr Latvala told Medscape Medical News . The study was published online October 26 in JAMA Psychiatry . No Link to Depression For the study, researchers used several Swedish national registers, including the Conscription Register. During a conscription assessment for the Swedish Armed Forces, which until 2010 was mandatory for men at age 18 years, RHR and blood pressure were measured. Valid RHR measurements were available for more than 1 million men, and valid systolic and diastolic blood pressure measurements were available for approximately 1.5 million men. For information on psychiatric disorders, researchers used the National Patient Register. They studied 7 categories of major disorders: OCD, anxiety disorders, posttraumatic stress disorder, depressive disorders, bipolar disorder, schizophrenia, and substance use disorders. They also looked at violent criminal convictions from the Swedish Crime Registry. The median length of follow-up was 31.8 years. After adjustment for birth year and conscription year, every 10-unit increase in RHR was associated with a 5% increased risk for depression (hazard ratio [HR], 1.05), an 8% increased risk for anxiety disorders, a 10% increased risk for schizophrenia, and an 18% increased risk for OCD. The associations were somewhat weakened after adjustment for height, weight, body mass index, cognitive ability, parental immigrant status, childhood socioeconomic status, and cardiorespiratory fitness. There were similar results for blood pressures. For example, a 10-unit increase in diastolic blood pressure was associated with a 6% elevated risk for anxiety (HR, 1.06) and an 11% increased risk for both OCD and schizophrenia in the fully adjusted model. Investigators compared men in the highest category of RHR (>82 beats per minute) with those in the lowest RHR category (<62 beats per minute). In a model adjusted for all covariates as well as cardiorespiratory fitness, men in the highest RHR category had a 69% increased risk for OCD (HR, 1.69; 95% confidence interval [CI], 1.46-1.94), a 21% increased risk for schizophrenia (HR, 1.21; 95% CI, 1.11-1.33), and an 18% increased risk for anxiety (HR, 1.18; 95% CI, 1.13-1.22). The investigators found similar associations after comparing highest vs lowest blood pressure measurements. Men with the highest diastolic blood pressure (>77 mm Hg) had a 30% to 40% higher risk for OCD than men with the lowest diastolic blood pressure (<60 mm Hg). There were no clear associations between the measurements and depression. Data for a Risk Score? In general, why would the relationships be strongest for OCD? \"OCD is typically a very severe disorder, and the clinical diagnosis might be more reliable compared to something like depression, which might be more heterogeneous,\" said Dr Latvala. The risks for substance use disorders and antisocial behavior were predicted by lower RHR and systolic blood pressure, especially after adjustment for the confounding effect of physical fitness. For example, in the fully adjusted model, the HR for violent criminality for the lowest RHR group compared with the highest was 1.45 (95% CI, 1.40-1.49). That elevations in RHR and blood pressure were associated with an increased risk for some psychiatric illnesses but lower measurements were associated with a risk for substance use disorders may seem counterintuitive, given the relationship between mental illness and substance use. It illustrates a \"highly complex picture\" of these associations, said Dr Latvala. Although anxiety and depression may lead to substance use, \"at the same time, there are other risk factors for substance use disorders, such as genetic factors,\" he said. Researchers excluded men who had a psychiatric diagnosis before their testing, but it is possible that the elevated measurements were early signs of mental illness. \"We know that most of these disorders tend to have an early onset in life, and it's a very likely scenario that at least some proportion of these men were already having some symptoms during adolescence when the heart rate and blood pressure were measured,\" said Dr Latvala. Dr Latvala stressed that he and his colleagues are not claiming a causal association. \"We are not saying that heart rate or blood pressure would causally increase the risk of these disorders. The more likely interpretation is that these physiological measures are perhaps indicators of some processes going on early on, and they are part of the risk for having these diagnoses later in life.\" The results, he said, do not have direct clinical implications. \"First of all, although we did find the association -- it's there, and it's real -- it's still only a statistical association.\" In addition, the association is not strong enough for clinicians to be able to \"predict who will get OCD or anxiety or whatever,\" and the mechanism driving the association is not that well understood, he said. Instead, this new information might be used in the future as part of a risk score. \"Perhaps elevated heart rate could be a small piece of that combination of different risk factors that might be useful for prediction.\" Dr Latvala has disclosed no relevant financial relationships. JAMA Psychiatry . Published online October 26, 2016. [1] Study Highlights The study was conducted in Sweden, which required a conscription evaluation at age 18 years for all young men until 2010. Men with severe illness were exempt from these evaluations, as were those who were missing parental data or who emigrated from Sweden after their examination. Men with resting blood pressure and heart rate evaluations were included in the study cohort. Using databases that could span decades, researchers evaluated national health registers for the inpatient and outpatient management of psychiatric disorders. They also evaluated records for violent criminal convictions. The main study outcome was the relationship between RHR and blood pressure and the risk for psychiatric illness. Researchers performed a multivariate analysis to account for sociodemographic and cognitive confounders, as well as participants' baseline exercise tolerance. 1,039,443 men had data available for RHR, and 1,555,979 men had blood pressure values recorded. The mean age at the time of examination was 18.3 years. The average RHR was 72.9 beats per minute, and the average blood pressure reading was 128.7/67.6 mm Hg. The median length of follow-up was 31.8 years. In fully adjusted analysis, men with a RHR in excess of 82 beats per minute experienced an HR for OCD of 1.69 (95% CI, 1.46-1.94) compared with men with an RHR of less than 62 beats per minute. The respective HR for schizophrenia in comparing these 2 groups was 1.21 (95% CI, 1.11-1.33), and the respective HR for anxiety disorders was 1.18 (95% CI, 1.13-1.22). The reverse relationship with RHR was noted for substance use disorders and violent criminality. The HR for substance use disorders in comparing men with a RHR more than 82 beats per minute vs those with a RHR less than 62 beats per minute was 0.95 (95% CI, 0.94-0.96). The respective HR for violent criminality was 0.90 (95% CI, 0.89- 0.91). In general, the same results held true in the evaluation of systolic blood pressure. Higher systolic blood pressure was associated with increased rates of OCD, schizophrenia, and anxiety disorders, but lower risks for substance use disorders and violent criminality. Bipolar disorder was not strongly associated with RHR or systolic blood pressure. An analysis that excluded men with psychiatric and cardiovascular illness at baseline failed to alter the main study conclusions. Clinical Implications Reduced beat-to-beat variability in heart rate is the most established difference in vital signs among adults with mental health disorders. The current study by Latvala and colleagues demonstrates that higher RHR and systolic blood pressure among young men were associated with increased rates of OCD, schizophrenia, and anxiety disorders, but lower risks for substance use disorders and violent criminality. Implications for the Healthcare Team: Clinicians should become aware that physiological measures such as blood pressure and an elevated heart rate may help identify individuals at risk for incident mental health disorders based on a longitudinal cohort study. CME Test 3 ",
				"clientUrl": "/viewarticle/872444",
				"creditType": ["CME", "Nurse CE", "ABIM MOC"],
				"cmeFlag": "CME / ABIM MOC / CE",
				"leadConceptId": 0,
				"concept": ["Increased Blood Pressure", "Pediatric Nursing", "Psychiatric Nursing", "Child and Adolescent Psychiatry", "Adolescent Medicine", "Cardiovascular Nursing", "Mental Illness", "Public Health Nursing", "Autonomic Nervous System", "Heart Rate Control"],
				"leadSpecialtyId": 9,
				"leadSpecialty": "Pediatrics",
				"allSpecialties": ["Pediatrics", "Cardiology", "Psychiatry", "Medscape Today", "Internal Medicine", "Nursing", "Family Medicine/Primary Care", "Public Health & Prevention"],
				"contentGroup": "Clinical Review",
				"origContentType": "Clinical Brief",
				"contentType": ["News"],
				"description": "This longitudinal cohort study demonstrates that blood pressure and pulse rate may predict incident mental health disorders among young men.",
				"legacyID": 872444,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Is High Blood Pressure a Sign of Mental Illness in Teens?",
				"suppressComment": "T",
				"creditsAvailable": ["PhysiciansFamily Physicians:AMA PRA Category 1 Credit(s)™AAFP Prescribed credit(s):0.25", "US Physicians:Points for ABIM MOC:0.25", "Nurses:ANCC Contact Hour(s):0.25", "Physicians:AMA PRA Category 1 Credit(s)™:0.25"],
				"maxCredits": [0.25],
				"publicationDate": 1480568400000,
				"postingDate": 1480568400000,
				"_version_": 1573508878745731072,
				"last_index_date": 1500615004301
			}, {
				"id": "pdctm_0901c79180ba3182",
				"activeCME": 1,
				"activityExpirationDate": 1530248400000,
				"authors": ["Carrie S. Oser", " Crystelle C. Fogle", " James A. Bennett"],
				"body": "Abstract and Introduction Abstract and Introduction Abstract Introduction. Pharmacists can assist patients in managing their blood pressure levels. We assessed whether adherence to blood pressure medication improved among people who used community pharmacies in rural Montana after pharmacists initiated consultations and distributed educational materials developed for the Million Hearts Initiative’s \"Team Up. Pressure Down.\" (TUPD) program. Methods. From 2014 to 2016, the Cardiovascular Health Program at the Montana Department of Public Health and Human Services conducted a statewide project to evaluate an intervention for adherence to blood pressure medication administered through community pharmacies. After the year 1 pilot, we redesigned the program for year 2 and year 3 and measured the percentage of participating patients who adhered to blood pressure medication. We also conducted a statewide survey to assess pharmacy characteristics, computer-system capabilities, and types of consulting services provided by pharmacists. Results. Twenty-five community pharmacies completed Montana’s TUPD program: 8 pharmacies in the pilot year, 11 pharmacies in year 2, and 6 pharmacies in year 3. For year 2 and year 3 combined, the percentage of participating patients who achieved blood pressure medication adherence improved preintervention to postintervention from 73% to 89%, and adherence improved in 15 of the 17 pharmacies. The pilot pharmacies identified 3 major barriers to project success: patient buy-in, staff burden in implementing the project, and funding. In the statewide assessment, TUPD-funded pharmacies were significantly more likely than non-TUPD–funded pharmacies to provide prescription synchronization and medication management with feedback to the patient’s physician. Conclusion. Community pharmacies in rural areas can effectively use brief consultations and standard educational materials to improve adherence to blood pressure medication. Introduction High blood pressure is a controllable risk factor for cardiovascular diseases (eg, heart disease, stroke). [1] However, patients with hypertension often find it challenging to manage their condition. Barriers to management may include problems with medication adherence, not understanding the seriousness of the condition, or difficulty making lifestyle changes. Community pharmacists can extend the reach of health care providers and assist patients in controlling their hypertension. With ready and consistent access to patients who refill prescriptions monthly, pharmacists are in a position to establish an ongoing relationship with their patients. A meta-analysis of 7 randomized controlled trials showed that adherence to blood pressure medication increased more in the pharmacist-led interventions than in the control groups. [2] In the 6 studies that provided quantitative data, adherence in the intervention groups increased from 56% (203 of 360 participants) to 68% (246 of 360 participants); in the control groups, adherence increased from 59% (190 of 320 participants) to 61% (195 of 320 participants). Another meta-analysis found that 7 of 16 pharmacist interventions significantly increased medication adherence [3] ; the difference between adherence in the intervention groups compared with the control groups ranged from 8 to 58 percentage points. Pharmacy-based interventions are also effective in improving medication adherence among people in racial/ethnic minority populations. [4,5] We found no studies of pharmacy interventions to improve adherence to blood pressure medication in rural areas. Because of a shortage of primary care providers in rural areas, [6] pharmacies in rural areas could play a larger role in improving medication adherence than pharmacies in urban areas. Pharmacists can help identify and overcome barriers (eg, financial difficulties, side effects) that health care providers may not detect during patient visits, which often are infrequent. Pharmacies also can assist patients in managing their blood pressure levels. [3,7] Only 2 interventions that we reviewed [4,8] provided patients with pharmacist consultations and educational materials on blood pressure medication adherence. However, these interventions did not rigorously assess the usefulness of the educational materials. We evaluated whether patients’ adherence to blood pressure medication improved in rural Montana when we used pharmacy consultations in combination with educational materials that were developed for the Million Hearts Initiative’s \"Team Up. Pressure Down.\" (TUPD) and were designed for community pharmacists and their patients. [9] Our secondary objective was to describe pharmacy characteristics, computer-system capabilities, and types of consulting services provided by pharmacists throughout Montana. Methods Methods This study consisted of 2 components: 1) a 3-year (February 2014–June 2016) intervention to improve adherence to blood pressure medication among people using community pharmacies in rural Montana and 2) a statewide assessment (November 2015–February 2016) of pharmacy characteristics, computer-system capabilities, and types of consulting services provided. Montana is the fourth largest state geographically but is ranked 48th in the United States for population density, with only 6.8 persons per square mile. [10] Much of the state is classified as an area with a shortage of health care professionals or as a medically underserved area. [11] According to rural–urban commuting area codes, less than 20% of Montana’s counties had census tracts with a classification of \"metropolitan area core\" or \"metropolitan area high commuting\". [12] For the TUPD project, most participating pharmacies were in counties outside these metropolitan areas. [13] Community Pharmacy Intervention In 2014, the Montana Cardiovascular Health (CVH) Program at the Department of Public Health and Human Services (DPHHS) initiated a project with 9 community pharmacies in Montana to conduct and evaluate a blood pressure medication adherence intervention. However, one funded pharmacy did not complete the project because of problems with business structure and staffing. The project used an implementation study design and 3 cohorts ( Box 1 ). The project was supported by the Centers for Disease Control and Prevention (CDC). [14] The Montana DPHHS did not require institutional review board approval because pharmacies submitted only de-identified aggregate data. The University of Montana’s Skaggs School of Pharmacy provided a list of 258 community pharmacies in Montana. A community pharmacy is designated by the Montana Department of Labor and Industry as a pharmacy that serves customers in a retail setting, such as a pharmacy chain or an independent pharmacy, rather than in an institutional setting, such as a hospital. To recruit pharmacies for the pilot project, the CVH Program mailed an application to all 258 community pharmacies listed, and the Montana Pharmacy Association emailed the announcement to its members. In addition, Montana’s Medicare Quality Innovation Network–Quality Improvement Organization helped recruit pharmacies and disseminate project materials. Montana DPHHS staff members reviewed 9 applications for the pilot year. The criteria for funding included providing an estimate of the number of patients in the pharmacy who were taking blood pressure medication and the number of patients to be tracked and providing an adequate description of a project plan, including selecting, tracking, and following up with patients. Applicants also were required to describe components that could be continued by the pharmacy without external funding. In the pilot year, all 9 applicants met the application criteria and were funded. Using a similar application and notification process, we funded 2 more cohorts: 11 pharmacies in year 2 and 7 pharmacies in year 3 (one of which did not complete the project because of a staffing shortage). Pilot Project. Each pilot pharmacy was required to recruit at least 25 patients. Participants were required to meet the following minimum criteria: 1) being an adult aged 18 years or older, 2) having had at least one pharmaceutical claim during the previous calendar year (ie, an active pharmacy patient), and 3) having had at least one current prescription for a medication to lower blood pressure. Pharmacies were permitted to customize approaches for identifying and recruiting participants (eg, letters, direct contact). As part of the project, pharmacies conducted a brief consultation with each participating patient. During the consultation, the pharmacist discussed medication management and changes in lifestyle behavior to help improve the patient’s medication adherence and blood pressure control. We asked the pharmacies to disseminate TUPD’s patient-education materials and information on the Dietary Approaches to Stop Hypertension (DASH) program [15] and to refer smoking patients to the Montana Tobacco Quitline. [16] TUPD’s patient-education materials included a blood pressure journal, a medication tracker wallet card, and a medication reminder handout. Additionally, participants received a postcard with information on steps to control blood pressure and a place to list pharmacy and prescription information. TUPD’s pharmacist materials included a pocket discussion guide, a drug-adherence work-up tool (to identify and address patient barriers to taking medication), a blood pressure guide (a quick reference on taking blood pressures manually and interpreting blood pressure readings), and a pharmacy poster. During the pilot program, pharmacies measured medication adherence by 1) calculating the number of days of refill for a blood pressure medication for each participating patient or 2) using another standard method, such as calculating the percentage of participating patients who achieved blood pressure medication adherence, measured as the proportion of days covered (PDC) by prescription claims as 80% or greater (based on prescription fill date and days of supply). We did not require pharmacies to adhere to a particular method of calculating adherence. Some pharmacies electronically tracked prescription fill dates, and others used an Excel (Microsoft Corp) spreadsheet. Although the pilot project was designed initially to be implemented during a 10-month period, it was implemented during a 4-month period because of a delay in budget approval. After the conclusion of the pilot program, we obtained feedback from the pilot pharmacies and modified the intervention for year 2 and year 3. We also sought federal guidance on a standard definition of medication adherence [17] and requested additional funding so that we could recruit more pharmacies and increase the funding award to pharmacies as an incentive for them to participate. Year 2 and Year 3. In year 2 and year 3, in addition to other program improvements ( Box 2 ), we required pharmacies to use a standardized definition for medication adherence (PDC ≥80%). We received additional funding, which allowed us to double the funding award to pharmacies. We shared lessons learned from the pilot pharmacies with the new pharmacies, emphasized project expectations, and provided additional technical assistance. Data collection. The CVH Program collected data from reports filed one month after the project began and final reports. Pre-intervention and postintervention data were collected on medication adherence at the start and end of each of the 3 project periods. The CVH Program developed a final report template that community pharmacies completed at the end of each project period. The final report gave information on barriers, lessons learned, sustainable components, and suggestions for improvement. The final reports also provided data on types of counseling provided and pharmacists’ perceptions of the usefulness of TUPD materials and resources. Lastly, the final report provided aggregate data on the percentage (numerator and denominator) of participating patients who adhered to their blood pressure medication schedule. In addition, for year 2 and year 3, the CVH Program periodically requested interim feedback from the participating pharmacies on progress made and barriers encountered. A consulting pharmacist reviewed the feedback and made suggestions to address barriers as part of his technical assistance. Statewide Pharmacy Assessment From November 2015 through February 2016, the CVH Program conducted a statewide assessment of community pharmacies to collect data required by CDC to measure grant performance. In October 2015, the CVH Program and a community pharmacist reviewed and revised a survey instrument that the program had designed and used in a statewide assessment in 2013. In November 2015, the Montana Department of Labor and Industry provided a list of licensed community pharmacies. We merged this list and the TUPD recruitment list from the Skaggs School of Pharmacy and eliminated duplicate pharmacies by matching license number, business name, and city, which yielded 259 community pharmacies. The survey, which was mailed, collected information on pharmacy characteristics (the number of pharmacists and pharmacy technicians); computer-system capabilities (acceptance of electronic prescriptions from outside health care facilities, automatic refills on certain maintenance medications, automated refill reminders for blood pressure medication); provision of prescription synchronization (the process of aligning refill dates for all of a patient’s multiple prescriptions); reimbursement of medication therapy management from Mirixa or OutcomesMTM, 2 leading vendors of medication therapy management services in Montana; and the types of consulting services provided by pharmacists. Medication therapy management is a service provided by pharmacists to optimize drug therapy and improve health outcomes. Data Analysis For year 2 and year 3 of the intervention, we aggregated the data from the final reports for medication adherence (percentage of participants with PDC ≥80% and total number of participants) from each pharmacy. Details on the calculation of PDC, including definition of terms, unit of analysis, and determination of numerators and denominators, are available elsewhere. [17] To generate an overall rate, we aggregated the data on medication adherence by year. The pilot sites were excluded from the medication adherence analysis because they were not required to use a standard definition for medication adherence. For the community pharmacy assessment, we analyzed data using IBM SPSS Statistics version 21 (IBM Corporation). We used χ 2 tests to assess any differences in pharmacy and consultation services offered by pharmacists, such as consultation on blood pressure medication adherence, between pharmacies funded by TUPD and pharmacies not funded by TUPD. We also used the nonparametric Mann–Whitney U test to compare differences between pharmacies funded by TUPD and pharmacies not funded by TUPD in the number of pharmacists and pharmacy technicians. A P value of < .05 was considered significant. Results Results Twenty-five community pharmacies completed Montana’s TUPD project: 8 in the pilot year, 11 in year 2, and 6 in year 3. All 25 pharmacies submitted a final report. For year 2 and year 3 combined (17 pharmacies), 534 patients completed the TUPD project, with 360 in year 2 and 174 in year 3; the aggregated percentage of participating patients who achieved blood pressure medication adherence increased from 73% pre-intervention to 89% postintervention (Figure). Blood pressure medication adherence improved in 15 of the 17 community pharmacies in year 2 and year 3. Figure. Percentage of patients who achieved blood pressure medication adherence (proportion of days covered [PDC] by prescription claims ≥80%) pre-intervention and postintervention among community pharmacies participating in TUPD (N = 17) in year 2 and year 3, by year and overall, Montana, July 2014–June 2016. Community pharmacies during the pilot year were excluded from this analysis because they were not required to use a standardized definition for medication adherence. Abbreviation: TUPD, Team Up. Pressure Down. Figure. Feedback From Pharmacists The pilot pharmacies identified 3 major barriers to project success: patient buy-in, staff burden in implementing the project, and funding. A lack of awareness of the importance of controlling blood pressure, a lack of willingness or interest in project participation, and lack of recognition of the benefits of participation were major obstacles among patients. Staff burden was the most common barrier reported by the pharmacies. Adding another program to a busy schedule was difficult. A lack of time limited the ability of the pharmacists to provide customer service and pharmacy counseling beyond the core task of dispensing medication. In the pilot project, the pharmacists’ suggestions for enhancing the project included developing a template for tracking patients, a notification letter to health care providers, and a checklist of topics to discuss with patients. These resources were added in year 2 and year 3. Other recommendations (a wallet card to log blood pressure values and a survey to obtain patient feedback) will be added in year 4. Feedback from year 2 and year 3 indicated that involving the entire pharmacy team in the project helped reduce the burden of work on the pharmacists. For example, one pharmacy created a system in which TUPD materials were attached to a patient’s medication refill. When the patient picked up the refill, the pharmacy technician notified the patient that the pharmacist wanted to speak with him or her. Another pharmacy involved the pharmacy technicians in using an alert system (tracking sheet) when a study patient was in the pharmacy so that pharmacists could provide consultations. TUPD-funded pharmacies reported that TUPD materials and resources were useful. Although all participating pharmacies reported distributing TUPD materials, pharmacists reported only 75% of project participants received these materials because some patients refused them. Pharmacists noted that the wallet card and journal were helpful and of interest to patients, although they noted that some of the materials could be written more concisely. Additionally, 21 pharmacies reported their pharmacists provided lifestyle counseling and medication therapy management to their patients with hypertension. The pharmacists noted that most of their patients appreciated the extra attention they received during the consultations. Pharmacists adjusted the length of the consultation according to the interest level and needs of each patient. Three pharmacists suggested that the TUPD project may be most suitable for patients with a new diagnosis of hypertension because patients with long-term hypertension had already found ways to manage their condition. One pharmacy lost many project participants because of the participants’ transient employment (oil workers). In addition, 13 pharmacies noted difficulty tracking patients (eg, patient used mail-order or 90-day prescriptions, transferred pharmacies, died, was hospitalized, or moved). Three pharmacies found opportunities to collaborate with patients’ providers to improve blood pressure control. Twenty pharmacies reported plans to sustain at least one project component to foster medication adherence (eg, measuring blood pressure on-site, offering counseling or medication reviews, providing blood pressure information materials, synchronizing medication, creating a system of automatic refills). Statewide Pharmacy Assessment The response rate for the community pharmacy assessment conducted was 46% (120 of 259). The average number of pharmacists per pharmacy in Montana was fewer than 3 ( Table ). We found no significant differences between TUPD-funded pharmacies and non-TUPD–funded pharmacies in the number of pharmacy staff members or pharmacy services related to whether or not automatic refills or refill reminders are provided ( Table ). TUPD-funded pharmacies were significantly more likely than non-TUPD–funded pharmacies to provide prescription synchronization and medication management with feedback to the patient’s physician. TUPD-funded pharmacies also were more likely than nonfunded pharmacies to report that pharmacists were reimbursed for formal medication therapy management from Mirixa or OutcomesMTM. Discussion Discussion Our findings indicate that it is feasible for community pharmacies in rural areas to provide their patients with brief consultations and TUPD educational materials on how to improve blood pressure medication adherence. Our results are similar to those reported in other studies, which found that pharmacist interventions could significantly improve medication adherence. [2–5,8,18,19] The project components in these previous studies were not identical to those in TUPD, however. Some of those interventions provided resources such as a take-home tool kit [4] or blood pressure cuffs for self-monitoring at home [5,7,8] that our project did not provide. Our study differed from most other studies in that ours focused only on rural pharmacies. Although one study did examine rural Minnesota pharmacies, it was a biennial pharmacy workforce survey of outpatient pharmacies rather than an intervention. [20] Also, we did not find any previous study that investigated use of TUPD materials. Our results suggest that the pharmacies were able to customize the project to fit their needs. In addition, our findings indicate that major components of the project can be integrated into the usual practice of community pharmacies in rural areas. Pharmacies that were already being reimbursed for medication therapy management or that synchronized refills may have been more willing to participate in this project because of their experience in patient consultations. This project has several limitations. First, our study did not include a control group; however, because this was a project evaluation and not a research project, a control group may not have been needed. Second, pharmacies were not required to collect data on patients’ blood pressure control. We did not institute this requirement because of limited pharmacist time, lack of adequate funding, and difficulty in bringing participants in for measurement. Since we did not require pharmacies to collect data on patients’ blood pressure, we could not conduct additional analyses. However, some participating pharmacies used a blood pressure cuff for on-site measurement, and some made the cuff available to nonparticipating patients. Third, because of the small sample of pharmacies, the results of our study may not be generalizable to all pharmacies. We expect to have a larger sample size for study when additional pharmacies are funded for 2 more years. Fourth, this project assessed only the perceptions of the pharmacists and not those of other stakeholders (pharmacy patients or health care providers). Lastly, because of the annual funding cycle of the CDC grant, we did not investigate long-term medication adherence. Despite these limitations, our project results suggest that community pharmacies in rural areas can use brief consultations and TUPD materials to improve blood pressure medication adherence. The TUPD project could be expanded to other states that have community pharmacies in rural areas. In year 2, the DPHHS diabetes program broadened the TUPD project by conducting a similar project with 7 of the pilot pharmacies, targeting pharmacy patients taking blood pressure and diabetes medications. Also, in 2016 the state asthma control program recruited 2 of the pilot pharmacies to address asthma medication adherence. This expansion of the TUPD blood pressure approach indicates the willingness of community pharmacies to work on chronic disease management. Future research should evaluate whether the TUPD strategy also improves medication adherence for patients with other chronic conditions such as diabetes or asthma. In addition, research could assess blood pressure control and medication adherence in community pharmacies in rural areas. ",
				"clientUrl": "/viewarticle/881868",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 281,
				"leadConcept": "Hypertension",
				"concept": ["Essential Hypertension", "Adherence", "Patient Counseling", "Patient Pharmaceutical Care Management", "Antihypertensive Agents", "Chronic Disease"],
				"leadSpecialtyId": 42,
				"leadSpecialty": "Public Health & Prevention",
				"allSpecialties": ["Public Health & Prevention", "Cardiology", "Internal Medicine", "Family Medicine/Primary Care"],
				"contentGroup": "Journal Article",
				"origContentType": "Journal Article",
				"contentType": ["Journal Article"],
				"description": "Can rural pharmacies help patients adhere to treatment for hypertension? A new statewide study says yes.",
				"legacyID": 881868,
				"pubDisplay": "Prev Chronic Dis",
				"siteOn": 2003,
				"title": "A Project to Promote Adherence to Blood Pressure Medication Among People Who Use Community Pharmacies in Rural Montana, 2014–2016",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/PCD-thumb.jpg"],
				"publicationDate": 1498712400000,
				"postingDate": 1498712400000,
				"_version_": 1573508893528555520,
				"last_index_date": 1500615018394
			}, {
				"id": "pdctm_0901c79180b7ad25",
				"activeCME": 1,
				"activityExpirationDate": 1527915600000,
				"authors": ["News Author: Troy Brown", " CME Author: Charles P. Vega"],
				"body": "Clinical Context Preeclampsia is a common yet potentially deadly complication of pregnancy, and the authors of the current recommendations provide a review of the epidemiology of preeclampsia. Preeclampsia complicates between 2% and 8% of pregnancies worldwide and accounts for approximately one-third of severe obstetric complications in the United States. Approximately 9% of maternal deaths in the United States are a result of preeclampsia and eclampsia. Risk factors for preeclampsia include a previous history of preeclampsia or eclampsia, a previous adverse pregnancy outcome, chronic conditions such as diabetes and hypertension, multifetal gestation, nulliparity, advanced maternal age, and low socioeconomic status. African American women are at a higher risk for preeclampsia compared with white women, which may be due to a higher number of routine risk factors for preeclampsia among African American women. What is clear is that case-fatality rates are 3 times higher in comparing African American women with white women. Screening for preeclampsia with routine blood pressure and urine examinations is an established part of routine prenatal care. However, can this practice pass the rigor of a review from the US Preventive Services Task Force (USPSTF)? The answer is detailed in \"Study Highlights.\" Synopsis and Perspective The USPSTF has finalized its recommendation of preeclampsia screening with blood pressure measurements throughout pregnancy for all pregnant women. The recommendation is a B recommendation, meaning there is moderate certainty that the net benefit is substantial. Jillian T. Henderson, PhD, and colleagues from the Kaiser Permanente Research Affiliates Evidence-based Practice Center published the recommendation and an accompanying systematic evidence review online April 25 in JAMA . [1] The recommendation applies to pregnant women without a current diagnosis of preeclampsia and without signs or symptoms of preeclampsia or hypertension. The USPSTF released a draft recommendation and evidence review on September 27, 2016, updating the 1996 recommendation. [2] The draft recommendation was available for public comment until October 24, 2016. Preeclampsia is associated with hypertension in pregnant women after 20 weeks of gestation. It is the second leading cause of maternal mortality in the world and a major cause of preterm birth and low birth weight in the United States. \"The complications of preeclampsia in part shaped the development of prenatal care in the United States. The timing and frequency of visits were chosen to improve detection of preeclampsia through the measurement of blood pressure at routine prenatal visits,\" Jeffrey D. Sperling, MD, and Dana R. Gossett, MD, from the Department of Obstetrics, Gynecology, and Reproductive Sciences, University of California, San Francisco, write in an accompanying editorial. [3] However, identifying women at high risk for preeclampsia has proven elusive. \"The USPSTF...determined that there was inadequate evidence on the effectiveness of risk prediction tools (eg, clinical indicators, serum markers, or uterine artery pulsatility index) to support different screening strategies,\" they explain. \"Such tools would have clinical value, because aspirin and achieving appropriate weight gain are effective as primary prevention strategies. Screening tools for preeclampsia could improve maternal and neonatal outcomes by allowing for early diagnosis and timely delivery of needed interventions (antenatal corticosteroids to reduce neonatal morbidity and mortality; magnesium sulfate for seizure prophylaxis and fetal neuroprotection; treatment of severe hypertension; delivery),\" Dr Sperling and Dr Gossett continue. \"However, despite recent advances in the understanding of preeclampsia, identifying women at risk remains a 'holy grail' of obstetrics. It is disappointing that since completion of the most recent systematic reviews evaluating this topic, there is not an accurate screening test or predictive model for preeclampsia,\" Dr Sperling and Dr Gossett add. Preeclampsia has much in common with other cardiovascular diseases, Nisha I. Parikh, MD, and Juan Gonzalez, MD, PhD, from the University of California, San Francisco, point out in an accompanying editorial published simultaneously in JAMA Internal Medicine . [4] \"Like acute myocardial infarction, stroke, and malignant forms of hypertension, the acute trigger for the onset of preeclampsia is not fully understood. And much like the acute onset of cardiovascular diseases...once preeclampsia is triggered, there is an ensuing cascade of vascular and endothelial dysfunction, inflammation, and coagulation dysfunction that can in turn lead to neurologic, cardiac, pulmonary, renal, and hepatic disease in pregnant women. Delivery is often one of the only means to stop this cascade of events,\" Dr Parikh and Dr Gonzalez write. They say it is noteworthy that the new recommendations deemphasize proteinuria measurements. \"Accumulating data indicate that the amount of proteinuria does not predict maternal or fetal outcome,\" they write. \"In the absence of proteinuria, preeclampsia is diagnosed as hypertension in association with other evidence of end organ damage.\" Dr Parikh and Dr Gonzalez add that pregnancy provides an ideal time to intervene with women who may be at risk for cardiovascular disease later in life. \"Pregnancy is essentially a cardiovascular stress test, and the development of preeclampsia among other pregnancy complications is the earliest marker of patients at risk for future [cardiovascular disease]. Streamlined methods within health care systems are needed to refer women with preeclampsia to clinicians capable of intensive cardiovascular risk-factor screening and management in the postnatal setting. Data suggest that women are motivated to seek health care during the early postpartum period, and we should leverage this window to institute lifestyle modifications in diet and physical activity that reduce blood pressure,\" they add. The authors and editorialists have disclosed no relevant financial relationships. JAMA . 2017;317:1629-1630, 1661-1667. JAMA Intern Med . Published online April 25, 2017. Recommendation Highlights Preeclampsia is defined as a blood pressure of at least 140/90 mm Hg on 2 occasions after 20 weeks of gestation. In addition, the diagnosis requires either a measure of proteinuria or other signs of organ damage, such as renal insufficiency or thrombocytopenia. Blood pressure readings are the main tool to screen for preeclampsia. The USPSTF recommends that blood pressure be measured at each prenatal care visit and elevated readings be confirmed with another measurement. Blood pressure screening has widely been found to be accurate, and there is no call for screening outside of the clinical encounter. 16 different risk prediction models for preeclampsia have been developed and tested. Although they all had at least good discrimination in predicting preeclampsia, the positive predictive value of these measures was only 4% to 39%. The USPSTF does not recommend the use of a specific prediction tool for preeclampsia. However, pregnant women should be assessed for their individual risk for preeclampsia with a screening history for risk factors described in \"Clinical Context.\" The USPSTF also does not recommend the routine use of urine tests to screen for preeclampsia. Urine protein dipstick testing has a wide range of sensitivity values in clinical studies and is considered unreliable as a diagnostic tool. Protein-to-creatinine and albumin-to-creatinine urine tests are limited by questionable specificity. A 24-hour urine collection for protein may be more accurate but is largely impractical for routine screening. No studies have directly compared the outcomes of screening vs no screening for preeclampsia. However, treatment of preeclampsia with magnesium sulfate appears to reduce the risk for eclampsia by more than half. Delivery of the fetus at week 37 of gestation or more also reduces the risk for adverse maternal outcomes among women with preeclampsia. Screening for preeclampsia with blood pressure is associated with a minimal risk for harm. One study found no difference in anxiety levels among women before and after risk stratification for preeclampsia. Overall, the recommendation to screen pregnant women routinely for preeclampsia gets a \"B\" grade from the USPSTF, meaning that there is moderate to high certainty of the benefit of screening. The USPSTF also recommends the use of low-dose aspirin for women at high risk for preeclampsia. Prophylaxis may begin after 12 weeks of gestation. The current recommendations jibe with those from the American College of Obstetrics and Gynecology, which emphasizes a history to assess women for the risk for preeclampsia as well as blood pressure readings at each prenatal visit. Clinical Implications Risk factors for preeclampsia include a previous history of preeclampsia or eclampsia, a previous adverse pregnancy outcome, chronic conditions such as diabetes and hypertension, multifetal gestation, nulliparity, advanced maternal age, low socioeconomic status, and African American race. The current recommendations from the USPSTF call for the routine screening for preeclampsia among pregnant women. The primary screening method should be blood pressure readings at each prenatal visit. Implications for the Healthcare Team: The current recommendations are as remarkable for what they encourage in practice (that is, blood pressure readings at every prenatal visit) as what they discourage (that is, the routine use of urine dipstick testing) to screen for preeclampsia. Avoiding unnecessary urine testing should make prenatal visits more efficient for the healthcare team and patient alike. CME Test 3 ",
				"clientUrl": "/viewarticle/880277",
				"creditType": ["CME", "Nurse CE", "ABIM MOC"],
				"cmeFlag": "CME / ABIM MOC / CE",
				"leadConceptId": 3032471,
				"leadConcept": "Pregnancy",
				"concept": ["Preventive Screening", "Preventive Medicine", "Preventive Medicine and Screening Recommendations", "Clinical Guidelines", "Treatment Guidelines", "Cardiovascular Nursing", "OB/GYN and Women's Health Nursing", "Preeclampsia", "Public Health Nursing", "Primary and Secondary Prevention of Coronary Artery Disease", "Prenatal Screening and Diagnostics"],
				"leadSpecialtyId": 16,
				"leadSpecialty": "Ob/Gyn & Women's Health",
				"allSpecialties": ["Ob/Gyn & Women's Health", "Cardiology", "Medscape Today", "Nursing", "Family Medicine/Primary Care", "Public Health & Prevention", "Emergency Medicine"],
				"contentGroup": "Clinical Review",
				"origContentType": "Clinical Brief",
				"contentType": ["News"],
				"description": "The US Preventive Services Task Force recommends screening for preeclampsia using blood pressure readings instead of routine urine testing.",
				"legacyID": 880277,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "USPSTF Issues Guidelines for Preeclampsia",
				"suppressComment": "T",
				"creditsAvailable": ["PhysiciansFamily Physicians:AMA PRA Category 1 Credit(s)™AAFP Prescribed credit(s):0.25", "US Physicians:Points for ABIM MOC:0.25", "Nurses:ANCC Contact Hour(s):0.25", "Physicians:AMA PRA Category 1 Credit(s)™:0.25"],
				"maxCredits": [0.25],
				"publicationDate": 1496379600000,
				"postingDate": 1496379600000,
				"_version_": 1573508880485318656,
				"last_index_date": 1500615005959
			}, {
				"id": "pdctm_0901c79180a86220",
				"activeCME": 1,
				"activityExpirationDate": 1513141200000,
				"authors": ["Charles B. Cairns", " Frederick S. Nolte", " Christopher W. Woods"],
				"body": "Educational Impact Challenge Assess your clinical knowledge by completing this brief survey. Answering these questions again after the activity will allow you to see what you learned and to compare your answers with those of your peers. 3 « Back Continue » 0 Slide 1. Slide 1. Advancing Care in Sepsis: Focus on Timely Diagnosis Slide 2. Slide 2. Panelists Slide 3. Slide 3. Discussion of Investigational Devices Slide 4. Slide 4. Introduction [1,2] Slide 5. Slide 5. Challenges in Diagnosing Sepsis [2,3] Non-specific presentation of sepsis is shaped by biological and clinical heterogeneity, impacted by both pathogen factors and host factors (age, sex, genetic determinants, co-morbid illness) with characteristics that evolve over time The signs and symptoms of sepsis are not specific and can be confused with non-infectious conditions, including pancreatitis, myocardial infarction, and chronic obstructive pulmonary disease (COPD) exacerbation Slide 6. Slide 6. Unmet Needs in Treating Sepsis [4,5] The drive to provide early appropriate therapy leads clinicians to provide broad-spectrum antibiotics at an early time period, which then drives the emergence of resistance This emergence of resistance to antibiotics makes it more difficult to achieve appropriate therapy Slide 7. Slide 7. Traditional Diagnostic Tools [6] Early identification of the patient with sepsis is essential Clinical diagnostic skills in the acute care setting are complemented with biomarkers C-reactive protein -- marker of inflammation [7,8] Poor specificity Long half-life Procalcitonin -- marker of inflammation [9-11] Currently being studied for potential utilization in antimicrobial stewardship programs to optimize pharmacotherapy Slide 8. Slide 8. Conventional Methods for ID and AST of Positive Blood Cultures Definitive identification of a pathogen can take 24 to 72 hours through traditional culture methods [12] This uncertainty can lead to the empiric administration of overly broad antimicrobial selection  Can result in treatment-related complications, antimicrobial resistance, as well as poor patient outcomes Incubation period needed for culture varies from 12 to 72 hours depending on the bacterial load, the bacteria itself, or if the pathogen is a fungus The gram stain does not provide specific guidance in pathogen identification Slide 9. Slide 9. New Options for ID and AST of Positive Blood Cultures New rapid diagnostic tests can help reduce time from blood culture positivity to identification of the organism and also identify key specific antibiotic resistance genes in positive blood cultures Slide 10. Slide 10. GeneXpert MRSA/SA Blood Culture [13] Slide 11. Slide 11. PNA-FISH [14,15] Slide 12. Slide 12. MALDI-TOF [16] Slide 13. Slide 13. Verigene Blood Culture Test [17,18] Slide 14. Slide 14. FilmArray BCID Panel [19] Slide 15. Slide 15. Overview of Currently Available Large Panel Rapid Diagnostic Devices Slide 16. Slide 16. Rapid Diagnostic Tests in Development [20] Slide 17. Slide 17. Potential Role and Clinical Utility of Rapid Diagnostic Methods Slide 18. Slide 18. Using a PCR-Based Blood Culture Identification Panel With an ASP [21] Slide 19. Slide 19. Implementation of Rapid Diagnostic Tests and ASPs [22,23] Slide 20. Slide 20. Concluding Remarks This content has been condensed for improved clarity. Educational Impact Challenge What did you learn from this activity? Please click on the \"Continue\" button to proceed to a brief survey to see how your knowledge improved after the education. You can also see how your answers compare with those of your peers. Educational Impact Challenge 4 ",
				"clientUrl": "/viewarticle/871087",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 3032590,
				"leadConcept": "Sepsis",
				"concept": ["Antibiotic Resistance", "Antibiotics", "Biomedical Technology", "Medical Technology", "Off-Label Use", "Polymerase Chain Reaction (PCR)", "Laboratory Diagnosis", "Infectious Disease Diagnostics", "Experimental Drug", "Microarray Technologies", "Clinical Research", "Antimicrobial Stewardship"],
				"leadSpecialtyId": 3,
				"leadSpecialty": "Infectious Diseases",
				"allSpecialties": ["Infectious Diseases", "Medscape Today", "Critical Care", "Emergency Medicine"],
				"origContentType": "Roundtable",
				"contentType": ["Article/Courses"],
				"description": "Join our panel of experts as they discuss advances in the diagnosis and management of sepsis.",
				"legacyID": 871087,
				"mediaFlag": "2",
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Advancing Care in Sepsis: Focus on Timely Diagnosis",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:0.50"],
				"maxCredits": [0.5],
				"multimedia": ["/thumbnail_library/871087.jpg"],
				"publicationDate": 1481605200000,
				"postingDate": 1481605200000,
				"_version_": 1573508890533822464,
				"last_index_date": 1500615015539
			}, {
				"id": "pdctm_0901c79180ab3035",
				"activeCME": 1,
				"activityExpirationDate": 1521262800000,
				"authors": ["Harvey L. Levy", " Barbara K. Burton", " Amy C. Cunningham"],
				"body": "Slide 1. Slide 1. Current Issues and Emerging Advances in the Management of PKU Slide 2. Slide 2. Panelists Slide 3. Slide 3. Discussion of Investigational Agents and Data Presented in Abstract Form Educational Impact Challenge Assess your clinical knowledge by completing this brief survey. Answering these questions again after the activity will allow you to see what you learned and to compare your answers with those of your peers. 3 Slide 4. Slide 4. Phenylalanine Pathway in Phenylketonuria [1] Phenylketonuria (PKU) is a disorder in which the amino acid phenylalanine (Phe) cannot be normally metabolized to tyrosine This conversion is due to an enzyme, phenylalanine hydroxylase (PAH), which requires a coenzyme, BH4, in order for it to be effectively active In PKU, PAH is defective Consequently, Phe in the blood is not converted to the amino acid tyrosine Elevated amounts of Phe cross into the brain High Phe concentrations are neurotoxic and result in neurocognitive and neuropsychiatric difficulties The PAH enzyme is generated by the PAH gene In PKU, this gene is mutated, which results in the development of defective enzyme that does not function appropriately to convert phenylalanine to tyrosine Slide 5. Slide 5. What Is Phenylketonuria? [1,2] The incidence of phenylketonuria differs with ethnicity PKU is most commonly identified by newborn screening Every newborn in the United States and in most of the developed world is screened for PKU before leaving the hospital PKU is diagnosed on the basis of a high blood [Phe] Slide 6. Slide 6. Loss of Metabolic Control: Possible Complications of Long-Term Elevated Blood [Phe] [3-8] Neurocognitive dysfunction and psychiatric symptoms are common in adult patients with PKU who have been poorly controlled [9] Executive function deficit is manifested by problems with short-term memory, organizational skills, and processing speed Patients with PKU have a greater likelihood of being diagnosed with attention deficit hyperactivity disorder (ADHD) All of these symptoms and problems are a result of lack of good metabolic control Over time, many adolescent and adult patients are unable to completely adhere to their management plan, which typically, is diet-based Developing these neurocognitive deficits then makes it more challenging to adhere to their PKU management which requires organization, planning, and executive functioning skills Even adults whose PKU has been well-controlled may experience difficulty with some higher level brain function Slide 7. Slide 7. Goal of Treatment: Control Blood [Phe] [1] Current guidelines suggest maintaining blood [Phe] below 360 µmol/L This is critically important in the pediatric population; however in adults, control may not need to be so tight Maintaining blood [Phe] in the range of 120 to 360 µmol/L is suggested by the American College of Medical Genetics and Genomics (ACMG) Practice Guidelines as optimal for all patients with PKU European guidelines were recently published for the diagnosis and management of patients with PKU [10] The guidelines recommend maintaining blood [Phe] between 120 to 360 µmol/L in patients up to 12 years of age and 360 to 600 µmol/L in adolescents and adults older than 12 years It is important to assess bone density in teens and adults because of an increased risk of osteopenia and osteoporosis [11,12] Best treatment requires close collaboration and teamwork with multiple specialists, including physicians, metabolic dietitians, social workers, nurses, and genetic counselors Slide 8. Slide 8. Understanding the Basis of Nutritional Management of PKU [13] When the PAH enzyme is dysfunctional, blood [Phe] builds up and accumulates to neurotoxic levels Blood tyrosine, an important substrate for neurotransmitter synthesis, also becomes deficient PAH is a catabolic enzyme and it is only active when there is more Phe absorbed from the diet than the body can use for protein synthesis Slide 9. Slide 9. Dietary Management of PKU [13] The average PKU diet may have as little as 6 to 15 grams of intact protein from food Obtain protein from fruits, vegetables, some starches, and specialty low-protein foods Average PKU diet allows <25% of average protein requirements from food and insufficient calories Slide 10. Slide 10. PKU Diet: Compliance Barriers PKU diet requires a lot of planning, record keeping, food preparation skills, and even math skills Patients need to understand that they often have to prepare foods that are different from what the rest of their family is going to eat Slide 11. Slide 11. Treatment Strategies for Adults With PKU There is also a population of adults with PKU who were born before newborn screening became routine; they were not treated until after they were symptomatic Neurological damage cannot be reversed, but instituting moderate changes in diet can improve behavior and cognition [13] Slide 12. Slide 12. Maternal PKU [1,14-16] Slide 13. Slide 13. Adjunct Pharmacotherapy: Sapropterin Dihydrochloride [1,17-19] Sapropterin dihydrochloride is a synthetic form of the co-enzyme BH4, needed by the PAH enzyme. When additional sapropterin is given to a patient with PKU who is responsive to it, it can increase the function of residual PAH in that person Sapropterin dihydrochloride does not work in all patients; however, when it does, it can be beneficial in keeping blood [Phe] within treatment range In patients who respond to sapropterin dihydrochloride treatment, it may allow an increase in dietary Phe, which can improve patients' quality of life Slide 14. Slide 14. Adjunct Therapy: Large Neutral Amino Acids [1,20] Large neutral amino acids (LNAAs) are a nutritional supplement There is a lack of well-designed and peer-reviewed studies of use of LNAAs [1] As a result, the benefit and risk profile is not well understood Slide 15. Slide 15. Pegvaliase: What Is It and How Does It Work? [21] Pegvaliase is being developed as an enzyme substitution (for the dysfunctional PAH enzyme) treatment for PKU that breaks down phenylalanine in the body It is a pegylated bacterial enzyme called phenylalanine ammonia lyase, which is not found in humans The pegylated form of phenylalanine ammonia lyase (pegvaliase) breaks down Phe into ammonia and trans-cinnamic acid, both of which can be readily excreted The pegylation helps to protect against the immunologic reaction to the foreign protein Slide 16. Slide 16. Pegvaliase: PRISM-2 Study Results [22] Pegvaliase is currently undergoing the completion of a placebo-controlled randomized phase 3 clinical trial Patients in the study had largely abandoned dietary treatment As per findings to date, the medication has to be started at a low dose and gradually uptitrated Slide 17. Slide 17. Concluding Remarks and Looking Ahead Slide 18. Slide 18. Thank You This content has been condensed for improved clarity. Educational Impact Challenge What did you learn from this activity? Please click on the \"Continue\" button to proceed to a brief survey to see how your knowledge improved after the education. You can also see how your answers compare with those of your peers. Educational Impact Challenge 4 ",
				"clientUrl": "/viewarticle/872901",
				"creditType": ["CME", "ABIM MOC"],
				"cmeFlag": "CME / ABIM MOC",
				"leadConceptId": 0,
				"concept": ["Nutrition", "Disease Management", "Adherence", "Patient Care Management", "Pregnancy", "Adjuvant Therapy", "Diet", "Inheritance", "Genetics", "Pathogenesis", "Experimental Drug", "Inborn Errors of Metabolism", "Inherited Metabolic Disorder", "Phenylketonuria", "Genetic Disorders", "Clinical Research", "Patient History", "Patient Assessment", "Multidisciplinary Team"],
				"leadSpecialtyId": 22,
				"leadSpecialty": "Diabetes & Endocrinology",
				"allSpecialties": ["Diabetes & Endocrinology", "Ob/Gyn & Women's Health", "Medscape Today", "Family Medicine/Primary Care"],
				"origContentType": "Roundtable",
				"contentType": ["Article/Courses"],
				"description": "Join the experts as they discuss updates in the management of patients with PKU.",
				"legacyID": 872901,
				"mediaFlag": "2",
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Current Issues and Emerging Advances in the Management of PKU",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:0.50", "US Physicians:Points for ABIM MOC:0.50"],
				"maxCredits": [0.5],
				"multimedia": ["/thumbnail_library/872901.jpg"],
				"publicationDate": 1489726800000,
				"postingDate": 1489726800000,
				"_version_": 1573508892837543936,
				"last_index_date": 1500615017736
			}, {
				"id": "pdctm_0901c79180a09aa3",
				"activeCME": 1,
				"activityExpirationDate": 1501650000000,
				"authors": ["Anne L. Peters", " Vivian A. Fonseca", " Matthew R. Weir", " Julio Rosenstock", " Yehuda Handelsman", " Joshua J. Neumiller"],
				"body": "Contents of This CME Activity div.articleTitle { font-size: 1.2em; font-weight: bold;} div#prgteaser {clear: left; padding-top: 10px;} All sections of this activity are required for credit. CV Benefit With Liraglutide: Perspectives From the LEADER Trial What are the key takeaways from the latest CV outcomes trial, LEADER? Vivian A. Fonseca, MD; Anne L. Peters, MD Examining the Effects of Empagliflozin on Microvascular and Macrovascular Outcomes What is the effect of empagliflozin on blood pressure and renal outcomes? Matthew R. Weir, MD; Anne L. Peters, MD Combination Therapy With an SGLT2 Inhibitor Plus a DPP-4 Inhibitor How effective is combination triple oral therapy for the treatment of type 2 diabetes? Julio Rosenstock, MD; Anne L. Peters, MD Quality Glucose Monitoring: Glycemic Variability and Quality of Glycemic Control What effect do newer antihyperglycemic classes have on glycemic variability? Yehuda Handelsman, MD; Anne L. Peters, MD Perspectives of a Pharmacist on Modern T2D Management How might new CV outcomes data impact the management of type 2 diabetes? Joshua J. Neumiller, PharmD, CDE; Anne L. Peters, MD CV Benefit With Liraglutide: Perspectives From the LEADER Trial « Back Continue » 0 Slide 1. Slide 1. American Diabetes Association (ADA) 2016 Conference Coverage: What's New and Improved in Type 2 Diabetes? Slide 2. Slide 2. Cardiovascular (CV) Benefit With Liraglutide: Perspectives From the LEADER Trial Slide 3. Slide 3. LEADER: Majority of Participants Had Previous CV Disease [1] Study results apply to those studied in the clinical trial; be careful in extrapolating to the general population Slide 4. Slide 4. ELIXA: Study Design [1] Slide 5. Slide 5. LEADER: Primary Outcome [1] Slide 6. Slide 6. LEADER: Cardiometabolic Factors [1] No increase in risk in pancreatitis or pancreatic cancer with liraglutide Slide 7. Slide 7. ELIXA: Study Design [2] Slide 8. Slide 8. FREEDOM-CVO Trial [3] Examining the Effects of Empagliflozin on Microvascular and Macrovascular Outcomes « Back Continue » 0 Slide 1. Slide 1. Examining the Effects of Empagliflozin on Microvascular and Macrovascular Outcomes Slide 2. Slide 2. Sodium-Glucose Cotransporter 2 (SGLT2) Inhibitors: Effect on Blood Pressure Modest lowering of systolic and diastolic blood pressure (about 2 to 4/about 1 to 2 mm Hg) with SGLT2 inhibitors [4-6] Reduction in blood pressure with empagliflozin without increases in heart rate [7] Whether blood pressure effect is class dependent remains unknown Slide 3. Slide 3. EMPA-REG: Renal Outcomes [8] Empagliflozin associated with fewer adverse renal outcomes in some patients Slide 4. Slide 4. Ongoing CREDENCE Study [9] Combination Therapy With an SGLT2 Inhibitor Plus a DPP-4 Inhibitor « Back Continue » 0 Slide 1. Slide 1. Combination Therapy With an SGLT2 Inhibitor Plus a Dipeptidyl Peptidase-4 (DPP-4) Inhibitor Slide 2. Slide 2. SGLT2 Inhibitors Plus DPP-4 Inhibitors [10] Slide 3. Slide 3. Efficacy and Safety of Dual Add-On of Saxagliptin (Saxa) Plus Dapagliflozin (Dapa) to Metformin (Met) [11] Slide 4. Slide 4. Quality Measures Assessment With Triple Therapy: Saxa Plus Dapa Plus Met [12] Reduction in blood pressure with triple therapy Slide 5. Slide 5. MARLINA Trial: Effect of Linagliptin on Microalbuminuria [13] Lowering of blood pressure may be associated with lowering of microalbumin Slide 6. Slide 6. Ongoing CARMELINA Trial [14] Quality Glucose Monitoring: Glycemic Variability and Quality of Glycemic Control « Back Continue » 0 Slide 1. Slide 1. Quality Glucose Monitoring: Glycemic Variability and Quality of Glycemic Control Slide 2. Slide 2. Moving Beyond Glycated Hemoglobin: Average Glucose [15] Slide 3. Slide 3. 24-Hour Glycemic Control of Dapa [16] Slide 4. Slide 4. Dapa Increased Time in Euglycemia [16] Sulfonylurea contributed to increased risk of hypoglycemia Slide 5. Slide 5. 24-Hour Glycemic Control of Exenatide Once Weekly [17] Slide 6. Slide 6. Exenatide Once Weekly Improved Glycemic Fluctuations [17] Exenatide once weekly was not associated with an increased risk of hypoglycemia Most common adverse events were mild injection site reactions, mild-to-moderate urinary tract infection, and mild-to-moderate nausea Perspectives of a Pharmacist on Modern T2D Management « Back Slide 1. Slide 1. Perspectives of a Pharmacist on Modern Type 2 Diabetes Management Slide 2. Slide 2. Recent CV Outcomes Trials: What We Learned [1,7,18] Slide 3. Slide 3. Potential Mechanisms for Effect of Empagliflozin on CV Death? [19-21] Risk of diabetic ketoacidosis increased in stressful conditions (eg, surgery) [21] People with latent autoimmune diabetes who are misdiagnosed as having type 2 diabetes at high risk for diabetic ketoacidosis [21] Slide 4. Slide 4. FREEDOM-2 Trial: ITCA 650* [22] Potential for nausea and vomiting remains Slide 5. Slide 5. Efficacy and Safety of Once-Weekly Semaglutide* [23,24] Slide 6. Slide 6. Exenatide Once Weekly Reduces Glycemic Variability [25] 3 Slide 7. Slide 7. Closing Comments Slide 8. Slide 8. Thank You *The US FDA has not yet approved this medication for use. This content has been condensed for improved clarity. ",
				"clientUrl": "/viewarticle/866327",
				"creditType": ["CME", "Nurse CE", "Pharmacist CE", "ABIM MOC"],
				"cmeFlag": "CME / ABIM MOC / CE",
				"leadConceptId": 1069,
				"leadConcept": "Type 2 Diabetes Mellitus",
				"concept": ["Diabetes Mellitus", "Cardiovascular disease (CVD)", "Coronary Artery Disease (CAD)", "Patient Pharmaceutical Care Management", "Clinical Pharmacology", "Patient Care Management", "Adverse Effects", "Cardiovascular Nursing", "Public Health Nursing", "Experimental Drug", "Pharmacologic Adverse Events", "Primary and Secondary Prevention of Coronary Artery Disease", "Coronary Heart Disease Risk Factors", "Clinical Research", "DPP-4 Inhibitors", "Noninsulin Antidiabetic Drugs", "SGLT2 Inhibitor"],
				"leadSpecialtyId": 22,
				"leadSpecialty": "Diabetes & Endocrinology",
				"allSpecialties": ["Diabetes & Endocrinology", "Cardiology", "Medscape Today", "Nursing", "Pharmacist", "Family Medicine/Primary Care"],
				"origContentType": "Commentary",
				"contentType": ["Expert Commentary"],
				"description": "In this series of interviews led by Dr Peters, experts in diabetes and nephrology comment on late-breaking data from the 2016 ADA meeting.",
				"legacyID": 866327,
				"mediaFlag": "2",
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "ADA 2016 Conference Coverage: What's New and Improved in Type 2 Diabetes?",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:0.50", "US Physicians:Points for ABIM MOC:0.50", "Nurses:ANCC Contact Hour(s):0.50", "Pharmacists:Knowledge-based ACPE:0.50"],
				"maxCredits": [0.5],
				"multimedia": ["/thumbnail_library/866327.jpg"],
				"publicationDate": 1470114000000,
				"postingDate": 1470114000000,
				"_version_": 1573508896846249984,
				"last_index_date": 1500615021559
			}, {
				"id": "pdctm_0901c79180a3593e",
				"activeCME": 1,
				"activityExpirationDate": 1513659600000,
				"authors": ["Anjay Rastogi"],
				"body": "The following cases are modeled on the interactive grand rounds approach. The questions within the activity are designed to test your current knowledge. After each question, you will be able to see whether you answered correctly and read evidence-based information that supports the most appropriate answer choice. The questions are designed to challenge you; you will not be penalized for answering the questions incorrectly. At the end of the activity, there will be a short post-test assessment based on the material presented. Case 1 200 133 Marta is a 48-year-old Hispanic woman with a 10-year history of type 2 diabetes (T2D). She has a body mass index (BMI) of 27.2 kg/m 2 , down from 28.4 kg/m 2 one year ago. Her waist-to-hip ratio is 0.82. Her primary care physician has referred her to you because of a recent drop in estimated glomerular filtration rate (eGFR) from 60 mL/min/1.73 m 2 one year ago to 43 mL/min/1.73 m 2 now. Marta has also displayed a recent persistent increase in blood pressure readings taken at home. When measured at this office visit, her blood pressure is 168/101 mm Hg. Marta's total serum cholesterol is 180 mg/dL, high-density lipoprotein cholesterol is 58 mg/dL, and low-density lipoprotein cholesterol is 93 mg/dL. Her albumin-to-creatinine ratio is 61 mg and previously was 104 mg. Sodium is 134 mEq/L, potassium is 4.2 mEq/L, chloride is 99 mEq/L, bicarbonate is 24 mEq/L, glucose is 225 mg/dL, and calcium is 9.5 mg/dL. A recent vitamin D level was 42 ng/mL. She has a white blood cell count of 6.2, hemoglobin of 13.9 g/dL, hematocrit of 40.4%, and a platelet count of 130. Her most recent glycated hemoglobin (HbA 1c ) level was 6.7%. Her current medications include metformin 1000 mg twice daily, glipizide 10 mg daily, lisinopril 10 mg, vitamin D3 1000 units daily, and hydrochlorothiazide (HCTZ) 25 mg. Marta has never smoked and denies alcohol use. She attributes her recent weight loss to following a popular carbohydrate-restricted diet regimen. 3 Discussion CKD is typically a progressive disease characterized by a continued decrease in the eGFR over time. There are several factors known to contribute to loss of renal function, and these should each be addressed to slow disease progression. Nearly 40% of adult individuals with T2D also have CKD. [1] The prevalence of CKD in patients with T2D varies by race and ethnicity, with black and Mexican-American patients being at higher risk compared with white patients. [1] The presence of hypertension in patients with T2D is strongly associated with concomitant CKD. [1] Hypertension is also strongly associated with CKD progression: numerous studies have shown that in both patients with diabetic and nondiabetic kidney disease, elevated blood pressure is associated with a more rapid decline in eGFR. [2] Factors such as smoking, obesity, age, and history of cardiovascular disease are also associated with the progression of CKD. In addition, microalbuminuria and proteinuria are well-established risk factors for the development and progression of CKD. Other factors that are associated with the risk for CKD include acute kidney injury, nephrolithiasis, hyperuricemia, and metabolic bone disease. [3-6] In patients who have both CKD and diabetes, glycemic control is an important factor in reducing the rate at which renal function declines. [7] 5 Discussion The RAAS is an important factor in the regulation of blood pressure, sodium, and water balance, as well as cardiovascular and renal homeostasis. Optimal management of CKD emphasizes RAAS blockade and blood pressure control. [8] An ACE inhibitor or ARB is recommended for patients with CKD and diabetes whose urinary albumin excretion is 30-300 mg/24 h and for all patients with CKD, with and without diabetes, whose urinary albumin excretion is >300 mg/24 h. [2] In addition, patients with albuminuria should receive ACE inhibitor or ARB therapy, irrespective of the need for blood pressure control. RAAS inhibitors (ACE inhibitors, ARBs, aldosterone antagonists, and direct renin inhibitors) should be avoided in patients with renal artery stenosis. [8] Although medications should be started at a lower dose in patients with CKD, guideline recommendations are to uptitrate and maximize the RAAS inhibitor dose whenever possible in patients with diabetes, CKD, and hypertension. [9] Table 1 suggests target doses of various RAAS inhibitors. [10] Table 1. RAAS Inhibitor Target Doses [10] Drug Class Target dose Benazepril ACE inhibitor 20-40 mg/day Captopril ACE inhibitor 25-150 mg 2 to 3 times daily Enalapril ACE inhibitor 10-40 mg/day Fosinopril ACE inhibitor 20-80 mg/day Lisinopril ACE inhibitor 20-40 mg/day Moexipril ACE inhibitor 7.5-30 mg/day Perindopril ACE inhibitor 4-16 mg/day Quinapril ACE inhibitor 20-80 mg/day Ramipril ACE inhibitor 1.25-20 mg/day Trandolapril ACE inhibitor 2-4 mg/day Candesartan ARB 2-32 mg/day Eprosartan ARB 400-800 mg/day Irbesartan ARB 150-30 mg/day Losartan ARB 25-100 mg/day Olmesartan ARB 20-40 mg/day Telmisartan ARB 40-80 mg/day Valsartan ARB 80-320 mg/day ACE = angiotensin-converting enzyme; ARB = angiotensin receptor blocker. Source: American Diabetes Association. [10] If blood pressure goals have not been met with RAAS inhibition, a dihydropyridine calcium channel blocker (CCB) such as amlodipine, or a thiazide-like diuretic, such as HCTZ or chlorthalidone, can be added and is a reasonable second choice. [10] However, if the patient's eGFR is <30 mL/min/1.73 m 2 , HCTZ or chlorthalidone are less efficacious; a loop diuretic is preferred instead. [10] It should be noted that thiazide-like diuretics have the potential for metabolic complications and patients should be monitored carefully. [11] Among the thiazide-like diuretics, chlorthalidone may be preferred because it has a longer half-life and was studied in the major hypertension trials, including ALLHAT and the recently concluded SPRINT. [12,13] CCBs are also a reasonable addition to the management of hypertension. Case 1, continued You increase Marta's lisinopril dose to 20 mg/day and ask her to return in 1 week for follow-up including labs. At that time, her serum potassium level is within normal limits (4.2 mEq/L), and her serum creatinine concentration is also within normal limits. Her blood pressure is 144/95 mm Hg. The urine albumin-to-creatinine ratio remains at 61 mg/g. 6 Discussion Blood pressure should be measured at every routine visit, and patients with diabetes who have elevated blood pressure should have the measurement confirmed on a separate day. Patients with diabetes and hypertension should be treated to a systolic blood pressure goal of <140 mm Hg and a diastolic goal of <90 mm Hg. [10,14-16] Lower goals may be appropriate for younger patients, patients with albuminuria, and/or patients with hypertension and one or more additional atherosclerotic cardiovascular disease risk factors, if the goal can be achieved without undue treatment burden. [10,17] In certain populations of patients with CKD, including the elderly and those with diabetes, more aggressive blood pressure targets could lead to negative outcomes, such as acute deterioration in kidney function, increased risk of cardiovascular events, and orthostatic hypotension. [10] Patients with diabetes and blood pressure >120/80 mm Hg should be counseled on lifestyle changes to reduce blood pressure. Patients with confirmed office-based blood pressure >140/90 mm Hg should also have prompt initiation and timely titration of pharmacological therapy to achieve blood pressure goals. [10] Home blood pressure monitoring and ambulatory blood pressure monitoring have better results in general as opposed to office measurements; therefore, it is important to educate the patient on the correct way to measure their blood pressure. Substantial evidence shows that RAAS inhibitors can slow the progression of worsening kidney disease in patients with diabetic nephropathy. The Irbesartan Diabetic Nephropathy Trial (IDNT) and RENAAL trial, which used irbesartan and losartan, respectively, demonstrated that patients treated with RAAS inhibitor therapy had decreased proteinuria and a lower incidence of the doubling of serum creatinine and end-stage renal disease (ESRD). [18,19] The significant improvements in renal outcomes in both studies were independent of the reductions seen in blood pressure. These studies both demonstrate the importance of continuing RAAS inhibitor therapy in this patient population to slow the rate of progression to ESRD. Case 1, continued You increase Marta's lisinopril dose from 20 to 40 mg/day. When she returns in the following 2 weeks, her: Serum potassium is 5.1-5.2 mEq/L (high-normal) Serum creatinine has increased by 25% and eGFR has dropped to 38 ml/min/1.73m 2 from 43 ml/min/1.73m 2 Bowel movements are regular 7 Discussion Potassium and/or serum creatinine are expected to increase when starting or changing the dose of an ACE inhibitor or an ARB. The rise in serum creatinine value usually begins a few days after beginning therapy with an ACE inhibitor or an ARB, as angiotensin II levels are rapidly reduced or blocked from binding. An increase in creatinine concentration of about 25% to 30% above baseline is acceptable. [20,21] Obtain potassium and serum creatinine levels before starting or changing the dose of an ACE inhibitor or ARB, and check them again 1 week after initiation or dose change. [8] It is also important to educate patients on the importance of a low-potassium diet. They should become aware that many salt substitutes contain potassium chloride and that these should be avoided when high potassium is a concern (Table 2). [22] Many patients are already on other diets, such as the DASH diet, for hypertension. This diet, as well as those for patients with diabetes, tends to be high in fruits and vegetables. These foods however, are high in potassium as well. Table 2. Elements of a Low-Potassium Diet [22] Element Description Potassium intake goals About 2000 mg/day is usually a reasonable target--individualize as indicated High-potassium foods Examples include: •\tFruits: apricots, bananas, cantaloupes, grapefruit juice, mangos, oranges, pomegranates, prunes, all dried fruits •\tVegetables: acorn squash, avocados, artichokes, beets, broccoli, brussel sprouts, butternut squash, carrots, okra, parsnips, potatoes, white and sweet, pumpkin, spinach, cooked, tomatoes/tomato products, vegetable juices •\tOther: bran/bran products, black beans, chocolate, nuts and seeds (including peanut butter), salt substitutes/lite salt, salt-free broth, milk and yogurt Prepared foods Always check the label for potassium content Nutritional supplements Ask patients about what they are taking and advise them to check with you prior to adding supplements to their diet Source:National Kidney Foundation. [22] Case 1, continued Marta continues to follow up over the next few months. Her potassium levels were within normal limits and she had no issues with her treatment plan. She presents today, at month 6, for another follow-up visit. Her blood pressure today is 130/80 mm Hg. Repeat lab results show that her potassium is 6.1 mEq/L. Her creatinine levels are unchanged. She mentions a recent urinary tract infection (UTI) that was treated with 800 mg sulfamethoxazole and 160 mg trimethoprim (TMP-SMX). In addition, she recently returned from a volunteer mission trip to Central America, for which she had to take chloroquine and an antiparasitic, ivermectin. 8 Discussion Trimethoprim induces a progressive but reversible increase of serum potassium concentrations in a substantial number of patients. Furthermore, treatment with recommended doses may cause hyperkalemia in patients with potassium metabolism disorders, or renal insufficiency. [23] Clinical studies have demonstrated that TMP-SMX, both at high doses and standard doses, can cause hyperkalemia. [23] Although the occurrence of hyperkalemia is not frequent, it is still an important factor to be aware of when prescribing TMP-SMX to patients. The structure of trimethoprim is similar to amiloride, a potassium-sparing diuretic. The adverse effect of hyperkalemia arises via competitive inhibition of epithelial sodium channels in the principal cells of the collecting ducts, reducing renal potassium excretion. [23] Marta's case illustrates the importance of checking medication lists, including over-the-counter medications and herbal supplements. This is essential both for finding potential causes for hyperkalemia and for checking for interactions between medications. Pharmacists should be vigilant in checking patient medications in the system to confirm that there are no dangerous interactions. Medications associated with an increased risk for hyperkalemia include: [24] Potassium-sparing diuretics, such as spironolactone, eplerenone, amiloride, and triamterene Beta-blockers Cyclosporine or tacrolimus Nonsteroidal anti-inflammatory agents Heparin Digoxin Conclusion You discontinue TMP-SMX and start Marta on ciprofloxacin 250 mg BID for the UTI. You ask her to return in 1 week. At follow-up, Marta's potassium level has normalized and is 4.7 mEq/L. She has recovered from the UTI and is doing well. Case 2 200 133 Carolyn is a 66-year-old black woman you have been treating for CKD for about 9 years. She currently has an eGFR of 26 mL/min/1.73 m 2 . She has a 3-year history of T2D and currently has New York Heart Association class II left-sided congestive heart failure (CHF). Her diabetes is well controlled, with an HbA 1c of 6.5% and no signs of diabetic retinopathy. Her BMI is 35.5 kg/m 2 . Her waist-to-hip ratio is 0.97. Her current medications include benazepril 20 mg, hydrochlorothiazide 25 mg, metoprolol tartrate, glipizide, and insulin glargine. A urine test reveals 800 mg/g on albuminuria testing. 9 Discussion A patient with an eGFR of 15 to 29 mL/min/1.73m 2 has stage 4 CKD (Table 3). [8] In a patient with diabetes, it is important to differentiate diabetic kidney disease (DKD) and non-diabetic kidney disease (NDKD), because the 2 conditions have distinct prognoses and require different therapeutic approaches. Table 3. Categories of GFR in CKD [8] GFR Category GFR, ml/min/1.73m 2 G1 ≥ 90 G2 60-89 G3a 45-59 G3b 30-44 G4 15-29 G5 <15 CKD = chronic kidney disease; GFR = glomerular filtration rate. Source: Inker LA. [8] Patients with diabetic nephropathy and type 1 diabetes often present with other signs of diabetic microvascular disease, such as retinopathy and neuropathy; however, this is less predictable in patients with T2D. [25,26] Patients with T2D who present with proteinuria and retinopathy will likely have diabetic nephropathy. On the other hand, if a patient does not have retinopathy, then they likely have NDKD. [27,28] The 2004 ADA position statement recommends screening patients with diabetes for microalbuminuria. [29] For patients with type 1 diabetes, screening is recommended in those who have had diabetes for more than 5 years. In patients with T2D, screening for diabetic nephropathy is recommended at the time of diagnosis. Once a diagnosis of microalbuminuria or macroalbuminuria is made, further workup, including measurement of the serum creatinine concentration and eGFR should also be performed to assess renal function. Renal biopsies are not routinely indicated, especially if the patient presents with a typical history; however, if the diagnosis cannot be clearly determined, then a biopsy can be performed to confirm diagnosis. The criteria for renal biopsy are currently not well established. In previous studies, the criteria for performing a renal biopsy in patients with type 1 diabetes were the presence of proteinuria with short duration of diabetes and/or rapid decline of renal function, along with absence of retinopathy. [30] The criteria for renal biopsy in patients with T2D are less clear; thus, in both T1D and T2D populations, the decision to perform a biopsy is made by the physician upon weighing the risks and benefits. In patients with DKD, ACE inhibitors and ARBs are effective in blood pressure reduction as well as delaying progression of nephropathy. [31,32] ACE inhibitors are more strongly recommended as initial therapy in T1D. [29] In most cases, diuretic therapy is also indicated as an add-on to further control blood pressure. Nondihydropyridine calcium channel blockers can also be utilized if treatment with a diuretic does not help reach blood pressure goal. The ultimate goal with these antihypertensive treatments is to reduce the blood pressure to less than 130/80 mm Hg. Treatment of micro or macroalbuminuria with strict glycemic control has not been established; however, studies have shown that improvement of glucose levels in addition to blood pressure levels can slow down progression of renal disease. [33] Most patients with NDKD have hypertension. In the AIPRI and REIN studies, the prevalence of hypertension in the study population was 92% and 84%, respectively. [34,35] Several studies have also shown that there is a strong relationship between high levels of blood pressure and worsening of kidney function; therefore, it is imperative to treat these patients with the appropriate drugs, which include at least 2 to 3 antihypertensive agents. [9,36,37] Target blood pressure in NDKD should be <130/80 mm Hg. Based on findings from several randomized trials showing the benefit of ACE inhibitors in slowing the progression of kidney disease in patients who have NDKD, the Kidney Disease Outcomes Quality Initiative (KDOQI) guidelines strongly recommend the use of ACE inhibitors in this patient population. They also state that ACE inhibitors, ARBs and CCBs have greater effects in reducing proteinuria in patients with NDKD, and also strongly recommend their use. Diuretics have been shown to potentiate the effects of ACE inhibitors and ARBs, and can be used as add-on therapy for these patients as well. [38] A detailed discussion of the management and treatment of patients with DKD and NDKD is beyond the scope of this activity. Please refer to JNC8, ADA2004, and the KDOQI guidelines for more information. Case 2, continued At the same office visit, Carolyn's blood pressure is 158/103 mm Hg. 10 Discussion As previously discussed, blood pressure control (achieving a target <130/80 mm Hg) reduces the risk of renal disease progression and cardiovascular morbidity and mortality. The use of calcium channel blockers in patients with CKD, diabetes, and hypertension can be considered if RAAS inhibitors have been prescribed and the patient’s blood pressure target has not been reached. [9] However, in Carolyn's case, since her eGFR has already declined to stage 4, a thiazide will probably be ineffective, and a trial of a loop diuretic such as furosemide is advisable. [9] Case 2, continued About 3 weeks after her office visit, Carolyn presented to the emergency department with extreme weakness, fatigue, and not feeling well overall. She was found to have a potassium level of 6.2 mEq/L and an eGFR of 22 mL/min/1.73m 2 . Electrocardiography showed peaked T waves. Carolyn received calcium gluconate, insulin with glucose, oral sodium polystyrene sulfonate (SPS), and sodium bicarbonate, and benazepril was withheld. She was held in the observation unit for 24 hours and subsequently discharged when her potassium was found to normalize at 4.9 mEq/L. The cardiologist refers her back to you for management of the hyperkalemia, and 2 days after her release from the hospital you see her in your office. She is currently following recommendations for a strict low-potassium diet, and she presents with a potassium level of 4.8 mEq/L. She is currently not on any RAAS inhibitor. 11 Discussion In addition to the beneficial effects in lowering blood pressure, RAAS inhibition protects patients with CKD from further decline in renal function. [39-41] However, the risk of severe hyperkalemia can be a factor that limits the use of RAAS inhibition in patients with CKD stage 3 or greater. ACE inhibitors block the development of circulating angiotensin II, and ARBs prevent angiotensin II from binding to the adrenal receptor. In these separate ways, each interferes with the stimulatory effect of angiotensin II on aldosterone secretion in the adrenal gland, resulting in impaired renal excretion of potassium. [24] Numerous other factors, such as older age, medications, and reduced renal function, appear to contribute to the risk of hyperkalemia as well. SPS is a cation-exchange resin that has been used for decades as the primary treatment for hyperkalemia. It is indicated for the treatment of acute hyperkalemia. It takes up potassium in the colon, where concentration of potassium is the highest, and releases sodium. It can be administered orally or by enema. However, there are few clinical trial data evaluating its efficacy, and its use is often limited by adverse events (Table 4). [42,43] In most cases, more than one dose of SPS is necessary to lower serum potassium levels, which can be problematic for many patients due to its unpleasant taste and side effect of diarrhea. SPS may also bind to other medications administered by mouth. In 2015, the US Food and Drug Administration (FDA) requested studies to investigate the drug's potential to bind to other orally administered medications, decreasing the effect of these medications. [44] In the meantime, to reduce this potential risk, it is recommended to take SPS 6 hours apart from other oral medications. Table 4. Sodium Polystyrene Sulfonate [45,46] Agent Mechanism of Action Potential Limitations Sodium polystyrene sulfonate (FDA approval 1958) Nonspecific sodium cation-exchange resin • GI disturbances • Poor tolerance due to taste and smell • Hypomagnesemia • Hypocalcemia • Systemic alkalosis • Colonic necrosis (rare but often fatal) • Multiple doses required • Increased sodium load • Hypokalemia • Potential drug-drug interactions FDA = US Food and Drug Administration; GI = gastrointestinal. Source: Sterns RH [45] , McGowan CE [46] . Historically, SPS was often administered with sorbitol, but this practice is no longer recommended. The addition of sorbitol was to help relieve constipation and fecal impaction resulting from SPS administration. [46] In September 2009, the FDA issued warnings with regard to the concomitant use of SPS and sorbitol, following reports of colonic necrosis, as well as rare but potentially serious gastrointestinal (GI) adverse events such as bleeding, perforation, and ischemic colitis. [47] Another effect of SPS is an increase in sodium load as a result of releasing sodium with potassium uptake. This is particularly a concern in patients with severe CHF, severe hypertension, edema, or renal disease. [48] Case 2, continued The day after her visit to your office, Carolyn calls saying that she has had severe vomiting each time she takes SPS and now gags at the very smell of it. 12 Discussion Patiromer is an orally administered potassium-binding agent that received FDA approval in 2015 for the treatment of chronic hyperkalemia. [49] Patiromer lowers potassium levels in patients with CKD, diabetes mellitus, hypertension, and heart failure, and in patients receiving RAAS inhibitors. Unlike SPS, patiromer is tasteless and odorless, and it is indicated for use once daily. Table 5. Patiromer [49] Agent Mechanism of Action Potential Limitations Patiromer (FDA approval 2015) Calcium-potassium cation-exchange resin • GI disturbances • Possible calcium load • Hypomagnesemia • Hypokalemia • Potential drug-drug interactions FDA = US Food and Drug Administration; GI = gastrointestinal. Source: Veltassa™ PI. [49] The efficacy and safety of patiromer has been established in several clinical trials. The AMETHYST-DN trial was a phase 2, 52-week open-label, dose-ranging study in outpatients with T2D. [50] The participants were stratified by baseline potassium level as having mild (n = 222) or moderate (n = 84) hyperkalemia. Patients with mild hyperkalemia were randomly assigned to receive patiromer doses of 4.2, 8.4, or 12.6 g twice daily. Patients with moderate hyperkalemia were randomly assigned to receive patiromer 8.4, 12.6, or 16.8 g twice daily. All patients were also treated with a RAAS inhibitor. Patients with mild hyperkalemia The 4.2-g dose was associated with a mean reduction of 0.35 mEq/L The 8.4-g dose was associated with a mean reduction of 0.51 mEq/L The 12.6-g dose was associated with a mean reduction of 0.55 mEq/L Patients with moderate hyperkalemia The 8.4-g dose was associated with a mean reduction of 0.87 mEq/L The 12.6-g dose was associated with a mean reduction of 0.97 mEq/L The 16.8-g dose was associated with a mean reduction of 0.92 mEq/L Hypomagnesemia (7.2%) was the most common treatment-related adverse event, and mild to moderate constipation (6.3%) was the most common GI adverse event. Hypokalemia (<3.5 mEq/L) was seen in 5.6% of patients. [50] In a post hoc analysis of AMETHYST-DN, investigators evaluated the change in serum potassium over 52 weeks in a subgroup of 79 patients with DKD who had hyperkalemia and resistant hypertension. [51] The results provide additional evidence of the benefits of patiromer in this population. Patients were classified as having resistant hypertension if they had a baseline systolic blood pressure >140 mmHg on 4 classes of antihypertensive medication, including a diuretic. All patients were on RAAS inhibitor therapy. Reductions in serum potassium were seen as early as 48 hours after the first patiromer dose, and significant ( P <.001) reductions from baseline were sustained throughout the 52 weeks of treatment. A phase 3 trial of patiromer, OPAL-HK, had 2 phases. [52] In the initial, 4-week, single-blind treatment phase, 92 patients with CKD and mild hyperkalemia received treatment with patiromer 4.2 g twice daily, and 151 patients with CKD and moderate to severe hyperkalemia were treated with patiromer 8.4 g. In this phase, patiromer was associated with significant reductions in serum potassium ( P <.001). At the end of the initial 4-week phase, randomized treatment began. Eligible patients (those with a baseline potassium level of 5.5 to <6.5 mmol/L in whom the level decreased to 3.8 to <5.1 mmol/L) entered 8 weeks of treatment in which they were randomly assigned to continue patiromer or switch to placebo. The primary efficacy end point of OPAL-HK was the difference in the median change in serum potassium level over the first 4 weeks of the randomized phase. [52] Among the 107 patients who entered the randomized withdrawal phase, the median increase in potassium from baseline of the randomized phase to week 4 was significantly greater with placebo than with patiromer ( P <.001). Recurrence of hyperkalemia (defined as potassium level ≥5.5 mmol/L) occurred in 60% of the patients in the placebo group compared with 15% in the patiromer group through week 8 ( P <.001). Mild to moderate constipation was the most common adverse event (in 11% of the patients); hypokalemia occurred in 3%. [52] According to a recent analysis of the OPAL-HK trial, patiromer significantly reduced serum potassium and aldosterone levels, independently of plasma renin activity. [53] This was true in both the initial 4-week treatment phase of the study and the 8-week randomized withdrawal phase. The use of patiromer was also associated with significant reductions in diastolic and systolic blood pressure in both phases of the trial. Similar to SPS, patiromer can potentially bind to other orally administered medications, reducing their effect. Sodium zirconium cyclosilicate (ZS-9) is an investigational drug that shows promise for treatment of hyperkalemia.(Table 6) Results from the phase 3 HARMONIZE (Hyperkalemia Randomized Intervention Multi-Dose ZS-9 Maintenance) trial support the efficacy of ZS-9 in the treatment of hyperkalemia. [54] In the 48-hour initial phase of this trial, 258 patients received 10 g of ZS-9 three times daily. Altogether, 237 patients achieved normokalemia (3.5-5.0 mEq/L) and entered a double-blind, randomized, 28-day phase in which they received one of three ZS-9 doses or placebo daily. Serum potassium was significantly lower on days 8 to 29 in all ZS-9 groups, compared with the placebo group ( P <.001 for all comparisons), and adverse events were comparable between groups. A larger phase 3 trial of ZS-9 (n = 753) had a similar 2-part design. [55] During the maintenance phase (days 3 to 14), the 5-g and 10-g doses of patiromer were significantly superior to placebo in maintaining normal potassium levels ( P =.008 and P <.001, respectively). The occurrence of adverse events was comparable in the ZS-9 groups and the placebo group. Hypokalemia developed in 10% of the 51 patients in the 10-g dose of ZS-9. Table 6. Sodium zirconium cyclosilicate [54-56] Agent Mechanism of Action Potential Limitations Sodium zirconium cyclosilicate (ZS-9) (Investigational) Selective potassium cation-trapping agent •GI disturbances •Increased sodium load •Hypokalemia •Possible drug-drug interactions GI = gastrointestinal. Source: Kosiborod M [54] , Packham DK [55] , Stavros F [56] . Case 2, continued You start Carolyn on patiromer 8.4 g, administered orally once daily with food. Carolyn returns for follow-up in 1 week. Her potassium is now 4.6 mEq/L, and the most recent electrocardiogram shows no abnormalities. Her magnesium levels are 1.9 mEq/L. She says she is tolerating her medications well, and she continues to follow a low-potassium diet. In concert with Carolyn's cardiologist, you increase her benazepril to 40 mg. Her potassium levels are 4.9 mEq/L at several subsequent visits. At her 6-month follow-up, Carolyn's potassium level is 5.3 mEq/L. You ask her whether she has been taking her medications as instructed, and she confirms that she is. You ask her whether there have been any major changes in her diet or lifestyle habits. She tells you that she has increased her exercise level and has begun following a diet designed to lower her blood pressure. She says she has cut down on convenience foods such as canned soups, entrees, vegetables, pasta, and frozen dinners. She is basing her menus on fresh, frozen, or no-added-salt canned vegetables, whole-grain pasta, and low-sodium lunch meats, and she has replaced table salt with pepper, herbs, and a salt substitute to give her food flavor. She has also added a daily cup of green tea. 13 Discussion Salt substitutes are often comprised of potassium chloride. Their use can cause hyperkalemia in patients with CKD. The hyperkalemia associated with the use of potassium chloride can be severe and even life-threatening. [57] It is also important at this point to make sure that Carolyn's patiromer treatment has been optimized. Although she responded quickly to the initial dose of 8.4 g, now her potassium level is rising and a dose escalation should be considered. Adjust the dose by 8.4 g daily as needed, at 1-week intervals, to obtain the desired serum potassium target range. [49] Conclusion Carolyn is maintained on a patiromer dose of 16.8 g and she achieves sustained normokalemia. She continues to experience mild constipation that she manages with diet. Furthermore, she is able to sustain treatment with benazepril 40 mg/day as 2 divided doses. Educational Impact Challenge What did you learn from this activity? Please click on the \"Continue\" button to proceed to a brief survey to see how your knowledge improved after the education. You can also see how your answers compare with those of your peers. Educational Impact Challenge 14 ",
				"clientUrl": "/viewarticle/867761",
				"creditType": ["CME", "Nurse CE", "Pharmacist CE", "ABIM MOC"],
				"cmeFlag": "CME / ABIM MOC / CE",
				"leadConceptId": 727,
				"leadConcept": "Chronic Kidney Disease (CKD)",
				"concept": ["Hypertension", "Diabetes Mellitus", "Type 1 Diabetes Mellitus", "Type 2 Diabetes Mellitus", "Heart Failure (HF)", "Renal Disease", "Lifestyle Counseling", "Professional Issues in Nursing", "Patient Counseling", "Patient Pharmaceutical Care Management", "Clinical Pharmacology", "Patient Care Management", "Adverse Effects", "Angiotensin II Receptor Blockade", "ACE Inhibitor", "Diet", "Cardiovascular Nursing", "Hyperkalemia", "Renin-Angiotensin System (RAS)", "Public Health Nursing", "Pharmacologic Adverse Events", "Patient History", "Patient Assessment"],
				"leadSpecialtyId": 44,
				"leadSpecialty": "Nephrology",
				"allSpecialties": ["Nephrology", "Cardiology", "Medscape Today", "Pharmacist", "Family Medicine/Primary Care"],
				"contentGroup": "Clinical Case",
				"origContentType": "Clinical Case",
				"contentType": ["Patient Case"],
				"description": "Join Dr Rastogi for a case-based discussion on individualized management and treatment of chronic kidney disease.",
				"legacyID": 867761,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Chronic Kidney Disease: Clinical Case Scenarios",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00", "US Physicians:Points for ABIM MOC:1.00", "Nurses:ANCC Contact Hour(s):1.00", "Pharmacists:ACPE Contact Hour(s):1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/867761.jpg"],
				"publicationDate": 1482123600000,
				"postingDate": 1482123600000,
				"_version_": 1573508885170356224,
				"last_index_date": 1500615010437
			}, {
				"id": "pdctm_0901c791809df9b1",
				"activeCME": 1,
				"activityExpirationDate": 1501304400000,
				"authors": ["Marlene Hilton", " Stephen Krieger"],
				"body": "Slide 1. Slide 1. Best Practices in Monitoring Adverse Events Associated With Established DMTs in MS Educational Impact Challenge Assess your clinical knowledge by completing this brief survey. Answering these questions again after the activity will allow you to see what you learned and to compare your answers with those of your peers. 3 Slide 2. Slide 2. Introduction to DMTs Multiple sclerosis (MS) is a chronic autoimmune disease that affects the central nervous system The majority of patients have the relapsing-remitting form of MS, although this may evolve into progressive MS in some patients Some of the newer disease-modifying therapies (DMTs) lead to more severe adverse events than others Slide 3. Slide 3. Injectable DMTs [1-5] Injectable therapies were the first group of agents approved in the treatment of MS Glatiramer acetate use does not generally cause systemic adverse effects Rarely, immediate post-injection reactions may occur Slide 4. Slide 4. Oral DMTs: Fingolimod [6] Treatment with oral DMTs is somewhat complex Prior to treatment with fingolimod, ensure patients are immune to varicella zoster, screen for macular edema, and perform an ECG to make sure there are no cardiac conduction abnormalities present Slide 5. Slide 5. Oral DMTs: Fingolimod (cont) [6] After the first dose of fingolimod is administered, monitor patients with ECG for 6 hours to make sure there is no effect on heart rate or blood pressure Regular monitoring includes blood cell counts and eye examinations Slide 6. Slide 6. Oral DMTs: Adverse Events [6-9] Liver function tests must be performed monthly for the first 6 months after a patient starts taking teriflunomide After 6 months, liver function tests can be performed less frequently Dimethyl fumarate is taken twice a day Blood cell counts should be carefully monitored while a patient is taking dimethyl fumarate A low white blood cell count can be associated with the risk of infection, principally progressive multifocal leukoencephalopathy (PML) [9] Slide 7. Slide 7. Monitoring Oral DMTs [9-11] There are some long-term risks associated with oral DMTs that require careful monitoring There are contraindications associated with some oral DMTs Fingolimod was not studied in patients with diabetes because of the increased risk of macular edema [10] Similarly, cardiac conditions might be a contraindication for fingolimod use Patients with lymphopenia may not be good candidates for dimethyl fumarate There is evidence of teratogenicity with teriflunomide use [11] Slide 8. Slide 8. Infusion DMTs [12-14] Mitoxantrone is an infused chemotherapy drug that is rarely used, principally because of its adverse events Natalizumab is a monoclonal antibody given once a month by infusion Main adverse event is PML Alemtuzumab is a monoclonal antibody given by infusion for 5 consecutive days, and then for 3 days a year later The infusion is typically performed at a center that is familiar with how to manage infusion reactions Monthly blood cell counts and urine tests must be performed to screen for other emergent autoimmune diseases, including immune thrombocytopenic purpura (ITP) and Goodpasture syndrome Slide 9. Slide 9. Infusion DMTs: Long-Term Serious AEs [15-18] The risk of PML with natalizumab use may increase over time in patients who are JC virus positive The risks of ITP with alemtuzumab may not emerge until the second or third year after the patient received therapy Slide 10. Slide 10. JC Virus Index [19,20] PML is an opportunistic infection of the brain Prior to initiating natalizumab, patients must be tested for the JC virus The JC virus index can give an idea of a patient's immune response and help stratify risk Slide 11. Slide 11. PML in MS [21] Signs and symptoms of PML can include cortical findings like a visual field cut, language disturbances, behavioral disturbances, and full hemiparesis [20] Magnetic resonance imaging (MRI) scans should probably be performed once a year in most patients with MS Scans should be performed more frequently in patients who are JC virus-positive and receiving natalizumab Slide 12. Slide 12. Conclusions Individualized treatment includes being mindful of contraindications that could increase any risk There is a need for continued vigilance and monitoring, and familiarity with the different adverse events that can occur with each DMT Slide 13. Slide 13. Thank You This content has been condensed for improved clarity. Educational Impact Challenge What did you learn from this activity? Please click on the “Continue” button to proceed to a brief survey to see how your knowledge improved after the education. You can also see how your answers compare with those of your peers. Educational Impact Challenge 4 ",
				"clientUrl": "/viewarticle/864381",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 918,
				"leadConcept": "Multiple Sclerosis (MS)",
				"concept": ["Progressive Multifocal Leukoencephalopathy", "Autoimmune Disease", "Interferon Therapy", "Patient Pharmaceutical Care Management", "Patient Care Management", "Adverse Effects", "Disease-Modifying Therapy", "Glatiramer Acetate", "Neurodegenerative Diseases", "Pegylated Interferon", "Pharmacologic Adverse Events", "Neuroinflammation", "Auto-inflammatory Diseases", "Patient Assessment", "Disease Surveillance"],
				"leadSpecialtyId": 26,
				"leadSpecialty": "Neurology & Neurosurgery",
				"allSpecialties": ["Neurology & Neurosurgery", "Medscape Today", "Family Medicine/Primary Care"],
				"origContentType": "Roundtable",
				"contentType": ["Article/Courses"],
				"description": "Listen to an interview with Dr Krieger about adverse events associated with disease-modifying therapies (DMTs) used to treat MS.",
				"legacyID": 864381,
				"mediaFlag": "2",
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Best Practices in Monitoring Adverse Events Associated With Established DMTs  in MS",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:0.25"],
				"maxCredits": [0.25],
				"multimedia": ["/thumbnail_library/864381.jpg"],
				"publicationDate": 1469768400000,
				"postingDate": 1469768400000,
				"_version_": 1573508882045599744,
				"last_index_date": 1500615007447
			}, {
				"id": "pdctm_0901c79180ac632c",
				"activeCME": 1,
				"activityExpirationDate": 1514523600000,
				"authors": ["Carolyn E. Barlow", " Kerem Shuval", " Bijal A. Balasubramanian", " Darla E. Kendzor", " Nina B. Radford", " Laura F. DeFina", " Kelley Pettee Gabriel"],
				"body": "Abstract and Introduction Abstract and Introduction Abstract Introduction. Objective estimates, based on waist-worn accelerometers, indicate that adults spend over half their day (55%) in sedentary behaviors. Our study examined the association between sitting time and cardiometabolic risk factors after adjustment for cardiorespiratory fitness (CRF). Methods. A cross-sectional analysis was conducted with 4,486 men and 1,845 women who reported daily estimated sitting time, had measures for adiposity, blood lipids, glucose, and blood pressure, and underwent maximal stress testing. We used a modeling strategy using logistic regression analysis to assess CRF as a potential effect modifier and to control for potential confounding effects of CRF. Results. Men who sat almost all of the time (about 100%) were more likely to be obese whether defined by waist girth (OR, 2.61; 95% CI, 1.25–5.47) or percentage of body fat (OR, 3.33; 95% CI, 1.35–8.20) than were men who sat almost none of the time (about 0%). Sitting time was not significantly associated with other cardiometabolic risk factors after adjustment for CRF level. For women, no significant associations between sitting time and cardiometabolic risk factors were observed after adjustment for CRF and other covariates. Conclusion. As health professionals struggle to find ways to combat obesity and its health effects, reducing sitting time can be an initial step in a total physical activity plan that includes strategies to reduce sedentary time through increases in physical activity among men. In addition, further research is needed to elucidate the relationships between sitting time and CRF for women as well as the underlying mechanisms involved in these relationships. Introduction Prolonged sitting time characterizes the daily lifestyle patterns of most people living in developed countries. [1] Estimates of median reported sitting time for US adults range between 6.5 to 8 hours per day. [2] Objective estimates, based on waist-worn accelerometers, indicate that adults spend over half their day (55%) in sedentary behaviors. [3] Several studies demonstrate direct, independent associations between sedentary behavior and cardiometabolic risk factors such as adiposity and fasting blood glucose level after adjustment for the beneficial effect of moderate-intensity to vigorous-intensity physical activity (MVPA), accumulated mostly during leisure or discretionary periods of the day. [4] However, within a 24-hour period, people spend a significant proportion of waking hours in sedentary behaviors or light-intensity physical activities relative to time spent in MVPA. [1] Therefore, investigators recently argued that accounting for an individual’s total physical activity level during the entire waking period, not just during isolated segments of the day (eg, time spent sitting or time spent highly active), is essential to understanding the complex relationships between physical activity behavior and cardiometabolic risk factors. [5] Furthermore, objectively measured total activity level per day appears to be more strongly associated with cardiometabolic risk factors than is MVPA per day. [6] Given that cardiorespiratory fitness (CRF) reflects a person’s habitual physical profile and overall general health, the primary goal of our study was to determine whether among adult men and women time spent sitting was associated with elevated levels of waist girth, body mass index, body fat percentage, total cholesterol, low-density lipoprotein (LDL) cholesterol, triglycerides, glucose, and resting systolic blood pressure; low levels of high-density lipoprotein (HDL) cholesterol; and the presence of metabolic syndrome. Secondary goals were to 1) examine whether CRF confounded or modified the associations between sitting time and cardiometabolic risk factors and 2) explore whether the role of CRF differed by sex. Methods Methods Participants included in this cross-sectional analysis received a preventive medical examination at the Cooper Clinic in Dallas, Texas, during 2010 through 2013 and provided written consent to participate in the Cooper Center Longitudinal Study (CCLS). Participants in CCLS are generally healthy and self-referred or referred by their employers to the Cooper Clinic for preventive medical examinations that include a physician-administered medical examination, fasting laboratory studies, body composition measurements, and a maximal treadmill graded exercise test. For our analysis, to eliminate the potential for a disease condition that could affect the exposure of interest (eg, a stroke may result in increased sitting time), participants were excluded if they reported a personal history of cardiovascular disease (n = 51), stroke (n = 27), or diabetes (n = 582) or if they did not reach 85% of their predicted maximal heart rate on the treadmill test (n = 137). Participants were also excluded if their data for some covariates were missing (n = 332). These criteria resulted in an analytic sample of 1,845 women and 4,486 men aged 20 to 79 years. Each year, the Cooper Institute’s institutional review board reviewed and approved the overall study. Our study also received exempt status from the University of Texas Health Science Center at Houston’s Committee for the Protection of Human Subjects. Sitting time was based on participants’ responses to a question on the medical history questionnaire completed before their clinical examination. The sitting question, derived from the Canada Fitness Survey, [7] assessed the proportion of time spent sitting during work, school, and housework during waking hours on a typical day. Response options were 1) almost none of the time (about 0%), 2) approximately one-quarter of the time (about 25%), 3) approximately half of the time (about 50%), 4) approximately three-quarters of the time (about 75%), and 5) almost all of the time (about 100%). Cardiometabolic Risk Factors (Primary Dependent Measures) Body mass index (BMI, kg/m 2 ) and body composition measurements (% body fat, waist girth) were measured during the preventive medical examination. These measurements were taken according to standard procedures by trained technicians and described previously. [8] Briefly, BMI was computed as weight in kilograms divided by height in meters squared measured on a stadiometer and a standard physician’s scale. Participants with BMI of 30 kg/m 2 or higher were classified as obese. [9] Waist girth (cm) was measured with a plastic tape at the level of the umbilicus following a normal exhalation. An elevated waist girth for men was 102 cm or greater and for women was 88 cm or greater. [10] Percentage of body fat was determined by measuring 7 skinfold sites (axilla, chest, abdomen, triceps, hip, thigh, and back) with calipers and inserting the sum of these skinfold measurements in a generalized body density equation to estimate percentage of body fat. [11] Sex-specific cut points of percentage of body fat (<25% or ≥25% for men and <32% or ≥32% for women) were used to classify patients as obese. [12] Serum samples taken after patients fasted for 12 hours were analyzed for lipids by using automated bioassays in accordance with standard procedures. Elevated lipid levels were defined by using the following cut points: total cholesterol higher than 200 mg/dL; LDL cholesterol higher than 100 mg/dL; HDL cholesterol less than 40 mg/dL for men and less than 50 mg/dL for women; triglycerides 150 mg/dL or higher; and fasting blood glucose 100 mg/dL or higher. [10] Resting blood pressure was auscultated as the first and fifth Korotkoff sounds according to a standard sphygmomanometer protocol. [13] Elevated blood pressure was defined as a systolic blood pressure 130 mm Hg or higher or diastolic blood pressure 85 mm Hg or higher, or both. [10] Using the criteria of the American Heart Association and the National Heart, Lung, and Blood Institute, we defined metabolic syndrome as meeting 3 or more of the following criteria: abdominal obesity (waist girth: ≥102 cm for men and ≥88 cm for women); high triglycerides (≥150 mg/dL); low HDL (<40 mg/dL for men and <50 mg/dL for women); high blood pressure (systolic blood pressure ≥130 mm Hg, or diastolic blood pressure ≥85 mm Hg, or physician-diagnosed history of hypertension); and high glucose (fasting blood glucose =100 mg/dL or physician-diagnosed history of high glucose). [10] Covariates CRF was assessed by using the time to complete a treadmill-graded exercise test and the modified Balke protocol described previously. [14] Duration on the treadmill is highly correlated with measured oxygen consumption (VO 2 ) (r = 0.92 for men [15] and r = 0.94 for women [16]). A value for maximal metabolic equivalent of tasks (METs) was estimated from the final speed and grade of the treadmill test. [17] Participants were asked to report the frequency and duration of 11 specific physical activity types: walking, running, treadmill, swimming, stationary cycling, bicycling, elliptical, aerobic dance, racket sports, vigorous sports, and other activity. These 11 activity types represent high-intensity MVPA. Summary estimates were computed by weighting the product of the reported frequency and duration (in minutes per week [min/wk -1 ]) by a standardized estimate of the MET of each activity type, [18] which was then summed across all activities performed. The leisure-time physical activity estimate was expressed as a log transformation of MET/min/wk -1 . On the basis of literature, we included additional covariates from the medical history questionnaire: age, sex, alcohol consumption, and smoking status. Alcohol consumption was calculated as the combined number of drinks per week of beer, wine, and hard liquor. Smoking status was categorized as current smoker or nonsmoker based on self-reported behavior. Three variables were created to indicate current medication use (yes/no) for hypertension, diabetes, or hyperlipidemia; a fourth variable, hormone replacement therapy, was created for women only. Medication use was reported by the patient to the study physician who conducted the medical examination. Statistical Analysis Descriptive characteristics of the study sample are presented by sex and for the total sample. To examine crude associations, we tested for linear trends reflecting the prevalence of each outcome for each sex across increasing categories of self-reported sitting time (ie, about 0% of the time to about 100% of the time). First, the potential effect modification of CRF on self-reported sitting time and each cardiometabolic risk factor was explored with the addition of an interaction term to a logistic regression model in which sitting time and CRF were used to predict each outcome. Next, CRF was added to the fully adjusted model to control for confounding effects after we determined that the effect size increased more than 10% with its inclusion in the fully adjusted model. Results are presented for each risk factor regressed against self-reported sitting time 1) adjusted for age (y) (model A); 2) adjusted for age and cardiorespiratory fitness (METs) (model B); and 3) adjusted for all covariates in model B and for self-reported physical activity (MET-minutes per week), alcohol consumption (drinks per week), smoking status (yes/no), waist girth (in models with lipids, glucose, or blood pressure as the outcome), and medication use associated with the outcome (model C). The presence of multicollinearity between self-reported physical activity and CRF was assessed and found to be weakly correlated (r = 0.34). Analyses were performed using SAS/STAT version 9.4 (SAS Institute, Inc). All significance testing was 2-sided with a P value of less than .05 considered significant. Results Results The average age of the analytic sample (n = 6,331) was 50.7 (SD 10.0) years old and consisted of mostly men (71%) ( Table 1 ). Eight percent of patients reported current smoking. Alcohol consumption was moderate (median [25th, 75th percentile], 4 [1, 9] drinks per week). A higher percentage of men (41%) than women (13%) reported sitting most or all of the time (≥75% of the time) during a usual day. The average CRF level was 11.6 (SD 2.2) METs for men and 9.8 (SD 1.9) METs for women. For men, high self-reported sitting time was significantly associated with high prevalence of cardiometabolic risk factors, including elevated waist girth, percentage of body fat, and obesity (all P for linear trend < .05) ( Table 2 ). No associations were observed for the other risk factors or metabolic syndrome. Similarly, for women, high self-reported sitting time was significantly associated with high prevalence of elevated waist girth and percentage of body fat, obesity, and metabolic syndrome (all P for linear trend < .001). In addition, the more women sat, the higher their levels of triglycerides and the lower their levels of HDL cholesterol (both P for linear trend < .001). For women, no associations were observed between self-reported sitting time and total cholesterol, LDL cholesterol, glucose, or blood pressure. Next, we assessed the role of CRF as an effect-modifying variable by adding a self-reported sitting time × CRF interaction term to the models for each separate cardiometabolic outcome. This interaction term was not significant for any of the cardiometabolic risk factors after adjustment for covariates for either men or women (all P > .05). For men, the crude associations that were observed between self-reported sitting time and each measure of adiposity remained significant after covariate adjustment, including CRF ( Table 3 ). More specifically, in model C, men who reported sitting about 100% of the time were more than twice as likely to be obese whether defined by waist girth (OR, 2.61; 95% CI, 1.25–5.47), or percentage of body fat (OR, 3.33; 95% CI, 1.35–8.20) relative to men who sat about 0% of the time. Similar to the results for men, associations between self-reported sitting time and each measure of adiposity were seen among women ( Table 3 ) when adjusted for age (model A). However, unlike men, when CRF was added to the model (model C), these associations for women were no longer significant. Self-reported sitting time was not associated with the remaining risk factors among men or women ( Appendix ). Discussion Discussion Our findings suggest that prolonged sitting is associated with high levels of adiposity among men even after accounting for their CRF level. However, this relationship between self-reported sitting time and adiposity was not found for women. Furthermore, for men, other cardiometabolic risk factors (elevated lipids, blood glucose, triglycerides, and blood pressure; low levels of HDL; and the presence of metabolic syndrome) were not significantly associated with sitting time. For women, self-reported sitting time was not associated with any individual cardiometabolic risk factor or the presence of metabolic syndrome. Previous cross-sectional studies report significant associations between sedentary behavior and various cardiometabolic risk factors after controlling for MVPA. [19,20] However, these studies probably suffer from incomplete ascertainment of an individual’s exposure to physical activity given that only a small portion of the day was examined (ie, 3% of their day assuming 30 minutes per day of MVPA during 16 waking hours), which in turn could explain the significant associations found in published study results. In their study of National Health and Nutrition Examination Survey (NHANES) participants, Maher et al found high-sensitivity C-reactive protein and triglycerides to be the only cardiometabolic risk factors associated with sedentary behavior when controlling for total physical activity time as assessed with accelerometers, which produce information about activity throughout the day. [5] Although these associations reached statistical significance, the relationships were weak and not of clinical significance. In addition, a prospective study of men in the CCLS cohort found that prolonged TV viewing and time spent in a car were detrimentally linked only to a marker of insulin sensitivity (but not to other cardiometabolic risk factors) when CRF was taken into account. [21] Similar to the results from NHANES, [5] our study found that self-reported sitting time was not associated with cardiometabolic risk factors other than obesity for men when reported physical activity level or cardiorespiratory fitness level are taken into account. However, little evidence exists of studies having explored the potential role of CRF in the relationship between estimates of total sitting time and cardiometabolic risk factors. The role of CRF appeared to differ for men and for women, and this finding also deserves further study. More specifically, for men, CRF confounded the relationship between sitting time and cardiometabolic risk factors: men had higher levels of muscle mass (70 kg) than women (50 kg), which might protect men against the adverse effect of prolonged sitting on lipids, glucose, and blood pressure, but not against the accumulation of body fat. For women, CRF may have confounded the effect of sitting time on some risk factors, but it did not modify this relationship. A previous cross-sectional study of the CCLS cohort found that the more women sat, the lower their fitness level. [22] Therefore, high levels of time sitting during the day could lower fitness levels and lower total daily caloric expenditures, which could lead to increases in women’s body fat. For different levels of CRF, we found no sex-related difference in the relationship between sitting time and cardiometabolic risk factors. Our study findings have public health and clinical implications: they indicate that, among men, increased self-reported long sitting time is related to a higher likelihood of obesity. These results along with other published study results point to a relationship between prolonged sedentary time and increased risk for chronic conditions and premature mortality among both men and women. [23,24] Reducing total sitting time and incorporating activity breaks into one’s daily schedule lowers cardiometabolic risk. [25] The American Cancer Society Guidelines on Nutrition and Physical Activity for Cancer Prevention underscores the need to reduce total sitting time along with habitually engaging in MVPA. [26] Therefore, developing and implementing programs specifically to reduce and break up sitting time at home and work is paramount. Primary care providers can play an important role in encouraging their patients to change their sedentary behavior. One study found that physicians were significantly more likely counsel their patients about the value of physical activity than to counsel them about the risks associated with sedentary behavior. [27] Tools, such as the Rapid Assessment Disuse Index specifically tailored for use at the point of care, can be used by physicians to assess patients with high levels of sitting and low levels of physical activity and provide pertinent and effective counseling. [27] In addition, the 5As model, [28] which has been used successfully to promote physical activity in primary care, can be applied to sedentary behavior counseling. Strengths of this study include a direct estimate of CRF, a comprehensive analytic approach, and a large sample size with numerous clinical covariates. Limitations of note were the self-reported measure of sitting time (which has not been validated), characteristics of the sample, and cross-sectional study design. More specifically, participants were asked to report estimates of time spent sitting during a typical day in broad categories which could result in misclassification of the exposure. In addition, participants were generally healthy, predominantly non-Hispanic white, and well-educated. The homogeneous nature of the cohort decreased the ability to generalize these results to more diverse populations. However, the socioeconomic homogeneity of this cohort reduced the likelihood of confounding by unmeasured factors such as occupation, income, and other socioeconomic indicators known to influence health. The cross-sectional study design limited reporting to the description of associations and thus results do not imply causality. The more men sat, the more likely they were to be obese by any definition (ie, BMI, percentage of fat, waist circumference), but no other cardiometabolic risk factors were significantly associated with sitting time. For women, after adjustment for CRF and other covariates, no significant associations were observed between sitting time and cardiometabolic risk factors. Our results support physicians who work with their male patients to control risk factors by advising them to reduce sitting time to avoid obesity and its associated health conditions. The reduction and interruption of sitting time can be an initial step in developing a total physical activity plan that includes strategies to reduce sedentary time through increases in physical activity. Assessment of the entire intensity spectrum of behaviors from sleep to vigorous-intensity physical activity will provide health professionals with the information needed to tailor physical activity plans for risk reduction and health promotion. ",
				"clientUrl": "/viewarticle/873569",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 5000056,
				"leadConcept": "Cardiometabolic Risk Factors",
				"concept": ["Hypertension", "Diabetes Mellitus", "Exercise", "Preventive Medicine", "Dyslipidemia", "Obesity", "Metabolic Syndrome", "Lifestyle Modification for Cardiovascular Health"],
				"leadSpecialtyId": 42,
				"leadSpecialty": "Public Health & Prevention",
				"allSpecialties": ["Public Health & Prevention", "Cardiology", "Internal Medicine", "Diabetes & Endocrinology", "Family Medicine/Primary Care"],
				"contentGroup": "Journal Article",
				"origContentType": "Journal Article",
				"contentType": ["Journal Article"],
				"description": "A new study evaluates the effect of sitting time on cardiometabolic risk factors.",
				"legacyID": 873569,
				"pubDisplay": "Prev Chronic Dis",
				"siteOn": 2003,
				"title": "Association Between Sitting Time and Cardiometabolic Risk Factors After Adjustment for Cardiorespiratory Fitness, Cooper Center Longitudinal Study, 2010–2013",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/PCD-thumb.jpg"],
				"publicationDate": 1482987600000,
				"postingDate": 1482987600000,
				"_version_": 1573508886861709312,
				"last_index_date": 1500615012045
			}, {
				"id": "pdctm_0901c79180a3693c",
				"activeCME": 1,
				"activityExpirationDate": 1505970000000,
				"authors": ["Francesca Tentori", " Geoffrey Block"],
				"body": "可下载的PDF中文版 Slide 1. Slide 1. Key Concepts in CKD-MBD: Essentials for Improving Outcomes Slide 2. Slide 2. CKD-MBD [1] Slide 3. Slide 3. High-Serum Phosphorus and Association With Outcomes [2-4] Slide 4. Slide 4. CKD-MBD Guidelines [1,5] One criteria included evidence-based data defined as more than 50 patients randomly assigned and followed for more than 6 months; 25 patients in each arm Slide 5. Slide 5. Key Updates in Draft KDIGO MBD Guidelines 2016 [5] New evidence does not support routine use of calcitriol to treat patients with early secondary hyperparathyroidism [6] No evidence of a safe dose of calcium for patients with kidney disease; evidence suggests harm when using calcium-based phosphate binders [7-10] Evaluate each patient individually, and treat appropriately Evidence supports use of dual-energy X-ray absorptiometry to assess bone mineral density, which predicts fracture risk [11] Slide 6. Slide 6. Is Vascular Calcification Modifiable in CKD? [12-16] Calcium and phosphorus have been shown to affect the development of vascular calcification Phosphorus is a key mediator Possibly mediates this through a direct effect on the blood vessels, changing the phenotype of the blood vessel smooth muscle cells Also has effects on fibroblast growth factor 23 Animals deficient in Klotho have been shown to age rapidly Slide 7. Slide 7. Simultaneous Assessment of Calcium-Phosphorus-PTH [17] Slide 8. Slide 8. Phosphate, Protein, and Diet [18,19] Slide 9. Slide 9. Role of Patient Education and Effective Communication [20] Slide 10. Slide 10. Closing Comments [21] Slide 11. Slide 11. Thank You for Participating in This Activity This content has been condensed for improved clarity. ",
				"clientUrl": "/viewarticle/867850",
				"creditType": ["CME", "Nurse CE", "Pharmacist CE", "ABIM MOC"],
				"cmeFlag": "CME / ABIM MOC / CE",
				"leadConceptId": 0,
				"leadSpecialtyId": 44,
				"leadSpecialty": "Nephrology",
				"allSpecialties": ["Nephrology", "Medscape Today"],
				"origContentType": "Roundtable",
				"contentType": ["Article/Courses"],
				"description": "Drs Francesca Tentori and Geoff Block review recent developments in CKD-MBD, including new guidelines and data.",
				"legacyID": 867850,
				"mediaFlag": "2",
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Key Concepts in CKD-MBD: Essentials for Improving Outcomes",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:0.25", "US Physicians:Points for ABIM MOC:0.25", "Nurses:ANCC Contact Hour(s):0.25", "Pharmacists:Knowledge-based ACPE:0.25"],
				"maxCredits": [0.25],
				"multimedia": ["/thumbnail_library/867850.jpg"],
				"publicationDate": 1474434000000,
				"postingDate": 1474434000000,
				"_version_": 1573508879328739328,
				"last_index_date": 1500615004854
			}, {
				"id": "pdctm_0901c79180b1d2ed",
				"activeCME": 1,
				"activityExpirationDate": 1529125200000,
				"authors": ["Stuart H. Isaacson", " Horacio Kaufmann", " Peter N. Schmidt"],
				"body": "Slide 1. Slide 1. Updates in Neurogenic Orthostatic Hypotension: 2017 Consensus Recommendations Slide 2. Slide 2. Panelists Slide 3. Slide 3. Discussion of Off-Label Treatments 3 Slide 4. Slide 4. Introduction to nOH [1,2] Slide 5. Slide 5. Symptoms of nOH [1] Symptoms of nOH, such as dizziness, lightheadedness, and falls, result from inadequate cerebral perfusion when the patient changes posture from sitting or supine to standing Blood pools in the lower part of the body and cannot return to the heart due to dysfunction of the autonomic nervous system. As a result, the blood is not appropriately pumped to the remainder of the body Slide 6. Slide 6. nOH in Patients With PD [3] Patients often do not realize that their sleepiness or their sensation of generalized weakness is due to a falling blood pressure (BP) that could be easily corrected If there is a cognitive disorder associated with the disease, there may be difficulty in understanding the questions that you ask the patient to identify nOH. It is important to properly screen these patients Slide 7. Slide 7. Questions to Ask the Patient During Screening [1] A positive answer by the patient to any of the listed questions should prompt the physician to measure the patient’s BP in both the supine and standing positions Slide 8. Slide 8. Identifying Symptoms of nOH [1] In orthostatic hypotension (OH), patients experience a pronounced increase in heart rate when their BP falls In nOH, there is no significant increase in heart rate on decreasing BP [4,5] An increase in heart rate of < 15 beats per minute is suggestive of nOH Heart rate is also fixed in patients with diabetic neuropathy or other neuropathies, whereas in most patients with synucleinopathies, there is a subtle increase in heart rate that occurs inappropriately in the setting of falling BP BP is not a fixed parameter in patients with nOH Decrease in BP is more prominent in the morning than later in the day Another important factor regarding BP in patients with nOH is that BP is low when patient is standing and high when patient is supine This can lead to a misdiagnosis and incorrect treatment plan for patients who have their BP measured only while in 1 position Slide 9. Slide 9. Confirming the Diagnosis: A Stepwise Approach [1] After decreases in BP are observed, the next step is to review the patient's medications and reduce or possibly discontinue any medication that could be causing a decrease in BP and, thus, worsening symptoms Many patients with decreasing BP are taking α-blockers for prostatic hypertrophy, antihypertensive medications, dopamine agonists, or other medications that can reduce BP Slide 10. Slide 10. Grading nOH Severity After Diagnosis: Proposed Scale [1] Slide 11. Slide 11. Treatment of nOH [1] Slide 12. Slide 12. Medication Review: What to Avoid [1] Patients whose BP is monitored only while in supine position may be prescribed antihypertensive medications Diuretics may be prescribed for mild swelling of the legs, which is common in many patients with Parkinson disease (PD) or in patients who are inactive Slide 13. Slide 13. Nonpharmacologic Therapy [1,6,7] It is important to implement nonpharmacologic measures even when using pharmacologic therapy to treat nOH Many patients, particularly older patients, are following low-salt diets, which is a sensible diet to prevent or treat hypertension; however, this diet can worsen nOH Advise the patients following a low-salt diet to increase salt and water intake [6,7] Drinking 500 mL of water before getting out of bed can significantly increase BP [6] Elevating the head of the bed during the night can help reduce supine hypertension and pressure diuresis, which can result in nocturia and blood volume depletion [1,8] Implementing nonpharmacologic measures will work in many patients to treat nOH; however, if the nOH is severe, the addition of pharmacologic therapy will be necessary Slide 14. Slide 14. Pharmacotherapy of nOH Slide 15. Slide 15. Pharmacotherapy of nOH: Fludrocortisone* [9] Concerns with the use of fludrocortisone are the long-term adverse events of cardiac fibrosis and the accelerated development of renal failure [10] These adverse events can be a result of stimulating mineralocorticoid receptors Supine hypertension is also associated with the drug Advise the patient to avoid lying down or sleeping in a flat position Slide 16. Slide 16. Pharmacotherapy of nOH: Vasoconstrictors [11-16] Midodrine -- direct α 1 -adrenergic agonist that produces vasoconstriction [11-13] Does not cross the blood-brain barrier Droxidopa -- precursor of norepinephrine, which is the naturally occurring sympathetic neurotransmitter that acts on several adrenergic vascular receptors [14-16] Crosses the blood-brain barrier, providing an additional effect of norepinephrine in the central nervous system This additional effect can be useful for patients with synucleinopathies that have marked norepinephrine deficiency in the central nervous system Not all patients respond to both medications so it is helpful to have the 2 options Slide 17. Slide 17. Droxidopa in nOH: Reduction in Falls [17] Falls have a major impact on a patient's quality of life and independent living status. They are also a common cause for entry to nursing facilities for many patients with PD [18] Falls have a major impact on hospitalizations. Many patients with PD can have poor outcomes if they are hospitalized There has been recent evidence that when patients with PD fall, incur a fracture, and require orthopedic surgery, they develop certain complications that do not occur in patients who do not have PD [19] Slide 18. Slide 18. Pharmacotherapy of nOH: Pyridostigmine* [1,20,21] Slide 19. Slide 19. Managing Pharmacotherapy and Symptoms [1] Midrodrine is dose dependent, and the dose can be uptitrated to provide symptomatic relief, as long as the agent is tolerated [22] Administration of midodrine can result in hypertension in both the supine and sitting positions It is recommended that patients not take midodrine within 5 hours of bedtime Starting dosage for droxidopa is 100 mg 3 times daily [14,23] Can be uptitrated to a maximum dosage of 600 mg 3 times daily (maximum total daily dose of 1800 mg) Horacio Kaufmann, MD: It may be helpful in some patients to give the highest dose of droxidopa in the morning, a lower dose before lunch, and an even lower dose in the afternoon -- and sometimes even skipping the third dose of the day if the patient is not going to be active. On the other hand, if the patient is going to be active, it is a good idea for the patient to take the medication before going out in the evening If hypotension persists with either midodrine or droxidopa, combination therapy can be considered; however, there are no clinical data on combination therapy with these 2 drugs Slide 20. Slide 20. Concluding Remarks Slide 21. Slide 21. Thank You * Not approved for this indication by the FDA. This content has been condensed for improved clarity. ",
				"clientUrl": "/viewarticle/876948",
				"creditType": ["CME", "ABIM MOC"],
				"cmeFlag": "CME / ABIM MOC",
				"leadConceptId": 0,
				"concept": ["Orthostatic Hypotension", "Clinical Guidelines", "Treatment Guidelines", "Adverse Effects", "Off-Label Use", "Acetylcholinesterase Inhibitor", "Corticosteroids", "Drug and Treatment Safety", "Pharmacologic Adverse Events", "Hypotension", "Alpha-Adrenergic Agonists", "Patient Assessment"],
				"leadSpecialtyId": 26,
				"leadSpecialty": "Neurology & Neurosurgery",
				"allSpecialties": ["Neurology & Neurosurgery", "Cardiology", "Medscape Today", "Family Medicine/Primary Care"],
				"origContentType": "Roundtable",
				"contentType": ["Article/Courses"],
				"description": "Join our expert panel as they discuss the latest consensus panel recommendations on diagnosing, managing, and treating patients with nOH.",
				"legacyID": 876948,
				"mediaFlag": "2",
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Updates in Neurogenic Orthostatic Hypotension: 2017 Consensus Recommendations",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:0.50", "US Physicians:Points for ABIM MOC:0.50"],
				"maxCredits": [0.5],
				"multimedia": ["/thumbnail_library/876948.jpg"],
				"publicationDate": 1497589200000,
				"postingDate": 1497589200000,
				"_version_": 1573508887445766144,
				"last_index_date": 1500615012594
			}, {
				"id": "pdctm_0901c79180b51f37",
				"activeCME": 1,
				"activityExpirationDate": 1526014800000,
				"authors": ["News Author: Sue Hughes", " CME Author: Laurie Barclay"],
				"body": "Clinical Context Exposure to lead, a developmental neurotoxin, occurs among children in the United States and globally. Long-term cognitive and socioeconomic harms related to lead exposure have not been clearly defined. However, young adults with lead exposure during childhood appear to have lowered intellectual function and changes in brain structure, suggesting long-term cognitive impact of early exposure. The goals of the prospective Dunedin Multidisciplinary Health and Development Study (DMHD) study were to examine the association of childhood lead exposure with cognitive function and socioeconomic status in adulthood and with changes in IQ and socioeconomic mobility between childhood and midlife, using a population in which lead exposure did not correlate with socioeconomic disadvantages. Study Synopsis and Perspective Exposure to lead in childhood is associated with lower cognitive function and socioeconomic status in midlife, a new study suggests. The study, which prospectively observed 565 children from New Zealand for 4 decades, found that those with higher lead exposure in childhood had significantly lower IQ scores and socioeconomic status at age 38 years than those with lower lead levels. Greater childhood lead exposure was also associated with greater declines in IQ from childhood to adulthood and greater declines relative to parents in occupational socioeconomic status. The results are published in the March 28 issue of JAMA . [1] \"This is the first study where children with routine lead exposure have been followed into midlife,\" lead author, Aaron Reuben, MEM, Duke University, Durham, North Carolina, commented to Medscape Medical News . \"We have now shown that lead exposure has long-term effects that don't go away. We can still detect the consequences 30 years later.\" He noted that the population included in this study was a normal cohort of children born in 1972-1973 shown to be representative of that age group of the general population of the western world. \"Most people who are now middle aged would have been exposed to a similar level of lead as we have seen in this study, so our results will probably apply to a large percentage of the population in whom we can expect a downward trend in IQ.\" The current analysis is part of DMHD, a prospective cohort study based on a population representative 1972-1973 birth cohort from New Zealand, and monitored so far to age 38 years. Of 1037 original participants, 1007 were alive at age 38 years, of whom 565 (56%) had undergone lead testing at age 11 years, with mean levels of 10.99 μg/dL. Results showed that after adjustment for maternal IQ, childhood IQ, and childhood socioeconomic status, each 5-μg/dL higher level of blood lead in childhood was associated with a 1.61-point lower IQ score at age 38 years, a 2.07-point lower score in perceptual reasoning, and a 1.26-point lower score in working memory. Associations of childhood blood lead level with deficits in verbal comprehension and processing speed were not statistically significant. After adjustment for confounders, each 5-μg/dL higher level of blood lead in childhood was associated with a 1.79-unit lower score in socioeconomic status. An association between greater blood lead levels and a decline in IQ and socioeconomic status from childhood to adulthood was observed, with 40% of the association with downward mobility mediated by cognitive decline from childhood. Another analysis showed that those who had higher lead exposure as a child (>10 μg/dL) had a 4.25-point lower IQ score at age 38 years than those with lead levels below 10 μg/dL in childhood. Dr Reuben noted that the effect of a 4-point decline in IQ would differ greatly in different individuals. \"It depends on where you start -- if you are at the genius level then you probably wouldn't notice a 4-point drop. But if you start at an average level or below then this would have a big effect. \"That is why we looked at socioeconomic status and we also saw a reduction in that so that even a mild drop in IQ seemed to have a knock-on effect on socioeconomic status,\" he added. \"Importantly, we found this occurred regardless of where people started out -- high or low in socioeconomic terms.\" The researchers also showed that those with high lead levels at age 11 years had a decline from their own childhood IQ. Dr Reuben explained that IQ scores normally stayed the same or possibly increased a little from childhood into midlife. \"But in high lead-exposed individuals we found that IQ scores actually dropped.\" Dr Reuben noted that the childhood lead levels in this study (average, 11 μg/dL) were normal for a developed country at that time but would now be much lower. \"To show how well things have improved, the average in the Western world is now under 3 μg/dL. We now think of 5 as being high, but it doesn't mean that under 5 is safe -- actually it is thought that any level of lead is harmful.\" \"At the start of this study lead exposure was similar across all socioeconomic groups, mainly because of the high levels in gasoline, and the use of lead paint and pipes. In the 70s and 80s it was everywhere, but since the mid-90s we have dramatically lowered the lead use. Now in most parts of the world the lead exposure burden is highly focused in low-income communities, and related to industrial sites or older residential homes.\" Curtailing Upward Mobility? He says these latest results point to lead levels as being one factor that could be curtailing upward mobility. \"Our results reinforce the need to make extra efforts to reduce lead levels in these low-income communities.\" In addition, Dr Reuben suggests that in areas recently exposed to lead pollution, extra efforts to compensate for its deleterious effect on IQ should be considered. \"These could include programs to improve education and nutrition in children, as we know these things can help brain development.\" In an accompanying editorial, [2] David C. Bellinger, PhD, MSc, Boston Children's Hospital, Boston, Massachusetts, notes that the total IQ loss in young children that is attributable to current exposures to lead still exceeds that attributable to many pediatric conditions, including brain tumors, congenital heart disease, and traumatic brain injury. \"Some exposure to lead is still virtually universal, and, because there is no safe level of lead, any exposure is detrimental. As a result, and in contrast to rare conditions, all children contribute to the total lead-related IQ loss at the population level.\" He points out that because effective options for secondary prevention are limited, reducing the health burden related to lead exposure will require vigorous primary prevention measures. \"Environments must be screened, in addition to children, so that the most hazardous sites can be effectively abated before rather than after a child's exposure occurs.\" Dr Bellinger adds that identifying educational interventions that improve the cognitive outcomes of lead-exposed children is an important research need because no data are available. He concludes that until these steps are taken, problems are almost certain to occur periodically. \"Children will continue to experience the greatest harm from lead exposure, and disadvantaged children will bear a disproportionate share of the burden,\" he writes. \"The findings of the study by Reuben et al show that these avoidable harms are long lasting and may prevent children from achieving their full potential.\" DMHD is supported by the New Zealand Health Research Council and the New Zealand Ministry of Business, Innovation, and Employment. This research received grant support from the US National Institute on Aging, the UK Medical Research Council, the Economic Social Research Council, and the Jacobs Foundation. Dr Bellinger discloses receipt of compensation as an expert witness for plaintiffs and defendants in civil litigation involving lead poisoning. JAMA. Published online March 28, 2017. Study Highlights In DMHD, 1037 population-representative children born in New Zealand in 1972-1973 were observed prospectively through age 38 years (1007 survivors), with cognitive and socioeconomic assessment at most recent follow-up in December 2012. Blood lead levels at age 11 years were measured in 565 children (54% boys; 93% white) as a marker of childhood lead exposure. Mean lead level was 10.99±4.63 µg/dL, with high levels in children from all socioeconomic strata. Cognitive testing at age 38 years included IQ (primary outcome) and Verbal Comprehension, Perceptual Reasoning, Working Memory, and Processing Speed indexes (secondary outcomes) of the Wechsler Adult Intelligence Scale-IV (WAIS-IV; IQ range, 40-160). The New Zealand Socioeconomic Index-2006 (NZSEI-06; range, 10 [lowest]-90 [highest]) measured socioeconomic status at age 38 years. Among the 565 participants (56%) with lead testing at age 11 years and cognitive/socioeconomic evaluation at age 38 years, mean WAIS-IV score was 101.16±14.82 and mean NZSEI-06 score was 49.75±17.12). Childhood lead exposure was associated with significantly lower cognitive function and socioeconomic status at age 38 years, after adjustment for maternal IQ, childhood IQ, and childhood socioeconomic status. For every 5-µg/dL higher level of blood lead in childhood, there was a 1.61-point decrease in adult IQ (95% confidence interval [CI], -2.48 to -0.74), a 2.07-point decrease in perceptual reasoning (95% CI, -3.14 to -1.01), and a 1.26-point decrease in working memory (95% CI, -2.38 to -0.14). IQ at age 38 years was 4.25 points lower in participants with childhood lead exposure of more than 10 μg/dL than in participants with lower lead levels. Although effect sizes were small and unlikely to attract clinical treatment, they are similar to IQ deficits associated with very low birth weight and other childhood risk factors. Associations of childhood blood lead level with verbal comprehension and processing speed deficits were not statistically significant. For every 5-µg/dL higher level of blood lead in childhood, there was a 1.79-unit decrease in socioeconomic status (95% CI, -3.17 to -0.40). Higher blood lead levels were associated with a decline in IQ and socioeconomic status from childhood to adulthood. Cognitive decline from childhood mediated 40% of the association of higher blood lead levels with downward mobility. Childhood lead exposure was also directly associated with decreases in socioeconomic status relative to the parents. On the basis of their findings, the investigators concluded that childhood lead exposure was associated with long-term cognitive and occupational consequences, and that cognitive impairment can persist and even worsen across decades. Although the cognitive decline in lead-exposed children was mild, it was accompanied by small but detectable downward social mobility by midlife. Findings from this observational design study suggest, but cannot prove, that lead negatively affects cognitive ability and socioeconomic status across time, regardless of early-life cognitive ability or socioeconomic status. The findings support possible early intervention for lead-exposed children. Study limitations include lack of generalizability to nonwhite samples, to populations with very low lead exposures, and to the United States and other settings where lead exposure is concentrated among the poor in larger cities. In addition, there were no measures of cumulative exposure to lead, and only a single measure of childhood lead exposure at age 11 years, precluding determination of the differential impact of early- vs later-life lead exposure. An accompanying editorial notes that total IQ loss in young children attributable to current lead exposures still exceeds that from brain tumors, congenital heart disease, and traumatic brain injury, mandating effective primary prevention. Clinical Implications A prospective, population-based study showed that childhood exposure to lead was associated with long-term cognitive and occupational consequences. Cognitive impairment associated with childhood lead exposure not only persists but may even worsen across decades, accompanied by small but detectable downward social mobility by midlife. Implications for the Healthcare Team: Members of the healthcare team should be aware that total IQ loss in young children attributable to current lead exposures still exceeds that from various other pediatric conditions, mandating effective primary prevention. CME Test 3 ",
				"clientUrl": "/viewarticle/878722",
				"creditType": ["CME", "Nurse CE"],
				"cmeFlag": "CME / CE",
				"leadConceptId": 3029637,
				"leadConcept": "Toxicology",
				"concept": ["Developmental Delay", "Lead Poisoning", "Growth and Development of Child", "Pediatric Nursing", "Cognition", "Cognitive Testing", "Socioeconomics", "Environmental Medicine", "Cognitive Impairment", "Psychosocial", "Public Health Nursing", "Pollutant", "Cognitive Deficits", "Neuropsychological Evaluation"],
				"leadSpecialtyId": 9,
				"leadSpecialty": "Pediatrics",
				"allSpecialties": ["Pediatrics", "Psychiatry", "Medscape Today", "Nursing", "Neurology & Neurosurgery", "Family Medicine/Primary Care", "Public Health & Prevention"],
				"contentGroup": "Clinical Review",
				"origContentType": "Clinical Brief",
				"contentType": ["News"],
				"description": "Childhood lead exposure was associated with poorer long-term cognitive and socioeconomic outcomes in a population where lead exposure was independent of socioeconomic status.",
				"legacyID": 878722,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Can Childhood Lead Exposure Affect Cognition in Midlife?",
				"suppressComment": "T",
				"creditsAvailable": ["PhysiciansFamily Physicians:AMA PRA Category 1 Credit(s)™AAFP Prescribed credit(s):0.25", "Nurses:ANCC Contact Hour(s):0.25", "Physicians:AMA PRA Category 1 Credit(s)™:0.25"],
				"maxCredits": [0.25],
				"publicationDate": 1494478800000,
				"postingDate": 1494478800000,
				"_version_": 1573508897541455872,
				"last_index_date": 1500615022221
			}, {
				"id": "pdctm_0901c79180a6af4a",
				"activeCME": 1,
				"activityExpirationDate": 1507957200000,
				"authors": ["Damrong Wiwatwongwana", " Pornpattana Vichitvejpaisal", " Lakkana Thaikruea", " Jakkrit Klaphajone", " Anuruk Tantong", " Atchareeya Wiwatwongwana"],
				"body": "Abstract and Introduction Abstract and Introduction Abstract Purpose. To investigate the anxiolytic effects of binaural beat embedded audio in patients undergoing cataract surgery under local anesthesia. Methods. This prospective RCT included 141 patients undergoing cataract surgery under local anesthesia. The patients were randomized into three groups; the Binaural beat music group (BB), the plain music intervention group (MI), and a control group (ear phones with no music). Blood pressure (BP) and heart rate were measured on admission, at the beginning of and 20 min after the start of the operation. Peri-operative anxiety level was assessed using the State-Trait Anxiety Inventory questionnaire (STAI). Results. The BB and MI groups comprised 44 patients each and the control group 47. Patients in the MI group and BB group showed significant reduction of STAI state scores after music intervention compared with the control group ( P < 0.001) but the difference was not significant between the MI and BB group (STAI-S score MI group - 7.0, BB group - 9.0, P = 0.085). Systolic BP was significantly lower in both MI ( P = 0.043) and BB (0.040) groups although there was no difference between the two groups ( P = 1.000). A significant reduction in heart rate was seen only in the BB group (BB vs control P = 0.004, BB vs MI P = 0.050, MI vs control P = 0.303). Conclusion. Music, both with and without binaural beat, was proven to decrease anxiety level and lower systolic BP. Patients who received binaural beat audio showed additional decrease in heart rate. Binaural beat embedded musical intervention may have benefit over musical intervention alone in decreasing operative anxiety. Introduction Anxiety is a common cause of psychological stress for patients undergoing eye surgery, as most of the operations are performed while the patient is awake. Worries about loss of control, being in an unfamiliar environment and expectation for good surgical results can produce high levels of peri-operative anxiety for patients. Music, among various interventions, has been proposed to reduce operative anxiety. Musical interventions affect not only the physiologic domains of the patient such as blood pressure and heart rate, but also emotional domains, such as perioperative anxiety levels. Exposure to auditory stimuli in the operation room such as the sound of the phaco machine and the professional conversations of surgeons may also cause emotional stress to the patient. Use of musical interventions, such as having the patient listen to prerecorded music through earphones, can relieve anxiety and reduce exposure to fearsome noises in the environment. [1-4] Bellan et al [5] reported a large-scale study of 144 patients undergoing cataract surgery and found that listening to music before surgery was associated with decreased anxiety. Cruise et al [6] found similar results in a cohort of 121 patients undergoing cataract surgery under retrobulbar block who were more satisfied with their experience if they listened to relaxing music rather than operating room noise alone during the surgical procedure. Binaural beats are special sounds perceived when two auditory stimuli of different frequency are presented to each ear. The use of these beats as a therapeutic tool has recently gained interest among neurophysiologists and clinicians. Binaural beats reportedly influence the brain through the entrainment of brainwaves and can be used to reduce anxiety and increase pain threshold. [7] Binaural beats are auditory processing artifacts, the perception of which arises in the brain for specific physical stimuli. This effect was discovered in 1839 by Heinrich Wilhelm Dove. When two tones that are close in pitch but not identical are sent to a different ear, the brain creates an interference which is called the binaural beat without any physical interaction between the waves. [7,8] Therefore, to generate binaural beats, pure tones must be presented to each ear through earphones. The frequency of the tones must be below about 1000 to 1500 hertz (Hz) for the beating to be heard. The binaural beat frequency is equal to the difference between the frequencies applied to each ear. The difference between the two frequencies must be small (below about 30 Hz) for the effect to occur. For example, if a 400 Hz sine wave is played into the right ear and a 410 Hz into the left ear, the brain is entrained towards the beat frequency of 10 Hz, in the alpha range which is associated with relaxation. Inducing brainwave states with binaural beats has been used to decrease anxiety in patients. The purpose of our study was to determine the anxiolytic effect of binaural beat embedded music compared with plain music without binaural beats and no musical intervention in patients undergoing cataract surgery under local anesthesia. Materials and Methods Materials and Methods The study was approved by the Institutional Review Board of the Faculty of Medicine, Chiang Mai University, Thailand (Research ID 34/ Study Code No. OPT-10-01-28-11-X). Figure 1. CONSORT flow diagram of the progress through phases of the study. Figure 1. This prospective, randomized, controlled study recruited 141 patients who were diagnosed with senile cataract and scheduled for phacoemulsification with intraocular lens implantation under local anesthesia at the Department of Ophthalmology, Faculty of Medicine, Chiang Mai University, Thailand, from January to April 2011 (Figure 1). Exclusion criteria included previous cataract surgery, blood pressure > 160/100 mmHg, hearing problems, infections in the ears and history of epilepsy. Patients were randomized in three groups, by using Random Allocation Software (Isfahan, Iran); the binaural beat group (BB), the plain musical intervention group (MI) and the control group (earphones with no music). Patients and researchers were blinded to allocation until administration of interventions. Subjective Assessment of Anxiety The subjects were asked to complete the State-Trait Anxiety Inventory questionnaires (STAI). The STAI measures anxiety with the state subscale and the trait subscale. The state subscale measures temporary anxiety. The value has variations for individuals for subjective feelings of tension, concern, and worries depending on the situation. The trait subscale is relatively stable in showing personal differences in how individuals differently experience anxiety. [9] The State-Trait Anxiety Inventory is a validated 40-item self-report measure that contains 20 items measuring state anxiety (STAI-S) and 20 items measuring trait anxiety (STAI-T). [9-11] Scores for state and trait components each range from 20 to 80 with a higher score corresponding to higher anxiety levels. Blood pressure and heart rate was recorded on admission (baseline), at the start of the operation, and 20-min after the initiation of the operation. Physiologic Assessment of Anxiety Blood pressure and heart rate were used as object measurements of anxiety. Blood pressure and heart rate of each patient was recorded on admission (baseline), at the beginning of the operation, and 20 min after intervention was administered. Interventions Binaural beats were synthesized with a Self Hypnosis and Relaxation Machine (S.H.A.R.M., CyberTeam, Ltd., Informer Technologies Inc., Madrid, Spain) version 2.4. The carrier tones at 109 and 209 Hz were utilized to create binaural beats with a frequency of 20 Hz in the first 5 min. The binaural beat frequency was set to decline gradually to the therapeutic frequency of 10 Hz within the following 5 min and sustained for another 50 min. Musical arrangements with relaxing components of melodies, tones and rhythms of 60-minute duration were embedded with the binaural beats. Natural sounds such as waterfall, bird chirping, ocean, river and forest sounds were also inserted. The binaural beat embedded audio was exported in MP3 format with high quality for use in the BB group. A plain music audio without binaural beats was produced for use in the MI group. The presence of binaural beats was very difficult to detect by experimental listeners. Before the operation, theperation, the eyes were dilated with tropicamide 1% (Mydriacyl, Alcon, Fort Worth, TX, USA) & phenylephrine hydrochloride 10% (Silom Medical, Bangkok, Thailand) and anesthetized with topical tetracaine hydrochloride 0.5% (Alcon). Lidocaine hydrochloride 2% (Xylocaine jelly, AstraZeneca, London, UK) was applied on call. A retrobulbar block was performed for all patients. Patients were assigned to one of the three groups: the BB group, the MI group or the control group. An iPod shuffle (Apple, Inc., Cupertino, CA, USA) MP3 player and canal-type stereo earphones (Elecom, Shanghai, China) were used to play music for both the BB and MI groups. Earphones were placed in both ears of the patients 10 min before the start of the operation. Patients in the control group wore earphones connected to an iPod without music. An appropriate volume level was chosen by the patient, which would still allow them to hear the surgeon's communication regarding the procedure or requesting their cooperation. Blood pressure and heart rate were recorded at the beginning of the operation and 20 min after the start of the operation time. Duration of the operation and intra-operative complications were recorded. All surgeries were performed by third year ophthalmology residents. Surgeons were not aware of the patients' intervention group. After completion of the operation, patients were transferred to the ward and asked to complete only the STAI-S questionnaire post-operatively. Statistical Analysis On the basis of the data provided by previous studies, [12] a sample size of 47 patients in each of the three groups was required to provide 90% power at the 5% two-sided level. Statistical analyses was performed using Epi Info for Windows Version 3.5.1 (CDC, Atlanta, GA, USA) and STATA version 11 (Stata Corp, College Station, TX, USA). The frequency distribution of demographic descriptive variables was used to identify the patients' demographic profiles. The demographic factors were controlled for by Random Allocation Software (freeware). The results are shown as mean ± standard deviation. Comparison of baseline characteristics between groups was performed with Fisher Exact test. Univariate analysis of anxiety-associated factors between the three groups (difference STAI-scores, blood pressure, heart rate) was performed with Sidak analysis. P-value ≤ 0.05 was considered statistically significant. Results Results Of the 143 patients recruited, two refused to participate because of personnel reason. Forty-seven patients were randomly allocated to one of the three intervention groups. Six patients (three patients in the BB and three patients in the MI group) were excluded because the duration of the operation was less than 20 min (Figure 1). There were no statistically significant differences in age, gender, baseline blood pressure, heart rate, operating time, and initial STAI-T and STAI-S scores between groups ( Table 1 ). Post-operatively, STAI-S score was reassessed at the ward and revealed significantly decreased scores in the MI and BB groups compared with the control group ( P < 0.001) ( Table 2 ). The BB group showed a slightly larger decrease in STAI-S score although this difference was not statistically significant. At 20 min into the operation, patients' heart rate was significantly lower in the BB group compared with the control group ( P < 0.001) and the MI group ( P < 0.050) ( Table 3 ). No adverse events occurred. Discussion Discussion Previous studies have reported the benefits of music for patients undergoing various types of surgery. [13-16] One such benefit is the relief of anxiety. Recent studies suggest that binaural auditory beats can affect anxiety. [17] Padmanabhan et al [12] reported that binaural beat audio can help decrease acute pre-operative anxiety before undergoing general anesthesia. To the best of our knowledge, this is the first study of the effect of binaural beat audio on operative anxiety patients in patients undergoing ophthalmic surgery under local anesthesia. Furthermore, we compared the effect of binaural beat embedded music with plain music and no musical intervention at all in order to document any additional effect of binaural beats on anxiety reduction. In our study, anxiety level was assessed by the Spielberger's STAI, which is one of the most commonly used subjective self-measuring tests. The STAI is now the standard tool for measuring preoperative anxiety. [10] Le Scouarnec et al [17] studied the use of binaural beat tones for treatment of patients diagnosed with mild anxiety. Their results showed a significant reduction in post-treatment STAI scores after 4 weeks of regularly listening to tapes imbedded with binaural beat music tones, although physiologic measure of anxiety reduction was not performed. Weiland et al [18] compared anxiety reduction effects of different original sound compositions (electroacoustic music, audio field recordings obtained from natural and constructed settings and audio field recordings with embedded binaural beat) with reconstructed ambient noise simulating an emergency department environment and headphones only without music in emergency department patients. They reported that musical interventions including binaural beat embedded compositions significantly reduced anxiety (assessed subjectively by STAI scores) compared with headphones only or simulated emergency department noise. In our study, we assessed the anxiety status of the patients by using both subjective and physiological measurement. We also found a statistically significant decrease in STAI-S score in both the BB group and MI group compared to the control group. The patients in the BB group had lower post-intervention STAI scores compared with the MI group, although the difference was not significant (-9.0 vs - 7.0; P = 0.085). Our physiologic outcome measurement of anxiety included systolic blood pressure and heart rate. Systolic blood pressure in the BB and MI groups were significantly lower than the control group. Patients in the control group who were not exposed to any music had increased systolic blood pressure during surgery. Heart rate in the BB group was significantly lower than the MI ( P = 0.050) and control groups ( P = 0.004) while there was no difference in heart rate of patients in the MI group compared with the control group ( P = 0.303). Therefore, we suggest that binaural beats may have an additional anxiolytic effect to plain musical interventions without binaural beats. Theoretically, an audio embedded with binaural beats can induce a predictable alteration in brainwave activity. The waxing and waning in amplitude of the resultant tones gives a characteristic binaural beat perception with a frequency equal to the difference between the two pure tones presented, provided that the original impulses are less than 1000 Hz and the difference between the two tones is between 1 and 30 Hz. If sustained binaural beat frequencies resonate throughout the brain, it will stimulate the brain and alter the levels of arousal via activation of the reticular-thalamic activating system. This process is called 'entrainment' and has been reported in previous researches with EEG (electroencephlogram) recording. [19] A weakness of our study was that the cataract surgery was performed by multiple surgeons in order to obtain a sufficient sample size for the study which may have confounded the results. In addition, deficiency of hearing was self-reported by the patient and not objectively tested in every patient, therefore, patients with mild hearing loss especially unilateral, may have been unaware of their deficit which may have influenced the results of the interventions. Other limitations of our study include lack of EEG recording facilities in the operating room and patients' post-intervention blood pressure was recorded only once. Furthermore, patients in the control group could only be masked until intervention was administered. Awareness of an individual's intervention group may have caused some bias in answering the post-intervention STAI. Keeping this in mind, we also recorded physiologic outcomes of anxiety which included heart rate and systolic blood pressure in order to confirm the decrease or increase in anxiety state of each patient. We explored the potential of the binaural beat frequency of 10 Hz (alpha frequency range) to decrease acute operative anxiety. The initial frequency of 20 Hz (beta frequency range) during the first 5 min of the audio file was set to be tuned with pre-operative anxiety in which the brainwave pattern was likely to be a beta pattern or arousal state. Therefore, through brain entrainment, a 10 Hz binaural beat would encourage the brain to produce a 10 Hz beat corresponding to a relaxed state of consciousness or alpha pattern. Decreased patient anxiety results in better patient compliance and better surgical outcomes. This is especially important for patients undergoing cataract surgery which is usually performed under local anesthesia. Conclusion Conclusion Our study supports the evidence that music can decrease operative anxiety. We suggest that binaural beat embedded musical intervention may have additional anxiolytic effects over music without binaural beats. Further studies on autonomic nervous system alteration in correlation with EEG recordings during exposure to binaural beats is needed to better understand how and to what extent these special tones can effect anxiety state. ",
				"clientUrl": "/viewarticle/869738",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 985,
				"leadConcept": "Cataract",
				"concept": ["Anxiety", "Cataract Surgery", "Complementary and Alternative Medicine (CAM)", "Surgical Complication", "Stress Management", "Psychological Stress", "Optometry"],
				"leadSpecialtyId": 36,
				"leadSpecialty": "Ophthalmology",
				"allSpecialties": ["Ophthalmology", "Psychiatry"],
				"contentGroup": "Journal Article",
				"origContentType": "Journal Article",
				"contentType": ["Journal Article"],
				"description": "Music, both with and without binaural beat, reduces anxiety levels and lowers systolic blood pressure during cataract surgery.",
				"legacyID": 869738,
				"pubDisplay": "Eye CME",
				"siteOn": 2003,
				"title": "The Effect of Music With and Without Binaural Beat Audio on Operative Anxiety in Patients Undergoing Cataract Surgery: A Randomized Controlled Trial",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/Eye-thumb.jpg"],
				"publicationDate": 1477976400000,
				"postingDate": 1476421200000,
				"_version_": 1573508895445352448,
				"last_index_date": 1500615020219
			}, {
				"id": "pdctm_0901c79180a7cd3f",
				"activeCME": 1,
				"activityExpirationDate": 1517029200000,
				"authors": ["Anil Yallapragada", " Souvik Sen", " Amar Anand"],
				"body": "The following cases are modeled on the interactive grand rounds approach. The questions within the activity are designed to test your current knowledge. After each question, you will be able to see whether you answered correctly and read evidence-based information that supports the most appropriate answer choice. The questions are designed to challenge you; you will not be penalized for answering the questions incorrectly. At the end of the activity, there will be a short post-test assessment based on the material presented. 3 Case 1: Thrombolytic therapy Patient Image 170 0 Karen is a woman aged 47 years in normal health and with no prior significant medical history. At approximately 12:35 PM, while moving her granddaughter's playpen, Karen developed sudden-onset, right-sided arm and leg weakness and difficulty speaking. She collapsed. Karen's granddaughter rushed to the next room to tell her grandfather, who called 911. 4 In a patient with acute stroke, the clinical presentation can provide important clues about the vascular territory affected. [1] The MCA is the largest cerebral artery and the most common site of acute ischemic stroke (AIS). [2] Classic symptoms of MCA occlusion include contralateral hemiplegia or hemiparesis and sensory loss (especially involving the face or arm). Laterality of an MCA occlusion also contributes to the clinical presentation. Most people are left-hemisphere dominant for language function, and MCA occlusion of the left hemisphere often results in significant language impairment. [1,3] Strokes affecting the right (nondominant) hemisphere are more likely to result in unilateral neglect (left hemineglect), in which the patient exhibits decreased attention to the left side of the body and a lack of awareness or concern about the stroke-related deficits. [1] Although less common, strokes involving other cerebral arteries may also produce characteristic clinical presentations [1,4] : Classic signs of an ACA stroke include contralateral leg weakness and sensory loss The posterior cerebral artery (PCA) supplies the medial occipital lobe and inferior and medial temporal lobes. PCA strokes commonly result in visual disturbances and are also associated with the \"D symptoms,\" including dizziness, diplopia, dysarthria, dysphagia, and dystaxia Vertebral arteries of the cervical vertebral column merge to form the basilar artery, which provides blood flow to the posterior portion of the brain, including the brainstem and cerebellum. Vertebral-basilar strokes may involve the cerebellum (typically resulting in impairments of balance or coordination) or the brainstem (producing potentially devastating strokes that may cause hemiparesis or quadriplegia, sensory loss affecting either hemibody or all four limbs, diplopia, dysconjugate gaze, slurred speech, impaired swallowing, decreased level of consciousness, and abnormal respiration) Case Continuation Emergency Medical Services (EMS) was notified by the grandfather, and arrived promptly on the scene. A first EMS call was placed at 12:44 PM, and a second at 12:52 PM. EMS collected data including symptoms, vital signs, and current anticoagulation therapy, which are summarized in Figure 1. Figure 1. EMS information for Karen Information collected by EMS Aphasia Left gaze preference Right sided weakness Face, arm, leg weakness Blood pressure: 183/124 mm Hg Heart rate: 88 bpm Sinus rhythm: 20 O2 saturation: 98% Blood Sugar: 83 mg/dL Intravenous access established No anticoagulation history Omeprazole The prehospital notification system was used to identify inclusion and exclusion criteria for treatment before the patient arrived at the hospital. An acute stroke code was activated while the patient was en route, enabling hospital staff to prepare before the arrival of the patient. 5 Tissue plasminogen activator is approved by the United States Food and Drug Administration (FDA) for the treatment of AIS. The recommended dose is 0.9 mg/kg (not to exceed 90 mg total dose), with 10% of the total dose administered as an initial bolus over 1 minute and the remainder infused intravenously over 60 minutes. [5] In two large, randomized, placebo-controlled clinical trials conducted by the National Institute of Neurologic Disorders and Stroke (NINDS), administration of tPA within 3 hours of the onset of AIS was associated with better clinical outcomes at 24 hours (one study only) and at 3 months (both studies), including a significant reduction in residual disability. [6] Subsequent clinical studies suggest that this time window could be expanded to 4.5 hours after stroke onset in certain patients without contraindications, although treatment should be administered as soon as possible after stroke onset. [7] The major risk of tPA treatment of acute stroke is symptomatic intracerebral hemorrhage. In randomized clinical trials, this occurred more often among patients treated with tPA (6.0%) than placebo (0.6%). The prescribing information provided by the manufacturer notes that the risk of bleeding is increased for patients with hypertension (systolic blood pressure >175 mm Hg or diastolic blood pressure >110 mm Hg). [5] According to AHA/ASA guidelines, tPA should not be administered to patients with systolic blood pressure >185 mm Hg or diastolic blood pressure >110 mm Hg. [7] Inclusion and exclusion criteria for the use of tPA within 3 hours of symptom onset, as recommended by AHA/ASA guidelines, are summarized in Table 1. Table 1. Inclusion and Exclusion Criteria for tPA Treatment Within 3 Hours of Stroke Onset [7] Inclusion Criteria Exclusion Criteria Relative Exclusion Criteria Diagnosis of ischemic stroke causing measurable neurological deficit Onset of symptoms <3 hours before beginning treatment Age ≥18 years Significant head trauma or prior stroke in previous 3 months Symptoms suggest subarachnoid hemorrhage Arterial puncture at noncompressible site in previous 7 days History of previous intracranial hemorrhage, Intracranial neoplasm, arteriovenous malformation, or aneurysm Recent intracranial or intraspinal surgery Elevated BP (systolic >185 mm Hg or diastolic >110 mm Hg) Active internal bleeding Acute bleeding diathesis, including but not limited to Platelet count <100000/mm 3 Heparin received within 48 hours, resulting in abnormally elevated aPTT greater than the upper limit of normal Current use of anticoagulant with INR >1.7 or PT >15 seconds Current use of direct thrombin inhibitors or direct factor Xa inhibitors with elevated sensitive laboratory tests (such as aPTT, INR, platelet count, and ECT; TT; or appropriate factor Xa activity assays) Blood glucose concentration <50 mg/dL (2.7 mmol/L) CT demonstrates multilobar infarction (hypodensity >1/3 cerebral hemisphere) Only minor or rapidly improving stroke symptoms (clearing spontaneously) Pregnancy Seizure at onset with postictal residual neurological impairments Major surgery or serious trauma within previous 14 days For patients beginning treatment within 3 to 4.5 hours after stroke onset, the guidelines recommend several additional exclusion criteria [7] : Age >80 years Severe stroke (NIHSS score >25) Taking an oral anticoagulant regardless of international normalized ratio (INR) History of both diabetes and prior ischemic stroke Regardless of the time between stroke onset and initiation of tPA, the guidelines recommend that the time from hospital admission to injection of the tPA bolus (the door-to-needle time) should be within 60 minutes. [7] Case Continuation Upon arrival to the emergency department (ED) at 1:05 PM, Karen was assessed by the ED physician and the stroke team while being transported to the computed tomography (CT) scanner. Blood pressure on arrival was 199/119 mm Hg. Karen was given two doses of labetalol 10 mg intravenous (IV). Her NIHSS score was 19 on arrival, with the following exam findings noted: awake, alert, no vocalization, expressive aphasia, comprehension intact and following commands, left gaze preference, right-sided pronounced facial droop, dense hemiparesis of right arm and right leg. Head CT was completed, and no hemorrhage or early ischemic changes were noted (see Figure 2). Figure 2. Head CT was Complete, and no Hemorrhagic or Early Ischemic Changes Were Noted 1 6 NECT is usually sufficient to identify contraindications to fibrinolytic therapy, and is most commonly used in acute stroke assessment. It should be obtained within 25 minutes of the patient's arrival in the ED. [7] NECT definitively identifies parenchymal hemorrhage, and can also identify other potential exclusion criteria for tPA and nonvascular causes of neurologic dysfunction (eg, tumors). NECT may also identify other signs of early central nervous system ischemia, including the loss of gray matter/white matter differentiation (eg, decreased distinction among the nuclei of the basal ganglia or blending of the densities of the cortex and underlying white matter) or swelling of the gyri with sulcal effacement. [7] NECT evidence of early, clear hypodensity or mass effect is associated with a markedly increased risk of hemorrhage after tPA therapy. AHA/ASA guidelines recommend that IV tPA should be withheld if frank hypodensity involves more than 33% of the MCA territory. [7] Case Continuation The patient was responsive to hypertensive treatment, with a blood pressure of 172/86 mm Hg. tPA was mixed at 13:16 and the bolus dose was administered at 13:20, for a door-to-needle time of 15 minutes (see Figure 3). Figure 3. Time From Initial Symptom Onset to Injection of tPA Bolus 1 7 In addition to symptomatic intracerebral hemorrhage, other potential adverse effects of tPA for acute stroke include systemic bleeding, myocardial rupture (if fibrinolytics are administered within a few days of acute myocardial infarction), and reactions such as anaphylaxis or angioedema. [7] Orolingual angioedema reactions may include swelling of the tongue, lips, and oropharynx, usually occurring contralateral to the ischemic cerebral hemisphere. These events are relatively rare (occurring in approximately 1.3% to 5.1% of patients who receive intravenous tPA for acute stroke), and are typically mild and transient. [7] However, angioedema can potentially cause airway obstruction and respiratory compromise, and it is important to recognize and manage it quickly when it occurs. [8] Concomitant use of angiotensin-converting enzyme inhibitors may increase the risk of orolingual angioedema. [5] Patients should be monitored during and for several hours after tPA infusion for orolingual angioedema, including inspection of the tongue, lips, and oropharynx. If angioedema develops, tPA should be discontinued if it is still running. [5,7] Recommended management options include prompt treatment with diphenhydramine 50 mg IV followed by either ranitidine 50 mg IV or famotidine 20 mg IV. If enlargement of the tongue continues, the patient should receive methylprednisolone 80 to 100 mg IV. If angioedema is not stopped by methylprednisolone, the patient should be treated by urgent administration of epinephrine 0.1% subcutaneous (0.3 mL) or by nebulizer (0.5 mL), with a STAT consult of ear/nose/throat, anesthesiology, or other appropriate in-house service for possible emergency cricotomy/tracheostomy or fiberoptic nasotracheal intubation. [8,9] 8 Approximately 25% to 30% of stroke patients have cryptogenic stroke. [10] Cryptogenic strokes are often caused by unrecognized AF, and identifying intermittent AF in patients with stroke is important to institute anticoagulation therapy as secondary prevention against subsequent embolic events. However, in clinical practice, most patients undergo only short-term ECG monitoring during the poststroke period. [10] AHA/ASA guidelines recommend cardiac monitoring for at least 24 hours beginning in the ED. [10] Longer-term monitoring over a period of several days may be required (eg, Holter monitoring or event-looped recording). The CRYSTAL-AF study examined the effectiveness of long-term ECG monitoring using an insertable cardiac monitor (ICM) to identify AF in patients with a recent ischemic stroke or transient ischemic attack (TIA; figure 4). [11] Patients with TIA were eligible only if symptoms at presentation included speech problems, limb weakness, or hemianopsia. They had no evidence of AF during 24 hours of ECG monitoring. Figure 4. ICM Shows Increased Incidence of AF 1 Case Conclusion Karen received an insertable monitor/loop recorder. AF was detected 2 months later, and she began anticoagulation therapy. She has had no further TIA- or stroke-like episodes since anticoagulation was initiated. She now enjoys playing with her grandchildren without any significant limitations on her quality of life. Case 2 Patient Image 170 0 William, a black man aged 54 years with a history of type 2 diabetes mellitus, hypertension, and gastroesophageal reflux disease, was working in his home office sometime before 9 AM, speaking on the phone. He realized that although he knew what he wanted to say, he couldn't get the words out. He also noticed some right arm weakness, but ignored the symptoms. Early that afternoon, his wife returned home to find that William was totally unable to speak. She called 911. When EMS arrived, William was found to be globally aphasic with complete right-sided weakness. EMS performed a Rapid Arterial oClusion Evaluation Stroke Scale (RACE Stroke Scale), which yielded a score >4. This is indicative of a large-vessel occlusion (Figure 5). This finding prompted EMS to take William to the closest comprehensive stroke center, given the possible need for thrombectomy. Through prehospital notification by the EMS, an acute stroke code was activated while the patient was en route enabling hospital staff at the stroke center to be prepared prior to arrival of the patient. Upon arrival at the ED at 1:30 PM, the patient was assessed by the ED physician and stroke team while being transported to the CT scan. His BP on arrival was 200/100. Figure 5. RACE Stroke Scale 1 9 In patients undergoing endovascular revascularization for acute stroke, aggressive management of hypertension is essential to reduce the risk of intracerebral hemorrhage following successful reperfusion. [12] Blood pressure lowering during acute stroke should be performed in a controlled manner, which can best be accomplished using intravenous antihypertensive therapies. AHA/ASA stroke guidelines recommend antihypertensive therapy for patients who are candidates for acute reperfusion therapy when blood pressure exceeds 185/110 mm Hg. [7] Recommended antihypertensive agents include IV labetalol 10 to 20 mg infused over 1 to 2 minutes, which may be repeated once; or nicardipine 5 mg/hour IV infusion (titrated up by 2.5 mg/hour every 5 to 15 minutes; maximum 15 mg/hour; when desired blood pressure is reached, dose is adjusted to maintain blood pressure within the desired range). Other agents may be considered when appropriate (eg, hydralazine, enalaprilat). If blood pressure is not controlled or diastolic blood pressure exceeds 140 mm Hg, IV sodium nitroprusside may be considered. [7] Arterial hypotension is less common after ischemic stroke, and suggests another cause. Hypotension is associated with a risk of decreased cerebral blood flow, brain injury, and poor clinical outcomes. [13-15] If arterial hypotension cannot be rapidly corrected by other means, vasopressor agents may be used to increase blood pressure. Some evidence suggests that volume expansion may also be appropriate. [7] After an endovascular procedure, patients often undergo blood pressure monitoring and management that is similar to that for tPA treatment. Blood pressure should be monitored regularly (eg, every 15 minutes for 2 hours, then every 30 minutes for 6 hours, then hourly for 18 hours), and maintained below 180/105 mm Hg. [12] Case Continuation William was found to have a partial right gaze preference, left homonymous hemianopia, left arm and leg weakness, decreased left-side sensation, visual and tactile neglect on the left, and an NIHSS score of 11 (see table 2). Table 2. NIH Stroke Scale Category Scale Definitions Score 1a. Level of consciousness 0 = alert 1 = not alert but arousable 2 = not alert, requires repeated stimulation 3 = unresponsive 0 1b. LOC questions (month and patient's age) 0 = answers both correctly 1 = answers 1 correctly 2 = answers neither correctly 0 1c. LOC commands: open/close eyes, grip/release non-paretic hand 0 = performs both tasks correctly 1 = performs 1 task correctly 2 = performs neither task correctly 0 2. Best gaze: horizontal eye movements (voluntary or reflexive) 0 = normal 1 = partial gaze palsy 2 = forced deviation 1 3. Visual: upper and lower quadrants of visual field are tested by confrontation, using finger counting or visual threat 0 = no visual loss 1 = partial hemianopia 2 = complete hemianopia 3 = bilateral hemianopia 2 4. Facial palsy: ask patient to show teeth or raise eyebrows and close eyes 0 = normal symmetrical movements 1 = minor paralysis 2 = partial paralysis 3 = complete paralysis 1 5. Motor arm: extend arms 90 degrees if sitting or 45 degrees if supine (each limb); drift is scored if arm falls before 10 seconds 5a: left arm; 5b: right arm 0 = no drift 1 = drift 2 = some effort against gravity 3 = no effort against gravity 4 = no movement UN = amputation 2 (left) 0 (right) 6. Motor leg: elevate leg 30 degrees (supine); drift if left falls before 5 seconds 6a: left leg; 6b: right leg 0 = no drift 1 = drift 2 = some effort against gravity 3 = no effort against gravity 4 = no movement UN = amputation 2 (left) 0 (right) 7. Limb ataxia: test with eyes open. Finger-nose-finger and heel-shin tests on both sides 0 = absent 1 = present in 1 limb 2 = present in 2 limbs UN = amputation 0 8. Sensory: sensation or grimace to pinprick. Test arms (not hands), legs, trunk, face 0 = normal 1 = mild-to-moderate sensory loss 2 = severe to total sensory loss 1 9. Best language: patient is asked to describe what is happening in a picture and read from a list of sentences 0 = no aphasia 1 = mild-to-moderate aphasia 2 = severe aphasia 3 = mute, global aphasia 0 10. Dysarthria: ask patient to read or repeat words from a list 0 = normal 1 = mild-to-moderate dysarthria 2 = severe dysarthria UN = intubated or physical barrier 0 11. Extinction and inattention (formerly neglect): can use information from previous measures 0 = no abnormality 1 = visual, tactile, auditory, spatial, or personal inattention 2 = profound hemi-inattention or extinction to more than 1 modality 2 Total   11 10 Over the last decade, an increasing number of endovascular treatment strategies have been introduced for the treatment of AIS. Some of these approaches include intraarterial thrombolysis, mechanical clot retrieval, mechanical clot aspiration, and acute angioplasty and stenting. [7,16] AHA/ASA guidelines note that patients eligible for intravenous tPA should receive it when possible. Intra-arterial fibrinolysis may be beneficial for patients with major ischemic stroke of <6 hours duration and occlusion of the MCA who are not candidates for intravenous tPA. However, tPA is not approved by the FDA for intraarterial use. [5,16] Mechanical thrombectomy may be pursued as a primary reperfusion strategy or in conjunction with fibrinolytic therapy. The AHA and ASA have recently issued updated guidelines for endovascular treatment of ischemic stroke. [16] Endovascular therapy with stent retrievers is considered reasonable for certain patients with anterior circulation stroke who have contraindications to tPA, when the procedure may be completed within 6 hours of stroke onset. [16] The guidelines note that, as with intravenous tPA, the time between symptom onset and reperfusion with endovascular therapies is strongly associated with eventual clinical outcomes. A meta-analysis included 5 randomized clinical trials with a combined population of 1287 patients. [17] Prior tPA therapy had been administered to 83.0% of patients in the endovascular thrombectomy group and 87.1% of those in the medical therapy group. The primary outcome was 90-day disability, which was measured using the modified Rankin scale (range, 0 to 6; lower score indicating less disability). Overall, disability at 90 days was lower for patients who were randomized to thrombectomy than to medical management alone (mean Rankin score 2.9 with thrombectomy versus 3.6). The odds ratio of a lower disability score with thrombectomy decreased with longer treatment delays. Case Continuation Head CT was completed, which revealed a hyperdense sign on the left. Computed tomography angiography (CTA) head and neck was performed to assess for a large vessel occlusion, which revealed a proximal left MCA thrombus with absent filling (see Figure 6). Figure 6. CTA Revealed Absent Filling on the Left MCA 1 11 Occlusion of a cerebral artery beyond a certain period of time will result in the development of a core of injury that is destined for irreversible destruction. This ischemic core is surrounded by an ischemic penumbra, which consists of at-risk but potentially salvageable tissue that is characterized by decreased electrical activity with preserved ion homeostasis and cellular membrane potentials. [18-19] This potentially salvageable penumbra is an important target of reperfusion therapy, [7] and the sizes of the core infarct and the surrounding ischemic penumbra are important considerations in patient selection. [20] Several methods may be used to establish the size of the core infarct, including direct methods (Alberta Stroke Program Early CT Score [ASPECTS], CTP, diffusion-weighted imaging [DWI volume]) and indirect methods (eg, CTA collaterals). [21-24] ASPECTS is a structured scoring system to evaluate the extent of ischemic injury. ASPECTS using a 10-point quantitative topographic CT scan score to provide reproducible grading of early ischemic hypodensity on pretreatment CT studies in patients with AIS of the anterior circulation. [25,26] A normal CT scan receives ASPECTS of 10 points, while a score of 0 indicates diffuse involvement throughout the MCA territory. [25] In clinical studies of thrombectomy for acute stroke, an ASPECTS score of 6 to 10 has been used to define small infarct cores, [27-28] and the benefits of mechanical thrombectomy have been observed primarily in this patient group. [16] DWI is the most sensitive and specific imaging technique for identifying the core infarct, with even early ischemic lesions exhibiting severe apparent diffusion coefficient changes. [7] The loss of collateral vessels on CTA also provides an indirect measure that is significantly correlated with the size of the core infarct. [24] Combined with parenchymal imaging, perfusion-weighted magnetic resonance imaging (MRI) or CTP imaging can be used to distinguish the ischemic penumbra from areas that are severely (and probably irreversibly) infarcted. Brain perfusion imaging provides information about regional cerebral hemodynamics, including cerebral blood flow, cerebral blood volume, and mean transit time. [7] On MRI, the ischemic penumbra may be indicated by a region where the volume of the MRI perfusion abnormality is larger than the volume of abnormal tissue on DWI (referred to as the perfusion-diffusion mismatch). [19] Identifying this mismatch can be used be crucial in selecting patients for reperfusion therapy. [29] On CTP imaging, the penumbra may be defined by areas of maintained blood volume but reduced blood flow, which may be imaged using the area of mismatch between mean transit time and cerebral blood volume. [30] AHA/ASA guidelines recommend the use of CTP or perfusion-weighted MRI to delineate the ischemic penumbra and areas that are severely/permanently infarcted. [7] Some studies have suggested that the response to reperfusion therapy may be greater in patients whose lesions contain small infarct cores and larger ischemic penumbras. [7] Given the differences in CTP hardware and software in different facilities, there are no currently standardized quantitative metrics with clearly defined standardized thresholds for guiding therapy. Within the last 5 years, the two multicenter, randomized, controlled clinical trials of endovascular treatment for AIS (SWIFT PRIME and EXTEND-IA), which used CTP as part of the neuroimaging selection criteria, showed the best outcomes with regard to functional independence 3 months after endovascular treatment. [31,32] Currently, the DEFFUSE 3 Trial is attempting to create standardized RAPID software CTP metrics to help guide therapy with regard to post-tPA neurovascular intervention. The parameters used in this study mirror the metrics that are commonly used by many stroke neurologists and may serve as a reasonable approach to evaluating CTP. These parameters include ischemic core infarct volume <70 mL (area of decreased cerebral blood volume), mismatch ratio ≥1.8 (area of decreased cerebral blood flow/cerebral blood volume), and mismatch volume ≥15 mL. [33] 12 Mechanical thrombectomy may produce recanalization of an occluded vessel through a combination of thrombus fragmentation, thrombus removal, and enhanced penetration by tPA. [7] Several thrombectomy devices have been approved by the FDA, including the Mechanical Embolus Removal in Cerebral Ischemia (MERCI) Retrieval System (approved in 2004), the Penumbra System (approved in 2007), the Solitaire Flow Restoration Device (approved in 2012), and the Trevo Retriever (approved in 2012). [7,16] AHA/ASA guidelines for revascularization of AIS, which were published in 2013, recommended that when mechanical thrombectomy is pursued, stent retrievers (eg, Solitaire Flow Restoration, Trevo) are generally preferred to coil receivers (eg, MERCI). [7] All 4 approved devices were considered useful in achieving recanalization in carefully selected patients, either alone in combination with fibrinolysis. The usefulness of mechanical thrombectomy devices other than the MERCI retriever, Penumbra System, Solitaire Flow Restoration, and Trevo was considered not well established. In addition, emergent intracranial angioplasty and/or stenting, was also described as not well established for AIS. These techniques were recommended only in the setting of a clinical trial. [7] Since the publication of the initial AHA/ASA guidelines, several additional studies reported better clinical outcomes with mechanical thrombectomy than conventional care in patients with AIS (see table 3). These included 5 randomized clinical trials that all used a similar study design (prospective, randomized, open-label, blinded-endpoint) and included an assessment of functional independence at 90 days post-stroke (defined as a modified Rankin score of 0-2). Table 3. Randomized Trials of Thrombectomy Trial Condition tPA Treatment? Randomization 90 Day Post-Stroke Functional Independence MR CLEAN [34] N=500 AIS 89% prior to randomization Usual care vs retrievable stent 32.6% intraarterial treatment vs 19.1% usual care ESCAPE [35] * =316 AIS with small infarct core, proximal intracranial arterial occlusion, moderate-to-good collateral circulation 75% Standard care vs standard care + thrombectomy 53% intervention group vs 29.3% usual care SWIFT PRIME [28] * N=196 Occlusion of proximal anterior intracranial circulation who received tPA 100% tPA alone vs tPA + Solitaire retriever 60% in tPA + thrombectomy group vs 35% in tPA alone EXTEND-IA [32] * N=70 AIS, occlusion of internal carotid or middle cerebral artery, evidence of salvageable brain tissue, ischemic core <70 ml on CT perfusion imaging 100% (within 4.5 hours; when eligible for tPA) tPA alone vs tPA + Solitaire retriever 71% tPA + endovascular treatment vs 40% tPA alone REVASCAT [36] † N=206 Confirmed proximal anterior circulation occlusion and absence or large infarcts (treated within 8 hours) 100% (when eligible for tPA) Medical management vs medical management + Solitaire stent retriever 43.7% endovascular treatment vs 28.2% medical management *Discontinued early because of positive outcome. † Discontinued early because of positive outcome in other endovascular therapy trials. The results of these studies were considered in updated and revised AHA/ASA endovascular treatment guidelines, which were published in 2015, [16] as well as in revised guidelines published in Europe, Canada, and other countries. [37] These guidelines note that in patients with anterior circulation occlusion who have contraindications to tPA (eg, time from stroke onset, prior stroke, serious head injury, hemorrhagic coagulopathy, receiving anticoagulant medication), endovascular therapy with stent retrievers within 6 hours of stroke onset is a reasonable option. [16] Although the benefits were considered less certain, the use of stent retrievers was also considered a reasonable option for some patients with occlusions of the M2 or M3 portions of the MCA, anterior cerebral arteries, vertebral arteries, basilar artery, or posterior cerebral artery, when treatment could be initiated within 6 hours. Stent retrievers were indicated in preference to the MERCI device, although devices other than stent retrievers may be reasonable under some circumstances. The goal of treatment should be to establish a Thrombolysis in Cerebral Infarction score of 2b (nearly complete reperfusion) or 3 (complete reperfusion) as early as possible, and within 6 hours of stroke onset. Case Conclusion William underwent thrombectomy with a stent retriever, which resulted in improvement in neurologic signs and symptoms. On a repeat postprocedural NIHSS, his score was 4. He continued to exhibit some mild decreased sensation and weakness on the left face, arm and leg. However, he no longer had any visual or tactile neglect. A repeat angiogram revealed complete patency of the left M1 segment with partial patency of the proximal sylvian branches. William underwent a thorough evaluation on the stroke floor, although this workup did not clearly identify an underlying stroke etiology. MRI on hospital day 2 revealed small scattered areas of restricted diffusion consistent with acute infarction in the right MCA territory. Carotid Doppler did not reveal any flow-limiting stenosis. Transthoracic echocardiogram was relatively unremarkable, with an ejection fraction of 65% and no appreciated embolic source. However, the left atrium was mildly dilated at 4.2 cm diameter. Transesophageal echocardiogram yielded similar findings. The patient's deficits continued to improve throughout admission. William was discharged on aspirin 81 mg daily and a statin for secondary stroke prevention. He was also discharged on a 30-day cardiac event monitor to evaluate for AF. A follow-up examination 5 weeks later found that William had been compliant with his home medications, and his 30-day cardiac event monitor findings were unremarkable. Educational Impact Challenge What did you learn from this activity? Please click on the \"Continue\" button to proceed to a brief survey to see how your knowledge improved after the education. You can also see how your answers compare with those of your peers. Educational Impact Challenge 13 ",
				"clientUrl": "/viewarticle/870716",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 477,
				"leadConcept": "Cerebrovascular Accident (CVA)",
				"concept": ["Angioneurotic Edema", "Hypertension", "Atrial Fibrillation", "Increased Blood Pressure", "Electrocardiogram (ECG)", "Clinical Guidelines", "Treatment Guidelines", "Patient Care Management", "Hospital Emergency Services", "CT Angiography", "Endovascular Techniques", "Neuroimaging", "Adverse Effects", "CT Scan", "Middle Cerebral Artery", "Thrombolytic Therapy", "Hemorrhage", "Stent", "Endovascular Stent", "Pharmacologic Adverse Events", "Ischemic Stroke", "Angioedema", "Acute Stroke Management", "Acute Stroke", "Middle Cerebral Artery Stroke", "Clinical Research", "Tissue Plasminogen Activator (tPA)", "Patient Assessment"],
				"leadSpecialtyId": 26,
				"leadSpecialty": "Neurology & Neurosurgery",
				"allSpecialties": ["Neurology & Neurosurgery", "Medscape Today", "Radiology", "Emergency Medicine"],
				"contentGroup": "Clinical Case",
				"origContentType": "Clinical Case",
				"contentType": ["Patient Case"],
				"description": "Follow 2 cases that demonstrate appropriate treatment selection and monitoring for patients with acute ischemic stroke.",
				"legacyID": 870716,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Current Approaches to the Management of Acute Ischemic Stroke",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/870716.jpg"],
				"publicationDate": 1485493200000,
				"postingDate": 1485493200000,
				"_version_": 1573508880782065664,
				"last_index_date": 1500615006251
			}, {
				"id": "pdctm_0901c79180a75289",
				"activeCME": 1,
				"activityExpirationDate": 1508821200000,
				"authors": ["Roland E. Schmieder", " Claudio Cricelli", " Massimo Volpe"],
				"body": "Slide 1. Slide 1. Blood Pressure Control: Dependence on Adherence Slide 2. Slide 2. Faculty Slide 3. Slide 3. Program Overview Slide 4. Slide 4. The Importance of BP Reduction [1] There is clear evidence that hypertension treatment is important Slide 5. Slide 5. BP Is Not Adequately Controlled [2-4] Claudio Cricelli, MD, PhD When we started measuring hypertension treatment outcomes 20-25 years ago, the results were quite uncertain In 2000-2002, we assumed that no more than 25%-30% of people would have blood pressure (BP) under control In my area in Italy, we select small groups of motivated general practitioners to participate in educational programs, and we have adherence rates of up to 70% Slide 6. Slide 6. Adherence Is a Cornerstone of BP Control [5,6] One of the cornerstones of BP control is to improve adherence to treatment, and we now have some advantages compared with the past The patient is a partner in BP control We also need to work with the media and regulatory authorities Slide 7. Slide 7. High Adherence Lowers the Risk for CV Events [7-9] It does not take a long time to evaluate adherence, but data from several thousand patients are needed Slide 8. Slide 8. Adherence: The Role of PCPs [10] Primary care physicians (PCPs) have a large number patients and a short time for each visit It can be difficult to discuss the disease with the patient and to convince them to be more adherent Achieving 100% adherence is very difficult, but specialists should work with PCPs to overcome this barrier and control BP Slide 9. Slide 9. Adherence Varies According to Drug Class [11] Within each class, there are short-acting and long-acting compounds To promote good adherence, it is important to reduce the number of pills and the number of doses Once-a-day compounds are preferable for improving adherence Slide 10. Slide 10. Pill Burden and Adherence [12,13] In primary care, our patients usually do not have just one problem; they have several Fewer pills increase and foster better adherence; too many pills may actually confuse patients Pill boxes are useful because they allow you to organize the therapy and to count the pills; if one of the boxes is still filled with pills, this shows that there is no adherence Slide 11. Slide 11. FDCs [14,15] Massimo Volpe, MD, PhD Antihypertensive therapy is very frequently the one that is sacrificed by the patient when they decide what to take and what not to take They may be more scared to drop, for instance, antiplatelet or antidiabetic therapy We have developed a platform to help the physician to make the treatment decision very easily and help the patient with pill boxes, packaging, etc Slide 12. Slide 12. Effect of FDCs on BP [16] Olmesartan and other long-lasting angiotensin II receptor blockers (ARBs) provide a great opportunity for us to reduce the number of pills and to improve BP control Slide 13. Slide 13. Effect of FDCs on Adherence [17] Dr Cricelli: I participated in the study (Levi and colleagues, 2016) In Italy, there has been strong opposition for many years to the use of FDC; many people believed it was dangerous We wanted to support the idea that giving an FDC would demonstrate a great improvement in patient adherence Slide 14. Slide 14. Effect of FDCs on Adherence (cont) [17] Slide 15. Slide 15. Effect of FDCs on Adherence (cont) [17] The 2 patient cohorts were informed and educated in the same way; the only difference between them was the number of pills Slide 16. Slide 16. Other Benefits of FDCs [16,18-20] It is difficult for patients to reduce the dosage of an FDC -- to take half or a quarter of a pill Slide 17. Slide 17. Healthcare Costs Associated With FDCs [20] FDCs have a role in reducing healthcare costs Slide 18. Slide 18. Which Patients Are Best Suited to FDCs? [21] PCPs should try to prescribe simplified antihypertensive therapy for patients with multiple comorbidities Unfortunately, this is often not easy in clinical practice because of a lack of resources or constraints by regulators and healthcare systems Slide 19. Slide 19. How Can We Improve Adherence to Antihypertensive Medications? [6,19] The message for doctors and patients is the importance of treating hypertension because hypertension kills people Slide 20. Slide 20. How Can We Improve Adherence to Antihypertensive Medications? (cont) [6] Some patients have a very complicated life, so we need to take that into account Slide 21. Slide 21. Summary Slide 22. Slide 22. Thank You ",
				"clientUrl": "/viewarticle/870248",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 281,
				"leadConcept": "Hypertension",
				"concept": ["Adherence", "Cardiovascular Risk Management", "Polypharmacy", "Patient Pharmaceutical Care Management", "Angiotensin II Receptor Blockade", "Antihypertensive Agents"],
				"leadSpecialtyId": 2,
				"leadSpecialty": "Cardiology",
				"allSpecialties": ["Cardiology", "Internal Medicine", "Family Medicine/Primary Care", "Nephrology"],
				"origContentType": "Roundtable",
				"contentType": ["Article/Courses"],
				"description": "Join Dr Schmieder and colleagues as they discuss the role of adherence to antihypertensive medication in achieving blood pressure control.",
				"legacyID": 870248,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Blood Pressure Control: Dependence on Adherence",
				"suppressComment": "T",
				"creditsAvailable": ["Non-US Physicians:CPD:0.50", "Physicians:AMA PRA Category 1 Credit(s)™:0.50"],
				"maxCredits": [0.5],
				"multimedia": ["/thumbnail_library/870248.jpg"],
				"publicationDate": 1477285200000,
				"postingDate": 1477285200000,
				"_version_": 1573508884271726592,
				"last_index_date": 1500615009569
			}, {
				"id": "pdctm_0901c79180b20727",
				"activeCME": 1,
				"activityExpirationDate": 1521781200000,
				"authors": ["News Author: Diana Swift", "  CME Author: Laurie Barclay"],
				"body": "Clinical Context In collaboration with the Bright Futures Periodicity Schedule Workgroup, the American Academy of Pediatrics (AAP) developed and approved its 2017 Recommendations for Preventive Pediatric Health Care. The AAP continues to mandate continuity of care, and avoidance of care fragmentation, in comprehensive health supervision. To reflect the most recent recommendations, the AAP plans to review and revise this Periodicity Schedule annually. The recommendations target children with competent parenting, without symptoms or signs of any important health problems, and with satisfactory growth and development. Children and adolescents with developmental, psychosocial, and chronic disease issues, and those with variations from normal, may need frequent counseling and treatment visits in addition to preventive care visits. Synopsis and Perspective The AAP has issued updated screening and assessment recommendations for children's preventive healthcare. Published online in Pediatrics , [1] the 2017 policy statement contains changes to 11 areas of care relative to the 2016 revision of the Bright Futures Periodicity Schedule. Some of the changes were implemented to make AAP guidelines, which cover care form birth to age 21 years, consistent with those of other national health promotion organizations. Led by Joseph F. Hagan Jr, MD, a pediatrician based in Burlington, Vermont, the periodicity schedule workgroup continues to stress that the AAP recommendations target children who are being raised in the context of \"competent parenting,\" who show no signs of serious health problems, and who are developing satisfactorily. \"Developmental, psychosocial, and chronic disease issues for children and adolescents may require frequent counseling and treatment visits separate from preventive care visits,\" they caution, adding that unusual family circumstances may necessitate additional visits. The AAP also continued to emphasize the need for \"unfragmented continuity of care\" in comprehensive health supervision. The recommendations further stress the need for pediatricians to verify whether, in fact, a child has had all necessary tests and, if not, to follow up quickly and appropriately. Changes to the 2017 schedule includes changes to the following care areas: Depression: Screening for adolescents should begin at age 12 years, as recommended by the US Preventive Services Task Force (USPSTF). In addition, physicians should ask about maternal depression at infants' 1-, 2-, 4-, and 6-month medical visits. \"The background rate of maternal depression is 1 in 6, and fathers get depressed, too,\" Dr Hagan told Medscape Medical News . If depression is present, referral to appropriate care should be made immediately. Psychosocial-behavioral: This update underscores that assessment should be family centered and, in addition to a child's social and emotional health, may include evaluation of caregivers and social determinants of health in the child's milieu. HIV: Universal screening for HIV should occur once between ages 15 and 18 years, which brings the AAP recommendation into line with USPSTF guidelines. \"The AAP's recommendations follow available evidence, and over the past several years there's finally been more evidence work by the USPSTF and others on what are the appropriate screening tools for children,\" Dr Hagan said. \"At the time of the first edition of Bright Futures in 2008, there were only two USPSTF statements that had to do with evidence on kids, and now there probably are 15 or 20.\" Sexually transmitted infections (STIs): Adolescents should be screened for these in accordance with the recommendations in the AAP's current Red Book: Report of the Committee on Infectious Diseases. [2] Hearing: The schedule now outlines the timing and follow-up for screening all infants for congenital deafness and hearing problems, stressing early verification of testing and follow-up as needed. Although these tests are usually performed in hospital programs, Dr Hagan said, \"[we] wanted to make sure that testing didn't slide through the cracks on the assumption it had already been done at the hospital.\" He added, \"There needs to be a plan if this testing failed or if it needs to be acted upon or if retesting is required.\" For adolescents, the recommendation has changed to auditory screening once during each of early, middle, and late adolescence, at ages 11 to 14 years, 15 to 17 years, and 18 to 21 years. Because impairment in this age group is usually high-frequency hearing loss related to loud noise exposure, adolescents should be tested with an audiometer at 6000 to 8000 decibels. \"Recent research has shown that you're not going to find anything if you only screen to 4000, but you will pick up something if you screen to 6000 and 8000,\" Dr Hagan said. Newborn blood and bilirubin: A new recommendation calls for routine 1-time bilirubin concentration screening at the neonatal visit, again with emphasis on test verification and follow-up. The timing and follow-up for neonatal blood testing have been detailed. Dyslipidemia: The update calls for screening once between ages 9 and 11 years, and once between ages 17 and 21 years, which is consistent with the guidelines of the National Heart, Lung, and Blood Institute. Oral health: Pediatricians should assess oral health at the 12- and 18-month visits and through visits to age 6 years, or until a child has a regular dental home. Another new addition, based on USPSTF evidence, is the recommended use of a dental varnish beginning at the eruption of the first tooth and then every 3 to 6 months until a child has a dental home or reaches age 5 years. The full 2017 schedule can be found the AAP's website. [3] The authors have disclosed no relevant financial relationships. Pediatrics . Published online February 16, 2017. Recommendation Highlights Updates to the 2016 Periodicity Schedule include hearing, behavioral, substance use, depression, maternal depression, newborn blood and bilirubin, STIs, HIV, dyslipidemia, and oral health screening. Clinicians should confirm whether a child has had all recommended tests and should follow up quickly and appropriately to perform missing tests and to intervene appropriately based on the results. All newborns should undergo hearing screening. Timing, criteria, and follow-up of newborn blood screening are based on the Secretary's Advisory Committee on Heritable Disorders in Newborns and Children and on state newborn screening laws and regulations. At the newborn visit, clinicians should screen for bilirubin concentration. Clinicians should screen for maternal depression at 1-, 2-, 4-, and 6-month visits and refer for intervention if indicated. Evaluation for a dental home should occur at the 12-month and 18-month visits through 6-year visits, with referral if there is none. Fluoride should be assessed from the 6- to 12-month visits and 18-month through 16-year visits, and oral supplementation with fluoride should be considered if the primary water source is deficient in fluoride. Adolescent risk assessment for hearing should occur once during each period. Audiometry including 6000-Hz and 8000-Hz high frequencies should be performed once each between ages 11 to 14 years, 15 to 17 years, and 18 to 21 years. Psychosocial/behavioral evaluation should be family centered and may involve examination of child social emotional health, caregiver depression, and social determinants of health. Substance abuse assessment should include a history of tobacco, alcohol, or drug use. Per USPSTF recommendations, routine adolescent depression screening should begin at age 12 years. Adolescent STI screening should follow recommendations in the current AAP Red Book: Report of the Committee on Infectious Diseases . To avoid confusion with selective screening recommendations for STIs, there is now a subheading for the HIV universal screening recommendation, to occur once between ages 15 and 18 years, per USPSTF recommendations, while preserving adolescent confidentiality. Adolescents who are sexually active, use injection drugs, or are being tested for other STIs are at higher risk and should be tested for HIV and reassessed annually. Dyslipidemia screening should occur once between ages 9 and 11 years and once again between ages 17 and 21 years, following National Heart, Lung, and Blood Institute guidelines. Clinical Implications At the newborn visit, clinicians should screen for bilirubin concentration and hearing, according to the AAP 2017 Recommendations for Preventive Pediatric Health Care (Periodicity Schedule). Adolescents should undergo audiometry testing including 6000-Hz and 8000-Hz high frequencies once each between ages 11 to 14 years, 15 to 17 years, and 18 to 21 years. Implications for the Healthcare Team: Clinicians should confirm whether a child has had all recommended tests and should follow up quickly and appropriately to perform missing tests and to intervene appropriately based on the results. CME Test 3 ",
				"clientUrl": "/viewarticle/877090",
				"creditType": ["CME", "Nurse CE", "Pharmacist CE", "ABIM MOC"],
				"cmeFlag": "CME / ABIM MOC / CE",
				"leadConceptId": 0,
				"concept": ["Sexually Transmitted Infection (STI)", "HIV Infection", "Growth and Development of Child", "Preventive Screening", "Preventive Medicine", "Pediatric Nursing", "Screening in Childhood", "Preventive Medicine and Screening Recommendations", "Clinical Guidelines", "Treatment Guidelines", "Adolescent Medicine", "HIV Prevention", "HIV Testing", "Sexually Transmitted Disease (STD) Prevention", "Public Health Nursing", "HIV Infection in Childhood", "Hearing Screening", "Newborn Screening", "Interprofessional Continuing Education"],
				"leadSpecialtyId": 9,
				"leadSpecialty": "Pediatrics",
				"allSpecialties": ["Pediatrics", "Medscape Today", "Nursing", "Pharmacist", "Family Medicine/Primary Care", "Public Health & Prevention"],
				"contentGroup": "Clinical Review",
				"origContentType": "Clinical Brief",
				"contentType": ["News"],
				"description": "The American Academy of Pediatrics has updated preventive screening recommendations, including hearing, behavioral, substance use, depression, newborn blood, sexually transmitted infections, and HIV.",
				"legacyID": 877090,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "AAP Releases Recommendations for Preventive Health Care",
				"suppressComment": "T",
				"creditsAvailable": ["PhysiciansFamily Physicians:AMA PRA Category 1 Credit(s)™AAFP Prescribed credit(s):0.25", "US Physicians:Points for ABIM MOC:0.25", "Nurses:ANCC Contact Hour(s):0.25", "Pharmacists:Knowledge-based ACPE:0.25", "Physicians:AMA PRA Category 1 Credit(s)™:0.25"],
				"maxCredits": [0.25],
				"publicationDate": 1490245200000,
				"postingDate": 1490245200000,
				"_version_": 1573508891824619520,
				"last_index_date": 1500615016769
			}, {
				"id": "pdctm_0901c79180bba959",
				"activeCME": 1,
				"activityExpirationDate": 1531458000000,
				"authors": ["News Author: Miriam E Tucker", " CME Author: Charles P. Vega"],
				"body": "Clinical Context Type 1 diabetes mellitus (T1DM) is associated with an increased risk for microvascular complications, including nephropathy and retinopathy. A previous study by Lebenthal and colleagues, published in the May-June 2012 issue of the Journal of Diabetes and Its Complications , [1] compared familial and sporadic T1DM in terms of the rate of complications. The mean age of study participants at the diagnosis of T1DM was 10.8 years, and they were followed for a mean period of 11.1 years. Familial T1DM was associated with worse HbA1c values compared with sporadic T1DM, and diabetic ketoacidosis was more common in familial cases. The cumulative rates of microvascular complications were 21.7% and 26.7% in the familial and sporadic T1DM groups, respectively, a nonsignificant difference. The most important risk factor for incident microvascular disease was the duration of T1DM, whereas HbA1c levels were better predictors of diabetic ketoacidosis. Beyond end-organ damage, T1DM may result in worse health-related quality of life (HRQOL). The current study explores variables associated with worse HRQOL among youth with T1DM. Study Synopsis and Perspective Diabetes-specific health-related quality of life is closely linked to glucose control in youth with T1DM, new international research suggests. That strong association and its potential mitigation by factors associated with better glycemic control point to opportunities for proactive intervention among vulnerable children, teenagers, and young adults, according to Barbara J. Anderson, PhD, professor of pediatrics at Baylor College of Medicine, Houston, Texas, and colleagues in their paper published online May 25 in Diabetes Care . [2] The data come from the global, observational, cross-sectional TEENs study of 5887 participants with T1DM aged 8 to 25 years from 20 countries in five continents and 219 centers worldwide. The relationship between HbA1cand diabetes-specific health-related quality of life (D-HRQOL) was consistent around the world, Dr Anderson told Medscape Medical News . \"It's a bidirectional relationship. They're so closely related it doesn't really matter which came first,\" in terms of intervention, she noted. The findings suggest it is important to ask about quality-of-life issues and to refer patients and families to mental health specialists when necessary. In particular, clinicians should be sure patients and their families understand that T1DM is difficult to control, and they should not expect perfect blood sugars all the time. \"The medical community often forgets to tell people that at diagnosis.... Families leave the hospital thinking if they do all the things they're told, they're going to get stable blood sugars,\" Dr Anderson commented. Females, Young Adults at High Risk In the study, the proportions of subjects achieving age-appropriate HbA1c targets were just 31.9% of 8- to 12-year-olds, 29.1% of 13- to 18-year-olds, and 18.4% of the young adult (19- to 25-year-old) group. The 19- to 25-year-old group reported lower scores on the 100-point D-HRQOL scale compared with the younger 2 age groups. And across all ages, the females reported lower D-HRQOL than did the males ( P  < .001; all were reported by the youths themselves, not their parents). Overall, D-HRQOL was significantly and inversely related to HbA1c: The lower the HbA1c, the better the D-HRQOL, with scores of 71.5, 68.4, and 64.8 for HbA1c values lower than 7.5%, 7.5% to 9%, and higher than 9%, respectively. Sex differences in quality-of-life reporting are consistent across different chronic medical conditions, and even among healthy young people, Dr Anderson pointed out. \"Girls consistently report lower quality of life than boys do. I think it speaks to the difficulty of being an adolescent female and all the things they're forced to deal with at that age that boys aren't.\" With diabetes, she added, females may be more prone to viewing themselves as \"damaged\" and attempt to hide or ignore their condition. Moreover, hormonal changes during puberty may affect blood glucose levels in females more than in males. Given all that, \"Maybe we should be proactive and put resources into interventions for young females that might pay off later in terms of quality of life and glycemic outcomes,\" she suggested. The findings of worse quality of life and glycemic control in the young adult age group is a major concern, she said, given that this group can fall through the cracks as they transition from pediatric to adult care. The handling of that situation is highly variable around the country. Some pediatric centers will keep patients into their early 20s and provide transition assistance, whereas others strictly cut people off when they turn 18 years old. In any case, that group also merits heightened attention, she said. Family Conflict Predicts Risk Among all the age groups, family conflict appeared to be very common and to underlie diminished D-HRQOL. Overall, 46% of the participants reported experiencing family conflict over monitoring blood glucose, and 39% over giving insulin. \"[T]he presence of diabetes-specific family conflict over blood glucose monitoring was significantly related to poorer D-HRQOL (P < 0.001),\" the authors write. \"Also, if a parent or participant had to reduce or stop working because of diabetes, the participant reported lower D-HRQOL ( P  < 0.001).\" \"We know that families play a large role in terms of diabetes management of young children and of teenagers. To find this in such a large global study was really important because family conflict is one of the potentially modifiable variables that we have as clinicians,\" Dr Anderson said. \"If my patient is from a single-parent family or their father is in jail, I can't change those things. But if there's a lot of family tension and conflict around diabetes, I know how to help people struggling with that.\" Specifically, she said, \"It's so easy to blame and shame a young person when they have a high number on the glucose meter, rather than to say, 'Isn't it great you checked your blood sugar? Now we know what to do about it.' Parents don't mean to do this, it's just that they're anxious.\" She advises physicians to simply ask families whether they are having arguments related to diabetes. \"I think the more we know this, the more we can try to be proactive.... We can say it's really important not to fight about blood glucose levels. They're not 100% under your child's control.\" Another important question is whether fear of hypoglycemia is leading the youngster to deliberately run blood sugars higher, a common problem. \"If we learn about these things, we can intervene,\" she noted. And if the problems seem beyond the physician's control, \"this might be the time to refer to a psychologist or social worker.\" Behaviors Associated With Better Control The study also identified 3 specific and potentially modifiable behaviors linked to better D-HRQOL: carbohydrate counting compared with avoiding simple sugars ( P  < .001), more frequent daily blood glucose monitoring (3-7 vs 0-2 days per week, P  < .001), and 30 minutes or more of daily physical activity ( P  < .001). Although access to test strips may be limited, even in wealthy countries, exercise and carb counting can always be advised, she noted. In 2012, when this study was performed, use of continuous glucose monitoring was quite low in all the regions studied, even in the United States and Western Europe. The recent uptick in use of continuous glucose monitoring as well as the newer closed-loop technologies may help improve T1DM control overall, but for teenagers, this can be a double-edged sword. \"Some teens won't wear the devices, and view them as part of the disease burden. This may be hard for physicians who are on the technology bandwagon, but as a psychologist, I can say that kids shouldn't be forced,\" Dr Anderson advised. Overall, \"this is pointing out that it isn't the insulin algorithm that controls glycemic outcomes, it's everything in the person's life.\" Funding for the TEENs study was provided by Sanofi Diabetes. Dr Anderson reports participation in advisory boards for Sanofi, research support from the National Institutes of Health, JDRF, the Leona M. and Harry B. Helmsley Charitable Trust, and consultancy for Sanofi. Disclosures for the coauthors are listed in the paper. Diabetes Care . Published online May 25, 2017. Study Highlights Study participants were between the ages of 8 and 25 years and had T1DM diagnosed before 18 years of age. All participants had T1DM of at least 1 year in duration and had experienced no change in their insulin dose in the last 3 months. HRQOL was measured using the PedsQL Diabetes module. The 5 subscales on the measure included diabetes symptoms, treatment barriers, treatment adherence, concern for hypoglycemia, and communication problems around diabetes. Researchers also recorded demographic data along with data regarding glycemic control, diabetes self-management behaviors, and family issues in the approach to diabetes management. The main study outcome was the potential relationship between these factors and diabetes-related HRQOL. 5887 children and adolescents from more than 20 countries provided data for the study. There were similar numbers of males and females in the research cohort, which was three-fourths white. Researchers divided the cohort into 3 groups, based on age: 8 to 12, 13 to 18, and 19 to 25 years old. 18%, 11%, and 9% of participants and/or parents in the 8- to 12-, 13- to 18-, and 19- to 25-year-old groups reported cutting back or stopping work because of diabetes. 46% of youth described family conflict about glucose monitoring, and 39% reported family conflict about the administration of insulin. Less than 30% of participants had achieved their HbA1c goal. The 19- to 25-year-old age group reported worse HRQOL compared with the younger age groups. Females reported lower HRQOL overall compared with males. Lower HbA1c and higher levels of parental education attainment was associated with improved HRQOL. Family conflict related to glucose self-monitoring was also associated with lower HRQOL. Improved diabetes self-management behaviors, including better diet, higher levels of exercise, and more frequent home glucose monitoring, were associated with improved HRQOL. Clinical Implications A previous study found that the rates of microvascular complications were 21.7% and 26.7% among young people with familial and sporadic T1DM, respectively, a nonsignificant difference. The most important risk factor for incident microvascular disease was the duration of T1DM. Variables associated with worse HRQOL in the current study of young people with T1DM included female sex, age 19 to 25 years, higher HbA1c levels, family conflict related to glucose self-monitoring, and worse diabetes self-management behaviors. Implications for the Healthcare Team: The healthcare team should be familiar with variables associated with worse HRQOL among youth with T1DM. Lower levels of HRQOL may reinforce negative care behaviors, creating a vicious cycle. CME Test 3 ",
				"clientUrl": "/viewarticle/882684",
				"creditType": ["CME", "Nurse CE", "Pharmacist CE", "ABIM MOC"],
				"cmeFlag": "CME / ABIM MOC / CE",
				"leadConceptId": 1068,
				"leadConcept": "Type 1 Diabetes Mellitus",
				"concept": ["Pediatric Nursing", "Adolescent Medicine", "Diabetic Microvascular Complications"],
				"leadSpecialtyId": 22,
				"leadSpecialty": "Diabetes & Endocrinology",
				"allSpecialties": ["Diabetes & Endocrinology", "Pediatrics", "Psychiatry", "Ob/Gyn & Women's Health", "Medscape Today", "Internal Medicine", "Nursing", "Pharmacist", "Family Medicine/Primary Care", "Allergy & Clinical Immunology", "Public Health & Prevention"],
				"contentGroup": "Clinical Review",
				"origContentType": "Clinical Brief",
				"contentType": ["News"],
				"description": "New study describes variables associated with worse health-related quality of life among youth with type 1 diabetes mellitus.",
				"legacyID": 882684,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Can Improved Quality of Life Improve Glucose Control in T1DM?",
				"suppressComment": "T",
				"creditsAvailable": ["PhysiciansFamily Physicians:AMA PRA Category 1 Credit(s)™AAFP Prescribed credit(s):0.25", "US Physicians:Points for ABIM MOC:0.25", "Nurses:ANCC Contact Hour(s):0.25", "Pharmacists:Knowledge-based ACPE:0.25", "Physicians:AMA PRA Category 1 Credit(s)™:0.25"],
				"maxCredits": [0.25],
				"publicationDate": 1499922000000,
				"postingDate": 1499922000000,
				"_version_": 1573508898097201152,
				"last_index_date": 1500615022750
			}, {
				"id": "pdctm_0901c79180b905b8",
				"activeCME": 1,
				"activityExpirationDate": 1529038800000,
				"authors": ["Sylvain A. Lother", " Walter Demczuk", " Irene Martin", " Michael Mulvey", " Brenden Dufault", " Philippe Lagacé-Wiens", " Yoav Keynan"],
				"body": "Abstract and Introduction Abstract and Introduction Abstract The incidence of group C and G Streptococcus (GCGS) bacteremia, which is associated with severe disease and death, is increasing. We characterized clinical features, outcomes, and genetic determinants of GCGS bacteremia for 89 patients in Winnipeg, Manitoba, Canada, who had GCGS bacteremia during 2012–2014. Of the 89 patients, 51% had bacteremia from skin and soft tissue, 70% had severe disease features, and 20% died. Whole-genome sequencing analysis was performed on isolates derived from 89 blood samples and 33 respiratory sample controls: 5 closely related genetic lineages were identified as being more likely to cause invasive disease than non-clade isolates (83% vs. 57%, p = 0.002). Virulence factors cbp , fbp , speG , sicG , gfbA , and bca clustered clonally into these clades. A clonal distribution of virulence factors may account for severe and fatal cases of bacteremia caused by invasive GCGS. Introduction Group C and G Streptococcus (GCGS) are quickly becoming a major public health concern as the incidence of invasive infection and severe disease is increasing. [1–6] In Manitoba, Canada, the incidence of GCGS bacteremia continues to increase, whereas the incidence of other invasive β-hemolytic streptococcal infections remains constant, [1] similar to trends observed in Finland, Denmark, and Israel. [3–5,7] These invasive infections cause severe illness, and up to 25% of patients die, [2,3,7–9] yet the factors contributing to disease severity and death remain unclear. Streptococcus dysgalactiae subsp. equisimilis (SDSE) is responsible for most cases of GCGS infections in humans. [10,11] Historically considered nonpathogenic commensal flora, SDSE is now implicated in skin and soft tissue infections, pharyngitis, bacteremia, endocarditis, sepsis, toxic shock, and other invasive infections [3,5,9,12–14] that extensively overlap with the clinical presentations of S . pyogenes (group A Streptococcus [GAS]) infections. Similar to S . pyogenes , SDSE form large β-hemolytic colonies on sheep blood agar with hyaluronic acid capsules but express Lancefield group C or G carbohydrate [15] and possess M protein, which is vital in inhibiting complement pathway activation and resisting phagocytic killing. [16] SDSE is genetically closely related to S . pyogenes , sharing 61%–72% sequence homology. [11,17] These pathogens can exchange genes through bacterial phages and other mechanisms. [11] Approximately 71 virulence factor genes from S . pyogenes have been identified in SDSE, including hemolysin, streptolysin, exotoxin, proteinase, adhesin, streptokinase, and hyaluronic acid genes. [11,18] S . pyogenes and SDSE carry streptolysin O ( slo ), which is required for invasive human infection, [11,19] and streptolysin S ( sagA ), which has been linked to necrotizing soft tissue infections. [20] Furthermore, the superantigen alleles speA , C , G , H , I , K , L , M , N , O , and P , which have been identified in S . pyogenes , have infrequently been identified in SDSE, but speJ and ssa are unique to GAS, and szeN , szeP , and szeF are unique to GCGS. [21] The only commonly reported superantigen of SDSE is speG . [11,22,23] Other commonly found virulence factors in SDSE are lmb , gapC , sagA , hylB , slo , scpA , and ska , whereas the presence of cbp , fbp , and sicG is variable and found only in a minority of strains. [22] A conclusive association between virulence profile and disease propensity or site of isolation has not been demonstrated. [18,22,24] The monitoring of emerging pathogens requires phenotypic and molecular-based typing methodologies. Multilocus sequence typing (MLST) can be useful in tracking short-chain transmission of infections, but application of whole-genome sequencing for comparative studies provides higher resolution through a genomic epidemiology approach to investigate strain relatedness and dynamics. To uncover factors that may contribute to increased GCGS pathogenesis, we describe the clinical features of 89 GCGS bloodstream infections and the distribution of sequence types (STs) and virulence factors by whole-genome sequencing of 122 invasive and noninvasive isolates. We conducted this study in accordance with the ethical principles at the University of Manitoba after obtaining approval from the Health Research Ethics Board and Research Impact Committee. Materials and Methods Materials and Methods Using the records of 2 large laboratories, we retrospectively identified GCGS bacteremia cases that occurred during January 2012–December 2014 in Winnipeg, Manitoba, Canada. We identified 89 bacteremic events (defined as ≥1 blood culture positive for GCGS during a single hospital admission) among a total of 84 patients. We reviewed charts to obtain patient characteristics and clinical parameters for each bacteremic event. During September–December 2014, within the same geographic location as the study cohort, community physicians collected control pharyngeal swab samples from outpatients with signs or symptoms of pharyngitis. The samples, which were obtained at the physicians’ discretion, were cultured for identification of pyogenic streptococci: 33 noninvasive GCGS isolates were detected. These GCGS isolates were recovered from patients with symptomatic pharyngitis, but their symptoms were not severe and not necessarily attributable to GCGS. Although these control isolates were not from asymptomatic volunteers, the clinical differences between invasive blood stream isolates and noninvasive respiratory isolates was sufficient to compare genetic differences. Disease Severity We considered patients with ≥1 of the following to have severe GCGS disease: in-hospital death, admission to intensive care unit, need for vasopressor or ventilatory support, diagnosis of streptococcal toxic shock syndrome (STSS) or infectious endocarditis, or a high-risk Simple Clinical Score ≥8 or Rapid Emergency Medicine Score ≥10. We defined STSS according to guidelines of the Working Group on Severe Streptococcal Infections. [25] We calculated Simple Clinical Scores and Rapid Emergency Medicine Scores primarily by using patient vital signs and other clinical features; high-risk scores are associated with a 9.0%–10.3% risk for death by 30 days after admission. [26–28] Collection and Identification of Bacteria At the discretion of the healthcare provider, patient blood samples were collected at symptom onset into BacT/Alert bottles (bioMérieux, Saint-Laurent, QC, Canada) according to institutional protocol and incubated using the BacT/Alert blood culture instrument (bioMérieux). Isolates were stored in frozen stocks in skim milk at −70°C and later retrieved by subculture for further analysis. A total of 92 GCGS isolates were recorded during the study period; 90 were retrieved, 2 were lost in storage, and 1 was identified as S. equi subsp. zooepidemicus by 16S rRNA sequence similarity and excluded from the study. We plated the 89 remaining isolates onto sheep blood agar (Oxoid, Nepean, ON, Canada) and aerobically incubated them for 24 h at 37°C in the presence of 5% CO 2 . We confirmed isolate identification by using MALDI-TOF (matrix-assisted laser desorption/ionization time-of-flight) mass spectrometry with the MALDI BioTyper system (Bruker, Boston, MA, USA) according to the manufacturer’s protocol. To confirm isolates with ambiguous MALDI-TOF mass spectrometry identifications, we used latex agglutination to Lancefield antigens C and G and the Vitek2 system (bioMérieux) for biochemical identification. All isolates were identified as S. dysgalactiae . Whole-Genome Sequencing We extracted DNA from cultures, created multiplexed libraries, assembled reads, and performed core nucleotide variation phylogenetic analyses ( Technical Appendix 1 ). In brief, we generated paired-end, 300-bp indexed reads on the Illumina MiSeq platform (Illumina, San Diego, CA, USA); the average yield was 1,015,107 reads/genome, and the average genomic coverage was 145×. Read quality was assessed by using FastQC version 0.11.4 (), assembled with SPAdes version 3.6.2 (), and annotated with Prokka version 1.11 (), yielding an average contig length of 39,313 bp and an average N50 contig length of 82,867 bp. [29–31] The high-quality reads were then mapped to the publically available reference genome, S. dysgalactiae subsp. equisimilis AC-2713 (GenBank accession no. NC_019042.1), by using SMALT version 0.7.5 (). Single-nucleotide variations (SNVs) were called using FreeBayes version 0.9.20 () and SAMtools mpileup (). [32] The percentage of bases in the core was 82.8%, and 21,746 sites were used to generate the phylogeny. We constructed a maximum-likelihood phylogenetic tree of informative SNV positions by using PhyML version 3.0 () [33] and visualized the tree by using FigTree version 1.4.1 (). [34] We determined phylogenetic clades by cluster analysis on the full dataset of blood and respiratory isolates (n = 122) and on isolates from blood only (n = 89) by using ClusterPicker version 1.2.4 () with the following settings: initial and main support thresholds = 0.9, genetic distance threshold = 4.5, and the large cluster threshold = 10. [34] We submitted whole-genome sequencing read data to the NCBI Sequence Read Archive () under BioProject accession number PRJNA325743. Molecular Typing We used the whole-genome sequencing data for in silico determination of MLST STs; virulence factors ( lmb , gapC , cba , cbp , fbp , sagA , slo , hylB , spegg , sicG , fbsA , pavA , fnbA , fnbB , gfbA , scpA , scpB , bca , cylE , ska , skc and skg ); [22,35] and superantigens ( speA , speB , speC , speF , spegg , speH , speI , speJ , speL , mf - 2 , mf - 3 , and smeZ ). [21,23] We determined Lancefield serogroups from sequences annotated with Prokka and confirmed them by serologic testing using commercial latex antisera (SSI Diagnostica, Hillerød, Denmark). We submitted MLST allelic profiles to the Streptococcus dysgalactiae MLST database (). We used allelic profiles to compute a goeBURST (global optimal eBurst; ) full minimum spanning tree using PHYLOViZ (); [36] groups were assigned by a single-locus variation from a founding ST. All strains were confirmed to belong to S . dysgalactiae subsp. equisimilis by BLASTn [37] alignment of 16S rRNA sequences to reference genomes of S . dysgalactiae subsp. dysgalactiae ATCC27957 and S . dysgalactiae subsp. equisimilis ATCC12394 (PubMed accession nos. NZ_CM001076.1 and NC_017567.1, respectively). Statistical Methods We used descriptive statistics, χ 2 test, Kruskal-Wallis test, and Fisher exact test to compare demographics between clusters of SDSE to determine whether they differed with respect to key risk factors. We used Fisher exact test to compare risk of death and other disease severity markers between ST clusters and clades. No observations were censored, so survival analysis techniques were not necessary. Results Results Patient Characteristics and Disease Severity We investigated 89 GCGS bacteremic events in 84 patients in Winnipeg during 2012–2014. Most patients (63%) were male, and the mean age was 61 years (SD ± 18.4 years). Many patients had co-existing conditions, predominantly cardiovascular disease (47%) and diabetes mellitus (43%). The most common source of bacteremia was from skin and soft tissue infections (51%), and 37% of patients had primary bacteremia. Infectious endocarditis was confirmed or suspected in 7% of patients. No patients had necrotizing fasciitis or pharyngitis ( Table 1 ). Figure 1. Maximum-likelihood whole-genome, core single-nucleotide variation (SNV) phylogenetic tree of 89 Streptococcus dysgalactiae subsp. equisimilis isolates from the blood of patients with group C and G Streptococcus causing severe infections, Winnipeg, Manitoba, Canada, 2012–2014. Multilocus sequence typing clonal complex relatedness groups were determined by using goeBURST (global optimal eBurst; ). In the mortality column, red and white squares indicate patient death and survival, respectively. In the severity column, red and white squares represent manifestation of severe and nonsevere disease, respectively. Black and white squares indicate the presence and absence of virulence factor genes, respectively. Scale bar indicates estimated evolutionary divergence between isolates, based on the average genetic distance between strains (estimated substitutions in sample/total high-quality SNVs). ICU, intensive care unit; IE, infectious endocarditis; MLST, multilocus sequence type; STSS, streptococcal toxic shock syndrome; SG, serogroup; ST, MLST; Y, year; M, mortality; S, severity; 1, cbp ; 2, fbp ; 3, speG ; 4, sicG ; 5, gfbA ; 6, bca . In 70% of the cases, bacteremia was associated with markers of severe disease, including admission to an intensive care unit (26%) and the need for vasopressor (19%) or ventilatory (17%) support. Seventeen percent of patients had a diagnosis of STSS, and 35%–61% of patients had high-risk disease severity scores. Twenty percent of patients with GCGS bacteremia died while in the hospital ( Table 2 ). SDSE Isolate Characteristics SDSE isolates from blood represented 89 (73%) of 122 total isolates; 33 (37%) of the 89 isolates were from female patients and 56 (63%) were from male patients. These isolates were classified as Lancefield groups G (63%) and C (37%). Respiratory isolates represented 27% (33/122) of the isolates; information regarding the number from female and male patients was not available. These isolates also were classified as Lancefield groups G (52%) and C (48%). Core Single-Nucleotide Variation Phylogenetic Analysis Phylogenetic analysis of all 122 isolates showed no association between infection type and patient sex, age, or disease severity ( Technical Appendix 1 Figure ). Compared with the heterogeneous nonclade isolates, those that clustered into clades A–E represented a higher proportion of blood isolates (25/45 [57%] vs. 64/77 [83%], respectively; p = 0.002). In addition, compared with the other clades combined, clade A was represented by significantly fewer blood isolates (36/38 [95%] vs. 28/39 [72%], respectively; p = 0.017). In silico molecular determinants (MLST, Lancefield serogroups, and virulence factors) were clustered in a clonal distribution ( Technical Appendix 1 Figure ). However, we found no significant associations when comparing blood and respiratory isolates. Figure 2. Minimum spanning tree representing the genetic relatedness of multilocus sequence types (MLSTs) of Streptococcus dysgalactiae subsp. equisimilis isolates from patients with group C and G Streptococcus causing severe infections, Winnipeg, Manitoba, Canada, 2012–2014. Genetic relatedness was determined by full goeBURST (global optimal eBurst; ) analysis using Streptococcus dysgalactiae MLST allelic profiles of 7 housekeeping genes. Numbers on nodes correspond to individual sequence types (STs) and colored nodes correspond to clonal cluster relatedness groups defined by a single-locus variation from a founding ST. Number labels on branches indicate the number of allelic variations between STs; branch lengths are not to scale. Cluster analysis of the 89 blood isolates yielded 5 clades, A–E (n = 64); the other 25 heterogeneous isolates were outside these lineages. Clade A isolates were Lancefield serogroup C, clades B–E were serogroup G, and the heterogeneous nonclade isolates were serogroups C (n = 5) and G (n = 20) (Figure 1). Isolate numbers 35, 49, 26, 40, 47, 45, and 51 were most genetically distant from the other blood isolates, averaging 3,897–3,987 SNVs. The greatest difference was 5,110 SNVs between isolate numbers 30 and 51 ( Technical Appendix 2 ). Clade C was the most genetically homogenous, showing a maximum of 138 SNVs between isolates in the clade. Clade B was the most diverse, showing a maximum difference of 600 SNVs between isolates ( online Technical Appendix Table 1 ). MLST STs for all 122 isolates generally correlated with specific phylogenetic clades and subclades (Figure 1; Technical Appendix 1 Figure ). The most common STs were ST20 (n = 28), followed by ST17 (n = 16) and ST15 (n = 9) (Figure 2). Clade A (n = 28) consisted entirely of ST20 isolates belonging to a singleton MLST relatedness group. Clade B (n = 13) belonged to MLST clonal complex (CC) 2, in which ST15 (n = 9), ST69 (n = 1), and ST274 (n = 2) isolates grouped into subclades. An isolate with ST276 (a double-locus variant of ST15) also clustered into clade B. Clades C (n = 14) and D (n = 5) belonged to MLST CC1; clade C consisted of ST17 isolates, and clade D consisted of ST282 isolates. Clade E (n = 4) belonged to MLST CC3, in which ST63 (n = 2), ST52 (n = 1), and ST164 (n = 1) isolates grouped into subclades. Although SNV phylogenetic analysis showed that ST17 (clade C) and ST15 (clade B) isolates were closely related, large variations in MLST separated them into distinct clonal clusters (Figure 2). Figure 3. Prevalence of sequence types, as characterized by multilocus sequence typing, among blood and respiratory isolates of Streptococcus dysgalactiae subsp. equisimilis from patients with group C and G Streptococcus causing severe infections, Winnipeg, Manitoba, Canada, 2012–2014. A total of 18 STs were unique to blood isolates: STs 4, 8, 38, 44, 52, 59, 63, 84, 138, 154, 265, 269, 270, 274, 275, 276, 279, and 282. A total of 8 STs were unique to respiratory isolates: STs 49, 68, 206, 266, 273, 277, 280, and 283 (Figure 3). Invasive Polymicrobial InfectionsInvasive Polymicrobial Infections Polymicrobial bacteremia with organisms other than GCGS alone was present in 18% (16/89) of patients. In 4 patients with non-GCGS organisms plus GCGS isolates (i.e., isolate nos. 3 and 57, which clustered in clade B; and nonclade nos. 12 and 74), the non-GCGS organisms were believed to represent 1) contaminants at the time of sample collection or 2) the nonprimary pathogen. Staphylococcus aureus co-infection was seen in 6 patients. Four patients had GCGS isolates that clustered into clade C (nos. 41, 70, 82, 85), and the isolates were all associated with severe disease features ( Technical Appendix 1 Table 2 ). Two of the 4 patients died. Distribution of Virulence Factors All 122 isolates carried virulence factors gapC , hylB , lmb , sagA , scpA , scpB , ska , skc , skg , and slo ; however, virulence factors cba , cfb , cylE , fbsA , fnbA , and pavA were universally absent. Other factors were variably present ( Table 3 ). Factors cbp , fbp , speG , sicG , gfbA , and bca clustered clonally into the phylogeny (Figure 1). All clade A and B isolates contained only speG , with the exception of 1 clade B isolate that also contained cbp , sicG , and gfbA . Clade C consisted of isolates with cbp , sicG , and gfbA ; clade D isolates had cbp , fbp , and sicG ; and clade E isolates had fbp , speG , and sicG . The virulence factor fbp was present in clades D and E and in 1 nonclade isolate (no. 28). Virulence factor bca was found variably in 5 nonclade isolates (nos. 49, 75, 74, 33, and 11) and in the reference isolate, AC-2713, which also contained genes speG and sicG . No association was discovered between the presence of these virulence factors and disease severity. Clinical Outcomes Within the Phylogeny Severe disease features were present in a similar proportion of patients with GCGS disease caused by clade A–E isolates (63%, 40/64 patients) and heterogeneous nonclade isolates (68%, 17/25 patients). There was an observed trend toward increased mortality in patients with isolates from clades A–E (14 deaths) compared with patients with nonclade isolates (4 deaths), although the difference was not statistically significant (p = 0.7698). The number of deaths resulting from GCGS bacteremia caused by the most common clades, A–C (13/55 [24%]), was not significantly different than the number caused by other clades (5/34 [15%]; p = 0.4179). The death rate was also higher among patients with ST15, ST20, and ST17 (26% [14/53 patients]) than among patients with other STs (11% [4/36 patients]), but the difference was not significant (p = 0.1075). Discussion Discussion Our findings from this large study of the genomic epidemiology and molecular determinants of invasive GCGS bacteremia in association with the clinical features and outcomes of disease contribute to an evolving understanding of the changing epidemiology of β-hemolytic streptococcal infections. Similar to the findings of others, [10] our findings showed that invasive infection is more common among older persons with underlying medical conditions. Although host factors probably contribute to changing epidemiology, enhanced GCGS virulence should be considered a contributor to the rising incidence GCGS bacteremia. We observed rates of severe disease (70%), ICU admission (26%), and toxic shock syndrome (17%) that were higher than those from previous reports, suggesting increased GCGS virulence, [8] Death occurred among 17 (20%) of the 84 patients with invasive GCGS bacteremia, a finding consistent with those in other reports, [7–10] As expected, skin and soft tissue infections served as the main portal of entry in more than half the cases of invasive GCGS bacteremia; however, primary bacteremia without alternate sources of infection was seen in a higher proportion (37%) of cases than seen in other reports, [3,5,14] Infections without a source of bacteria entry could represent more effective bacterial penetration of skin and mucosal barriers and evasion of the host immune response due to enhanced pathogenic mechanisms. Organisms in clades B–E were entirely Lancefield group G and had higher rates of invasive infections, possibly suggesting acquired genetic determinants are contributing to increased virulence and evolutionary selection of these clades. However, in this study, no single genetic determinant could account for an organism’s ability to cause invasive infection. Although respiratory tract isolates in our study served as noninvasive controls, they were collected from persons with symptomatic pharyngitis, in whom host defenses might prevent severe infection and invasion into the blood stream. Host defenses may have obscured recognition of a shared invasion factor that could not be detected in our comparisons. The virulence factor profiles we described were similar to those previously reported. [11,18,22,23,35] However, sicG was present in a substantially higher proportion of isolates in our study (38.5%) than in another study (9.0%), [18] and it was primarily within clades C–E. The gene for bca , which has only rarely been described in SDSE, was present in a minority of our isolates (9.0%). The superantigen speG gene was found to cluster in Lancefield groups C and G, belonging to clades A and B, respectively, and was present in a proportion of isolates similar to that described in other reports. [18,22] The reference isolate, AC-2713, also possessed all 3 of these virulence factors. All other superantigens found in GAS were absent from the isolates in our study. The toxin gene sagA was present in all invasive and noninvasive isolates in our study. Although this toxin has previously been implicated in necrotizing skin and soft tissue infections, [20] we did not confirm these findings in our study. No cases of necrotizing fasciitis were present in the study cohort; however, skin and soft tissue infections were common and severe, requiring surgical intervention in 17 (19%) of the 89 patients with bacteremia. A specific cluster within clade C organisms was associated with polymicrobial bacteremia with S . aureus . All 4 patients co-infected with S . aureus and clade C GCGS organisms had severe infections: 2 patients, 1 of whom died, required renal replacement therapy; 1 was an intravenous drug user with endocarditis; and 1 was a 60-year-old man with diabetes who sought medical care for STSS from an unknown source and subsequently died. All isolates had cbp , sicG , and gfbA virulence factors. Three of the 4 patients had risk factors for endovascular infection; however, the clustering of these organisms may suggest a synergistic effect of co-infection and invasion with S . aureus . Overall, the rising incidence and severity of invasive GCGS infections are probably associated with several evolving bacterial virulence factors. These factors probably take advantage of aging hosts with complex chronic diseases, susceptibilities, and co-existing conditions. Although our findings did not show a single virulence factor to account for emerging virulence, clonal clustering of factors within clades causing invasive infection suggests a survival and invasion advantage over clades without similar virulence clusters. Antimicrobial pressure may lead to accelerated transfer of genetic material, leading to acquisition of virulence factors. Furthermore, it is possible that newly acquired or novel virulence factors not previously described in other β-hemolytic streptococci are present. In conclusion, the frequency of invasive GCGS infections is surpassing that of GAS infections in patients in Manitoba, Canada, and these infections are associated with severe disease and death. Related strains that cluster clonally are more likely than others to cause invasive disease. The clonal distribution of virulence factors, in combination with host factors, is probably contributing to the emergence of invasive GCGS. ",
				"clientUrl": "/viewarticle/881216",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 3029299,
				"leadConcept": "Skin and Soft Tissue Infection",
				"concept": ["Bacteria", "Infectious Disease Diagnostics", "Streptococcal Infection", "Bacteremia"],
				"leadSpecialtyId": 3,
				"leadSpecialty": "Infectious Diseases",
				"allSpecialties": ["Infectious Diseases", "Internal Medicine", "Public Health & Prevention"],
				"contentGroup": "Journal Article",
				"origContentType": "Journal Article",
				"contentType": ["Journal Article"],
				"description": "Group C and G Streptococcus clonal clusters are more likely to cause invasive infection, creating an emerging public health burden because of increasing incidence and disease severity.",
				"legacyID": 881216,
				"pubDisplay": "Emerging Infectious Diseases CME",
				"siteOn": 2003,
				"title": "Clonal Clusters and Virulence Factors of Group C and G Streptococcus Causing Severe Infections, Manitoba, Canada, 2012–2014",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/EmergInfectDis-thumb.jpg"],
				"publicationDate": 1497502800000,
				"postingDate": 1497502800000,
				"_version_": 1573508881642946560,
				"last_index_date": 1500615007070
			}, {
				"id": "pdctm_0901c79180b64f1e",
				"activeCME": 1,
				"activityExpirationDate": 1526101200000,
				"authors": ["Patrick Urwin", " Kumar Thanigaikumar", " James W. Ironside", " Anna Molesworth", " Richard S. Knight", " Patricia E. Hewitt", " Charlotte A. Llewelyn", " Jan Mackenzie", " Robert G. Will"],
				"body": "Abstract and Introduction Abstract and Introduction Abstract Sporadic Creutzfeldt-Jakob disease (sCJD) has not been previously reported in patients with clotting disorders treated with fractionated plasma products. We report 2 cases of sCJD identified in the United Kingdom in patients with a history of extended treatment for clotting disorders; 1 patient had hemophilia B and the other von Willebrand disease. Both patients had been informed previously that they were at increased risk for variant CJD because of past treatment with fractionated plasma products sourced in the United Kingdom. However, both cases had clinical and investigative features suggestive of sCJD. This diagnosis was confirmed in both cases on neuropathologic and biochemical analysis of the brain. A causal link between the treatment with plasma products and the development of sCJD has not been established, and the occurrence of these cases may simply reflect a chance event in the context of systematic surveillance for CJD in large populations. Introduction Human prion diseases are a group of rare and fatal neurodegenerative diseases that include idiopathic (sporadic), genetic (inherited), and acquired (infectious) disorders. [1] All are associated with the accumulation of an abnormal isoform of the prion protein (PrP Sc ) in the central nervous system. [1] The most common human prion disease is the sporadic form of Creutzfeldt-Jakob disease (sCJD), which occurs worldwide with a relatively uniform incidence of 1–2 cases per million population per year, a peak incidence in the 7th decade of life, and a median duration of illness of 4 months. The relatively consistent mortality rates associated with sCJD, the overall random spatial and temporal distribution of cases, and the absence of any confirmed environmental risk factor have led to the hypothesis that sCJD occurs because of the spontaneous generation of PrP Sc in the brain. [1] In contrast, variant Creutzfeldt-Jakob disease (vCJD) is an acquired disorder that is most likely caused by the consumption of meat or meat products contaminated with the bovine spongiform encephalopathy agent. The median age at death in vCJD is 30 years, with a median duration of illness of 14 months. Most cases of vCJD have occurred in the United Kingdom, which has had the largest epizootic of bovine spongiform encephalopathy in the world. Of the 178 UK vCJD cases, 3 have been identified as cases of secondary transmission caused by the transfusion of nonleukodepleted red blood cell components from vCJD-infected blood donors. Lookback studies have shown no evidence of transmission through blood transfusion in sCJD, [2,3] despite the identification of PrP Sc in some peripheral tissues [4] and experimental evidence, which demonstrated infectivity in blood [5] by using intracerebral inoculation of highly sensitive transgenic mice. The absence of clinical cases causally linked to past treatment with fractionated plasma products has been used as evidence of the safety of these products in relation to sCJD. [6] These products are generally manufactured from the pooled plasma from several thousand donors; production using UK plasma was discontinued in 1999. We describe 2 cases of sCJD in patients who had previously received treatment with UK plasma–sourced plasma products; both patients had been informed that they were at increased risk for vCJD because of that treatment. The clinical features and investigations in these cases were typical of sCJD; the neuropathologic diagnosis in both cases was sCJD (subtype MM1). The Investigation The Investigation The UK National CJD Research and Surveillance Unit has been carrying out systematic epidemiologic study of CJD since 1990. The methodology of this study has been published previously. [7] In brief, patients with suspected CJD are referred by clinicians and visited by a research registrar, who obtains details of the clinical history and investigations, information on a range of possible risk factors, and past medical history. The Transfusion Medicine Epidemiology Review study investigates potential links between donors and recipients of labile blood components and, in cases of sCJD, investigates patients who have a history of blood donation or having received a blood transfusion. Coordinated surveillance of CJD has been undertaken in the European Union since 1993. [8] National surveillance programs for CJD also are in place in several other countries, including Australia, Canada, Japan, and the United States. Case 1 In 2014, a 64-year-old woman suffered a rapidly progressive dementia with deterioration in driving skills and balance disturbance, then limb coordination deficits with handwriting impairment. In the second month, her gait deteriorated, becoming shuffling and unsteady, she struggled to dress herself, and she had onset of daytime hypersomnolence. She became distractible, had visual misperceptions, emotional lability, and spatial memory problems. She was hospitalized at the beginning of the third month of her illness and had onset of cortical blindness, myoclonus, and akinetic mutism. She experienced rapid decline and died after a total illness duration of 3 months. An electroencephalogram performed during the final stages of illness showed background slowing and runs of periodic complexes, and a magnetic resonance imaging (MRI) brain scan showed high signal in the caudate heads with posterior cortical ribboning. A cerebral spinal fluid (CSF) 14–3–3 assay and real-time quaking-induced conversion test for PrP Sc both were positive. Prion protein gene ( PRNP ) sequencing showed no mutations with methionine homozygosity at codon 129. Postmortem examination of the brain showed widespread spongiform encephalopathy of predominantly microvacuolar type. Immunocytochemistry for prion protein gave a widespread positive reaction in a granular/synaptic pattern (Figure). No plaques or plaque-like structures were identified. Results of immunocytochemistry for disease-associated prion protein were negative in peripheral nerve, liver, lymph node, appendix, and spleen. Western blot analysis of frontal cortex and cerebellum confirmed the presence of protease-resistant prion protein with a type 1A isoform. Figure. Results of neuropathologic examinations of the brains of the 2 patients with sporadic Creutzfeldt-Jakob disease, United Kingdom, 2014. A) Microvacuolar spongiform change in the frontal cortex (case 1). Hematoxylin and eosin stain; original magnification ×400. B) Fine granular/synaptic accumulation of abnormal prion protein in the cerebral cortex (case 1). 12F10 antiprion protein antibody; original magnification ×400. C) Microvacuolar spongiform change with neuronal loss and gliosis in the frontal cortex (case 2). Hematoxylin and eosin stain; original magnification ×400. D) Focally intense granular/synaptic accumulation of abnormal prion protein in the cerebral cortex (case 2). 12F10 antiprion protein antibody; original magnification ×400. Figure. The patient had been diagnosed with von Willebrand disease in childhood. Her early therapies include numerous transfusions of red blood cells and platelets; in more recent years, she received plasma-derived and recombinant factor VIII and additional blood component transfusions at times of hemorrhage. Factor VIII was administered on 4 occasions in the 1990s and during 2000–2004 and von Willebrand factor/factor VIII (Haemate-P) during 2001–2013. Because of her history of exposure to UK-sourced plasma products, for public health purposes she had been informed that she was at risk for vCJD, although she was not known to have been exposed to factor VIII derived from a batch including a vCJD donation. She had no history of potential iatrogenic exposure to CJD and no family history of CJD. Donors for all blood or platelet transfusions since 2001 have been identified. Of the 107 donors, 106 are still alive, with a median age of 55 years (range 27–80 years). ( Table 1 ). One donor of leukodepleted platelets, which were transfused 12 years before clinical onset in the recipient, died in 2013 at 76 years of age, and the diagnoses on the death certificate were vascular dementia and bladder cancer. Identification of donors for transfusions before 2001 has not been possible. Case 2 In 2014, a 64-year-old woman reported day/night reversal of sleep patterns and, 3 months later, excessive tearfulness, for which she was started on antidepressants. She then had onset of writing problems, followed during the next few days by increasing language problems that led to expressive dysphasia. She deteriorated rapidly thereafter, requiring assistance with her activities of daily living and having coordination and memory problems, jerking movements suggestive of myoclonus, and itching in both arms. She was admitted to the hospital and experienced a probable focal seizure with secondary generalization. She had onset of a homonymous hemianopia and limb rigidity and then became bedbound and mute, dying 7 months after the onset of symptoms. An electroencephalogram performed during the final stages of illness showed widespread slowing, more evident on the left. An MRI brain scan showed left-sided caudate head and anterior putaminal high signal. Diffusion weighted imaging showed areas of cortical high signal. Results of a CSF 14–3–3 assay and real-time quaking-induced conversion tests were positive. Consent for full sequencing of the PRNP was not obtained; methionine homozygosity at codon 129 was identified. Postmortem neuropathologic examination of the brain showed a widespread spongiform encephalopathy with microvacuolar spongiform change, neuronal loss, and gliosis. Immunostaining for prion protein showed widespread positivity with a granular/synaptic pattern (Figure). No amyloid plaques were identified. Western blot analysis confirmed the presence of protease resistant prion protein with a type 1A isoform. There was no evidence of abnormal prion protein accumulation in spleen and appendix either on immunocytochemistry or high sensitivity Western blot analysis. The patient was known to have hemophilia B since 1964 and had received plasma-derived and recombinant factor IX during 1984–2012. For public health purposes, she had been informed that she was at risk for vCJD and in 1991 had received factor IX derived from a pool containing plasma from a donor who subsequently had vCJD. She had no history of potential iatrogenic exposure to CJD and no family history of CJD. In 1985, the patient received 6 units of fresh frozen plasma (FFP). Tracing of donors has not been possible. Discussion Discussion This report describes 2 cases of sCJD in patients with a history of treatment with UK-sourced plasma products, 1 with a history of hemophilia B and 1 with von Willebrand’s disease. To our knowledge, no previous case of sCJD in a person with a history of extended exposure to plasma products has been reported. It is clearly of concern that there have been 2 such cases in a relatively short period in the UK, where many plasma product recipients have been informed that they are at increased risk for vCJD. However, a causal link between the treatment with plasma products and the onset of sCJD has not been established, and the occurrence of these cases may simply reflect a chance event in the context of systematic surveillance of CJD in large populations. Both patients had been informed that they were at increased risk for vCJD, and considering the evidence for the type of CJD in the 2 cases is important. Both patients had a clinical phenotype suggestive of sCJD, including a short duration of illness, typical early symptoms, a suggestive MRI scan, and, in 1 patient, a typical EEG. Notably, both patients had a positive real-time quaking-induced conversion test result for PrP Sc in CSF; previously this test had not been positive in any case of vCJD evaluated in our laboratory ( Table 2 ). [9] However, neuropathological examination was critical; it showed appearances typical of sCJD in both patients and no evidence of peripheral pathogenesis on immunostaining of lymphoreticular tissues, a feature that is observed in all tested specimens of vCJD patients to date. [10] Furthermore, both patients had a type 1A isoform PrP Sc on Western blot consistent with a diagnosis of sCJD subtype MM1. [11] Neither patient had a history of potential iatrogenic exposure or a family history of CJD, and for the case for which sequencing of the PRNP was performed, no mutations were detected. In both cases, an MM genotype occurred at codon 129 of PRNP , which does not distinguish between sCJD and vCJD. Laboratory transmission studies to provide evidence of agent strain in the cases have not been possible. One patient had received multiple transfusions of blood components over an extended period, and the other had received 6 units of FFP 19 years before clinical onset, raising the possibility that these cases could have resulted from secondary transmission through blood components. In the case of the patient with von Willebrand disease, 107 donors have been traced, and none appear in the register of cases of CJD kept at the National CJD Research and Surveillance Unit. However, it has not been possible to obtain information on blood transfusions for this patient before 2001 nor on the FFP transfusions for the patient with hemophilia B. Lookback studies in the United States and United Kingdom have provided no evidence of transfusion-transmission of sCJD, [2,3] and although 1 study suggested an increase in risk after a lag period of 10 years, [12] this finding was not confirmed in another study. [13] The balance of evidence indicates that, if sCJD is transmitted by blood transfusion, it must be a rare event, if it happens at all, and transfusion transmission is probably not the explanation for the 2 cases we describe. Systematic surveillance for CJD, including a coordinated study in Europe, [14] has been carried out in many countries over the past 25 years and is continuing. Many of these studies obtain information on potential risk factors, including details of past medical history. To date, no case of sCJD has been reported in a person who has received treatment for a clotting disorder. In fact, the absence of such a case has been used to argue against the possibility that plasma-derived products pose a risk for sCJD transmission. [6] CJD surveillance centers are aware of the relevance of this issue, and sCJD patients with a history of treatment with plasma products probably would have been identified and reported if they occurred. Although it is surprising that 2 cases of sCJD have been identified among a population of 4,000–5,000 patients in the UK who have been treated for clotting disorders with fractionated plasma products, the total population under surveillance for CJD in Europe and internationally exceeds 500 million. Assuming an annual incidence rate of sCJD of 1.5–2.0 per million population, [15] the occurrence of 2 cases of sCJD in this total population may not imply a causal link between the treatment and the occurrence of the disease. The 2 cases were identified over a period of months, and no further cases have been found since 2014; however, continuing to search for such cases through CJD surveillance programs is essential. ",
				"clientUrl": "/viewarticle/879494",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 64652,
				"leadConcept": "Hemophilia",
				"concept": ["Creutzfeldt-Jakob Disease (CJD)", "Neurodegenerative Diseases", "Prion Disease", "Hematology", "Plasma", "Hematological Disorders", "Factor VIII", "Hemophilia B", "Von Willebrand Disease", "Blood Transfusion"],
				"leadSpecialtyId": 3,
				"leadSpecialty": "Infectious Diseases",
				"allSpecialties": ["Infectious Diseases", "Hematology-Oncology", "Internal Medicine", "Public Health & Prevention"],
				"contentGroup": "Journal Article",
				"origContentType": "Journal Article",
				"contentType": ["Journal Article"],
				"description": "Two cases of sporadic Creutzfeldt-Jakob disease were reported for the first time in patients with clotting disorders treated with fractionated plasma products, but a causal link is unproven.",
				"legacyID": 879494,
				"pubDisplay": "Emerging Infectious Diseases CME",
				"siteOn": 2003,
				"title": "Sporadic Creutzfeldt-Jakob Disease in 2 Plasma Product Recipients, United Kingdom",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/EmergInfectDis-thumb.jpg"],
				"publicationDate": 1496293200000,
				"postingDate": 1494565200000,
				"_version_": 1573508875908284416,
				"last_index_date": 1500615001617
			}, {
				"id": "pdctm_0901c79180a0464c",
				"activeCME": 1,
				"activityExpirationDate": 1501563600000,
				"authors": ["Nicola Hanania"],
				"body": "Introduction More than 24 million people in the United States are affected by asthma, a chronic inflammatory disease of the airways. [1] Achieving asthma control, reducing the risk of exacerbations, and improving quality of life are the central goals of asthma management. Despite receiving guidelines-based therapies, approximately 5% to 10% of patients have severe asthma, characterized by the difficulty in achieving disease control despite high-intensity treatment (ie, high-dose inhaled corticosteroids [ICSs] plus a second controller medication and/or systemic corticosteroids). [2] These patients have significant asthma-related morbidity and account for a disproportionate burden of disease in terms of healthcare resource utilization. [3] Recent research has focused on biological markers to identify this difficult-to-treat population and guide the development of targeted treatments, which may actually modify their disease. 4 Phenotypes and Endotypes Advances in science have led to recognition that severe asthma is a complex, heterogeneous syndrome. The severity of symptoms, their triggers, and the type and degree of inflammation may vary from patient to patient, resulting in different responses to the same treatment. Multiple phenotypes and endotypes have been proposed to classify asthma, reflecting observable attributes and pathophysiologic properties of the disease, respectively. [2] These phenotypes include allergic/nonallergic and eosinophilic/noneosinophilic asthma. Endotypes typically relate to pathophysiologic mechanisms driving a specific phenotype, including cells that drive inflammation (eg, dendritic cells, B- and T- lymphocytes, eosinophils, mast cells, and innate immune cells) and their signaling molecules (eg, cytokines). [3] In recent years, researchers have been investigating biomarkers as a way to help identify and classify patients with specific asthma phenotypes and endotypes. The Role of T2 Biomarkers Type 2 (T2) biomarkers identify drivers in the T2 inflammation pathways, primarily T helper 2 (Th2) cells and type 2 innate lymphocyte (ILC2) cells, but also, basophils, eosinophils, and mast cells. These biomarkers can be found in exhaled air, blood, or sputum and reflect the activity of the produced cytokines such as interleukin (IL)-5, IL-13, and IL-4--the signature cytokines that are produced during type 2 immune responses. [4-5] Research has shown that patients with \"T2-high\" asthma typically have eosinophilic inflammation (driven by IL-5, IL-13, and IL-4) and immunoglobulin E (IgE)-mediated inflammation. \"T2-low\" asthma is more likely to be driven by neutrophilic inflammation or, in rare cases, no airway inflammation is present. [3] To date, no reliable biomarkers have been identified for clinical use for T2-low asthma, which may be driven by inflammatory cells, such as Th17, and neutrophils and cytokines, such as IL-17 and IL-23. [4] Biomarkers that identify drivers of inflammation in T2-high asthma disease are proving to be useful to clinicians in targeting therapy (predicting biomarkers) and monitoring response (pharmacodynamic biomarkers) to therapy. Sputum and Blood Eosinophils Among the T2 biomarkers for asthma currently approved for clinical use and being evaluated in ongoing studies are blood and sputum eosinophils. Sputum eosinophils would be an ideal biomarker; however, the specialized clinical expertise required to collect sputum and measure eosinophil levels is not usually practical in a busy clinical practice. [5] Measurement of blood eosinophil levels is inexpensive and can be done routinely in patients with asthma, and the results correlate well with levels of eosinophils in sputum. [4] Studies have shown blood eosinophil levels of 400/mm 3 were associated with higher frequency and severity of exacerbations. [5] IgE For identification of allergic asthma, another phenotype of T2 asthma, measurement of IgE levels can be performed in blood samples by clinical laboratories via immunoassay. [4] The total serum IgE level is believed to reflect airway inflammation. [6] and the presence of allergen-specific IgE indicates that an individual has atopic asthma. [4] For patients for whom allergy skin testing is not possible, obtaining a allergen-specific IgE level is a good alternative. Two other biomarkers that may be useful in identifying specific phenotypes of T2 asthma are fractional exhaled nitric oxide (FeNO) and serum periostin. FeNO FeNO is a marker of eosinophilic airway inflammation. It can be measured noninvasively using devices that are available and approved by the US Food and Drug Administration (FDA). According to the American Thoracic Society (ATS) recommendations, a FeNO <25 parts per billion in adults suggests a reduced likelihood of eosinophilic inflammation whereas a FeNO >50 parts per billion suggests that eosinophilic inflammation is likely. [7] Use of this biomarker may help identify patients who may respond poorly to inhaled corticosteroids or have poor adherence with these drugs. Clinicians who are considering using FeNO in their practices should consult the ATS guidelines for information on appropriate cut-off levels in children and adults. [7] Levels of FeNO may also be predictive of response to existing and emerging biologics, such as those targeting IgE and IL-13. Serum Periostin Another biomarker for T2 asthma that is currently being studied in clinical trials is serum periostin. This protein is released from the subepithelium of the airway and reflects the activity of IL-13, an effector cytokine that is important in the airway inflammation cascade in T2 asthma. [8] Early studies suggest that patients with asthma who have very high levels of periostin may be responsive to anti-IL-13 medications and ICSs. [9-10] Because periostin levels can be measured in serum, periostin has potential for use as a biomarker in the outpatient setting. However, the variability in periostin levels between age groups has been well documented and represents a potential impediment to its clinical use. [4] Studies are ongoing to examine periostin levels in patients with severe asthma over time and determine potential confounders. Additional research is ongoing to determine considerations for using this biomarker in clinical practice. [11-12] New and Emerging Targeted Therapies In tandem with development of biomarkers to identify therapeutic targets, new biologic therapies have been FDA-approved, and others are in the development pipeline. IgE Omalizumab received FDA approval for treatment of moderate to severe persistent allergic asthma in patients whose symptoms are not controlled with corticosteroids. [13-14] Omalizumab is an anti-IgE monoclonal antibody and the first biologic therapy approved for use in a specific phenotype of severe asthma. Clinical trials have shown that adding this injectable drug to corticosteroids in patients with allergic asthma reduces exacerbation risk with minimal improvement in lung function. [14-16] IL-5 For patients with eosinophilic inflammation that persists despite treatment with inhaled or systemic corticosteroids, their disease may be responsive to therapies that target IL-5, a cytokine which recruits eosinophils from bone marrow to the airway. [4] Two such drugs that target IL5--mepolizumab and reslizumab--have received FDA approval, and a third agent that targets the IL-5 receptor, benralizumab, is in development. Mepolizumab is an anti-IL-5 antibody given on a monthly basis as a subcutaneous injection. [17] In randomized, double-blind, placebo-controlled trials in patients with severe eosinophilic asthma, mepolizumab has been shown to have a significant glucocorticoid-sparing effect, reduce exacerbations, and improve control of asthma symptoms. [18-20] In March 2016, an intravenous formulation of reslizumab was the most recent biologic therapy approved by the FDA, based on results from 4 double-blind, randomized, placebo-controlled trials in patients with severe eosinophilic asthma inadequately controlled with currently available therapies. [21-22] In the studies, patients receiving reslizumab had a significant reduction in the frequency of asthma exacerbations and significant improvement in lung function. Benralizumab is a monoclonal antibody that targets the IL-5 receptor and depletes blood and airway eosinophils. In a phase 2b randomized dose-ranging study, benralizumab reduced asthma exacerbations in adults with uncontrolled eosinophilic asthma and baseline eosinophils of at least 30 cells per µL. [23] In 2 phase 3 trials in adults and adolescents aged 12 years and older, the drug achieved its primary endpoint of safety and efficacy as an add-on therapy for severe uncontrolled asthma with eosinophilic inflammation. [24] Results from those trials, however, have not yet been published. Mepolizumab, reslizumab, and benralizumab all have been tested in patients with severe asthma who had high blood levels of eosinophils at baseline, and they stand to be of most benefit in patients who have a history of exacerbations and are already on high-dose ICSs and other controller therapies. Blood eosinophil level has been shown to be a useful biomarker for identifying patients who would be likely to respond drugs that target IL-5 or its receptor. IL-13 Another cytokine target in the T2 inflammation pathway for which biologic therapies are being investigated is IL-13. It is a target of interest for severe asthma because it has a pleiotropic effect, impacting mucus production and airway remodeling in addition to recruiting eosinophils to the airway. [25] Lebrikizumab and tralokinumab are the 2 anti-IL-13 therapies currently under investigation in clinical trials. Results from 2 phase 2 randomized, placebo-controlled trials show that lebrikizumab is effective in reducing asthma exacerbations and improving lung function in patients with moderate to severe asthma with high baseline periostin levels and who remain uncontrolled despite current standard-of-care treatment. Reduction in exacerbations was more pronounced in the periostin-high patients (all doses: 60% reduction) than in the periostin-low patients (all doses: 5% reduction). [9] Compared with the periostin-low patients, the periostin-high patients also had greater improvements in forced expiratory volume in one second (FEV 1 ). [9] In a randomized, double-blind, placebo-controlled phase 2b trial, 2 different dosing regimens of tralokinumab had acceptable safety and tolerability profiles, but did not significantly lower exacerbation rates in patients with severe asthma. When the drug was given every 2 weeks it did, however, result in improvement in FEV 1 . [10] As a result, tralokinumab's possible use in a defined population of patients with severe uncontrolled asthma is now being investigated in phase 3 trials. [26-28] Further studies are needed of both lebrikizumab and tralokinumab in order to determine what role these drugs might have in clinical practice. IL-4 / IL-13 Dupilumab targets IL-4 receptor alpha, a receptor that is shared by IL-13 and IL-4. IL-4 itself is an important biomarker in the cascade that plays a role in eosinophilic recruitment and has downstream effects. [3] In a phase 2b trial in patients with moderate to severe asthma, dupilumab improved lung function, as measured by FEV 1 , and reduced the annualized severe exacerbation rate, suggesting that it may be beneficial in this population. [29] Several phase 3 trials of the drug, which is an injectable and has been studied for monthly or semi-monthly use, are under way. [30-33] This drug has also shown a beneficial effect in atopic dermatitis. Biomarkers in Practice Research has made progressive strides in recent years in defining phenotypes and endotypes of asthma, with the goal of addressing the unmet need of patients with severe disease who are at increased risk of morbidity and mortality because of lack of response to traditional therapy. Most of the biomarkers that are approved for use or nearing approval reflect T2-high airway inflammation; however, at present, their use is limited to a subset of patients who suffer from severe disease. Currently, these biomarkers can serve dual purposes, as predictive biomarkers and/or pharmacodynamic biomarkers (Table 1). Table 1. Potential Roles of T2-High Biomarkers in Management of Severe Asthma 700 421 1 FeNO = fractional excretion of nitric oxide; IgE = immunoglobulin E; IL = interleukin; T2 = type 2. Parulekar AD, Atik MA, Hanania NA. Curr Opin Pulm Med . 2014;20:60-65. [4] For patients with severe asthma, the ability to use biomarkers to better define asthma phenotypes and endotypes and target biologic therapy offers hope of improved outcomes. As this area of research in asthma expands, clinicians will be increasingly called upon to adopt a new paradigm in the treatment of asthma, one focused on an individualized approach to management based on the inflammation drivers at the root of the disease, rather than being limited to the amelioration of symptoms. Educational Impact Challenge What did you learn from this activity? Please click on the “Continue” button to proceed to a brief survey to see how your knowledge improved after the education. You can also see how your answers compare with those of your peers. Educational Impact Challenge 5 ",
				"clientUrl": "/viewarticle/866141",
				"creditType": ["CME", "ABIM MOC"],
				"cmeFlag": "CME / ABIM MOC",
				"leadConceptId": 251,
				"leadConcept": "Asthma",
				"concept": ["Cytokines", "Nitric Oxide", "Eosinophils", "Immunoglobulin E (IgE)", "Monoclonal Antibody", "Biologic Therapy", "Pathogenesis", "Biomarker", "Interleukin"],
				"leadSpecialtyId": 38,
				"leadSpecialty": "Allergy & Clinical Immunology",
				"allSpecialties": ["Allergy & Clinical Immunology", "Pulmonary Medicine", "Medscape Today", "Family Medicine/Primary Care"],
				"origContentType": "Roundtable",
				"contentType": ["Article/Courses"],
				"description": "Dr Nicola Hanania provides current research in the utility of biomarkers and their role in targeting biologic treatments in severe asthma.",
				"legacyID": 866141,
				"mediaFlag": "2",
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Advances in Biomarkers for Type 2 Asthma Management",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:0.25", "US Physicians:Points for ABIM MOC:0.25"],
				"maxCredits": [0.25],
				"multimedia": ["/thumbnail_library/866141.jpg"],
				"publicationDate": 1470027600000,
				"postingDate": 1470027600000,
				"_version_": 1573508884408041472,
				"last_index_date": 1500615009702
			}, {
				"id": "pdctm_0901c79180a1c74a",
				"activeCME": 1,
				"activityExpirationDate": 1504155600000,
				"authors": ["Jørgen Vestbo", " Marc Miravitlles", " Wisia Wedzicha"],
				"body": "Slide 1. Slide 1. Dual Bronchodilation in COPD: From Clinical Trial Evidence to Clinical Practice Slide 2. Slide 2. Faculty Slide 3. Slide 3. Introduction [1] Slide 4. Slide 4. GOLD Recommendations: First-Line Pharmacologic Therapy for Stable COPD [2] In 2011, Global Initiative for Chronic Obstructive Lung Disease (GOLD) released a new recommendation focusing on patients either at low or high risk of exacerbations Other drugs can have an effect, such as phosphodiesterase-4 (PDE4) inhibitors, macrolides, and combinations of these drugs Bronchodilators are the mainstay of chronic obstructive lung disease (COPD) therapy as they reduce symptoms Long-acting muscarinic antagonists (LAMAs) particularly prevent exacerbations We need to discuss how long-acting beta agonist (LABA)/LAMA combinations fit in in current practice and how they compare with inhaled corticosteroid (ICS) treatments Slide 5. Slide 5. Available and Emerging LABA and LAMA Bronchodilators for COPD More studies have been done with some of the LABA/LAMA combinations than with others and the available data therefore reflect this Slide 6. Slide 6. LABA/LAMA Dual Bronchodilation vs Monocomponents: Indacaterol/Glycopyrronium [3] The combinations of LABA/LAMA have provided better bronchodilator effects compared with monotherapies The goal of treatment is to improve lung function as much as possible Slide 7. Slide 7. LABA/LAMA Dual Bronchodilation vs Monocomponents: Tiotropium/Olodaterol [4] All the combinations of 2 bronchodilators (eg, indacaterol/glycopyrronium, tiotropium/olodaterol, aclidinium/formoterol, and umeclidinium/vilanterol) provide better lung function compared with monotherapies In patients with mild COPD and mild airflow obstruction, it is possible that 1 bronchodilator may reach the maximum bronchodilator effect In patients with moderate or severe COPD, 2 bronchodilators add to what can be achieved with a single bronchodilator Slide 8. Slide 8. Patient-Reported Dyspnea Scores After 6 Weeks of Treatment [5] It is important to determine how these findings translate in patient-reported outcomes (PROs), ie, in what the patient perceives and feels about the disease Some data show that 2 bronchodilators can also improve dyspnea in patients further than with 1 single bronchodilator For the impact on exacerbations, it was not well accepted that bronchodilators alone could improve or reduce exacerbations Slide 9. Slide 9. Annualized Rate of Moderate or Severe Exacerbations: SPARK [6] The SPARK study showed that a LABA/LAMA combination could reduce further exacerbations compared with a single LAMA bronchodilator LAMAs were more effective than LABAs in preventing exacerbations Slide 10. Slide 10. Clinician Perspective on Which Patients Are Most Suited for Dual Bronchodilation [2,3,7] Slide 11. Slide 11. Time to Effect of Single Dose of Umeclidinium/Vilanterol vs Monocomponents or Placebo [8] Clinical trials have shown that the effect of bronchodilators on lung function and on PROs can occur within weeks or days of treatment Slide 12. Slide 12. Patients Determine the Effect of Therapy on Symptom Control There are a lot of data on symptoms, and fewer data on exacerbations There have been fewer studies comparing bronchodilators with the other recommended treatment, ie, an ICS/LABA combination Trials on exacerbation take longer than trials on symptoms Slide 13. Slide 13. Lung Function Improvement With Umeclidinium/Vilanterol vs Fluticasone/Salmeterol [9] There have been 2 studies performed with dual bronchodilators (umeclidinium/vilanterol and indacaterol/glycopyrronium) compared with ICS/LABA on lung function One expects an improvement in forced expiratory volume in 1 second (FEV 1 ) with a combination of 2 bronchodilators because LABA/ICS includes only 1 bronchodilator There are improvements in FEV 1 with dual bronchodilators, as well as changes in PROs, particularly effects on shortness of breath Slide 14. Slide 14. Time to First Moderate or Severe COPD Exacerbation for Indacaterol/Glycopyrronium vs Salmeterol/Fluticasone [10] The LANTERN study was performed mainly in China and FEV 1 was the primary outcome Data on exacerbation showed that time to the first moderate or severe exacerbation was prolonged with indacaterol/glycopyrronium compared with the LABA/ICS salmeterol/fluticasone (ie, there was less susceptibility to exacerbation on the dual bronchodilator) Slide 15. Slide 15. FLAME Study Design and Objective [11] Exacerbation studies must be performed over 1 year because exacerbations are seasonal and two-thirds occur during the winter months The FLAME study was a direct comparison of LABA/LAMA indacaterol/glycopyrronium against the LABA/ICS salmeterol/fluticasone It aimed to show that the dual bronchodilator was equivalent to the LABA/ICS Once equivalence was established, superiority of 1 of the compounds could be tested Slide 16. Slide 16. Time to First Exacerbation for Indacaterol/Glycopyrronium vs Salmeterol/Fluticasone [11] The FLAME study showed that the study treatments were equal and then continued on to test superiority For all exacerbations (ie, mild, moderate, and severe), there was a reduction of exacerbations with indacaterol/glycopyrronium compared with the LABA/ICS salmeterol/fluticasone For time to the first exacerbation, the reductions were consistent for mild, moderate, and severe exacerbations (ie, those requiring hospital admission) There were consistent reductions in the annual rate of exacerbations Reduction in severe exacerbation rates was not significant, likely due to relatively small numbers Slide 17. Slide 17. Rate of Exacerbation by Specific Subgroups [11] The time to first exacerbation, which is a measure of a patient's susceptibility to have an event, was equivalent to the rate used to measure exacerbations over the whole study year The study also examined how patients' stable baseline characteristics affected exacerbation Prior ICS treatment, reversibility, or disease severity did not show a significant effect on the results According to a prespecified analysis, the association between blood eosinophil levels and exacerbation rates was measured The reduction of exacerbations with indacaterol/glycopyrronium was similar regardless of baseline blood eosinophil count Slide 18. Slide 18. Most Frequent AEs: FLAME Study [11] With regard to safety, there may be concern that dual bronchodilators could increase the risk of cardiovascular events, although this has not been seen Many studies have found that dual bronchodilators are safe and have the adverse events (AEs) profiles expected in the general COPD population In FLAME, when LABA/LAMA and LABA/ICS were compared, there was a small, but significant, increase in episodes of pneumonia in patients on LABA/ICS Mortality was the same with 24 deaths in each group Slide 19. Slide 19. Lung Function With Triple Therapy: LAMA + ICS/LABA vs ICS/LABA + Placebo [12] There are studies of triple therapy (ie, LABA/LAMA and ICS) tested against LABA/ICS and against LABA/LAMA Studies to date indicate that in triple vs dual therapy, there is a slight increase in lung function in patients on the triple vs dual, whether LABA/LAMA or LABA/ICS This will require further evaluation in the future Slide 20. Slide 20. Real-Life Use of ICS [2,13] Slide 21. Slide 21. Effect of ICS Withdrawal on Lung Function and Exacerbations [14] In the INSTEAD trial, in patients with moderate COPD, withdrawing ICS showed no impairment in lung function or quality of life, and no increased risk of exacerbations Often patients might have had an exacerbation, or felt worse and were put on an ICS/LABA and continue on that treatment for a number of years This indicates that ICS can be discontinued in a patient who is stable and who had no indication for ICS treatment, and that the patient can be put on a dual bronchodilator Slide 22. Slide 22. ICS Withdrawal and Exacerbations in Patients With Severe COPD: WISDOM [15] The WISDOM study included patients with an indication for ICS (ie, FEV 1 <50% predicted and at least 1 exacerbation in the previous year) Patients were randomized to continue on triple therapy (LABA/LAMA/ICS) or to discontinue the ICS and stay on a dual bronchodilator (LABA/LAMA) There was no increased risk of exacerbations, but patients withdrawn from ICS experienced a small reduction in lung function This is opposite to what would be expected Caution should be used when discontinuing steroids in patients with more severe COPD Slide 23. Slide 23. Risk of Severe COPD Exacerbation After ICS Withdrawal [15] In the WISDOM trial, there was a 20% increased risk of severe exacerbations, although this was not statistically significant Patients with severe, hospitalized exacerbations in the baseline state tend to have more symptoms and will therefore need to further step up therapy in the future with anti-inflammatory treatment Slide 24. Slide 24. New Data and a Shift in Treatment Strategy? Slide 25. Slide 25. Role of Bronchodilators as Basis of Treatment Patients could also have bronchiectasis and need to be seen by a specialist Slide 26. Slide 26. Post Hoc Analysis of FORWARD Study Data According to Blood Eosinophil Level [16] Post hoc analyses suggest a relationship between increasing exacerbation frequency and the percentage or absolute blood eosinophil level (EOS) The effect of ICS seemed to be greater at higher blood EOS A number of community-based studies have examined the association between blood EOS and exacerbations The Copenhagen General Population Study, found a relationship between blood EOS and severe exacerbations, but less of an association with moderate exacerbations [17] Slide 27. Slide 27. Prospective Study of Blood Eosinophil Level and Exacerbation Rate in FLAME [11] The FLAME study prospectively examined EOS This was not in the protocol because it predated the current knowledge about eosinophils In the FLAME population, the baseline blood EOS did not make a difference on the exacerbations Slide 28. Slide 28. Concluding Remarks Slide 29. Slide 29. Thank You This content has been condensed for improved clarity. ",
				"clientUrl": "/viewarticle/867036",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 260,
				"leadConcept": "Chronic Obstructive Pulmonary Disease (COPD)",
				"concept": ["Primary Care", "Combination Drug Therapy", "Beta-Adrenergic Agonist", "Eosinophils", "Inhaled Corticosteroid", "Adverse Effects", "Bronchodilator", "Pharmacologic Adverse Events", "Clinical Research", "Biomarker"],
				"leadSpecialtyId": 34,
				"leadSpecialty": "Family Medicine/Primary Care",
				"allSpecialties": ["Family Medicine/Primary Care", "Pulmonary Medicine", "Internal Medicine"],
				"origContentType": "Roundtable",
				"contentType": ["Article/Courses"],
				"description": "Drs Vestbo, Miravitlles, and Wedzicha discuss the latest on dual bronchodilation in COPD.",
				"legacyID": 867036,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Dual Bronchodilation in COPD: From Clinical Trial Evidence to Clinical Practice",
				"suppressComment": "T",
				"creditsAvailable": ["Non-US Physicians:CPD:0.25"],
				"maxCredits": [0.25],
				"multimedia": ["/thumbnail_library/867036.jpg"],
				"publicationDate": 1472619600000,
				"postingDate": 1472619600000,
				"_version_": 1573508889420234752,
				"last_index_date": 1500615014477
			}, {
				"id": "pdctm_0901c79180a7873f",
				"activeCME": 1,
				"activityExpirationDate": 1508994000000,
				"authors": ["News Author: Pauline Anderson \nCME Author: Charles P. Vega"],
				"body": "Clinical Context The Zika virus continues to be a threat, especially with new cases related to infection acquired within the United States. In an editorial accompanying the current research study, Roos provides a review of the epidemiology and clinical symptoms of Zika virus syndrome. Zika virus is categorized in the same family of flaviviruses as West Nile, yellow fever, and dengue viruses. It is transmitted primarily via the bite of the Aedes mosquito, although individuals may also acquire the Zika virus infection through sexual intercourse or blood transfusion. Nonetheless, only 20% of patients infected with the Zika virus demonstrate typical symptoms of fever, arthralgia, maculopapular rash, and conjunctivitis. The editorial describes how the Zika virus has a predilection for the central nervous system. The most devastating complication of Zika virus syndrome is the potential for microcephaly and other nervous system abnormalities in the offspring of women infected with Zika virus during pregnancy. However, microcephaly is not the only serious consequence of Zika virus infection during gestation. The current study by Tanuri and colleagues evaluates young children exposed to the Zika virus in utero to evaluate the impact of infection on young children more completely. Study Synopsis and Perspective A new investigation of the Zika virus in Brazil has produced additional insights about the neurologic manifestations in babies exposed to this virus. The analysis of 11 confirmed fetal cases of Zika determined that the babies had neurologic changes in addition to microcephaly. The study, published October 3 in JAMA Neurology , [1] highlights the importance of imaging at approximately 18 weeks of gestation in suspected cases of Zika infection, said study author Amilcar Tanuri, MD, PhD, professor, Universidade Federal do Rio de Janeiro, Brazil. As with yellow fever, dengue, and West Nile viruses, the Zika virus is an arthropod-borne flavivirus transmitted mostly through the bite of an Aedes mosquito. The Zika virus, which can be found in body fluids, is spread through the placenta, during sexual intercourse, or via blood transfusions. Patients with the infection can present with low-grade fever, arthralgia, rash, headache, and/or myalgia, but most infections are asymptomatic. In addition to congenital abnormalities, the virus infection has been associated with Guillain-Barré syndrome (GBS). [2] The current study included pregnant mothers referred to the fetal medicine service of the Instituto Paraibano de Pesquisa Professor Joaquim Amorim Neto in Brazil between October 2015 and February 2016. The fetuses of these women had abnormalities in brain development, as shown by ultrasound imaging. Investigators performed amniocentesis in all women for laboratory confirmation of Zika infection by polymerase chain reaction (PCR). Researchers observed the women until they gave birth. After birth, they conducted additional imaging and collected samples of amniotic fluid, cord blood, and placenta. By these means, Zika diagnoses were confirmed in all but 2 patients. Both of these patients were included in the study on the basis of a strong immunoglobulin G anti-Zika immune profile. \"This means that we were sure that the 11 cases were infected by Zika, and we focused our attention on the kinds of lesions that showed up on images,\" said Dr Tanuri. Three of the 11 babies died after birth. Two mothers consented to autopsies, which were performed less than 8 hours after death. The surviving infants were observed from gestation to age 6 months. The median cephalic perimeter at birth was 31 cm, which the authors said is lower than the limit for considering microcephaly. However, they noted that some infants had a head circumference measure that was consistent with their gestational age. Universal Neurologic Impairment The researchers found neurologic impairments in all cases. There was a common pattern of brain atrophy and changes associated with disturbances in neuronal migration. Dr Tanuri pointed out that Zika induced \"very specific lesions,\" with the difference in severity being based on where the virus replicates in the brain. \"We saw two different patterns: one where the whole brain is smaller and the other pattern with ventriculomegaly and water inside the brain. Both patterns are induced by the same virus.\" If the virus replicates in important structures, such as the brainstem or cerebellum, the outcome seems to be much worse than if it replicates in the cortex. In all babies who died, the virus had attacked the brainstem, said Dr Tanuri. Evaluating the brainstem on fetal magnetic resonance imaging may help predict the likelihood of survival of the newborn, he added. It is unclear what factors determine where in the brain the virus will replicate, said Dr Tanuri. Results of testing for other causes of microcephaly, such as drug use, alcohol consumption, smoking, and medications, were negative. Tests for other arboviruses, including the dengue virus, also had negative results. New Nomenclature Most of the women in the study demonstrated symptoms of Zika infection in the first trimester, which could be associated with the disturbance in neuronal migration processes and the formation of the neural tube, write the authors. All but one of the mothers had a skin rash at the beginning of the pregnancy. Unlike authors of other reports, Dr Tanuri and his colleagues did not observe changes in umbilical and cerebral blood flow, even in the most serious cases. The authors made several conclusions. One was that because microcephaly is not the only Zika manifestation, the term \"congenital Zika syndrome\" should be used instead of \"microcephaly associated with Zika virus infection.\" \"What seems to be universal is that microcephaly is not the sole finding but is a consequence of several brain injuries,\" write the authors. \"Growth restriction and other damages, such as ophthalmologic alterations, were observed in neonates. Indeed, we observed a pronounced ventriculomegaly in most patients that could influence the observed microcephaly.\" Dr Tanuri stressed the importance of ultrasound imaging at approximately the third trimester \"to report or to isolate or identify babies or fetuses\" who are infected. \"If I am following up a pregnant woman, and I do ultrasound at 18 weeks and some lesions show up, this is a sign\" that will identify babies already infected with Zika. The problem in Brazil and other low-income countries is that routine ultrasound examination is not widely available, said Dr Tanuri. Collecting amniotic fluid during gestation is another valuable tool for a prenatal diagnosis, he said. Another Surge on the Way? As summer will soon arrive in Brazil, Dr Tanuri is concerned about a surge in Zika cases. From November to January, temperatures can get extremely high in the region and mosquitoes are much more prevalent. \"I hope that things are settled, but we have to be vigilant.\" He said he is also worried about an epidemic in Puerto Rico. \"I heard that nearly 2000 pregnant women there are infected with Zika.\" Dr Tanuri is hopeful that an antiviral drug will soon be developed to block transmission of the virus through the placenta to the fetus. \"If an antivirus is effective and not toxic, you can give it to moms in endemic areas.\" However, he said he has \"some doubts\" about the development of a Zika vaccine. \"You need to know much more about the virus before proposing a vaccine; we know nothing about the immune response\" to this virus. Vaccine on the Way? In an accompanying editorial, [3] Raymond P. Roos, MD, Department of Neurology, University of Chicago, Chicago, Illinois, said that although it is \"reassuring\" that at least 18 manufacturers and institutions are pursuing a vaccine, \"issues may complicate the development of a successful Zika virus vaccine.\" One such issue, said Dr Roos, is that there may be difficulty in raising Zika virus-neutralizing antibodies in dengue virus-endemic areas because of the serologic cross-reactivity between these 2 viruses. He noted that many questions related to the Zika virus infection remain unanswered. Among these, he said, are the following: \"How frequently does asymptomatic infection or second- and third-trimester infection lead to CNS [central nervous system] disease? Is Zika virus-induced GBS the typical immune-mediated disease or is there a direct virus invasion? What are the long-term sequelae of intrauterine Zika virus infection? What is the reason for the substantial size, severity, and unexpected complications of the recent Zika virus outbreak in the Americas compared with what has been seen with this virus in the past?\" Another important question is what neurologists can do regarding the Zika situation, said Dr Roos. It would be \"valuable\" to have adult and pediatric neurologists network with the Centers for Disease Control and Prevention to establish a surveillance system that could track Zika virus-induced GBS and CNS disease. \"This would facilitate the identification and characterization of disorders, the formation of a registry, and the mounting of comprehensive epidemiological studies.\" According to background in the editorial, the Zika virus was first isolated in the Zika forest of Uganda in 1947 from rhesus monkeys being investigated for the yellow fever virus. The first major outbreak was recognized in the Yap Islands in Micronesia in 2007, followed by an outbreak in French Polynesia. (All Zika genomes sequenced from the 11 current cases belonged to the Zika Asian lineage. These were all related to the viruses identified in the French Polynesian outbreak.) The recent outbreak in Brazil began in April 2015. Since then, thousands of cases of microcephaly and CNS developmental abnormalities associated with the Zika virus have been reported in the Americas. Cases have now been reported in 23 countries and territories in this region. Earlier this year, the World Health Organization designated the Zika virus epidemic as a public health emergency of international concern. Medscape Medical News approached Kate Russell, MD, MPH, epidemic intelligence service officer, Centers for Disease Control and Prevention, for her views of the new findings. \"This series adds to the growing literature that microcephaly is one of multiple neurologic consequences of congenital Zika virus infection,\" said Dr Russell. \"We know that Zika virus infection during pregnancy is a cause of microcephaly and other severe brain defects; however, more information is needed to understand the full clinical spectrum of the effects of Zika virus infection during pregnancy.\" Because it is difficult to predict at birth what problems infants will have from exposure to Zika virus during gestation, \"close follow-up of infants with and without microcephaly whose mothers have evidence of Zika infection are needed\" to better understand the impact of the infection, added Dr Russell. The study authors and editorial writer have disclosed no relevant financial relationships. JAMA Neurol. Published online October 3, 2016. Study Highlights Study participants were women with suspected Zika virus infection during pregnancy who were referred to a research center in Brazil between October 2015 and February 2016. From more than 150 women referred for observation, 11 were chosen for the study because of evidence of fetal brain lesions on ultrasound imaging. Researchers performed ongoing evaluations of expectant mothers in the study, including ultrasound and magnetic resonance imaging studies of the fetus as well as amniocentesis. Samples from multiple sources were tested for viral RNA of the Zika virus. Reverse-transcription PCR (RT-PCR) testing results confirmed Zika virus RNA in the amniotic fluid in 6 of 11 women. Three other women tested positive on placental tissues or cord blood, and 2 women tested negative on RT-PCR but had strong evidence of an antibody reaction linked with Zika virus infection specifically. The median maternal age was 25 years, and 45% of mothers were primigravidas. All women participating in the study had a rash during the first trimester of pregnancy. The median gestational age at delivery was 39 weeks. 3 infants died shortly after delivery, and 2 families consented for autopsy. The median cephalic diameter at birth was 31 cm. Other causes of microcephaly were excluded in the study sample. The most common finding on fetal imaging in the sample was severe cerebral atrophy with microcephaly. Most cases demonstrated hypodevelopment of the cerebellum and brainstem. Fetal akinesia deformation sequence or arthrogryposis was observed in 3 infants, and these infants all died after delivery. Amniotic fluid volume was normal in 9 patients, and Zika virus infection did not appear to affect placental blood flow. Pathologic examination of 2 brains from infants who died demonstrated enlarged ventricles and leptomeninges congested with lymphocytes. The surviving children had a range of neurologic abnormalities. The main ocular findings were paresis of the oculomotor muscles. Phylogenetic analyses demonstrated that the current Zika virus outbreak in the Americas is more closely related to the Asian-Pacific lineage vs African lineage of the virus. In the 2 infants who died, there was variation in the Zika virus lineage in comparing analyses from different tissues within the same host. Clinical Implications Zika virus is categorized in the same family of flaviviruses as West Nile, yellow fever, and dengue viruses. It is transmitted primarily via the bite of the Aedes mosquito, although individuals may also acquire Zika virus infection through sexual intercourse or blood transfusion. Nonetheless, only 20% of patients infected with the Zika virus demonstrate typical symptoms of fever, arthralgia, maculopapular rash, and conjunctivitis. In the current study by Tanuri and colleagues, the case-fatality rate for congenital Zika virus infection was 27%. Oculomotor abnormalities among surviving infants were common, and most infants demonstrated hypodevelopment of the cerebellum and brainstem. Amniotic fluid volume was normal in 9 infants, and Zika virus infection did not appear to affect placental blood flow. Implications for the Healthcare Team: The healthcare team should closely follow data and recommendation from the US Centers for Disease Control and Prevention regarding Zika virus epidemiology and prevention, and the findings from the current study reinforce the potential risk for Zika virus infection during pregnancy. CME Test 3 ",
				"clientUrl": "/viewarticle/870375",
				"creditType": ["CME", "Nurse CE"],
				"cmeFlag": "CME / CE",
				"leadConceptId": 6007450,
				"leadConcept": "Zika Virus",
				"concept": ["Insect Bite", "Viral Infection", "Pediatric Nursing", "Travel Medicine", "Epidemiology", "Guillain-Barre Syndrome", "Polymerase Chain Reaction (PCR)", "Ultrasonography", "Pregnancy", "Congenital Anomaly", "Laboratory Diagnosis", "Neonatal Medicine", "OB/GYN and Women's Health Nursing", "Public Health Nursing", "Epidemic", "Guillain-Barre Syndrome in Childhood", "Outbreak", "Tropical Diseases", "Microcephaly"],
				"leadSpecialtyId": 3,
				"leadSpecialty": "Infectious Diseases",
				"allSpecialties": ["Infectious Diseases", "Pediatrics", "Ob/Gyn & Women's Health", "Medscape Today", "Nursing", "Neurology & Neurosurgery", "Family Medicine/Primary Care", "Public Health & Prevention", "Pathology & Lab Medicine"],
				"contentGroup": "Clinical Review",
				"origContentType": "Clinical Brief",
				"contentType": ["News"],
				"description": "A new observational study reports that the Zika virus is associated with far more neurologic damage than microcephaly alone.",
				"legacyID": 870375,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Zika Virus: More Than Just Microcephaly",
				"suppressComment": "T",
				"creditsAvailable": ["PhysiciansFamily Physicians:AMA PRA Category 1 Credit(s)™AAFP Prescribed credit(s):0.25", "Nurses:ANCC Contact Hour(s):0.25", "Physicians:AMA PRA Category 1 Credit(s)™:0.25"],
				"maxCredits": [0.25],
				"publicationDate": 1477458000000,
				"postingDate": 1477458000000,
				"_version_": 1573508897050722304,
				"last_index_date": 1500615021753
			}, {
				"id": "pdctm_0901c79180bba95d",
				"activeCME": 1,
				"activityExpirationDate": 1531544400000,
				"authors": ["News Author: Nicola M. Parry", " CME Author: Charles P. Vega"],
				"body": "Clinical Context Sarcopenia is defined by a loss of muscle mass and function, and the authors of the current study, provide a brief review of the clinical phenomenon of sarcopenia. Loss of muscle mass is a normal part of the aging process among adults. Overall, the loss of muscle mass begins in middle age and advances at a rate of 6% per decade. The excessive muscle loss of sarcopenia is related to reduced quality of life and a higher risk for falls. Multiple factors contribute to sarcopenia. Hypertension and hypercholesterolemia can contribute to sarcopenia, as can physical activity and nutrition factors. Smoking has been associated with a higher risk for sarcopenia as well. Alcohol and its metabolites have been associated with the inhibition of muscle protein synthesis in animal models, and ethanol can directly inhibit rapamycin, which serves as a regulator of protein synthesis. The current study evaluates a large cohort of women to establish whether alcohol might directly affect the risk for sarcopenia. Study Synopsis and Perspective High-risk alcohol consumption is associated with a greater risk for muscle tissue loss in postmenopausal women, a new study shows. Yu-Jin Kwon, MD, from Yonsei University College of Medicine, Seoul, Republic of Korea, and colleagues published the results of their cross-sectional Korea-based study online June 5 in Menopause . \"The prevalence of sarcopenia increased from low-risk to high-risk groups,\" the authors write. \"In addition, women in the high-risk alcohol-drinking group were more likely to be current smokers, and have worse blood pressure and total cholesterol.\" Aging results in a progressive loss of muscle mass and function called sarcopenia, with midlife muscle mass declining to approximately 75% after age 80 years. This translates to decreased muscle strength, which, in turn, increases risk for falls and fractures, impairs overall ability to perform tasks of daily living, and reduces quality of life. As the world's older population continues to grow, the effect of sarcopenia and its related morbidity thus represents a significant public health concern. Prevention and early detection of sarcopenia among postmenopausal women could therefore help prevent aging-related diseases. Although aging is the leading cause of sarcopenia, various behavioral factors, such as alcohol consumption and smoking, can also contribute to increased risk for sarcopenia. However, few studies have examined the relationship between muscle tissue loss and alcohol consumption. The researchers therefore set out to examine the association between drinking patterns and the risk for sarcopenia among postmenopausal women. The researchers used whole-body dual-energy X-ray absorptiometry to measure participants' body composition, and defined sarcopenia as 2 standard deviations below the means of the appendicular skeletal muscle/weight (percentage) values for healthy young men or women. They also used the Alcohol Use Disorders Identification Test (AUDIT) questionnaire to screen for alcohol drinking patterns, grouping participants into 1 of 3 categories, according to their AUDIT score: low-risk drinkers (0-7), intermediate-risk drinkers (8-14), and high-risk drinkers (at least 15). Of the 2373 postmenopausal women (mean age, 62.4 years) included in the study, 188 (8.2%) met the criteria for sarcopenia. Among those with sarcopenia, the researchers found that its prevalence was almost 4 times greater in women in the high-risk alcohol drinking group than in those in the low-risk group. The prevalence of sarcopenia in the low-risk alcohol drinking group was 7.6%, increasing to 11.0% in the intermediate-risk group and 22.7% in the high-risk group (P = .003). The researchers also adjusted for confounding variables (age, body mass index, systolic blood pressure, total cholesterol, fasting blood glucose, household income, education level, daily calorie intake, current smoking, regular exercise, and household food security status) and showed that compared with the low-risk group, the odds ratio for sarcopenia in the high-risk group was 4.29 (95% confidence interval, 1.87-9.82). The authors acknowledge the limitations of this study, including its cross-sectional design, which prevents establishing a causal link between alcohol drinking patterns and sarcopenia. And because the AUDIT was administered as a self-report questionnaire, participants may have underreported their alcohol consumption and drinking pattern score, in particular because alcohol use is less socially acceptable for women in Korean culture. In addition, participants' muscle strength and physical performance were not examined in the assessment of sarcopenia. Dr Kwon and colleagues therefore stress the need for further studies to incorporate the AUDIT or other similar measures to clarify this association between high-risk alcohol drinking and sarcopenia among postmenopausal women. The authors have disclosed no relevant financial relationships. Menopause. Published online June 5, 2017. [1] Study Highlights Study data were drawn from the Korea National Health and Nutrition Examination Survey, and researchers focused on data collected between 2008 and 2011 among women in menopause. Women receiving hormone therapy were excluded from evaluation, and the study cohort was generally healthy. Participants completed an interview that focused on sociodemographic and health habit variables. They also completed measurements of body mass index, blood pressure, and blood work. The Alcohol Use Disorders Identification Test (AUDIT) was used to screen participants for alcohol drinking patterns. High-risk adults had an AUDIT score of 15 or more, whereas intermediate risk was defined by an AUDIT score of 8 to 14. The low-risk cohort of women (AUDIT score, 0-7) was used as a comparator group. Body composition and skeletal muscle mass were measured with dual-energy X-ray absorptiometry. The main study outcome was the relationship between sarcopenia and alcohol drinking behaviors. This was adjusted to account for age, smoking status, body mass index, blood pressure, food security status, physical activity, daily calorie intake, laboratory values, and household income. 2373 women participated in the study. The mean age of participants was 62.4 years, and the average body mass index was 24.2 kg/m 2 . The average AUDIT score was 2.8. 8.2% of women had sarcopenia. The prevalence of sarcopenia among low-, intermediate-, and high-risk drinking groups was 7.6%, 11.0%, and 22.7%, respectively. Compared with the low-risk group, the adjusted odds ratio for sarcopenia was 4.29 (95% confidence interval, 1.87-9.82) in the high-risk drinking group. The respective odds ratio for the intermediate-risk group was 2.25 (95% confidence interval, 1.06-4.77). All of the domains of the AUDIT, including hazardous drinking, alcohol dependence, and harmful alcohol drinking, were associated with a higher risk for sarcopenia. Clinical Implications Loss of muscle mass is part of the normal aging process. Overall, the loss of muscle mass begins in middle age and advances at a rate of 6% per decade. Risk factors for sarcopenia include hypertension, hypercholesterolemia, physical activity, smoking, and malnutrition. The current study demonstrates that intermediate- and high-risk alcohol consumption was independently associated with a higher risk for sarcopenia among postmenopausal women. Implications for the Healthcare Team: Adults should be routinely screened for harmful drinking behaviors, and the healthcare team should consider sarcopenia a sign of harmful drinking among women. CME Test 3 ",
				"clientUrl": "/viewarticle/882688",
				"creditType": ["CME", "Nurse CE", "ABIM MOC"],
				"cmeFlag": "CME / ABIM MOC / CE",
				"leadConceptId": 1429,
				"leadConcept": "Menopause",
				"concept": ["Health Education and Counseling", "OB/GYN and Women's Health Nursing", "Alcohol Use", "Sarcopenia"],
				"leadSpecialtyId": 16,
				"leadSpecialty": "Ob/Gyn & Women's Health",
				"allSpecialties": ["Ob/Gyn & Women's Health", "Medscape Today", "Internal Medicine", "Diabetes & Endocrinology", "Nursing", "Family Medicine/Primary Care", "Public Health & Prevention"],
				"contentGroup": "Clinical Review",
				"origContentType": "Clinical Brief",
				"contentType": ["News"],
				"description": "Alcohol consumption was associated with a higher risk for sarcopenia in a new study.",
				"legacyID": 882688,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Can Heavy Drinking Increase Postmenopausal Sarcopenia Risk?",
				"suppressComment": "T",
				"creditsAvailable": ["PhysiciansFamily Physicians:AMA PRA Category 1 Credit(s)™AAFP Prescribed credit(s):0.25", "US Physicians:Points for ABIM MOC:0.25", "Nurses:ANCC Contact Hour(s):0.25", "Physicians:AMA PRA Category 1 Credit(s)™:0.25"],
				"maxCredits": [0.25],
				"publicationDate": 1499749200000,
				"postingDate": 1499749200000,
				"_version_": 1573508890005340160,
				"last_index_date": 1500615015038
			}, {
				"id": "pdctm_0901c79180b4eae1",
				"activeCME": 1,
				"activityExpirationDate": 1524200400000,
				"authors": ["Kezhen Fei", " Jesica S. Rodriguez-Lopez", "  Marcel Ramos", " Nadia Islam", " Chau Trinh-Shevrin", " Stella S. Yi", " Claudia Chernov", " Sharon E. Perlman", " Lorna E. Thorpe"],
				"body": "Abstract and Introduction Abstract and Introduction Abstract Introduction. Racial/ethnic minority adults have higher rates of hypertension than non-Hispanic white adults. We examined the prevalence of hypertension among Hispanic and Asian subgroups in New York City. Methods. Data from the 2013–2014 New York City Health and Nutrition Examination Survey were used to assess hypertension prevalence among adults (aged ≥20) in New York City (n = 1,476). Hypertension was measured (systolic blood pressure ≥140 mm Hg or diastolic blood pressure ≥90 mm Hg or self-reported hypertension and use of blood pressure medication). Participants self-reported race/ethnicity and country of origin. Multivariable logistic regression models assessed differences in prevalence by race/ethnicity and sociodemographic and health-related characteristics. Results. Overall hypertension prevalence among adults in New York City was 33.9% (43.5% for non-Hispanic blacks, 38.0% for Asians, 33.0% for Hispanics, and 27.5% for non-Hispanic whites). Among Hispanic adults, prevalence was 39.4% for Dominican, 34.2% for Puerto Rican, and 27.5% for Central/South American adults. Among Asian adults, prevalence was 43.0% for South Asian and 39.9% for East/Southeast Asian adults. Adjusting for age, sex, education, and body mass index, 2 major racial/ethnic minority groups had higher odds of hypertension than non-Hispanic whites: non-Hispanic black (AOR [adjusted odds ratio], 2.6; 95% confidence interval [CI], 1.7–3.9) and Asian (AOR, 2.0; 95% CI, 1.2–3.4) adults. Two subgroups had greater odds of hypertension than the non-Hispanic white group: East/Southeast Asian adults (AOR, 2.8; 95% CI, 1.6–4.9) and Dominican adults (AOR, 1.9; 95% CI, 1.1–3.5). Conclusion. Racial/ethnic minority subgroups vary in hypertension prevalence, suggesting the need for targeted interventions. Introduction Hypertension is a major risk factor for cardiovascular disease and worsens outcomes for people with diabetes or kidney disease. [1–4] The 1960s Charleston Heart Study and other cohort studies show higher prevalence of hypertension among black participants than among white participants. [5,6] More recently, National Health and Nutrition Examination Survey (NHANES) data from 1999–2010 showed a higher prevalence of hypertension among black adults than among white or Mexican American adults (black men [39.6%], white men [29.8%], Mexican American men [26.4%], black women [43.1%], white women [26.9%], Mexican American women [27.7%]), with stable rates of disparities from 1999 to 2010. [7] In 2011–2014, NHANES oversampled Asian and Hispanic participants to produce reliable estimates; hypertension prevalence among non-Hispanic Asian adults (24.9%) and Hispanic adults (25.9%) was similar and lower than the prevalence among non-Hispanic white adults (28.0%). [8] To our knowledge, few population-based studies have examined differences among Hispanic and Asian subgroups. Recent health examination data collected from racially/ethnically diverse urban settings could shed light on the heterogeneity of data on hypertension prevalence among racial/ethnic subgroups. For example, the Hispanic Community Health Study/Study of Latinos is a longitudinal cohort of 16,415 urban Hispanic adults in the United States. Although the study is not population-based, it estimated the prevalence of hypertension at its Bronx site as 29.5% among Dominicans, 28.6% among Puerto Ricans, and 26.6% among Central Americans, and a significantly lower prevalence of 13.3% among Mexican Americans. [9] The Multi-Ethnic Study of Atherosclerosis also found lower hypertension prevalence among Mexican Americans than among other Hispanic subgroups. [10] In 2004, the New York City Health and Nutrition Examination Survey (NYC HANES), modeled after NHANES, measured blood pressure in a population-based sample of adults in New York City aged 20 or older [11] . NYC HANES 2004 was the first population-based study to examine differences in hypertension prevalence among Asian and Hispanic subgroups. Following NHANES measurement protocols, researchers measured the blood pressure of participants in clinics using a mercury manometer and estimated an hypertension prevalence of 25.5% among adults in New York City overall, 32.8% among black adults, 26.4% among Hispanic adults, 24.7% among Asian adults, and 21.1% among non-Hispanic white adults. The objective of our study was to describe the prevalence of hypertension among adults in major racial/ethnic minority population groups and among Asian and Hispanic subgroups using data from NYC HANES 2013–2014 before and after adjusting for demographic characteristics. Because of the rapidly changing composition of the population in New York City, monitoring the prevalence of hypertension by racial/ethnic categories is important. We hypothesized that the prevalence of hypertension among adults in Hispanic and Asian subgroups would differ from the prevalence among non-Hispanic white adults. Methods Methods NYC HANES is a population-based, cross-sectional survey of adults in New York City. Data for the most recent survey were collected from August 2013 through June 2014; details of the study design are available elsewhere. [12] Briefly, a probability-based, 3-stage clustering design was used to select households in New York City. The survey included 3 components: an in-person interview, a physical examination (to measure blood pressure, pulse, height, weight, and waist circumference), and biological specimen collection. All participants gave informed consent. The survey was conducted in English, Spanish, Russian, Mandarin, or Cantonese, with telephone translation available for other non–English-speaking participants. The study protocol was approved by the institutional review boards of the City University of New York School of Public Health, the New York City Department of Health and Mental Hygiene, and RTI International. The overall response rate was 36%; 1,527 individuals completed the survey. Differences between unweighted and weighted demographic distributions were modest and nonsignificant, suggesting that the final sample was broadly representative of the city’s population. [12] For this analysis, we included all participants in NYC HANES who were not pregnant and had either valid blood pressure measurements or information on hypertension diagnosis or medication. Twenty pregnant women were excluded, and 31 participants were excluded because of either invalid blood pressure measurements or missing information on hypertension diagnosis or medication; on average, these 31 participants did not differ from the final sample on age, sex, race/ethnicity, body mass index (BMI), or education. The final analytic sample consisted of 1,476 adults. Before the study, we calculated that the sample size required to estimate the prevalence of a condition with a prevalence range similar to that of hypertension (25%–30%) with a margin of error of ±4.0% was 1,800 to 1,935 participants. To compare NHANES 2013–2014 data on hypertension prevalence with national data, we downloaded national data from the Centers for Disease Control and Prevention and examined differences by sex, income, and education. [13] Measures The instrument used to measure blood pressure in the 2013–2014 NYC HANES differed from that used in 2004. Instead of a mercury sphygmomanometer, [11] an automatic inflatable digital blood pressure monitor with 4 cuff sizes (LifeSource UA-789AC, A&D Medical Ltd) was used to measure blood pressure in the participant’s home [12] ; 3 measurements were taken for each participant. The mean of the second and third values was used as the final measurement. Blood pressure measurements determined by this device were validated as equivalent by the American National Standards Institute to measurements determined by an electronic sphygmomanometer. [14] Hypertension was defined as systolic blood pressure of 140 mm Hg or more, diastolic blood pressure of 90 mm Hg or more, or self-reported hypertension diagnosis and current use of prescribed antihypertensive medication. [15] Weight was measured to the nearest 0.1 kg and height to the nearest 0.5 cm. BMI was calculated as weight in kilograms divided by height in meters squared (kg/m 2 ); BMI categories were classified according to NHANES protocol. [16] BMI in our sample ranged from 13 to 69. Heavy alcohol use was defined as more than 2 drinks per day and every day for men, and more than 1 drink per day and every day for women. One drink was explained to participants as a 12-ounce beer, a 5-ounce glass of wine, or one-and-a-half ounces of liquor. Current smoker was defined as someone who answered yes to \"Have you smoked at least 100 cigarettes in your entire life\" and stated that he or she currently smokes some days or every day. Categorization of a participant’s major racial/ethnic group was based on the participant’s responses to the following questions, which are used in NHANES [16] : \"Do you consider yourself as Hispanic/Latino?\" and \"What race/races do you consider yourself?\" Adults were categorized into 5 mutually exclusive major race/ethnicity groups: non-Hispanic white (white), non-Hispanic black (black), non-Hispanic Asian (Asian), Hispanic, and non-Hispanic other. Seventy \"non-Hispanic other\" adults were excluded from group analysis because of small sample size. Asian adults were further categorized as East/Southeast Asian or as South Asian according to responses to questions about their Asian origin and ancestry. East/Southeast Asian adults included those of Chinese, Japanese, Korean, Filipino, Laos, Thai, Cambodian, and Vietnamese origin. South Asian adults included those of Bangladeshi, Indian, East Indian, Asian Indian, Nepalese, Pakistani, Sri Lankan, and Goan origin. Hispanics were further categorized as Puerto Rican, Dominican, or Central/South American based on responses to questions about their Hispanic/Latino origin or ancestry. Central/South American adults included those of Mexican, Cuban, Costa Rican, Guatemalan, Honduran, Nicaraguan, Panamanian, Salvadoran, Argentinean, Bolivian, Chilean, Colombian, Ecuadorian, Paraguayan, Peruvian, Uruguayan, Venezuelan, and other Central and South American origin or ancestry. Statistical Analyses Statistical analyses were weighted to adjust for the complex sampling design, nonresponse, and poststratification. A design poststratification weight was created to represent the New York City population by age, sex, race/ethnicity, borough of residence, education, and marital status, using the American Community Survey 2013. [17] Weights were then further adjusted for item-level nonresponse. [12] SAS version 9.4 (SAS Institute, Inc) was used to perform all analyses. Prevalence estimates were age standardized to the 2000 US population. [18] Relative standard errors were calculated for each estimate to assess reliability; none, however, were above 30%. Rao–Scott χ 2 tests were used for bivariate comparisons. Multivariable logistic regression was used to assess racial/ethnic differences by adjusting for age, sex, education, and BMI. We did not estimate changes in hypertension prevalence between the 2004 NYC HANES and the 2013–2014 NYC HANES because each survey used a different method for measuring blood pressure. Effect modification between race and sex, education, and BMI on hypertension was assessed by adding individual interaction terms in multivariable logistic regression; we performed further stratified analysis only if a significant interaction was found. Statistical significance level was set at .05. Results Results The racial/ethnic distribution of NYC HANES 2013–14 was diverse: 35.0% were white, 27.1% were Hispanic, 21.3% were black, and 14.2% were Asian. Asian participants were younger than those in other major racial/ethnic groups ( P = .01) ( Table 1 ). A greater proportion of Hispanic adults than adults in other major racial/ethnic groups had less than a high school education and less than $20,000 in annual household income ( P < .001). We found a higher proportion of women among black adults than that among white adults ( P = .03). A greater proportion of white adults than adults in other major racial/ethnic groups had private health insurance coverage ( P < .001). Black and Hispanic adults had a greater prevalence of obesity than did white or Asian adults (black, 36.9% and Hispanic, 36.8% vs white, 27.6% and Asian, 14.9%; P < .001). The prevalence of smoking did not significantly differ across major racial/ethnic groups. Within Hispanic and Asian subgroups, demographic profiles and health behaviors varied. Among Hispanic adults, the largest subgroup was from Central and South America (38.4%), followed by Puerto Rico (36.0%), and the Dominican Republic (23.1%). Among Asian adults, 62.4% were of East/Southeast Asian origin, and 31.8% were of South Asian origin. Among Hispanic subgroups, adults from the Dominican Republic had the greatest proportion of women ( P = .004) and the greatest percentage of adults with less than a high school education ( P = .05). Compared with other Hispanic subgroups, a greater proportion of Dominicans had Medicaid/Medicare or other government health insurance and a lower proportion had private health insurance. Central/South Americans had the greatest proportion of uninsured adults ( P = .002). A greater proportion of Puerto Rican adults were current smokers compared with Dominican and Central/South American adults (Puerto Rican, 32.9% vs Dominican, 7.5%, and Central/South American, 8.8%; P < .001). Among Asians, East/Southeast Asian adults had a greater proportion of adults with more than a high school education than South Asians (71.6% vs 52.2%, P < .001). A greater proportion of South Asian adults were obese compared with East/Southeast Asian adults (18.4% vs 9.9%, P = .001). The overall prevalence of hypertension among adults in New York City was 33.9% and increased with age ( Table 2 ). Prevalence was 10.4% among adults aged 20 to 39, 40.2% among those aged 40 to 59, and 64.0% among those aged 60 or older. After age standardization, men were slightly more likely than women to have hypertension (36.2% vs 31.8%, P = .01). White adults had a significantly lower rate of hypertension than black, Asian, or Hispanic adults: the age-standardized prevalence was 27.5% for white, 43.5% for black, 38.0% for Asian, and 33.0% for Hispanic adults. Age-standardized hypertension prevalence was significantly higher among adults from South Asia (43.0%), East/Southeast Asia (39.9%), and the Dominican Republic (39.4%) than among white adults (27.5%) ( P < .001). In multivariate logistic regression, after adjusting for age, sex, education, and BMI, black and Asian adults had significantly greater odds of hypertension than whites (black, adjusted odds ratio [AOR], 2.6; 95% CI, 1.7–3.9; Asian, AOR, 2.0; 95% CI, 1.2–3.4), but adjusted odds for Hispanic and white adults were similar ( Table 3 ). After adjustment, Puerto Rican, Central/South American, and South Asian adults had odds of hypertension similar to those for whites, but Dominican adults had nearly twice the odds of white adults (AOR, 1.9; 95% CI, 1.1–3.5). East/Southeast Asian adults had the greatest odds of hypertension, nearly 3 times that of white adults (AOR, 2.8; 95% CI, 1.6–4.9). Figure. Prevalence of age standardized hypertension by major racial/ethnic group, Hispanic and Asian subgroups, and body mass index, New York City Health and Nutrition Examination Survey, 2013–2014. Relative standard errors for estimates were <30% for all races and ethnicities, except normal/underweight Dominicans (33%). We could not produce reliable estimates for South Asians in the overweight and obese categories, so no bars appear for those categories. Figure. A significant interaction ( P = .002) between race and BMI indicated a potential differential effect of BMI on hypertension across racial/ethnic groups. After stratifying analyses by BMI group, we found that prevalence of hypertension increased monotonically as BMI increased among white, black, and Hispanic adults but not among Asian adults (Figure). In the normal/underweight category ( Table 3 ), hypertension prevalence among black, Hispanic, and Asian adults differed significantly from prevalence among white adults. Among normal/underweight people, non-Hispanic black (AOR, 6.6; 95% CI, 2.7–16.0) and Asian adults (AOR, 5.8; 95% CI, 2.3–14.9) had approximately 6 times greater odds of hypertension than white adults, whereas Hispanics had 3.5 (95% CI, 1.4–8.7) times greater odds of hypertension than white adults. Normal/underweight East/Southeast Asian adults had the greatest odds of hypertension (AOR, 7.0; 95% CI, 2.5–19.3) compared with normal/underweight white adults. Normal/underweight Central/South Americans had 4.5 times greater odds (95% CI, 1.4–14.3), and Puerto Ricans and South Asians had 3.6 times greater odds (95% CI, 1.0–12.4 for Puerto Ricans; 1.1–11.8 for South Asians) of hypertension than normal/underweight white adults. Among overweight adults, only black adults (AOR, 2.6; 95% CI, 1.3–4.8) and East/Southeast Asian adults (AOR, 2.7; 95% CI, 1.2–6.4) had a significantly higher prevalence of hypertension than white adults. Among obese adults, we found no differences in hypertension between white adults and adults in the other 3 major racial/ethnic groups; among subgroups, only obese Central/South American adults had lower odds of hypertension than obese white adults (AOR = 0.4; 95% CI, 0.2–0.9). Discussion Discussion We estimated hypertension prevalence for racial/ethnic groups using a population-based sample of adults in an ethnically/racially diverse urban setting. In addition to confirming a greater prevalence of hypertension among black adults, we found substantial differences among racial/ethnic groups, even after adjusting for BMI, age, and sociodemographic characteristics. In particular, we observed significantly greater hypertension prevalence among Asian adults than among white adults. We also found that, once subgroup differences in age, education, gender and BMI were taken into account, larger proportions of adults from East/Southeast Asia and from Dominican Republic had hypertension, and differences in hypertension prevalence among racial/ethnic subgroups was especially pronounced among normal/underweight adults. Our study found greater prevalence of hypertension among Hispanic adults in New York City than Yoon et al found in a national sample of Hispanic adults (33.0% vs 25.9%). [8] Hispanic New Yorkers differ from Hispanic Americans elsewhere both in their country of origin and in income. Whereas 44.2% of Hispanic adults participating in NYC HANES had an annual household income less than $20,000 in 2013–2014, only 26.8% of Hispanics participating in NHANES had annual household income less than $20,000 in 2013–2014. Low socioeconomic status is associated with a greater risk of hypertension. [19,20] Moreover, the Hispanic Community Health Study/Study of Latinos showed that age-adjusted hypertension prevalence among Hispanic subgroups varied significantly among cities. For example, Central/South Americans in Chicago had significantly lower prevalence of hypertension than Central/South Americans in the Bronx or Miami. [9] Our study found that Dominican adults had a significantly higher prevalence of hypertension than white adults, consistent with other community- and population-based studies showing greater prevalence of hypertension among Dominicans than among whites. [9,21,22] We also found hypertension prevalence to be high among Puerto Rican adults, but the disparity between Puerto Rican adults and white adults was not as marked as the disparity between Dominican adults and white adults, especially after adjusting for BMI. Our study found significantly greater prevalence of hypertension among Asian adults in New York City than Yoon et al found among Asian adults in a national sample (38.0% vs 24.9%). [8] NYC HANES estimates of hypertension prevalence among Asian subgroups, however, were similar to estimates in the Multi-Ethnic Study of Atherosclerosis and the Mediators of Atherosclerosis in South Asians Living in America study (MASALA), community-based cohort studies carried out in the San Francisco Bay area and around Chicago. Hypertension prevalence among Chinese adults in our study was 35.6%, compared with 39% in the Multi-Ethnic Study of Atherosclerosis, and our hypertension estimate for South Asian adults was 43.0%, compared with 41% in MASALA. [23,24] Higher hypertension prevalence among Asian adults in New York City than among Asian adults nationally may be explained by differences in country of origin or in socioeconomic characteristics. [25] Our study found that 29.5% of Asian adults had annual household income less than $20,000 and 37.3% had only a high school diploma or less. In contrast, only 12% of Asians participating in NHANES had annual household income less than $20,000 and only 27% had only a high school diploma or less. Asian adults in New York City had a significantly higher prevalence of hypertension than white adults. This elevated prevalence corresponds with elevated mortality from hypertensive heart disease and cerebrovascular disease, especially hemorrhagic stroke, among Asian Americans compared with white Americans. [26] Unadjusted hypertension prevalence was particularly high among South Asian adults in our study, but when we accounted for age, education, and obesity, the prevalence of hypertension was highest among East/Southeast Asian adults. The odds of hypertension among nonoverweight Asian adults was greater than among nonoverweight white adults, suggesting that Asians are more vulnerable to hypertension at lower BMI, similar to the phenomenon observed with diabetes. [27] Two other studies found high rates of hypertension among nonoverweight Asian adults. [28,29] Clinicians should be aware that Asians may be at risk for hypertension and hypertension-related disease even at normal BMI. Furthermore, NHANES shows that Asian Americans have 1) lower levels of awareness of hypertension when their disease is diagnosed and 2) lower levels of adherence to hypertension medication than white or black Americans have. [30] Because of the disproportionate share of death caused by cardiovascular and cerebrovascular disease among Asian American adults, screening and education are needed. Strengths of our survey include its population-representativeness, objective measures of blood pressure, and the use of multiple languages in interviewing and examining participants to ensure inclusion of New York City’s diverse racial/ethnic minority populations. One limitation was the small sample size for some racial/ethnic subgroups, requiring us to combine certain subgroups (such as Mexicans, other Central Americans, and South American) to ensure reliability. Although the sampling design and statistical weighting process reduced the risk of selection bias, eligible participants who completed the study may have differed from those who did not. The distribution of unweighted demographic characteristics of our study participants was similar to census distributions. [12] Finally, this study was cross-sectional, precluding any ability to infer cause-and-effect between characteristics of survey participants and prevalence of hypertension. Our study underscores the need to disaggregate data for subgroups of Hispanic and Asian populations; overall population data may mask differences among subgroups. Targeted strategies for hypertension prevention and treatment are needed for various racial/ethnic subgroups, taking into account cultural practices, BMI-specific risks, and community awareness and support. Education for health care providers is also needed to raise awareness of subgroup differences and increase hypertension detection. The use of community health workers and the coordination of care can increase knowledge of cardiovascular disease and improve management of hypertension in racial/ethnic minority groups. [25,31] Improved screening for hypertension, increased awareness of risk factors, and better hypertension management could mitigate the burden of hypertension on vulnerable racial/ethnic minority populations. ",
				"clientUrl": "/viewarticle/878634",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 281,
				"leadConcept": "Hypertension",
				"concept": ["Preventive Medicine", "Cardiovascular Risk Management", "Racial and Ethnic Disparity", "Chronic Disease"],
				"leadSpecialtyId": 42,
				"leadSpecialty": "Public Health & Prevention",
				"allSpecialties": ["Public Health & Prevention", "Cardiology", "Internal Medicine", "Family Medicine/Primary Care"],
				"contentGroup": "Journal Article",
				"origContentType": "Journal Article",
				"contentType": ["Journal Article"],
				"description": "A new study reveals surprising racial and ethnic differences in the prevalence of hypertension.",
				"legacyID": 878634,
				"pubDisplay": "Prev Chronic Dis",
				"siteOn": 2003,
				"title": "Racial and Ethnic Subgroup Disparities in Hypertension Prevalence, New York City Health and Nutrition Examination Survey, 2013–2014",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/PCD-thumb.jpg"],
				"publicationDate": 1492664400000,
				"postingDate": 1492664400000,
				"_version_": 1573508896769703936,
				"last_index_date": 1500615021485
			}, {
				"id": "pdctm_0901c79180a35967",
				"activeCME": 1,
				"activityExpirationDate": 1504933200000,
				"authors": ["Lars Rydén"],
				"body": "Introduction The European Association for the Study of Diabetes (EASD) meeting takes place in Munich, Germany, from September 12 to 16, 2016. [1] The EASD 52nd Annual Meeting is one of the largest international diabetes conferences, covering basic and clinical science, comprising symposia, lectures and abstracts (1167 abstracts were accepted). Furthermore, 12 industry-supported symposia will be held. [1] With the inclusion of the most cutting-edge development in basic research and the latest advances of clinical management in the field of diabetes, this year’s meeting is not expected to disappoint. Following the impressive and surprising results presented at last year’s EASD meeting for empagliflozin and its beneficial effects on cardiovascular (CV) outcomes in patients with type 2 diabetes (T2DM), attendees are looking forward to further updates and analyses from the upcoming presentation title, \"EMPA-REG OUTCOME: One Year Later\" (Friday, September 16). [1] Furthermore, although the results of the LEADER study were initially presented at the 76 th Scientific Sessions of the American Diabetes Association (ADA), the results will be reported again at this year’s EASD meeting (Thursday, September 15). In addition, results of a third, long-term CV outcome trial (CVOT), SUSTAIN 6, are eagerly awaited (Friday, September 15). [1] Risk for CV Disease in People With T2DM A majority of patients with T2DM either die from or acquire serious manifestations of CV disease. [2] The risk of a patient with T2DM suffering a major adverse cardioarvascular event (MACE) of either myocardial infarction (MI), stroke, or heart failure (HF) and subsequent CV death is more than double that of a person without T2DM. [2-4] Furthermore, kidney (more than a third of patients with T2DM have chronic kidney disease) and eye problems due to microvascular complications are highly prevalent in patients with T2DM. [5] T2DM is a complex metabolic disorder with decreased sensitivity to insulin as an important part and endothelial dysfunction, increased thrombogenicity and dyslipidemia as other features. These perturbations contribute to the development and progression of atherosclerosis. [2] Patients with insulin resistance but who do not present with T2DM are also at increased risk for CV disease. [2] Contribution of Glucose-lowering Medications to CV Risk The evidence for a beneficial effect of blood glucose lowering on macrovascular events (ie, MACE) is very limited, in particular when studied over a relatively short time period. [6] In the landmark, long-term UK Prospective Diabetes Study, where patients were followed for up to 20 years, a significant effect on CV mortality emerged. [7,8] In contrast, several other large clinical trials, including the ACCORD, ADVANCE, and VADT trials failed to show significant benefits on lowering the incidence of macrovascular events. [9-11] Lifestyle changes (diet, exercise, not smoking) and controlling dyslipidemia and high blood pressure, with the use of statins and antihypertensive medications respectively, are thought to be proportionately more important than glycemic control in reducing MACE events in patients with T2DM. [2,12,13] Nevertheless, despite these measures, there remains an unmet clinical need to reduce CV mortality, with the prognosis for patients with T2DM considerably worse than for patients without diabetes. [2,3,6] Majority of CVOTs Have Demonstrated Neutral Effects In 2008, the United States Food and Drug Administration (FDA) recommended that new glucose lowering medicines for T2DM should undergo CVOTs to establish their CV safety, following reports that some antihyperglycemic drugs may cause CV harm. [14] It should be emphasized that such CVOTs are designed as safety -- not efficacy -- trials and as such the primary objective is to exclude CV side effects rather than confirm a beneficial impact on mortality and morbidity. [3] Not surprisingly, the majority of CVOTs have shown neutral effects (Table 1). [3,4,15] Noninferiority was demonstrated for insulin glargine (ORIGIN), various dipeptidyl peptidase-4 (DPP-4) inhibitors (SAVOR-TIMI, EXAMINE, TECOS), and the glucagon-like peptide-1 receptor agonist (GLP-1 RA), lixisenatide (ELIXA). [3,4] CV safety was confirmed, although for saxagliptin and alogliptin, HF rates were higher and warnings have been added to the prescribing information. [16] None of these studies demonstrated cardioprotective benefit. [3,4] Table 1. Major CVOTs With Glucose Lowering Medications in Patients With T2DM at High Risk of a CV Event Trial Name Agent/ comparator N Primary Endpoint Follow-Up End of Trial HbA1c (%) Primary Outcome HR (95% CI) ORIGIN Insulin glargine/ conventional 12,537 3-point MACE 6.2 years Insulin 6.2 Control 6.5 Neutral HR 1.02 (0.94 to 1.11) SAVOR- TIMI 53 Saxagliptin/ placebo 16,492 3-point MACE 24 months Saxagliptin 7.7 Placebo 7.9 Neutral HR 1.00 (0.89 to 1.12) EXAMINE Alogliptin/ placebo 5380 3-point MACE 18 months Alogliptin 7.7 Placebo 8.0 Neutral HR 0.96 (-1.16) TECOS Sitagliptin/ placebo 14,671 4-point MACE 36 months Sitagliptin 7.1 Placebo 7.4 Neutral HR 0.98 (0.99 to 1.08) ELIXA Lixisenatide/ placebo 6068 4-point MACE 25 months Lixisenatide 7.4 Placebo 7.6 Neutral HR 1.02 (0.89 to 1.17) EMPA-REG OUTCOME Empagliflozin/ placebo 7020 3-point MACE 37 months Empagliflozin 7.8 Placebo 8.2 Superior to placebo HR 0.86 (0.74 to 0.99) LEADER Liraglutide/ placebo 9340 3-point MACE 46 months Liraglutide 7.7 Placebo 8.1 Superior to placebo HR 0.87 (0.78 to 0.97) 3-point MACE = composite of CV death and nonfatal MI or stroke; 4-point MACE = composite of CV death, nonfatal MI or stroke and hospitalization for unstable angina; CI = confidence interval; CVOT = cardiovascular outcomes trial; CV = cardiovascular; HbA1c = glycated hemoglobin; HR = hazard ratio; MI = myocardial infarction; T2DM = type 2 diabetes mellitus Sources: Ryden L et al [3] ; Sattar N, et al [4] ; and Marso SP, et al. [15] CVOTs Demonstrating Significant Reductions In CV Risk EMPA-REG OUTCOME Empagliflozin is a sodium-glucose cotransporter 2 (SGLT2) inhibitor. In the EMPA-REG OUTCOME trial (randomized, double-blind, placebo-controlled; median duration of treatment 2.6 years; median observation time 3.1 years.), the primary outcome (3-point MACE; death from CV causes, nonfatal MI, or nonfatal stroke) was significantly reduced by 14% in the pooled empagliflozin group (10 or 25 mg; no dose related difference in outcome) vs placebo. [17] Concomitant risk reducing therapy was well managed with a vast majority of patients treated with statins and renin-angiotensin-aldosterone (RAAS) inhibitors, and aspirin was used when appropriate. [17] The study protocol allowed adjustment of glycemic agents after 12 weeks at the discretion of the attending physician. This explains why glucose control between the groups was similar by the end of the trial (less than 0.4% difference in glycated hemoglobin [HbA1c] between groups). [17] There were remarkable reductions in CV mortality (38%), hospitalizations for HF (35%), and total mortality (32%). These effects that indeed came as a surprise were evident already within a few months after study start were well maintained. The observed differences between the placebo and empagliflozin arms increased progressively over the 3 year treatment period. [2,16] There was no significant change in typical atherothrombotic events (ie there was only a minor reduction of MI and a trend toward higher rates of stroke). [17,18] The rapid onset of action, with no beneficial effect on MI or stroke, strongly suggests that the positive improvements in CV risk factors (improved blood glucose control, weight loss, decreased blood pressure, increased high density lipoprotein cholesterol [HDL-C], decreased uric acid) were not the mechanism by which empagliflozin had such profound effects on CV mortality. [2,3,5,6,17-21] EMPA-REG OUTCOME: HF Results More than 20% of patients with T2DM greater than 65 years of age suffer from HF. [20] These patients have a truly poor prognosis, with median survival estimated at approximately 4 years. [20] Subgroup analysis from the EMPA-REG OUTCOME trial for patients with T2DM and HF showed that empagliflozin caused a 34% reduction in HF hospitalization or CV death. [20] Empagliflozin had similar efficacy in patients diagnosed with or without HF at baseline and independently of glucose-lowering medications or medicines used to treat HF. [20] Empagliflozin also significantly reduced all-cause hospitalization by 11%. Furthermore, empagliflozin reduced the need for the introduction of loop diuretics by 38%. The majority of patients were treated with antihypertensive drugs, with empagliflozin providing additional benefit over standard care. It should be noted that empagliflozin is the only glucose lowering drug which has been shown to improve HF outcomes in patients with T2DM. [20] Indeed, following these results, HF clinical guidelines have been updated to include empagliflozin as a treatment option in patients with T2DM to reduce hospitalization for HF. [22] EMPA-REG OUTCOME: Renal Results The blood glucose lowering efficacy of empagliflozin depends on blood glucose concentration and renal function and is independent of insulin secretion or insulin resistance. However, a drug working on the kidney raises concerns about long-term adverse renal effects and renal function should always be assessed before starting a SGLT2 inhibitor and monitored on a regular (at least yearly) basis. [5] A prespecified secondary objective of the EMPA-REG OUTCOME trial was to examine the effects of empagliflozin on microvascular outcomes. In this respect almost all the beneficial effects were on renal outcomes. [5] Empagliflozin caused an initial decrease in eGFR which stabilized over time and reversed completely when treatment was stopped at study end, indicating that glomerular hemodynamic changes were not permanently reduced. [5] Empagliflozin significantly reduced the decline in renal function (Table 2). [5] The relative risk of incident or worsening nephropathy was significantly reduced by 39%, progression to macroalbuminuria by 38%, doubling of serum creatinine by 44%, and there was a 55% lower relative risk of renal-replacement therapy. There was no difference in the rate of incident albuminuria. [5] Notably, apart from an increase in genital infections in the empagliflozin group, overall adverse events were similar in both the empagliflozin and placebo groups. Adverse events associated with acute renal failure were higher in the placebo group. [5] The beneficial effects of empagliflozin on renal function were obtained in patients whose blood pressure was well controlled and who were on extensive use of RAAS blockers demonstrating a supplementary effect of empagliflozin to that of the RAAS-blockade. [5] Table 2. Risk Comparison for Renal Outcomes in the EMPA-REG OUTCOME Trial Renal Outcome Measure Patients (%) HR (95% CI) Empagliflozin Placebo Incident or worsening nephropathy 12.7 18.8 0.61 (0.53 to 0.70) Progression to macroalbuminuria 11.2 16.2 0.62 (0.54 to 0.72) Doubling of serum creatinine level accompanied by eGFR of ≤45 mL/min/1.73 m 2 1.5 2.6 0.56 (0.39 to 0.79) Initiation of renal replacement therapy 0.3 0.6 0.45 (0.21 to 0.97) Incident albuminuria in patients with a normal albumin level at baseline 51.5 51.2 0.95 (0.87 to 1.04) CI = confidence interval; eGFR = estimated glomerular filtration rate; HR = hazard ratio Source: Wanner C et el. [5] LEADER The hypothesis of the LEADER double-blind trial was that liraglutide would be noninferior to placebo with regard to the 3-point MACE primary outcome. [15] Over 9000 patients were randomized, with median time of exposure of 3.5 years and median follow-up of 3.8 years. A high dose of 1.8 mg liraglutide was used in a patient population where baseline mean duration of diabetes was 12.8 years, HbA1c was 8.7% and 81.3% had established CV disease. [15] After 3 years, HbA1c levels were 0.4% lower in patients treated with liraglutide. CV safety was noninferior but importantly, 3-point MACE was 13% lower in the liraglutide group and liraglutide was significantly superior at improving outcomes vs placebo. [15] CV mortality was reduced by 22% and death from any cause by 15%. There was a nonsignificant trend for nonfatal MI and nonfatal stroke to be lower in the liraglutide group. CV risk factor mean differences vs placebo were: body weight decreased 2.3 kg, systolic blood pressure decreased 1.2 mmHg, diastolic blood pressure increased 0.6 mmHg, and heart rate increased 3.0 bpm. Liraglutide reduced hospitalizations for HF, although the difference was not significant. [15] As with the EMPA-REG OUTCOME trial, the beneficial effects of liraglutide on microvascular outcomes were on renal outcomes (liraglutide slightly increased the rate of retinopathy events). Nephropathy events occurred in 5.7% of patients in the liraglutide group vs 7.2% in the placebo group (HR 0.78). [15] There was a significant difference in adverse events leading to permanent discontinuation with liraglutide (9.5%) vs placebo (7.3%), mainly accounted for by the increased incidence of gastrointestinal adverse events with liraglutide. [15] Patient baseline characteristics and populations were different between the EMPA-REG OUTCOME and LEADER trials, therefore, direct comparisons cannot be made between the trials. However, in contrast to the EMPA-REG OUTCOME trial, the CV beneficial effects of liraglutide required at least 1 year to start to emerge and were heterogeneous on the components of the 3-point MACE. [15] The LEADER results may relate to a decreased progression of atherosclerosis. [15] There may be other possibilities as well among them perhaps that severe hypoglycemia was significantly less common in the liraglutide group and such hypoglycemia is related to a worse outcome including mortality. SUSTAIN-6 A press release disclosed the top-line results for the effects of semaglutide on MACE events in the SUSTAIN-6 trial. [23] Semaglutide was administered subcutaneously once weekly, to approximately 3300 patients with T2DM for 2 years. Noninferiority for CV safety was achieved using a composite of a 3-point MACE and there was a significant reduction in CV risk. These outline results are intriguing, possibly suggesting a significant effect with semaglutide in a shorter time-frame than found in the LEADER study, and with a smaller sample size. Additional data and further explanations will be presented at the EASD Annual Meeting. [1] EMPA-REG OUTCOME: What’s Next? EMPA-REG OUTCOME was a successful clinical study, providing extensive data regarding the reduction in CV risk patients with T2DM treated with empagliflozin. On the other hand several unsolved questions have results. [24] Mechanistically, it is unclear how treatment with empagliflozin could produce such CV benefit. Several candidates can be taken into consideration: Hemodynamic changes: lowering both preload (reduction of blood volume) and afterload (reduced blood pressure and aortic stiffness) may account for the CV benefits observed [25] Shift in fuel metabolism: A rare adverse event with the use of SGLT2 inhibitors is ketoacidosis. [26] SGLT2 inhibitors increase fat oxidation, the end product of which is acetyl coenzyme A, which can then be shunted towards ketone body and β-hydroxybutyrate production, especially as SGLT2 inhibitors also increase glucagon secretion, which also causes increased ketone body production. [2,19] However, by increasing ketone body production moderately, so avoiding the adverse event of ketoacidosis, this theoretically could be advantageous in the failing heart. Patients with T2DM have insulin resistance and therefore do not utilize glucose efficiently. An alternative energy source is free fatty acids (FFAs), but these require more oxygen and this results in a decrease in cardiac efficiency and HF. Using ketone bodies or β-hydroxybutyrate is significantly more efficient and the heart extracts ketone bodies avidly [2,18,19] Increased oxygen delivery: SGLT2 inhibitors increase hematocrit, increasing oxygen delivery to tissues if blood flow remains constant [19] Uric acid: SGLT2 inhibitors decrease plasma uric acid, which would be expected to reduce blood pressure, prevent vascular damage and decrease renal microvascular complications [19] The potential mechanisms outlined above require further clinical study to improve our understanding of the relationship between empagliflozin treatment and CV risk reduction in patients with T2DM observed in EMPA-REG OUTCOME. Significant research presented at this year’s EASD Annual Meeting is expected to be devoted to uncovering these mechanisms, and determining which patients would be the most appropriate for treatment with SGLT2 inhibitors. Conclusion Following the close of the 2016 Annual Meeting of the EASD, there are several other CVOTs expected to report in the next few years, for SGLT2 inhibitors (dapagliflozin and canagliflozin), DPP-4 inhibitors (linagliptin), and GLP-1 RAs (exenatide once-weekly, dulaglutide). [27-32] Data from these trials will add to data that we currently have and help to further determine whether the CV benefits previously observed are therapeutic class effects or unique to each agent. Publication of recent clinical trials and the anticipation of future data make this a very exciting time for clinicians who manage patients with diabetes. ",
				"clientUrl": "/viewarticle/867765",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 1069,
				"leadConcept": "Type 2 Diabetes Mellitus",
				"concept": ["Diabetes Mellitus", "Diabetic Nephropathy", "Cardiovascular disease (CVD)", "Type 2 Diabetes Mellitus With Complications", "Heart Failure (HF)", "Coronary Artery Disease (CAD)", "Cardiovascular Risk Management", "Risk Management", "Adverse Effects", "Macrovascular Complications of Diabetes", "International Practice of Medicine", "Pharmacologic Adverse Events", "Primary and Secondary Prevention of Coronary Artery Disease", "Coronary Heart Disease Risk Factors", "Clinical Research", "Noninsulin Antidiabetic Drugs", "SGLT2 Inhibitor"],
				"leadSpecialtyId": 2,
				"leadSpecialty": "Cardiology",
				"allSpecialties": ["Cardiology", "Diabetes & Endocrinology", "Family Medicine/Primary Care", "Nephrology"],
				"origContentType": "Commentary",
				"contentType": ["Expert Commentary"],
				"description": "Dr Rydén highlights new clinical research being presented at the 2016 EASD annual meeting regarding CV risk management in T2DM.",
				"legacyID": 867765,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "CV Risk Management in T2DM: Latest Perspectives from EASD 2016",
				"suppressComment": "T",
				"creditsAvailable": ["Non-US Physicians:CPD:0.50"],
				"maxCredits": [0.5],
				"multimedia": ["/thumbnail_library/867765.jpg"],
				"publicationDate": 1473397200000,
				"postingDate": 1473397200000,
				"_version_": 1573508891964080128,
				"last_index_date": 1500615016908
			}, {
				"id": "pdctm_0901c79180ad42e8",
				"activeCME": 1,
				"activityExpirationDate": 1521090000000,
				"authors": ["Carlos Aguiar", " Anthony M. Heagerty"],
				"body": "Slide 1. Slide 1. Resistant Hypertension or Poor Patient Adherence? Tips to Gain Control Slide 2. Slide 2. Faculty Slide 3. Slide 3. HTN Burden of Disease [1,2] Slide 4. Slide 4. Importance of Appropriate HTN Treatment [3] Slide 5. Slide 5. Case Study: Michael Slide 6. Slide 6. Case Study: Michael (cont) Slide 7. Slide 7. Potential Reasons for Uncontrolled BP in Michael Slide 8. Slide 8. Case Study: Michael (cont) Slide 9. Slide 9. Resistant HTN: Definition [4,5] Slide 10. Slide 10. Causes of Resistant HTN [6] Slide 11. Slide 11. Medication Adherence and BP Management [7-9] Most patients with hypertension (HTN) have an asymptomatic condition It is important that patients understand the rationale for good adherence to antihypertensive therapy Good blood pressure (BP) control lowers their risk for cardiovascular (CV) events Consistent adherence, which results in good BP control, is key Slide 12. Slide 12. Factors Contributing to Nonadherence With Antihypertensive Medication [10] It is important that patients are engaged in their management and that the need for regular adherence with the prescribed regimen is emphasized Slide 13. Slide 13. Barriers to Adherence: Complex Medication Regimen [11,12] It is important to keep the regimens for the disease management as simple as possible Not only for BP management, but all concomitant comorbidities Risk factors for adverse events multiply Slide 14. Slide 14. Why It Is Important to Take Medications as Directed [9] Slide 15. Slide 15. Other Causes of Resistant HTN [6] Slide 16. Slide 16. Fixed-Dose Combination vs Free-Drug Combination: Effects on BP [13] Slide 17. Slide 17. Prevalence of First CV Event: Fixed-Dose Combination vs Free-Drug Combination* [14] Fixed-dose combinations generally result in better BP control compared with their free-drug combinations Slide 18. Slide 18. Healthcare Costs in Hypertensive Patients Treated With a Fixed-Dose Combination [15] In terms of costs, there is no question pharmacoeconomically that effective BP control with branded drugs is inevitably cheaper than actually treating the consequences of HTN Slide 19. Slide 19. Case Study: Final Recommendations for Michael Slide 20. Slide 20. Conclusions Slide 21. Slide 21. Thank You This content has been condensed for improved clarity. ",
				"clientUrl": "/viewarticle/874014",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 281,
				"leadConcept": "Hypertension",
				"concept": ["Uncontrolled Hypertension", "Hypertensive Cardiovascular Disease", "Increased Blood Pressure", "Cardiovascular disease (CVD)", "Coronary Artery Disease (CAD)", "Adherence", "Cost of Illness", "Costs and Cost Analysis", "Cardiovascular Risk Management", "Combination Drug Therapy", "Antihypertensive Agents", "Primary and Secondary Prevention of Coronary Artery Disease", "Coronary Heart Disease Risk Factors", "Clinical Research", "Patient History", "Chronic Disease", "Patient Assessment", "Resistant Hypertension"],
				"leadSpecialtyId": 2,
				"leadSpecialty": "Cardiology",
				"allSpecialties": ["Cardiology", "Family Medicine/Primary Care", "Nephrology"],
				"origContentType": "Roundtable",
				"contentType": ["Article/Courses"],
				"description": "Join Drs Aguiar and Heagerty as they discuss barriers related to medication adherence and blood pressure control in patients with hypertension.",
				"legacyID": 874014,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Resistant Hypertension or Poor Patient Adherence? Tips to Gain Control",
				"suppressComment": "T",
				"creditsAvailable": ["Non-US Physicians:CPD:0.25"],
				"maxCredits": [0.25],
				"multimedia": ["/thumbnail_library/874014.jpg"],
				"publicationDate": 1489554000000,
				"postingDate": 1489554000000,
				"_version_": 1573508890485587968,
				"last_index_date": 1500615015490
			}, {
				"id": "pdctm_0901c791809df9fc",
				"activeCME": 1,
				"activityExpirationDate": 1501563600000,
				"authors": ["Saul J. Karpen"],
				"body": "Slide 1. Slide 1. Pediatric Cholestatic Jaundice: Differential Diagnosis of Treatable Disorders Slide 2. Slide 2. A Common Clinical Challenge: Neonatal Jaundice -- Is It Physiologic or Pathologic? Jaundice is 1 of the more common clinical features in newborns Slide 3. Slide 3. Case: Full-Term Female Infant Slide 4. Slide 4. Neonatal Jaundice [1,2] Slide 5. Slide 5. Neonatal Jaundice (cont) Slide 6. Slide 6. Case (cont): Recurrence of Jaundice After Initial Improvement Breastfeeding often leads to physiologic jaundice Slide 7. Slide 7. Case (cont): Diagnosis -- Prolonged Neonatal Jaundice Slide 8. Slide 8. Prolonged Neonatal Jaundice: Breast Milk-Related Jaundice [3] Slide 9. Slide 9. Prolonged Neonatal Jaundice: Is It Noncholestatic or Cholestatic in Origin? [4] Breastfed infants can have liver disease Infants who are not breastfed can have jaundice Cholestatic jaundice is likely to be pathologic Some conditions can be treated, but if treatment is delayed, the outcomes are not as good Slide 10. Slide 10. Liver Disease in the Newborn Slide 11. Slide 11. Differential Diagnosis of Cholestasis in Newborns: Think Anatomic Slide 12. Slide 12. Differential Diagnosis of Cholestasis in Newborns (cont) Slide 13. Slide 13. Evaluating Prolonged Neonatal Jaundice: Visual Assessment Is Observer Dependent [6,7] Jaundice is clinically evident when total serum bilirubin level is 2.5 to 3.0 mg/dL (42 to 51 µmol/L) Slide 14. Slide 14. NASPGHAN/ESPGHAN Recommendations for Evaluation of the Potential for Cholestatic Liver Diseases [8] Slide 15. Slide 15. Evaluation of the Infant With Persistent Jaundice [9] Slide 16. Slide 16. Evaluation of the Infant With Persistent Jaundice (cont) [8] Do not rely on parent's report of stool or urine color; look yourself Slide 17. Slide 17. Physical Examination of the Infant With Persistent Jaundice: Head to Toe Slide 18. Slide 18. Physical Examination of the Infant With Persistent Jaundice: Head to Toe (cont) [8] Slide 19. Slide 19. Evaluation of the Infant With Persistent Jaundice: Additional Laboratory Tests Order obvious tests based on family history Order others, 1 test at a time; can take weeks to get result Use of gene panels is a more efficient approach Slide 20. Slide 20. Evaluation of the Infant With Persistent Jaundice: Additional Laboratory Tests (cont) Slide 21. Slide 21. Differential Diagnosis: Intrahepatic Cholestasis: Red Flags That Require Early Intervention Slide 22. Slide 22. Differential Diagnosis of Treatable Disorders: Single-Gene Defects: Identification and Early Intervention Can Make a Difference Signs and symptoms include: Poor growth Vitamin deficiencies (a lack of vitamin A, D, K, or E) Pale, foul-smelling stools Dark urine Enlarged liver or spleen Liver disease from an unknown cause Slide 23. Slide 23. Origins of Neonatal Cholestasis The γ-glutamyl transpeptidase (GGTP) level is low, which is indicative of a transporter gene defect α 1 -antitrypsin deficiency -- most common inherited liver disease in whites Slide 24. Slide 24. Emory Cholestasis 57 Gene Panel*: Only 1 Blood Sample Required to Identify Key Genes [10] There is a good probability that neonatal cholestasis is genetic in origin CLIA-approved laboratories with gene panel: 1 blood sample for all Can identify key genes for cholestasis with 1 blood test Slide 25. Slide 25. NASPGHAN/ESPGHAN Recommendations [8] Slide 26. Slide 26. NASPGHAN/ESPGHAN Recommendations (cont) [8] Slide 27. Slide 27. NASPGHAN/ESPGHAN Recommendations (cont) [8] Slide 28. Slide 28. NASPGHAN/ESPGHAN Recommendation: Consider Whether a Liver Biopsy Would Be Helpful [8] Slide 29. Slide 29. Liver Biopsy for Biliary Atresia: Does the Patient Need An Intraoperative Cholangiogram? [11] 100% sensitive, 76% specific [12] Can also identify fibrosis or cirrhosis in infants who were not evaluated early Slide 30. Slide 30. Biliary Atresia Slide 31. Slide 31. Therapies Are Available for Some Disorders Specific diagnoses can be made for specific gene defects Infants benefit because there are therapies for some There are no effective therapies for cholestasis in general Slide 32. Slide 32. Concluding Remarks: Take-Home Messages Slide 33. Slide 33. Thank you for participating in this activity. This content has been condensed for improved clarity. ",
				"clientUrl": "/viewarticle/864394",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 0,
				"concept": ["Newborn Jaundice", "Jaundice", "Liver Disease", "Liver", "Biliary Tract", "Biopsy", "Liver Biopsy", "Genetic Liver Disease", "Genetic Testing", "Genetics", "Neonatal Medicine", "Biliary Atresia", "Biliary Obstruction", "Cholestasis", "Conjugated Hyperbilirubinemia", "Diagnostic Liver Biopsy", "Patient Assessment"],
				"leadSpecialtyId": 9,
				"leadSpecialty": "Pediatrics",
				"allSpecialties": ["Pediatrics", "Medscape Today", "Gastroenterology", "Family Medicine/Primary Care"],
				"contentGroup": "Clinical Review",
				"origContentType": "Clinical Review",
				"contentType": ["Article/Courses"],
				"description": "Is the infant's jaundice noncholestatic or cholestatic? How do you determine?",
				"legacyID": 864394,
				"mediaFlag": "2",
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Pediatric Cholestatic Jaundice: Differential Diagnosis of Treatable Disorders",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:0.50"],
				"maxCredits": [0.5],
				"multimedia": ["/thumbnail_library/864394.jpg"],
				"publicationDate": 1470027600000,
				"postingDate": 1470027600000,
				"_version_": 1573508879564668928,
				"last_index_date": 1500615005084
			}, {
				"id": "pdctm_0901c79180a359f4",
				"activeCME": 1,
				"activityExpirationDate": 1506142800000,
				"authors": ["Stephan Stilgenbauer"],
				"body": "Case Study, Part 1 Narrator: Karl Robinson, a 70-year-old man, presented to his primary care physician 2 weeks ago complaining of mild fatigue and fever. Physical examination revealed large cervical and inguinal lymphadenopathies, the largest of which was 5 cm in diameter. His physician referred him to an oncologist who suspected chronic lymphocytic leukemia (CLL) and ordered blood tests, which showed several abnormalities: Hemoglobin = 9.2 g/dL Platelet count = 117 Normal lactate dehydrogenase, total bilirubin, and haptoglobin Absolute lymphocyte count = 52 x 10 9 /L with 85% small lymphocytes Mr Robinson is now returning to the clinic to discuss those results with his oncologist. Doctor: Hello again, Mr Robinson. How have you been feeling? Karl: I’m still very tired most of the time, but other than that nothing really out of the ordinary. Doctor: Have you experienced any fever or infections, or have you had night sweats or pain in the abdomen? Karl: [Trying to recall any such events] I don’t think so, no. Doctor: Good, that’s encouraging. We do have the results of the tests that we did, and overall they suggested that you might have chronic lymphocytic leukemia, or CLL. This diagnosis was confirmed by another test that looked at the type of circulating blood cells, called fluorescence flow cytometry. Karl: [ Alarmed ] Is CLL a kind of cancer? Doctor: Yes, that’s right. It affects the blood cells and bone marrow. Karl: So will I need to have chemotherapy? Doctor: CLL typically progresses quite slowly, and people who are in the early stages of the disease often don’t receive any treatment to start with. In your case, however, you are showing symptoms, including anemia -- likely due to bone marrow infiltration -- as well as the cervical and inguinal growths that we discussed at your last appointment. So these things mean that your leukemia is advanced. Karl: Does that mean it’s already too late for me to have treatment then? Doctor: No, not at all, Mr Robinson, but we should get you started on it sooner rather than later. Fortunately, there are several good treatments that can help control CLL. Karl: So I’ll start treatment immediately? Doctor: Well, we need to do some more testing to determine what would be the best treatment for you. We can get that started on that today; we should have the results quite quickly and then we can decide on the most suitable treatment. Karl: Alright. 3 Initial Assessment of Newly Diagnosed CLL Stephan Stilgenbauer, MD: Hello, I’m Dr Stephan Stilgenbauer, a professor in the department of internal medicine III at Ulm University in Germany. Before treating this patient for CLL, I would order cytogenetic testing for chromosome 17p deletion (del(17p)), as well as TP53 mutation. We want to be able to thoroughly explain treatment options to patients like Mr Robinson, and today cytogenetic testing is essential for informing the selection of appropriate CLL therapy. Slide 1. Slide 1. TP53 is one of the strongest prognostic markers in patients with CLL who receive current-standard first-line chemoimmunotherapy. [1] Genetic abnormalities involving 17p, which reflects lesions in the TP53 gene, are associated with the worst clinical prognosis. Fludarabine/cyclophosphamide/rituximab, the FCR regimen, is a standard initial treatment for young and fit patients with CLL. However, patients with del(17p) do not respond well to this regimen and have rapidly evolving disease, with a median survival of fewer than 3 years. [2] Other therapeutic options must therefore be considered in those individuals. Cases of TP53 mutation without del(17p) do occur, and these patients have a similar clinical course to those with del(17p). Slide 2. Slide 2. Other clinical features that I would consider when selecting treatment include the patient’s age, performance status, comorbidities, and current therapies. [3,4] In addition, I would order tests to ensure kidney and liver function are within acceptable limits, as this is important in determining drug dosage of potential therapies. Bone marrow biopsy is often performed in clinical trials, and it may be useful in determining the amount of CLL cell infiltration. However, it would not be essential in this patient because we can get all the information we need from the peripheral blood. We would only need it to confirm a complete response to treatment. Lymph node biopsy is not required to make the diagnosis of CLL, as we can do this from peripheral blood. A biopsy is indicated only if Richter transformation is suspected. [3,4] Mr Robinson’s physician now has the results of his 17p and TP53 tests, and is going discuss the treatment options with him. Case Study, Part 2 Doctor: [2 weeks later: Fade in mid-conversation] Let’s talk about the treatment options. You actually have several things in your favor. Your kidney function is good, you have no other diseases or health issues that I’m aware of, and you’re not taking any other medications. Karl: No, nothing. Doctor: During your first visit you said that the symptoms you’ve experienced don’t prevent you from doing all of the things that you ordinarily do. Karl: Not so far. Doctor: Your \"performance score,\" which measures how much the cancer affects your life, is 0. Taken together these things suggest that -- even though your leukemia is somewhat advanced, with treatment, you should do quite well. Karl: That’s encouraging. Will I be able to get started with treatment right away? Doctor: Yes. The genetic testing did not show any abnormalities that would affect your treatment at this stage, so you have a few options. Karl: Alright, what are they? Doctor: In general, there are 2 types of medication. One is traditional chemotherapy. That means you would come here and we would give you the drugs through an intravenous drip. You would receive treatment once every 4 weeks for a target of 6 cycles. Karl: Would I get sick and have all of those other things that people get with chemotherapy? Doctor: Most patients do have some side effects with chemotherapy. We typically give a combination of drugs called FCR. The good news is that you only have the chemotherapy for a finite period of time, and then it’s done. Many people have complete clearance of the leukemia cells, and that can last for several years. However, FCR does have a high rate of side effects, such as damage to healthy blood cells and infections. It can be especially difficult for older patients, and at 70 you’re not as young as you used to be. Karl: That sounds as though it would be pretty awful, but I suppose that once the treatment is over, I don’t have to worry about it again unless the leukemia comes back. Doctor: That’s true. There is also another chemotherapy called bendamustine that is also very effective and doesn’t usually have as severe side effects as FCR. The other option would be a newer medication called ibrutinib that targets a specific weaknesses in the cancer cells. You would take pills every day, rather than coming in for intravenous treatment. Karl: Would there be fewer side effects? Doctor: None of the treatments are free from side effects altogether, but the side effects are typically milder with this newer agent. We would also still want to monitor you in case you develop low blood counts, and we will have to pay close attention if you get an infection, which could be more serious for you. Karl: Is ibrutinib just as effective as the chemotherapy? Doctor: The results with the newer therapies have been very good, but they are a little different. The leukemia doesn’t go away completely, as it can for a long period of time with chemotherapy. Ibrutinib can reduce it to a much lower level, where there are generally no symptoms, and maintain it there. Karl: Does that mean I would keep taking the medication? Doctor: Yes, you would take it every day for several years, and quite possibly for life. Karl: Is there a risk that after a while it could stop working? Doctor: That can happen. Karl: What would I do then? Doctor: Well I think we would have a few options that we could consider in that situation. Karl: I see. It’s all rather a lot to take in. Doctor: Yes, it is Karl: What do you recommend doing now? 4 Weighing First-line Treatment Options for CLL Dr Stilgenbauer: FCR has been the standard of care for the treatment of CLL for more than a decade, and because this patient has no 17p deletion, at the moment, it would certainly be an option for him. Slide 3. Slide 3. FCR has exhibited a high response rate: 95% overall with a 72% complete response (CR), and a median time to disease progression of 80 months. [2,5,6] In patients who achieve a CR with minimal residual disease negativity, the median time to progression is longer. [2,5-7,8] A long-term follow-up of patients treated with FCR in a clinical trial showed that many patients remained free from progression for over 10 years. [9] However, FCR has a high rate of serious adverse events – or AEs -- such as cytopenias and infections. There is a significant risk of prolonged cytopenias (19% lasting longer than 3 months) and the development of myelodysplastic syndrome or acute myeloid leukemia. [2,5,6,10] FCR can be especially difficult for older patients, [11] so I would probably be more cautious in a 70-year-old man like Mr Robinson than in somebody younger. Slide 4. Slide 4. Bendamustine, on the other hand, is an alternative chemotherapy that is given either with or without rituximab. Bendamustine with rituximab, the BR regimen, has been shown to be almost as efficacious as FCR in patients who are 65 years of age or older. BR, however, is generally much better tolerated, particularly in elderly patients. [12] Idelalisib + rituximab is not currently approved as first-line therapy, and trials studying its use in the first-line setting have been halted due to many patients experiencing AEs. Ibrutinib is a Bruton’s tyrosine kinase inhibitor that has been proven successful in the treatment of several B-cell malignancies. It has recently been approved as first-line treatment for CLL in both Europe and the United States. Slide 5. Slide 5. In the RESONATE-2 trial, ibrutinib was given as a first-line therapy and patients aged 65 years and older and achieved an 84% reduction in risk of progression or death compared with chlorambucil. Eighty-six percent of patients treated with ibrutinib achieved a response, compared with 35% of patients who received chlorambucil. [13] Slide 6. Slide 6. A 3-year follow-up of patients who received first-line treatment with ibrutinib found that the median duration of therapy in this group was 30 months, with 81% of these patients still remaining on ibrutinib after 3 years. In addition, the quality and frequency of responses to ibrutinib appear to increase over time. [14] 4% of patients discontinued ibrutinib treatment due to AEs, specifically pneumonia, subdural hematomas, and atrial fibrillation. [15] My main concern when using ibrutinib would be atrial fibrillation and hemorrhage. There are certain other comorbidities that can increase a patient’s risk for AEs, but these can be managed. At the moment, there are no head-to-head data comparing FCR and ibrutinib in young, otherwise healthy patients who do not have a 17p deletion. Therefore, generally a key consideration for each regimen is patient quality of life. It should be noted that del(17p) is more frequently observed in treated patients than in untreated ones, suggesting treatment-driven selection. Patients who initially tested negative for del(17p) can become positive at a later date, so regular del(17p) retesting is essential for any patient. It is quite common for patients like Mr Robinson to be concerned about what would happen if their CLL returned after a period of successful remission. In that situation, if the patient had received chemotherapy and the initial response to treatment lasted a long time -- at least 3 years, for instance -- the same treatment can often be used again. If the response to chemoimmunotherapy did not last very long, or if the initial treatment is no longer working, a different type of treatment may be more beneficial. Physicians and patients are also especially concerned about using ibrutinib in the first-line setting; that when it fails, it could not be used again as a second-line option. However, data from RESONATE-2 and the phase 3 study in the relapsed/refractory setting suggest that the outcome and response is potentially better when ibrutinib is given as an initial therapy, likely due -- at least partly -- to reduced CLL-related or treatment-related mortality. [13,14] However, for patients who stop taking ibrutinib -- either because of disease progression or side effects -- studies in the relapsed/refractory setting have shown that the prognosis could be potentially poor. [16-18] Slide 7. Slide 7. We do not yet have comparable data in the first-line setting; however, several treatment options are available if a patient discontinues ibrutinib, including idelalisib + rituximab and venetoclax. [19,20] Just because you discontinue one B-cell targeting agent it doesn't mean that another B-cell targeting agent would be ineffective, as these other agents target different cellular pathways. Chemoimmunotherapy is even a possibility if the patient remains negative for del(17p) or TP53 mutations. Let’s return to the case as Mr Robinson’s doctor provides this option for treatment. Case Study, Part 3 Doctor: [Conversation continues from previous scene] Many of my patients have done very well on ibrutinib. Although they have to keep taking it and can experience some mild side effects, they don’t generally experience the much more difficult side effects that tend to come with intravenous chemotherapy. Karl: I think that would be my preference as well. I don’t really like the idea of having chemotherapy. I'd really rather have the pills that I can take at home, instead of having something unpleasant pumped into my arm. Doctor: That’s quite normal. Many of my patients feel that way. Karl: It’s also kind of comforting in a way to have a therapy that will keep the leukemia under control, as opposed to stopping treatment and then waiting and wondering when it will come back. Doctor: Yes, that’s one way of looking at it. It is going to be important, however, that you do take the ibrutinib every day. You’ll take 3 pills together at the same time, and you do need to continue taking all 3 each day. Karl: Does it matter what time of day I take them? Do I have to take them with food or anything like that? Doctor: Not really, Mr Robinson. Just pick a time when it fits in well with your routine so that you’ll remember to take them every day. It doesn’t matter whether you take the pills with food or not, but I would certainly recommend taking them with a glass of water. Karl: Alright. Doctor: To start with it’s quite common to have more fatigue, as well as heartburn, diarrhea, and some mild pain in your joints. These things tend to improve fairly quickly, and often go away within 2 to 3 months. [Patient nods in understanding] Ibrutinib makes people bleed and bruise more easily, so you may also notice some bruising that occurs for no apparent reason. Again, this usually goes away over time. However, if you’re going to have surgery of any kind, please let me know. We would have to stop the ibrutinib for a short period before and after surgery, as it can lead to bleeding complications. Karl: Alright, I’ll do that. Doctor: We’ll monitor your blood regularly to make sure that everything is OK. Also, it’s important that you let us know if you have any infections or heart palpitations, and to advise us before you start taking any other medications. Karl: It’s a lot to remember. Doctor: Don’t worry, we’ll give you some information to take home that explains everything. Once you get started, I’m sure you’ll be able to handle it without much difficulty. Karl: Let’s hope so, doctor. [Fades out] Doctor: [4 weeks later: Fades in with doctor standing in front of patient, having just examined his lymph nodes] Well, the swelling in your lymph nodes has definitely gone down, and according to the latest tests, your blood count has improved. How have you been feeling since you started taking the ibrutinib? Karl: It hasn’t been too bad. I have noticed some aching in my joints from time to time, but nothing serious. Doctor: That’s good. Let me know if the aching gets any worse, but in most people it does go away after a few weeks. Karl: Alright. Doctor: You’ve been taking all 3 pills every day? Karl: Yes, I take them first thing in the morning with a glass of water while I’m making a cup of tea. Doctor: That’s perfect. Now, we have the results of your latest blood tests and everything looks fine. Karl: Oh good. Doctor: Your lymphocyte count is around 100 now, which is actually an increase from your last test. Karl: Is that a problem? Doctor: Not usually. When somebody starts taking ibrutinib, their white blood cell count typically increases gradually over the first couple of months. That’s because the cells come out of the lymph nodes and go into the blood. Then the count is stable for a while and, as the cells die off, it gradually goes down again. It’s nothing to worry about at the moment, but we’ll keep an eye on it. Karl: Alright. Doctor: Everything seems to be going nicely, and I’ll see you again in about 4 weeks. Karl: There’s just one other thing, doctor. Doctor: What’s that, Mr Robinson? Karl: You said that I should let you know if I need to have any surgery. Doctor: Yes, that’s right. What’s going on? Karl: I’ve been having some discomfort with one of my teeth lately, and the dentist thinks that the best thing would be to remove it. Is that going to be an issue with bleeding? Will I need to stop taking the pills for that? 5 Strategies for Managing Adverse Events and Improving Compliance of Ibrutinib When a patient on ibrutinib requires a surgical procedure, it is recommended that they stop taking ibrutinib for a period of time before and after the procedure, depending on the type of procedure and the bleeding risk. [15] Slide 8. Slide 8. The CLL Society advises that patients should hold their ibrutinib for 3 days before and after minor procedures, such as tooth extractions and bunionectomy, and for 7 days before and after major surgeries, such as gall bladder removal or knee surgery. Warfarin or other vitamin K antagonists should not be administered concomitantly with ibrutinib, and certain supplements, such as fish oil and vitamin E, should be avoided. Use of ibrutinib in patients requiring other anticoagulants or medicinal products that inhibit platelet function may increase the risk of bleeding, so particular care should be taken in patients who require anticoagulant therapy. [13,15] Therapies like ibrutinib that interfere with trafficking and adhesion of malignant lymphocytes by disrupting B-cell signaling can result in treatment-related lymphocytosis. [21] This is nothing to worry about; there is no evidence that outcomes are any worse in patients who experience lymphocytosis. If patients are concerned that the increase in lymphocytes is a sign that their CLL is getting worse, you can reassure them that this is not the case. Slide 9. Slide 9. Around two-thirds of patients who received ibrutinib in 3 CLL registration studies experienced lymphocytosis, defined as an increase in lymphocytes of 50% or more from baseline and above the absolute lymphocyte count of 5000/mcL. The onset of isolated lymphocytosis typically occurs during the first month of therapy with ibrutinib, and resolves in around 14 weeks; however, it can occur as less than 1 week or as long as 2 years in occasional cases. [15] Slide 10. Slide 10. Adherence to the daily ibrutinib regimen is essential. A subanalysis of the RESONATE trial showed that adherence to the recommended dose of ibrutinib in patients with CLL who had received previous therapy improved extended progression-free survival, compared with patients who did not adhere to their treatment regimen. [22] I have found that adherence to the treatment regimen is less of an issue when patients start therapy, because wanting to get rid of their symptoms motivates them. However, as their CLL improves and those symptoms disappear, the source of their motivation is gone. It’s not unusual 6 months to a year after starting treatment for patients to start questioning whether they really need to continue taking ibrutinib. Therefore, it is a good idea to consider ways to monitor and enhance treatment adherence with ibrutinib, not only when they first start taking it, but also once their symptoms have resolved. In conclusion, treatment options have increased, and new agents may offer options in the first-line setting, particularly for patients of advanced age. It is important to test for del(17p), as well as TP53 mutation at each line of therapy. New agents have their own distinct side effect profiles that should be considered. When administering ibrutinib, it is important to be aware of the potential for lymphocytosis, bleeding, and drug interactions, and to withhold treatment when the patient is undergoing a surgical procedure. Thank you for watching today, I hope you find this program to be helpful in your own clinical practice. For further discussion of this topic with other learners, please continue to Medscape Discuss by clicking the \"Join the Discussion\" button. To proceed to the post-test, click on the \"Earn CME Credit\" link on this page. This transcript has been edited for style and clarity. ",
				"clientUrl": "/viewarticle/867780",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 1551,
				"leadConcept": "Chronic Lymphocytic Leukemia",
				"concept": ["Cancer", "Chemotherapy", "Leukemia", "Immunotherapy", "Disease Management", "Adherence", "Patient Pharmaceutical Care Management", "Patient Care Management", "Adverse Effects", "Antineoplastic Drug", "Cancer Diagnostics", "Genetic Testing", "Genetics", "Laboratory Diagnosis", "Targeted Cancer Therapy", "Tyrosine Kinase Inhibitor", "Hematological Disorders", "Tumor Genetics", "Pharmacologic Adverse Events", "Chronic Leukemia", "Clinical Research", "Biomarker", "Patient Assessment", "Patient Simulation"],
				"leadSpecialtyId": 0,
				"contentGroup": "Clinical Case",
				"origContentType": "Clinical Case",
				"contentType": ["Patient Case"],
				"description": "In this case, Dr Stilgenbauer discusses initial assessment of and treatment options for a newly diagnosed patient with CLL.",
				"legacyID": 867780,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Managing Treatment-Naive Disease in Patients With CLL",
				"suppressComment": "T",
				"creditsAvailable": ["Non-US Physicians:CPD:0.25"],
				"maxCredits": [0.25],
				"multimedia": ["/thumbnail_library/867780.jpg"],
				"publicationDate": 1474606800000,
				"postingDate": 1474606800000,
				"_version_": 1573508886543990784,
				"last_index_date": 1500615011742
			}, {
				"id": "pdctm_0901c79180b3048a",
				"activeCME": 1,
				"activityExpirationDate": 1526706000000,
				"authors": ["William W. Busse", " Kian Fan Chung", " Marc Humbert", " Ian D. Pavord"],
				"body": "Contents of This CPD Activity All sections of this activity are required for credit. Section 1. Key Aspects of Severe Asthma: An Update in Current Treatment Recommendations Dr Busse reviews the epidemiology of asthma, the clinical features of the disease, and its impact on patients' quality of life. William W. Busse, MD Section 2. Eosinophilic Asthma: The Role of IL-5 and the Importance of Biomarkers in Phenotyping Watch Dr Chung explore the role of IL-5 in the development and release of eosinophils in severe asthma. Kian Fan Chung, MD, DSc Section 3. Treatment Recommendations for Severe Asthma Dr Humbert reviews current treatment options for severe asthma, including targeted therapies. Marc Humbert, MD, PhD Section 4. Clinical Evidence Supporting Biologic Therapy Dr Pavord discusses the clinical data supporting the use of anti-IL-5 therapies for severe asthma. Ian D. Pavord, MB BS, MRCP, DM, MA, FERS, FMediSci   Key Aspects of Severe Asthma: An Update in Current Treatment Recommendations « Back Continue » 0 Slide 1. Slide 1. Key Aspects of Severe Asthma: An Update in Current Treatment Recommendations Slide 2. Slide 2. A Worldwide Asthma Overview [1] Slide 3. Slide 3. What Are the Unmet Medical Needs of Asthma? [1] Slide 4. Slide 4. GINA-Based Treatment Steps [2] A basic factor in the treatment of asthma is the use of anti-inflammatory medication such as inhaled corticosteroids (ICS) As the disease becomes more severe, the doses of the ICS and additional treatments such as long-acting beta-agonists (LABAs), leukotriene-receptor antagonists (LTRAs) and anticholinergics are added to this treatment to better control the disease However, there are patients who achieve stage 4 or 5 in whom -- despite using all of the appropriate medications in large doses -- disease control is not achieved Slide 5. Slide 5. Goals of Asthma Management [3] Of the future risks, asthma exacerbations and loss of lung functions appear to be tied together and of considerable concern Slide 6. Slide 6. Exacerbations in Asthma [3] More frequent exacerbations have been associated with a risk of progressive loss of lung function Slide 7. Slide 7. Approach to Poorly Controlled Asthma Slide 8. Slide 8. Asthma Cluster Analysis [4] Asthma is a heterogeneous disease and multiple phenotypes exist Each of these phenotypes has very distinct characteristics, which explains why there is such a variability in severity and responsiveness to treatment Findings from a cluster analysis of about 1000 patients included in the Severe Asthma Research Project identified 5 general classes of asthma Slide 9. Slide 9. Definition of Severe Asthma [5] Patients with uncontrolled asthma have an asthma control questionnaire (ACQ) score of greater than 1.5, an asthma control test of less than 20, and usually require frequent doses of short-acting beta-agonists (SABAs) The forced expiratory volume in 1 second (FEV1) of these patients is usually less than 80% predicted, and high doses of medications may or may not provide full control of the asthma In many cases, they already have been seen by a specialist but these patients continue to have symptoms Slide 10. Slide 10. Emerging Asthma Phenotypes [2] Slide 11. Slide 11. Current and Emerging Targeted Therapies in Severe Asthma [6] Slide 12. Slide 12. The Next Topics to Be Discussed in This Series Eosinophilic Asthma: The Role of IL-5 and the Importance of Biomarkers in Phenotyping « Back Continue » 0 Slide 1. Slide 1. Eosinophilic Asthma: The Role of IL-5 and the Importance of Biomarkers to Phenotyping Eosinophilic asthma has been well established as one of the phenotypes of asthma and has received special attention in the last 10 years in patients with severe asthma Severe asthma is defined as asthma that does not respond adequately to conventional asthma treatments including corticosteroids Much of this attention has been focused on this phenotype of severe eosinophilic asthma because of the recent availability of targeted therapies directed at the eosinophilic phenotype, in the form of an anti-IL-5 antibody therapy Slide 2. Slide 2. Evidence for Eosinophils as an Important Effector Cell in Asthma With the advent of fiber optic bronchoscopy procedures that allowed safe sampling of the lower airways, eosinophils were also found in the airways of living chronic asthmatics This finding was often associated with blood eosinophilia Severe eosinophilic asthma can therefore be defined as a phenotype of asthma where there are increased levels of eosinophils, either in biopsies or sputum despite taking adequate doses of ICS, with or without oral corticosteroid therapy (OCS) Slide 3. Slide 3. Clinical Profile of Late-Onset Eosinophilic Asthma [7] Severe eosinophilic asthma is less common in early onset asthma, which occurs in patients younger than 12 years The average age of onset of late-onset of severe eosinophilic asthma ranges between 25 to 35 years There is also an equal distribution of men and women, which is different from the usual preponderance of females seen in non-severe-eosinophilic asthma It is important to note that regarding the association with chronic rhinosinusitis and nasal polyposis, these patients are often on OCS therapy, in addition to high-dose ICS therapy Slide 4. Slide 4. U-BIOPRED: Clustering on Clinical Features [8] Further validation and confirmation of this severe eosinophilic asthma phenotype has come from a recent analysis of the severe asthma cohort, in U-BIOPRED U-BIOPRED is a project supported by the European Union designed to study and phenotype asthma using a systems medicine approach Slide 5. Slide 5. U-BIOPRED: TACs of Moderate-Severe Asthma [9] A different approach involved clustering on differentially expressed genes in sputum samples between eosinophilic asthma and non-eosinophilic asthma Slide 6. Slide 6. Mechanisms of Severe Asthma [7] Slide 7. Slide 7. Role of Interleukin-5 in Asthma [10] Slide 8. Slide 8. Mepolizumab, an Anti-IL-5 Antibody, in Severe Eosinophilic Asthma [11] Mepolizumab is an anti-IL-5 antibody that was developed for treatment of severe eosinophilic asthma Data showed that use of this agent led to reduction in exacerbations and an improvement in FEV1 in patients with severe eosinophilic asthma This establishes severe eosinophilic asthma as a Th2, or T2-high endotype that can be detected with a high blood eosinophil count Treatment Recommendations for Severe Asthma « Back Continue » 0 Slide 1. Slide 1. Treatment Recommendations for Severe Asthma Slide 2. Slide 2. GINA-Based Treatment Steps [2] Slide 3. Slide 3. Asthma Phenotypes [12] Slide 4. Slide 4. Asthma Heterogeneity: Asthma Phenotypes [5] Guidelines developed in 2014 by the European Respiratory Society (ERS) and the American Thoracic Society (ATS) identified asthma phenotypes to help identify the best treatment strategy for patients with severe disease Slide 5. Slide 5. Targets for Biologic Treatments of Asthma When the ERS/ATS guidelines were developed in 2014, there were few data available from randomized controlled trials [3] At that time, anti- immunoglobulin E (IgE) therapy with omalizumab was considered only as a therapeutic trial in both in adults and in children Slide 6. Slide 6. Omalizumab for Severe Asthma [13] This is explained by the availability of a few randomized control trials including the pivotal INNOVATE study, which showed a 26% reduction of exacerbation with the addition of omalizumab vs placebo, and a reduction of 50% of severe exacerbation, and 44% of total emergency visit rates. Slide 7. Slide 7. Omalizumab for Severe Asthma (cont) [13] Slide 8. Slide 8. Targets for Biologic Treatments for Asthma Slide 9. Slide 9. Mepolizumab in Severe Eosinophilic Asthma [11] In the MENSA study, mepolizumab treatment was associated with a 50% reduction in the exacerbation rate in patients with difficult to treat severe eosinophilic asthma In this study, the subcutaneous use of mepolizumab was as efficacious as intravenous (IV) use Slide 10. Slide 10. Conclusions Clinical Evidence Supporting Biologic Therapy   « Back   Slide 1. Slide 1. Clinical Evidence Supporting Biologic Therapy Slide 2. Slide 2. Effect of Mepolizumab on Sputum Eosinophils and Traditional Outcomes [14,15] The first studies looking at the clinical impact of treatment with anti-IL-5 therapies were conducted nearly 20 years ago, but they were not considered successful Outcome measures were traditional, such as the morning peak expiratory flow Based on this outcome measure, this study was negative, with no evidence that mepolizumab was beneficial in this patient population However, around the same time as these studies were being carried out, it became apparent that severe asthma particularly was highly heterogeneous, particularly with respect to the lower airway pathology The other major insight was that the main clinical manifestation of persistent eosinophilic airway inflammation in patients with severe asthma was an increased risk of exacerbation Mepolizumab was thus considered to be a useful treatment in patients who had eosinophilic airway inflammation and who had the main clinical events associated with that pathology -- namely, asthma exacerbations Slide 3. Slide 3. Mepolizumab in Severe Eosinophilic Asthma [16] Slide 4. Slide 4. Effect of Mepolizumab on Airway Inflammation and Clinical Parameters [16] This study was strikingly positive and showed a strong biological effect, including a marked reduction in blood eosinophil count that was sustained throughout the study There was also evidence of a significant reduction in induced sputum eosinophil counts Although there was little evidence of improvement in symptoms or lung function, a small improvement in asthma related quality of life was seen Slide 5. Slide 5. Effect of Mepolizumab on Airway Inflammation and Clinical Parameters (cont) [16] The most striking finding of this study was the number of severe asthma exacerbations Slide 6. Slide 6. Mepolizumab: Oral Corticosteroid Sparing Effect [17] Another study published at the same time looked at impact of monthly mepolizumab 750 mg given for 24 weeks in patients who had severe asthma and required regular oral prednisolone to control it In this study, patient in the mepolizumab group had improvements in some clinical measures, including lung function Slide 7. Slide 7. DREAM and MENSA Studies [11,18] The DREAM study included 616 patients with severe asthma who had a history of 2 or more exacerbations in the last year More permissive criteria for eosinophilic airway inflammation were allowed in this study, including blood eosinophil measures This study also showed very clearly that there were only 2 variables associated with the beneficial effect of mepolizumab: the number of asthma exacerbations and the peripheral blood eosinophil count The MENSA study replicated the findings of the DREAM study beautifully and showed that 100 mg subcutaneously was as effective as 75 mg IV This study evaluated 576 patients with severe asthma and 2 or more exacerbations in the last year, and with blood eosinophil counts of more than 150/mm 3 and/or >300/mm 3 in the last 12 months Slide 8. Slide 8. Exacerbation Rate Reduction by Baseline Blood Eosinophil Count (DREAM and MENSA) Slide 9. Slide 9. What Treatment Effects Can Be Expected With Mepolizumab? Slide 10. Slide 10. Mepolizumab: Patient Selection Slide 11. Slide 11. Which Biologic? Slide 12. Slide 12. Effect of Dupilumab on Exacerbations of Moderate to Severe Asthma [20] Slide 13. Slide 13. Substratification of Eosinophilic Airway Disease? Slide 14. Slide 14. Conclusions Reducing type 2 or eosinophilic airway inflammation with biological drugs greatly affects exacerbation risk The use of anti-IL-5 therapy such as mepolizumab has a clinically important impact on the requirement for regular oral corticosteroids Dupilumab has important beneficial effects on manifestations of eosinophilic inflammation outside the lung, particularly in the skin and nose Slide 15. Slide 15. Thank you ",
				"clientUrl": "/viewarticle/877593",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 251,
				"leadConcept": "Asthma",
				"concept": ["Mild Persistent Asthma", "Mild Intermittent Asthma", "Clinical Guidelines", "Pharmacogenomics", "Treatment Guidelines", "Airway", "Airway Inflammation", "Inhaled Corticosteroid", "Biologic Therapy", "International Practice of Medicine", "Asthma With Adult Onset", "Allergic Asthma", "Asthma in Childhood", "Pathogenesis", "Clinical Research", "Biomarker", "Interleukin Antagonist", "Interleukin"],
				"leadSpecialtyId": 13,
				"leadSpecialty": "Pulmonary Medicine",
				"allSpecialties": ["Pulmonary Medicine", "Family Medicine/Primary Care"],
				"origContentType": "Commentary",
				"contentType": ["Expert Commentary"],
				"description": "Watch this video series on the optimal diagnosis of severe asthma and the use of anti-IL-5 therapies in this setting.",
				"legacyID": 877593,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Key Aspects of Severe Asthma: A 2017 Update",
				"suppressComment": "T",
				"creditsAvailable": ["Non-US Physicians:CPD:0.75"],
				"maxCredits": [0.75],
				"multimedia": ["/thumbnail_library/877593-thumb.jpg"],
				"publicationDate": 1495170000000,
				"postingDate": 1495170000000,
				"_version_": 1573508896216055808,
				"last_index_date": 1500615020957
			}, {
				"id": "pdctm_0901c79180a134f9",
				"activeCME": 1,
				"activityExpirationDate": 1501650000000,
				"authors": ["News Author: Roxanne Nelson"],
				"body": "Clinical Context Treatment of patients with stage II colon cancer after surgical resection is still controversial, as approximately 80% are cured by surgery alone, but adjuvant chemotherapy is frequently offered to high-risk stage II patients. However, an overall survival benefit from adjuvant therapy is still unclear, even in those with high-risk disease based on standard clinicopathologic criteria or gene signatures. The main goal of this study by Gibbs and colleagues was to show that analysis of postoperative circulating tumor DNA (ctDNA) could be used as an indicator of minimal residual disease in patients with stage II colon cancer, identifying patients who would eventually go on to have recurrent disease diagnosed on conventional radiology. Secondary goals were to analyze serial samples to assess changes in ctDNA concentration across time and/or in response to adjuvant therapy, and to determine whether persistently detectable ctDNA identified treated patients who would later have radiologic recurrence. Study Synopsis and Perspective A simple blood test may be able to predict the likelihood of disease recurrence in colorectal cancer, according to a new report. The genetic test can detect ctDNA after patients with stage II colon cancer undergo surgical resection, which, in turn, appears to identify many of those at the highest risk for recurrence. The test results could help clinicians decide about use of adjuvant therapy. In a study of 230 patients with stage II colon cancer, the test results demonstrated that those who tested positive for ctDNA postoperatively were at extremely high risk for radiologic recurrence (hazard ratio [HR], 18; P =2.6 × 10 -12 ). The findings were published in the July 6 issue of Science Translational Medicine . [1] No ctDNA tests for cancer have been approved, but growing evidence suggests that ctDNA is a viable approach for both the earlier detection of cancer recurrence and evaluating response to therapy. [2] \"There are multiple potential applications for this test, and further studies are required to determine which has the biggest impact on outcomes,\" said study author Peter Gibbs, MBBS, MD, an associate professor at the Walter and Eliza Hall Institute of Medical Research, Parkville, Australia. \"At this point the strongest data are for defining which stage II patients need only surgery,\" he told Medscape Medical News . Dr Gibbs explained that prospective studies are required to demonstrate that selecting the patients with detectable ctDNA for chemotherapy improves outcomes. Currently, there is only anecdotal evidence about chemotherapy benefitting these patients. Being able to detect early recurrence with ctDNA could also affect survival. \"But again, this needs to be demonstrated in prospective studies of ctDNA-guided follow-up,\" said Dr Gibbs. Liquid Biopsy The idea of using \"liquid biopsy\" has created quite a buzz in the cancer community because it is a faster and less invasive method than tissue biopsies. In the largest studies to date, more than 17,000 liquid biopsies from 15,191 patients with more than 50 different types of advanced cancer have revealed genetic mutations similar to those found with traditional tissue biopsy. [3] For example, a blood test to measure ctDNA in women with early-stage breast cancer who had undergone neoadjuvant chemotherapy and surgery detected ctDNA in blood samples as early as 2 to 4 weeks after surgery in some patients. [4] Most of these women (89%) went on to experience a relapse. The US Food and Drug Administration, in fact, has just approved the first blood-based genetic test that can detect epidermal growth factor receptor gene mutations in patients with non-small cell lung cancer. [5] In the current study, the authors performed parallel sequencing-based assays to evaluate the ability of ctDNA to detect minimal residual disease in 1046 plasma samples that were obtained prospectively from 230 patients with resected stage II colon cancer. Among the 178 patients who did not receive adjuvant chemotherapy, ctDNA was detected postoperatively in 14 patients (7.9%). Of this small group, disease recurred in 11 (79%) at a median follow-up of 27 months. Conversely, there was a recurrence in only 16 (9.8%) of 164 patients with negative ctDNA results (HR, 18; P <.001). In the 52 patients who received chemotherapy, the presence of ctDNA after they completed their treatment was also associated with an inferior recurrence-free survival (HR, 11; P =.001). Overall, patients who were ctDNA positive postoperatively had a markedly reduced recurrence-free survival (RFS) compared with those who had a ctDNA-negative status (HR, 18; P =2.6 × 10 -12 ). Estimates of being recurrence free at 3 years were 0% for the ctDNA-positive group vs 90% for the ctDNA-negative group. Noteworthy is that cancer recurred in 14 patients whose blood tests showed no cancer-linked DNA. This result indicates that the test is not flawless. Clinicopathologic variables significantly associated with RFS in univariate analysis included T stage, lymph node yield, and lymphovascular invasion. However, the authors note that postoperative ctDNA status had a greater effect on RFS than did any of the other individual clinicopathologic risk factors in any combination. On multivariable analysis, postoperative ctDNA status continued to remain an independent predictor of RFS both for patients who did not receive adjuvant chemotherapy (HR, 28) and for all patients in the cohort (HR, 14). \"We showed in our study that ctDNA can often detect disease recurrence before it becomes evident radiographically,\" commented study author Yuxuan Wang, from the Ludwig Center and Howard Hughes Medical Institute at Johns Hopkins Kimmel Cancer Center, Baltimore, Maryland. \"For patients in whom we can detect early recurrence with ctDNA, there is a larger window of opportunity to initiate or modify treatment for better outcomes,\" she told Medscape Medical News . She added that they expect ctDNA to have the same usefulness to predict recurrence for other stages of colon cancer. As for next steps, Dr Gibbs pointed out that the test is moving into phase 3 clinical trials. The researchers have initiated a randomized study in stage II colon cancer in which 450 patients are being randomly assigned to ctDNA-guided adjuvant therapy (therapy is given if ctDNA is detected and not given if ctDNA is not given) vs standard of care. The study was funded by Ludwig Cancer Research, the Conrad N. Hilton Foundation, the Sol Goldman Sequencing Facility at Johns Hopkins, the National Institutes of Health's National Cancer Institute (CA43460, CA152753, CA006973), and the Victorian Cancer Agency. Several of the authors have disclosed relevant financial relationships, which are noted in the original study. Sci Translat Med . Published online July 6, 2016. Study Highlights The prospective study cohort consisted of 230 patients with resected stage II colon cancer. Investigators used parallel sequencing-based assays on 1046 plasma samples to detect minimal residual disease using ctDNA. Among 178 patients not treated with adjuvant chemotherapy, 7.9% had postoperative detection of ctDNA. Of these patients, 79% had recurrence at follow-up (median, 27 months). Among patients not treated with adjuvant chemotherapy and with negative ctDNA postoperatively, only 9.8% had disease recurrence (HR, 18; 95% confidence interval [CI], 7.9-40; P <.001). Among patients receiving chemotherapy, the presence of ctDNA after completion was also associated with worse RFS (HR, 11; 95% CI, 1.8-68; P =.001). Overall, patients who tested positive for ctDNA vs those who tested negative had dramatically decreased RFS (HR, 18; P =2.6 × 10 -12 ); 3-year RFS was 0% vs 90%, respectively. However, 14 of the 230 patients had a ctDNA-negative status postoperatively but later experienced cancer recurrence, suggesting false-negative results. Univariate analysis showed that T stage, lymph node yield, and lymphovascular invasion were significantly associated with RFS, but postoperative ctDNA predicted RFS better than any other risk factors alone or in any combination. Multivariable analysis showed that postoperative ctDNA status independently predicted RFS for patients untreated with adjuvant chemotherapy (HR, 28) and for all patients in the cohort (HR, 14). Postoperative ctDNA status improved RFS risk estimates for both patients with clinicopathologic low-risk (HR, 28; 95% CI, 8.1-93) and high-risk (HR, 7.5; 95% CI, 2.6-22) disease. On the basis of these findings, the investigators concluded that ctDNA detection after resection of stage II colon cancer gives direct evidence of residual disease and identifies patients at very high risk for recurrence, helping to inform adjuvant treatment decisions. Avoidance of unnecessary adjuvant chemotherapy for 6 months could spare the associated risk for potentially serious adverse events in up to 40% of patients with stage II disease who now receive such treatment. Currently, absolute risk reduction associated with adjuvant chemotherapy in these patients is only 3% to 5%, and there is no good method to monitor its impact. Benefits of ctDNA as a predictor of recurrence and marker of response include availability in postoperative blood samples and identification of residual disease undetectable on imaging. The investigators recommend that ctDNA be considered not as a conventional biomarker of recurrence risk but more like a staging test such as a computed tomography (CT) scan. However, ctDNA is not a perfect indicator of residual disease: with a single plasma sample taken during the immediate postoperative period having a sensitivity of 48% to predict recurrence at 36 months, which is still better than that for CT scan. Whereas CT scans have limited specificity, ctDNA has a very high specificity of 97%. Median lead-time from ctDNA detection to radiologic recurrence was more than 5 months, which might be sufficient to change patient management. Enrolling only patients with detectable ctDNA into clinical trials would enrich trial cohorts with patients at very high risk for recurrence, substantially reducing needed sample sizes and costs. Study limitations include the small number of patients with detectable ctDNA postoperatively and possibly limited generalizability. Clinical Implications A prospective study in stage II colon cancer showed that ctDNA analysis of postoperative blood samples defines a population at very high risk for recurrence. Postoperative ctDNA measurement is superior to clinicopathologic measures currently used to guide adjuvant chemotherapy. Implications for the Healthcare Team: Postoperative ctDNA applications may include the potential to modify or change therapeutic management before bulky disease develops. CME Test 3 ",
				"clientUrl": "/viewarticle/866713",
				"creditType": ["CME", "Nurse CE", "ABIM MOC"],
				"cmeFlag": "CME / ABIM MOC / CE",
				"leadConceptId": 3032296,
				"leadConcept": "Colorectal Cancer",
				"concept": ["Cancer", "Colon Cancer", "Disease Recurrence", "Disease Management", "Colorectal Disease", "Cancer Diagnostics", "Genetic Testing", "Genetics", "Laboratory Diagnosis", "Tumor Pathology", "Oncology Nursing", "Clinical Pathology", "Tumor Genetics", "Public Health Nursing", "Colorectal Tumor", "Disease Surveillance", "DNA Sequencing"],
				"leadSpecialtyId": 7,
				"leadSpecialty": "Hematology-Oncology",
				"allSpecialties": ["Hematology-Oncology", "Medscape Today", "Internal Medicine", "Gastroenterology", "Nursing", "Family Medicine/Primary Care", "Public Health & Prevention", "Pathology & Lab Medicine"],
				"contentGroup": "Clinical Review",
				"origContentType": "Clinical Brief",
				"contentType": ["News"],
				"description": "In stage II colon cancer, analysis of circulating tumor DNA detects minimal residual disease and predicts recurrence.",
				"legacyID": 866713,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Can Circulating Tumor DNA Predict Colon Cancer Recurrence?",
				"suppressComment": "T",
				"creditsAvailable": ["PhysiciansFamily Physicians:AMA PRA Category 1 Credit(s)™AAFP Prescribed credit(s):0.25", "US Physicians:Points for ABIM MOC:0.25", "Nurses:ANCC Contact Hour(s):0.25", "Physicians:AMA PRA Category 1 Credit(s)™:0.25"],
				"maxCredits": [0.25],
				"publicationDate": 1470114000000,
				"postingDate": 1470114000000,
				"_version_": 1573508897587593217,
				"last_index_date": 1500615022265
			}, {
				"id": "pdctm_0901c79180b3045c",
				"activeCME": 1,
				"activityExpirationDate": 1524805200000,
				"authors": ["News Author: Pam Harrison", " CME Author: Charles P. Vega"],
				"body": "Clinical Context Guidelines from the American Academy of Pediatrics previously recommended a daily total of less than 2 hours of screen time among children. The latest version of these recommendations continues to call for a regular restriction on screen time, although it allows more flexibility in the duration of screen time. Regardless, these recommendations are designed to protect children from the negative health effects of increased screen time, particularly obesity. Tandon and colleagues evaluated the average amount of screen time among preschool children, and patterns of screen time at home and in different care settings. Their results were published in the February 2011 issue of the Journal of Pediatrics. [1] More than 80% of the cohort of 8950 children received some form of child care. The average daily total of screen time was 4.1 hours, with 3.6 hours totaled at home and 0.4 hours in child care. Children receiving care in child-care centers had the lowest average exposure to screen time, even lower than children attending Head Start programs. Parental care at home was associated with the most average screen time. Pediatric obesity has been associated with increased screen time, but can screen time worsen metabolic outcomes? The current study by Nightingale and colleagues evaluates this issue. Study Synopsis and Perspective Children who spend more than 3 hours per day glued to a screen are more likely to be fatter and have early risk factors for type 2 diabetes, especially insulin resistance, than those who spend 1 hour per day or less, new research underscores. \"Recommendations from the American Academy of Pediatrics (AAP) previously suggested that children should limit daily screen time to <2 hours,\" lead author Claire M. Nightingale, PhD, University of London, London, United Kingdom, and colleagues write in their study, published online in the Archives of Disease in Childhood . [2] \"Our findings suggest that reducing screen time may be beneficial in reducing type 2 diabetes risk factors in both boys and girls and in different ethnic groups from an early age,\" they add. Boys and Black Children Reported Most Screen Time The Child Heart and Health Study in England (CHASE) [3] is a cross-sectional survey of heart health carried out in children between 9 and 10 years old attending 200 primary schools in London, Birmingham, and Leicester. A total of 4495 children were included in this analysis, which was performed from 2004 to 2007 and included anthropometric measurements and fasting blood glucose levels. Physical activity was assessed in a subset of the cohort (n=2031). \"Overall, 4% of the study population reported no screen time,\" Dr Nightingale and coauthors report; 37% of the children reported spending 1 hour or less of daily screen time, whereas 28% reported they spent between 1 and 2 hours per day. Some 13% of the group said they spent between 2 and 3 hours of screen time per day while the final 18% reported spending more than 3 hours per day. Boys were more likely than girls to engage in more than 3 hours of daily screen time at 22% vs 14%, respectively, the investigators note. Black children (African-Caribbean) were also more likely to report more than 3 hours of daily screen time, at 23% vs 16% of both white and South Asian kids, respectively. Using children who spent 1 hour per day or less in screen time as a reference group, those who spent more than 3 hours per day in screen time had a 1.9% higher ponderal index, an indicator of weight in relationship to height. Skinfold thickness was also 4.5% higher and the fat mass inxdex 3.3% higher in children who engaged in the most screen time compared with those who engaged in the least. Levels of leptin, a hormone that controls appetite, were 9.2% higher in children who engaged in the most vs the least screen time, as were insulin levels, which were 10.7% higher, and levels of insulin resistance, which were 10.5% higher in those with the most vs those with the least screen time. \"Adjustment for fat mass index reduced effect sizes for insulin and IR [insulin resistance] by approximately one-quarter,\" the researchers observe. Noteworthy is that the associations seen between risk markers for diabetes and daily screen time were not affected by either socioeconomic status or, somewhat surprisingly, by levels of physical activity as assessed in the subset of children in the cohort. However, there was \"no formal evidence of a trend between screen time and HbA 1c [glycated hemoglobin], fasting glucose, and other cardiovascular risk factors, including lipids and blood pressure (even with further adjustment for height),\" the authors state. They point out that although the use of electronic devices was already pervasive when their analysis was carried out, more options such as tablets and smartphones have since become available, extending screen time options to many more children. Thus, these findings may be of \"considerable potential public-health interest,\" given that recent trends indicate screen time-related activities are increasing in childhood and that these activities could have harmful health-related consequences in adulthood, they conclude. The authors have disclosed no relevant financial relationships. Arch Dis Child. Published online March 13, 2017. Study Highlights The Child Heart and Health Study in England provided data for study analysis. This study was a cross-sectional analysis of heart health among children between 9 and 10 years old attending elementary school. Children were evaluated for body mass index, blood pressure, and several measures of adiposity, including skinfold thickness at 4 anatomic sites and hand-to-foot bioimpedance. They also completed a number of metabolic tests while fasting, including HbA 1c , glucose, insulin, lipids, and C-reactive protein. A subgroup of children completed testing for physical activity using an accelerometer. Screen time was assessed by a question regarding television viewing and time spent playing video games. The survey was completed between 2004 and 2007, before cellular and tablet technologies were more widely adopted for entertainment. The main study outcome was the relationship between screen time and metabolic studies. Children reporting screen time of 1 hour or less per day were considered the referent group. Researchers adjusted for sex, age, and ethnicity in their study analysis. 4495 children with an average age of 9.9 years participated in the study. There were slightly more girls than boys in the cohort, and the study population was diverse in race and ethnicity. 4% of children reported no screen time, whereas 37% reported 1 hour or less per day. 28% had 1 to 2 hours of screen time per day, and 13% reported 2 to 3 hours of screen time daily. 18% watched television or played video games for more than 3 hours per day. High amounts of screen time were more common among boys vs girls and among children of black African-Caribbean descent. Girls had increased adiposity compared with boys and worse control of glucose and lipid metabolism. Adiposity was higher in comparing children with more than 3 hours of screen time vs children with 1 hour or less of screen time daily. Body mass index was 1.9 kg/m 2 higher in the cohort with the most screen time vs the referent group. Leptin levels were 9.2% higher on average among children with more than 3 hours of screen time compared with children with 1 hour or less of screen time daily. The respective mean difference in insulin levels was 10.7%, and insulin resistance was 10.5% more severe in the cohort with the most screen time. However, screen time had no effect on HbA 1c , glucose levels, serum lipids, or blood pressure. Additional analyses that included socioeconomic level and physical activity as covariates failed to alter the main study outcome. Clinical Implications A previous study by Tandon and colleagues found that the average amount of daily screen time among toddlers was 4.1 hours. The highest duration of screen time was when children were at home receiving care from a parent. The current study by Nightingale and colleagues demonstrates that insulin resistance was associated with high amounts of screen time among children. However, screen time had no effect on HbA 1c , glucose levels, serum lipids, or blood pressure. Implications for the Healthcare Team: Screen time among children can be a target for team-based interventions. Parents can be educated about effective techniques to reduce screen time, and the team can arrange follow-up to assess progress in this important lifestyle issue. CME Test 3 ",
				"clientUrl": "/viewarticle/877587",
				"creditType": ["CME", "Nurse CE", "ABIM MOC"],
				"cmeFlag": "CME / ABIM MOC / CE",
				"leadConceptId": 5000056,
				"leadConcept": "Cardiometabolic Risk Factors",
				"concept": ["Type 2 Diabetes Mellitus", "Insulin Resistance", "Exercise", "Lifestyle Counseling", "Growth and Development of Child", "Pediatric Nursing", "Type 2 Diabetes Mellitus With Pediatric Onset", "Obesity", "Adolescent Medicine", "Obesity in Children", "Metabolic Syndrome", "Metabolism", "Psychosocial", "Public Health Nursing", "Lifestyle Modification for Cardiovascular Health", "Interprofessional Continuing Education", "Child"],
				"leadSpecialtyId": 9,
				"leadSpecialty": "Pediatrics",
				"allSpecialties": ["Pediatrics", "Cardiology", "Medscape Today", "Internal Medicine", "Diabetes & Endocrinology", "Nursing", "Neurology & Neurosurgery", "Family Medicine/Primary Care", "Public Health & Prevention", "Nephrology"],
				"contentGroup": "Clinical Review",
				"origContentType": "Clinical Brief",
				"contentType": ["News"],
				"description": "A new survey study finds that screen time is associated with obesity and insulin resistance among children.",
				"legacyID": 877587,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Can Screen Time Affect Diabetes Risk in Kids?",
				"suppressComment": "T",
				"creditsAvailable": ["PhysiciansFamily Physicians:AMA PRA Category 1 Credit(s)™AAFP Prescribed credit(s):0.25", "US Physicians:Points for ABIM MOC:0.25", "Nurses:ANCC Contact Hour(s):0.25", "Physicians:AMA PRA Category 1 Credit(s)™:0.25"],
				"maxCredits": [0.25],
				"publicationDate": 1493269200000,
				"postingDate": 1493269200000,
				"_version_": 1573508879974662144,
				"last_index_date": 1500615005473
			}, {
				"id": "pdctm_0901c79180a7cd3a",
				"activeCME": 1,
				"activityExpirationDate": 1511413200000,
				"authors": ["Robert R. Henry"],
				"body": "The following cases are modeled on the interactive grand rounds approach. The questions within the activity are designed to test your current knowledge. After each question, you will be able to see whether you answered correctly and read evidence-based information that supports the most appropriate answer choice. The questions are designed to challenge you; you will not be penalized for answering the questions incorrectly. At the end of the activity, there will be a short post-test assessment based on the material presented. Case 1: Patient History Patient Image 170 0 Miguel is a 50-year-old Hispanic man diagnosed with type 2 diabetes (T2D) 2 years ago. He works as a computer analyst. He had a myocardial infarction (MI) 2 years ago. An angiogram showed widespread 4-vessel disease, and drug-eluting stents were implanted. At the time, Miguel's fasting glucose was elevated at 110 mg/dL, with a glycated hemoglobin (HbA 1c ) of 6.9%. Lifestyle modifications were recommended. Miguel was referred for evaluation after recent labs showed an HbA 1c of 9.6% and fasting blood glucose of 222 mg/dL. There is a history of T2D on both sides of his family, and many of Miguel's family members are obese. His father, who had insulin-dependent T2D, died at the age of 54 after an MI. Table 1. History and Physical Examination History Findings Medical Remote MI, prior stenting, hypertension, dyslipidemia, T2D, obesity Family Mother: T2D. Father: hypertension, dyslipidemia, T2D (died at age 54 of MI) Social Married with 3 children; has 1 to 2 beers a couple times per week; doesn't smoke; works long hours as a computer analyst; little to no exercise during the week Past and current medications Lisinopril 40 mg, amlodipine 10 mg, carvedilol 12.5 mg, clopidogrel 75 mg, atorvastatin 20 mg, aspirin 81 mg Other Admits to sometimes forgetting to take his medication; recent difficulty with sleeping Recent lab work Findings HbA 1c 9.6% Fasting blood glucose 222 mg/dL LDL-C 98 mg/dL HDL-C 33 mg/dL Triglycerides 205 mg/dL eGFR 72 mL/min/1.73 m 2 SGOT 48 (normal range, 5-40) U/L SGPT 61 (normal range, 7-56) U/L Physical examination Findings Vital signs 148/88 mm Hg; heart rate = 74 bpm General impression Obese, mild sweating BMI 34.6 kg/m 2 (abdominal circumference = 154 cm) Skin Clear, no rash Chest and lungs Bilateral crepitations on inspiration; S3 heart sound on precordial auscultation (consistent with mild CHF if not SOB at rest/minimal exercise); no elevated JVP Abdomen Soft, distended, nontender, liver edge palpable 2 cm below right mid-costal cartilage, no masses Lower extremities Bilateral mild pedal edema (pitting edema of 1 to 2-plus) BMI = body mass index; bpm = beats per minute; CHF = congestive heart failure; eGFR = estimated glomerular filtration rate; HbA 1c = glycated hemoglobin; HDL-C = high-density lipoprotein cholesterol; JVP = jugular venous pressure; LDL-C = low-density lipoprotein cholesterol; MI = myocardial infarction; S3 = third heart sound; SGOT = serum glutamic oxaloacetic transaminase; SGPT = serum glutamic pyruvic transaminase; SOB = shortness of breath; T2D = type 2 diabetes. You explain to Miguel that Hispanics are more likely to have diabetes than non-Hispanic whites, with 12.8% of Hispanics in the United States having diabetes compared with 7.6% of non-Hispanic whites. [1] Hispanics with diabetes tend to experience more complications, including a 51% higher mortality rate, than non-Hispanic whites with diabetes. [2] You explain to Miguel that controlling blood sugar through a combination of diet, exercise, and medication is a proven way to reduce complications, including diabetes-related mortality and cardiovascular (CV) events, such as MI and stroke. According to findings from registry data, Miguel could reduce his risk of a CV death by 45% and of a CV event by 39% for every 1% reduction in HbA 1c that he achieves. [3] In addition, you tell Miguel that his blood pressure is not well controlled. Uncontrolled blood pressure contributes to increased CV risk and events. His heart rate of 74 bpm indicates he does not have adequate β-blockade. He also needs reemphasis on the importance of diet and lifestyle modification and needs diet and lifestyle modification advice (with his spouse) for both diabetes and blood pressure control. Elevated serum glutamic oxaloacetic transaminase (SGOT)/serum glutamic pyruvic transaminase (SGPT) in a T2D individual with central obesity such as Miguel is consistent with fatty liver and increased risk for complications of hepatic steatohepatitis (chronic hepatic inflammation, increased fibrosis, cirrhosis) and increased (an additional risk factor) risk for CV disease. 3 Initial Combination Therapy In A Newly Diagnosed Patient With T2D The American Diabetes Association (ADA) recommends 7.0% to be the starting point for HbA 1c targets, with the specific HbA 1c goal customized for an individual patient's baseline characteristics, risk for hypoglycemia, attitude/personal goals, and other factors. [4,5] Given that Miguel is 50 years old and has not reported episodes of severe hypoglycemia, a less stringent HbA 1c goal (ie, >7.0%) is not indicated. Thus, an HbA 1c target of less than 7.0%, and possibly lower, is appropriate. [4] Although the American Association of Clinical Endocrinologists advocates an HbA 1c goal of 6.5%, [6] it's unclear whether it would be attainable for this patient. Although Miguel is motivated since turning 50, his compliance with lifestyle modification and treatment regimens suggest that a more stringent HbA 1c goal at the outset may be ambitious and perhaps counterproductive if Miguel believes the HbA 1c goal is unachievable. The Role of SGLT2 Inhibitors in the Treatment of T2D Because their mechanism of action (MOA) is independent of insulin, SGLT2 inhibitors are associated with a low incidence of hypoglycemia, particularly when combined with metformin, which also has minimal potential for hypoglycemia. The SGLT2 cotransporters are almost exclusively expressed in the proximal tubules of the kidney, is specific for glucose, and accounts for an estimated 90% of glucose reabsorption in the kidneys. [7,8] There is a linear relationship between plasma glucose concentration and the amount of glucose filtered in the kidneys (at normal glomerular filtration rate); however, there is a threshhold at which this linear relationship is disrupted. [8] In patients with T2D, this threshold is increased. Of note, patients with T2D have increased SGLT2 expression, which heightens reabsorption of glucose in the kidney and the subsequent excess glucose entering the blood stream. Thus, by inhibiting SGLT2 activity, the threshold is reduced, excess glucose is not reabsorbed by the kidney, and urinary glucose excretion is increased. [7,8] In addition to a diuretic effect, SGLT2 inhibition blocks renal reabsorption of sodium and exerts an osmotic diuretic effect, which may be beneficial. [9,10] Because of their unique MOA, SGLT2 inhibitors can be considered for patients across the spectrum of T2D severity: both those who have been recently diagnosed as well as those who have significant loss of ß-cell function. The MOA of SGLT2 inhibitors is complementary to that of commonly used anti-hyperglycemic treatments, including metformin, glucagon-like peptide-1 (GLP-1) receptor agonists, dipeptidyl-peptidase-4 (DPP-4) inhibitors, and insulin. SGLT2 inhibitors are usually prescribed as a second- or third-line therapy. When taken as monotherapy, SGLT2 inhibitors typically reduce HbA 1c by 0.5% to 1.0%. [11-13] To date, there are 3 SGLT2 inhibitors that have received regulatory approval in the United States (Table 2). Table 2. Current FDA-Approved SGLT2 Inhibitors   Canagliflozin [11] Dapagliflozin [12] Empagliflozin [13] Dosage forms/strengths Tablets/100 and 300 mg Tablets/5 and 10 mg Tablets/10 and 25 mg Recommended dosing 100 mg daily before first meal 5 mg daily in morning with or without food 10 mg daily in morning with or without food Half life 12 to 15 h 17 h 10 to 19 h Peak levels 2.8 to 4.0 h after ingestion 1.5 after ingestion 1.5 hours after ingestion Metformin extended release (ER or XR) can be used in combination with the SGLT2 inhibitor, but patients with elevated HbA 1c requiring dual therapy may benefit from a fixed-dose combination (FDC) of 2 oral anti-hyperglycemic medications in a single pill, as a lower pill burden may enhance patient compliance. Observational studies suggest that an FDC can achieve significantly greater HbA 1c reduction compared with coadministration of separately dispensed T2D medications; however, the cost of FDC medication may be prohibitive for some patients and/or may not be covered by some insurers. [14] Thus, a patient's ability and willingness to pay for anti-hyperglycemic medications should be considered when formulating a treatment plan, according to the ADA's patient-centered approach to T2D treatment. [5] Table 3 shows the available FDCs of metformin and SGLT2 inhibition. There are also FDCs of metformin and DPP-4 inhibitors as well as metformin and older anti-hyperglycemic medications, such as a thiazolidinedione. Some FDCs use immediate-release (IR) metformin, whereas others use metformin XR or ER. [14] More recently, an FDC of a SGLT2 inhibitor and a DPP-4 inhibitor (empagliflozin/linagliptin) has become available in the United States [15] ; a FDC of dapagliflozin/saxagliptin is currently under review by the US Food and Drug Administration (FDA). Table 3. Available Dosage Forms and Strengths of SGLT2 Inhibitors Combined With Metformin INVOKAMET ® [16] Synjardy ® [17] XIGDUO ® XR [18] 50 mg canagliflozin/ 500 mg metformin 5 mg empagliflozin/ 500 mg metformin 5mg dapagliflozin/ 500 mg metformin 50 mg canagliflozin / 1000 mg metformin 5 mg empagliflozin/ 1000 mg metformin 5mg dapagliflozin/ 1000 mg metformin 150 mg canagliflozin/ 500 mg metformin 12.5 mg empagliflozin/ 500 mg metformin 10mg dapagliflozin/ 500 mg metformin 150 mg canagliflozin/ 1000 mg metformin 12.5 mg empagliflozin/ 1000 mg metformin 10mg dapagliflozin/ 1000 mg metformin Note: A boxed warning for lactic acidosis associated with metformin in the above FDCs was issued in May 2016 for INVOKAMET, June 2016 for XIGDUO XR, and July 2016 for Synjardy. FDC = fixed-dose combination. 4 Extraglycemic Effects of SGLT2 Inhibitors Increased glycosuria related to SGLT2 inhibition likely contributes to modest weight loss of 2 kg to 5 kg. [19] Imaging studies have also shown that SGLT2 inhibitors can reduce visceral fat, with approximately two-thirds of weight loss stemming from reductions in fat mass. [10] As visceral adiposity is associated with higher risk for CV events and mortality, [20] the reduction in visceral and subcutaneous fat suggests a CV benefit. Studies have also shown a reduction in the average waist circumference in patients with T2D taking SGLT2 inhibitors. [21,22] A systematic analysis of 27 randomized controlled trials showed that SGLT2 inhibitors lower blood pressure by about 3 mm Hg to 5 mm Hg for systolic blood pressure and approximately 2 mm Hg for diastolic blood pressure. [10] It is thought that weight loss, diuresis, and sodium depletion contribute to the blood pressure improvement. Emerging evidence also suggests that certain SGLT2 inhibitors may reduce arterial stiffness, which may also play a role in lowering blood pressure. Theoretically, weight loss, diuresis, and improvement in blood pressure should be particularly beneficial in patients with T2D and heart failure (HF). Notably, SGLT2 inhibitors are not associated with an increased heart rate, which has been observed with some newer anti-hyperglycemic treatments. [10] Although SGLT2 inhibitors may increase high-density lipoprotein-cholesterol (HDL-C), they also modestly raise low-density lipoprotein-cholesterol (LDL-C) levels. In general, there is no change in the ratio of HDL-C to LDL-C. Lower triglyceride levels are frequently seen with SGLT2 inhibitor use. The net clinical benefit of changes in lipid parameters has not yet been elucidated. [10] Still, SGLT2 inhibitors may not be optimal for some patients. Men and women with a history of urinary tract infections (UTIs) or genital mycotic infections may be more susceptible to these occurrences while taking an SGLT2 inhibitor. The genital mycotic infections have been reported as mild to moderate and treated by standard topical and/or oral antifungal therapies. Bone fractures are also a warning for some SGLT2 inhibitors, which may be a concern for patients with osteoporosis. [23] 5 Completed CV Outcomes Trial For Empagliflozin EMPA-REG OUTCOME randomly assigned patients with T2D and high CV risk receiving standard-of-care T2D treatment to empagliflozin 10 mg, empagliflozin 25 mg, or placebo. [24] EMPA-REG OUTCOME was the first-ever trial to demonstrate a CV benefit for a specific anti-hyperglycemic therapy. The primary outcome endpoint was a composite that included CV-related death and nonfatal MI or stroke for the pooled empagliflozin group (n=4687) vs control (n=2333). Significantly fewer patients taking empagliflozin compared with control participants met the primary outcomes endpoint at 10.5% and 12.1%, respectively, demonstrating superiority of empagliflozin ( P =.04) (Table 4). Table 4. Primary Outcome: Death From CV Causes, Nonfatal MI, or Nonfatal Stroke   Placebo (n=2333) Empagliflozin (n=4687) Hazard Ratio (95% CI) P Value No. (%) Rate/1000 patient-yr No. (%) Rate/1000 patient-yr Death from CV causes, nonfatal MI, or nonfatal stroke 282 (12.1) 43.9 490 (10.5) 37.4 0.86 (0.74, 0.99) Noninferiority, P <.001; Superiority, P =.04 CV = cardiovascular; CI = confidence interval; MI = myocardial infarction. Zinman B, et al. [24] A significant reduction in the incidence of death from CV causes was the primary difference between the pooled empagliflozin cohort and control at 3.7% and 5.9%, respectively ( P <.001). The relative risk reduction for CV-related death for empagliflozin was 38%. Results were consistent among subgroups and between the 2 doses of empagliflozin. For all-cause mortality, empagliflozin had a 32% relative risk reduction compared with placebo, which translates to a number needed to treat of 39 to prevent one death over a 3-year period (Table 5). Table 5. All-Cause Mortality   Placebo (n=2333) Empagliflozin (n=4687) Hazard Ratio (95% CI) P Value No. (%) Rate/1000 patient-yr No. (%) Rate/1000 patient-yr Death from any cause 194 (8.3) 28.6 269 (5.7) 19.4 0.68 (0.57, 0.82) <.001 CI = confidence interval. Zinman B, et al. [24] Interestingly, these mortality benefits were attained despite higher-than-goal HbA 1c , which averaged 7.81% at week 206 for patients taking empagliflozin 10 mg (compared with 8.07% at baseline). Thus, the mortality benefit is not likely entirely attributable to these small improvements in glucose control. The principal investigators of the study hypothesize that multiple mechanisms drive the CV benefit. Proposed mechanisms include cardiorenal effects, reduction in arterial stiffness, and cardiac oxygen demand, in addition to the downstream effects of weight loss, reduction in waist circumference and visceral fat, and blood pressure improvement. [25,26] Of note, even in the context of a randomized controlled trial that allowed adjustment of anti-hyperglycemic medication, lowering HbA 1c to less than 7.0% can be difficult. EMPA-REG OUTCOME showed no significant differences between the treatment and control arms with regard to nonfatal MI or nonfatal stroke. Regarding hospitalizations, no significant differences were determined between the groups regarding hospitalization for unstable angina, but significantly fewer patients taking empagliflozin had HF hospitalizations than those in the control arm, at 2.7% and 4.1%, respectively ( P =.002) (Table 6). Table 6. Hospitalization for Heart Failure   Placebo (n=2333) Empagliflozin (n=4687) Hazard Ratio (95% CI) P Value No. (%) Rate/1000 patient-yr No. (%) Rate/1000 patient-yr Hospitalization for HF 95 (4.1) 14.5 126 (2.7) 9.4 0.65 (0.50, 0.85) .002 CI = confidence interval; HF = heart failure. Zinman B, et al. [24] Type 2 diabetes and HF are common comorbidities. One study showed that more than 20% of Medicare beneficiaries with T2D also have HF. In patients with diabetes, HF is associated with a dire prognosis, with a 5-year survival rate of only 12.5% compared with more than 80% for patients with T2D and no HF. [27] Managing these 2 complex conditions is challenging, and there is a dearth of scientific evidence on the effects of glucose-lowering agents (with the exception of thiazolidinediones) in patients with HF. [28] There has been conflicting evidence whether newer treatments (eg, DPP-4 inhibitors [more specifically, saxagliptin]), have a safety signal for HF in patients with T2D. [29] Recently, additional analysis of EMPA-REG OUTCOME showed that empagliflozin is effective for patients with preexisting CV disease, T2D, and HF. Empagliflozin resulted in a significant reduction ( P <.001) in the incidence of HF hospitalization or CV-related death or HF hospitalization or HF-related death compared with placebo for the overall trial cohort. The number needed to treat to prevent one HF hospitalization or CV death was 35. Specifically, 10.4% of patients with HF taking empagliflozin had HF hospitalization over the study period compared with 12.3% of patients with HF taking placebo. For the composite of HF hospitalization and CV death, a smaller percentage of patients taking empagliflozin vs placebo had HF hospitalization or CV death, at 16.2% and 20.1%, respectively, for a hazard ratio of 0.72. [30] At baseline, 9.9% of patients randomly assigned to an empagliflozin arm and 10.5% of patients randomly assigned to control had HF. In general, these patients were receiving standard HF regimens (eg, angiotensin-converting enzyme inhibitors or angiotensin receptor blockers, β blockers, and oral diuretics). More than half of patients with HF were taking insulin (53.2% of pooled empagliflozin group, 60.7% of control). Thus, the subanalysis of EMPA-REG OUTCOME demonstrates that patients with T2D and HF can be effectively treated with standard HF pharmacotherapies and combination anti-hyperglycemic regimens. [30] Empagliflozin is the first SGLT2 inhibitor to complete an FDA-mandated CV outcomes trial. CANVAS and DECLARE-TIMI 58 are evaluating the long-term CV outcomes associated with use of canagliflozin and dapagliflozin, respectively. CANVAS is expected to report results in 2017, with DECLARE-TIMI 58 results slated for 2018. [31,32] 6 Empagliflozin Reduces Risk Of Kidney Disease In Adults With Diabetes Miguel's estimated glomerular filtration rate (eGFR) is adequate for SGLT2 inhibitors to be effective. Because of their mechanism of action, these drugs have minimal-to-modest efficacy at eGFR <45 mL/min/1.73m 2 and should not be used when eGFR is <30 or <45 mL/min/1.73m 2 (this differs for various SGLT2 inhibitors). In EMPA-REG OUTCOME, worsening of nephropathy was defined by one of several events: macroalbuminuria, doubling of serum creatinine levels in the context of eGFR <45 mL/min/1.73 m 2 , need for renal-replacement therapy, or death from renal causes. Using these criteria, a smaller percentage of patients taking empagliflozin had worsening kidney disease compared with control participants, at 12.7% and 18.8%, respectively. This corresponds to a 39% relative risk reduction ( P <.001). Empagliflozin was also associated with significant relative risk reductions in other areas, including doubling of serum creatinine level and progression to albuminuria (Figure 1). [33] Figure 1. Relative Risk Reduction Afforded by Empagliflozin vs Placebo 1 During the initial 4 weeks of empagliflozin treatment, eGFR declined for patients taking either the 10-mg or 25-mg dose (an average decline of 0.62 mL/min/1.73 m 2 in the 10-mg group and decrease of 0.82 mL /min/1.73 m 2 in the 25-mg group) whereas control patients experienced an increase in eGFR in the initial treatment period. For the remainder of the study, patients taking empagliflozin had stable eGFR and control patients had a significant decline in eGFR. At last follow-up, the eGFR for patients taking empagliflozin approximated 73 to 74 mL/min/1.73 m 2 compared with <70 mL/min/1.73 m 2 for control participants. At the end of the study, patients in the treatment group stopped taking empagliflozin and eGFR increased. Thus, the effects of empagliflozin on eGFR were reversed, even after long-term use. There was a lower incidence of acute kidney injury in patients taking empagliflozin compared with placebo at 2.1% and 3.6%, respectively, for individuals with eGFR of <59 mL/min/1.73 m 2 . [34] Separately, in June 2016, the FDA issued a drug safety communication for acute kidney injury associated with use of canagliflozin and dapagliflozin. In roughly 50% of reported cases, acute kidney injury occurred within one month of treatment. [33] Case 1 (cont) Miguel later mentions that he has gained about 20 lb in the past 2 years and has not been able to commit to the walking exercise regimen recommended to him after his MI. He says that he takes his medications regularly -- although he admits to occasionally forgetting to take doses -- and has decreased his alcohol consumption to 1 to 2 beers each week. He admits he could improve his diet and characterizes snacking at the computer a \"problem.\" 7 Cultural Competency in Diabetes Care Hispanic cuisine varies by region (eg, Mexico, Puerto Rico, etc). Thus, referral to a dietitian who can help Miguel and his family design culturally appropriate food plans is needed. Family members, especially a spouse or other family members of relevance should be included in dietary/cultural aspect of diet/lifestyle. In addition, a dietitian can educate Miguel and his family on the glycemic effect of foods they normally eat. Miguel and his family can likely benefit from reinforcement of the 3 goals in medical nutrition therapy in diabetes management: (1) glucose control, (2) cholesterol control, and (3) blood pressure control. [35] Cultural competence is \"the ability of individuals to establish effective interpersonal and working relationships that supersede cultural differences,\" [36] but barriers -- including language barriers, clinicians' lack of knowledge of cultural traditions around food and how services could meet patients' needs in this respect, lack of resources, and variation in cultural competence even among clinicians within a clinic -- can adversely affect provision of health care in minority ethnic groups. [37] Being culturally competent means educating Miguel and his family around food and dietary change based on the kinds of foods to which his family is already accustomed. Culturally competent care can help improve the clinician-patient relationship; communication among clinicians, patients, and caregivers; and patient outcomes. [36] Tailoring community-based diabetes interventions to immigrant cultures has shown that culturally tailored diabetes programs are effective in improving patients' objectively measured clinical outcomes -- in particular HbA 1c levels -- and psychobehavioral outcomes. Patients were also highly satisfied with bilingual clinicians and bilingual educational programs. [38] Conclusion/Follow-Up Miguel returns for his 3-month follow-up visit. His HbA 1c has decreased from 9.6% to 7.5%, with a fasting plasma glucose of 121 mg/dL. His blood pressure has improved to 139/82 mm Hg, and he has lost 7 lb. His cholesterol levels remain elevated at 92 mg/dL (his atorvastatin needs to be increased to 40 to 80 mg to get LDL-C <70 mg/dL). Although he feels better, he is somewhat frustrated as his HbA 1c is still not at goal, and he admits that he is mindful that his father died young. Given Miguel's medical history (eg, prior MI) and the patient's desire to improve his HbA 1c , it is important to intensify treatment rather than simply reinforce diet, exercise, and drug compliance. At baseline, Miguel was on the borderline of when bariatric surgery may be considered (eg, body mass index >35 kg/m 2 ). Therefore, intensifying his pharmacotherapy is the appropriate next step. Adding an injectable GLP-1 receptor agonist to Miguel's regimen is the optimal intensification strategy at this time. GLP-1 receptor agonists have a glucose-dependent MOA, slow gastric emptying, and increase satiety, which assists with weight loss. In addition, GLP-1 receptor agonists are not associated with hypoglycemia and are effective with lowering postprandial glucose levels. Common adverse effects include gastrointestinal (GI) problems, such as nausea and diarrhea, and an increased heart rate. [4] Case 2: Patient History Patient Image 170 0 Martha is 74-year-old black woman with a body mass index of 30.4 kg/m 2 . She lives alone in an apartment, which is located near her daughter, who has accompanied her on the office visit. Martha's medical history includes hypertension, dyslipidemia, and HF (Class I/II). She fractured her ankle 6 years ago after stepping off a curb and has had intermittent UTIs and vaginal yeast infections throughout her working life. Current medications include once-daily doses of furosemide 20 mg, atorvastatin 20 mg, and liraglutide 1.8 mg, as well as metformin 1500 mg (850 mg twice daily). At the office visit, her blood pressure is 146/88 mm Hg. Recent lab results show an HbA 1c of 7.6%, LDL-C of 68, and an eGFR of 52 mL/min/1.73 m 2 . 8 Addition of SGLT2 Inhibitor Therapy to GLP-1 Receptor Agonist Therapy For patients such as Martha, who require further improvement in glycemic control despite having a GLP-1 receptor agonist on board, the addition of a third noninsulin agent can be considered. [5] The ADA/European Association for the Study of Diabetes recommends that, in triple combination, agents with complementary mechanisms of action be used, in addition to taking into consideration the potential for adverse effects, costs, drug-drug interactions, and effect on adherence. As aforementioned, the rationale, benefits, and adverse effects of each new medication should be discussed with the patient. Adding an SGLT2 inhibitor, because of their mechanism of action (glucosuric effect), may be synergistic to metformin and the GLP-1 receptor agonist (glucagon reduction) and also has the advantage of promoting further weight loss and blood pressure decrease; however, the potential benefits of this triple therapy have not been confirmed in large clinical trials. [39] One single-arm study plans to enroll about 90 patients with T2D and evaluate the effect on fasting plasma glucose and HbA 1c of an SGLT2 inhibitor and a GLP-1 receptor agonist. Patients can be treatment-naive or stable while taking metformin, and results are expected in February 2017. [40] A small, retrospective, observational study (n=14) of an SGLT2 inhibitor and a GLP-1 receptor agonist showed that the combination when added to background T2D therapy of metformin and/or a sulfonylurea lowered HbA 1c more than had been achieved when patients had been on a GLP-1 receptor agonist and the background T2D therapy. Specifically, the average HbA 1c was lowered by 29% (mean reduction: 25.5 mmol/mol) at 20 weeks compared with HbA 1c reduction of 8.0 mmol/mol for patients taking a GLP-1 receptor agonist and T2D background therapy. The mean weight loss was 2.6 kg for patients who had an SGLT2 inhibitor and a GLP-1 receptor agonist added to background therapy. [41] 9 Acute Kidney Injury Warning For Some SGLT2 Inhibitors Martha can be considered for either canagliflozin or empagliflozin, as dapagliflozin is not recommended for patients with eGFR <60 mL/min/1.73 m 2 . [12] Renal function should be assessed routinely and use of canagliflozin or empagliflozin discontinued if the patient's eGFR falls and remains <45 mL/min/1.73 m 2 . [11,13] In June 2016, the FDA issued a drug safety communication for canagliflozin and dapagliflozin related to the risk for acute kidney injury based on reports submitted to the FDA Adverse Event Reporting System database. From late March 2013 to mid October 2015, there were 101 cases of acute kidney injury for patients taking either canagliflozin or dapagliflozin. According to the safety communication, acute kidney injury occurred within 30 days of treatment initiation for about half of the cases. Chronic renal insufficiency, hypovolemia, HF, and HF treatment regimens (eg, angiotensin-converting enzyme inhibitors, angiotensin receptor blockers, diuretics) could predispose a patient taking canagliflozin or dapagliflozin to acute kidney injury. [34] 10 Possible Adverse Effects Of SGLT2 Inhibitors On Bone Analysis of 9 clinical studies of canagliflozin showed an incidence of bone fractures of 1.4 per 100 patient years (canagliflozin 100 mg) and 1.5 per 100 patient years (canagliflozin 300 mg) vs 1.1 per 100 patient years for the comparator treatment. Fractures happened after just 12 weeks of treatment, typically occurred when the person fell from a standing position, and commonly affected upper limbs. [11] This, along with Martha's remote history of an ankle fracture with minimal trauma, as well as her age and postmenopausal status should be considered when selecting an SGLT2 inhibitor. The FDA is continuing to evaluate the risk for bone fractures with dapagliflozin and empagliflozin. 11 Glucosuria And Predisposition To Genital Infections And UTIS Pharmacologically induced glucosuria with SGLT2 inhibitors can provide a favorable growth environment for genital microorganisms and thus increases the risk of developing genital infections and UTIs. In general, patients with diabetes are more likely to experience UTIs and non-sexually transmitted genital infections than patients without diabetes. A meta-analysis of 22 observational studies showed that 12.2% of patients with diabetes compared with 4.5% of control patients had asymptomatic bacteriuria, with 14.2% of female patients with diabetes having asymptomatic bacteriuria vs 5.1% of women in the control group. In an observational study performed in the primary care setting in the United Kingdom, the incidence of UTI was approximately 60% higher for patients with diabetes compared with healthy individuals. For patients with diabetes, female sex, elevated HbA 1c , and elderly age are associated with greater likelihood of UTI. [42] Pooled clinical studies of empagliflozin showed a UTI incidence of 9.3% for empagliflozin 10 mg and 7.6% for empagliflozin 25 mg compared with 7.6% for control. Women taking empagliflozin experienced a higher rate of UTI compared with men, at 16.6% and 3.2%, respectively, for 10 mg; however, patients aged 75 years or older had a higher UTI rate, at 15.7% for empagliflozin 10 mg and 15.1% for empagliflozin 25 mg compared with 10.5% for control. [13] Most UTIs will respond to treatment. For older patients such as Martha, taking empagliflozin, voiding the bladder before bedtime, and proper hygiene should be reinforced to minimize the risk for UTI. Education regarding hygiene, clothing, and diet can help avoid UTIs in most instances (Table 7). Table 7. Suggestions for Women to Help Avoid UTIs While on SGLT2 Inhibitors Hygiene Wipe from front to back Take showers vs prolonged baths Avoid long intervals between urination Void bladder after intercourse Clothing Avoid tight-fitting undergarments Diet Increase consumption of water SGLT2 = sodium-glucose cotransporter 2; UTI = urinary tract infection. 12 Euglycemic Diabetic Ketoacidosis And SGLT2 Inhibitors Case reports suggest that diabetic ketoacidosis (DKA) associated with SGLT2 inhibitors can occur in the absence of marked hyperglycemia and/or following surgery. Most instances of DKA with an SGLT2 inhibitor have occurred in patients with type 1 diabetes, which is an off-label use in the United States. [43] The mechanism for lower-than-expected hyperglycemic (euglycemic) DKA in patients with T2D taking an SGLT2 inhibitor is not fully understood but is likely related to persistent glucosuria associated with SGLT2 inhibition. [44] Analysis of DKA in the canagliflozin T2D clinical trial program, which included 17,596 patients, showed that DKA occurred at a low frequency (<0.1%), which was similar to that seen in the general population of patients with T2D. Of note, most of the patients with a serious adverse event of DKA were on insulin and had precipitating factors. [45] Peters et al reported on 13 episodes of euglycemic DKA in 9 individuals (7 with type 1 diabetes, 2 with T2D) taking canagliflozin. Neither the patients nor the healthcare providers initially recognized that the individuals were experiencing development of DKA; however, as with most cases of DKA, patients responded to intravenous fluids and insulin. In the Peters et al case report, the 2 individuals with T2D experienced euglycemic DKA following surgery. [46] These reports of DKA, with or without marked hyperglycemia, have occurred in individuals taking canagliflozin, which was the first SGLT2 inhibitor approved for use in the United States. It is thought that all drugs in the SGLT2 inhibitor class will ultimately show a similar risk for DKA. [46] Analysis of clinical trials for dapagliflozin and empagliflozin in T2D also show a DKA incidence of less than 0.1%. [44] Most of the reports of euglycemic DKA for patients with T2D have been related to food (carbohydrates and calories) as well as fluid restriction related to surgery. [43,44] Thus, when DKA is considered in SGLT2-inhibitor treated diabetes, evaluation for the presence of ketonuria and ketonemia must be performed, with intravenous fluids and insulin doses administered as necessary. [44,47] As of yet, there is an absence of clinical data to guide the cessation of SGLT2 inhibitor therapy before and after surgery. [45] In routine clinical practice, it's reasonable to perform tests for ketonuria and ketonemia for patients with T2D taking SGLT2 inhibitors who complain of nausea, vomiting, inability to maintain fluid or food intake, recent alcohol intake, or excessive exercise, even if blood glucose levels are only mildly elevated. [43,47] Case Conclusion Like all medications, SGLT2 inhibitors have many benefits along with some risks. Given her medical history, Martha needs to know about the possibility of UTIs and genital mycotic infections as well as potential risk for fracture that could arise from taking empagliflozin or other SGLT2 inhibitor. This information is critical to enable Martha to participate in shared-decision making and enhance Martha's treatment adherence. In addition, Martha needs to be counseled on the rare incidence of DKA in patients with T2D and that she must inform her healthcare team about planned surgeries. Since Martha is on anti-hypertensive medications (including loop diuretics), she is at increased risk for hypotension because of the osmotic diuresis associated with SGLT2 inhibitor use. Her blood pressure should be carefully monitored after administration of an SGLT2 inhibitor and reduction or discontinuation of furosemide considered. Educational Impact Challenge What did you learn from this activity? Please click on the \"Continue\" button to proceed to a brief survey to see how your knowledge improved after the education. You can also see how your answers compare with those of your peers. Educational Impact Challenge 13 ",
				"clientUrl": "/viewarticle/870711",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 1069,
				"leadConcept": "Type 2 Diabetes Mellitus",
				"concept": ["Recurrent Urinary Tract Infection", "Urinary Tract Infection (UTI)", "Diabetes Mellitus", "Cardiovascular disease (CVD)", "Type 2 Diabetes Mellitus With Complications", "Heart Failure (HF)", "Renal Disease", "Coronary Artery Disease (CAD)", "Health Education and Counseling", "Fractures", "Lifestyle Counseling", "Primary Care", "Professional Issues in Nursing", "Patient Counseling", "Cardiovascular Risk Management", "Patient Pharmaceutical Care Management", "Clinical Pharmacology", "Patient Care Management", "Adverse Effects", "Off-Label Use", "Racial and Ethnic Disparity", "Cultural Competence", "Diet", "Pharmacodynamics", "Cardiovascular Nursing", "Diabetic Ketoacidosis", "Acute Kidney Injury", "Public Health Nursing", "Lifestyle Modification for Cardiovascular Health", "Pharmacologic Adverse Events", "Primary and Secondary Prevention of Coronary Artery Disease", "Renal Glucosuria", "Clinical Research", "Noninsulin Antidiabetic Drugs", "Patient History", "Hemoglobin A1c", "SGLT2 Inhibitor", "Physician Assistants", "Patient Assessment"],
				"leadSpecialtyId": 34,
				"leadSpecialty": "Family Medicine/Primary Care",
				"allSpecialties": ["Family Medicine/Primary Care", "Cardiology", "Medscape Today", "Diabetes & Endocrinology", "Nursing", "Pharmacist"],
				"contentGroup": "Clinical Case",
				"origContentType": "Clinical Case",
				"contentType": ["Patient Case"],
				"description": "Learn how SGLT2 inhibitors can be incorporated into individualized treatment plans in this interactive case-based activity.",
				"legacyID": 870711,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Patients With Complicated T2D: What's the Best Intensification Plan?",
				"suppressComment": "T",
				"creditsAvailable": ["Physicians:AMA PRA Category 1 Credit(s)™:1.00"],
				"maxCredits": [1.0],
				"multimedia": ["/thumbnail_library/870711.jpg"],
				"publicationDate": 1479877200000,
				"postingDate": 1479877200000,
				"_version_": 1573508884000145408,
				"last_index_date": 1500615009321
			}, {
				"id": "pdctm_0901c79180bc4aba",
				"activeCME": 1,
				"activityExpirationDate": 1532149200000,
				"authors": ["News Author: Sue Hughes", " CME Author: Laurie Barclay"],
				"body": "Clinical Context After acute stroke, supine positioning may improve cerebral blood flow but also increase risk for aspiration pneumonia and cardiopulmonary dysfunction. Some evidence suggests the lying-flat position increases blood flow in major arteries and improves cerebral oxygenation, whereas a sitting-up position with the head elevated may lower intracranial pressure in patients with large hemispheric ischemic stroke. Guidelines recommendations and clinical practice therefore vary widely regarding head positioning after acute ischemic stroke. The goal of the Head Positioning in Acute Stroke Trial (HeadPoST) was to examine whether outcomes of various types of acute stroke could be improved by the lying-flat position, with the patient fully supine with the back horizontal and the face upward to increase cerebral perfusion, initiated soon after a stroke and maintained for 24 hours in a range of healthcare settings. Study Synopsis and Perspective Results of the HeadPoST, showing no difference in disability outcomes in patients with acute stroke who were laid flat vs those sitting up for the first 24 hours, were published in the June 22 issue of the New England Journal of Medicine . The study was first presented at the International Stroke Conference in February, and was reported by Medscape Medical News at that time. In the journal article, the authors, led by Craig S. Anderson, MD, from the George Institute for Global Health, Sydney, Australia, explain that it has been thought that lying a patient flat after acute stroke may improve cerebral perfusion, but there has been concern about a possible increase in the risk for aspiration pneumonia. To investigate the issue further, the researchers conducted the current study, in which 11,093 patients with acute stroke (85% ischemic) were randomly assigned to receive care in a lying-flat position or a sitting-up position with the head elevated to at least 30 degrees. The median interval between the onset of stroke symptoms and the initiation of the assigned position was 14 hours; patients in the lying-flat group were less likely than patients in the sitting-up group to maintain the position for 24 hours (87% vs 95%; P < .001). In a proportional-odds model, there was no significant shift in the distribution of 90-day disability outcomes on the global modified Rankin Scale between patients in the lying-flat group and patients in the sitting-up group (unadjusted odds ratio for a difference in the distribution of scores on the modified Rankin Scale in the lying-flat group, 1.01; P = .84). \"Mortality within 90 days was 7.3% among the patients in the lying-flat group and 7.4% among the patients in the sitting-up group (P = 0.83). There were no significant between-group differences in the rates of serious adverse events, including pneumonia,\" the authors write. They add that \"[t]he negative results of this trial suggest that any modification of cerebral blood flow that may have occurred as a result of head positioning initiated within 24 hours was insufficient to reduce the neurologic deficit associated with acute stroke.\" They note that most patients in the trial had the assigned head position implemented after the time window for reperfusion with thrombolytic or endovascular treatment had passed, and the patients had mostly mild neurologic deficits from a range of causes of stroke. They therefore suggest that earlier initiation of head position after symptom onset, when the ischemic penumbra is potentially modifiable, may have produced different results. The authors point out that the rate of pneumonia was lower in this trial than in some other series, which they say might relate to \"careful assessment and care of patients, including the use of dysphagia screening protocols and feeding regimens, as well as the exclusion of high-risk patients such as those who underwent intubation.\" The trial was funded by the National Health and Medical Research Council of Australia. Dr Anderson reports receiving advisory board fees from Medtronic and AstraZeneca and lecture fees and travel support from Takeda China and Boehringer Ingelheim. Disclosures for the coauthors appear in the paper. N Engl J Med . Published June 22, 2017. [1] Study Highlights This trial took place at metropolitan and rural hospitals and various resource settings in 9 countries. Participants with acute stroke (n=11,093; 85% ischemic strokes) were randomly assigned by admitting hospital to receive care in a lying-flat position or a sitting-up position with head elevation of at least 30 degrees, starting soon after hospital admission and maintained for 24 hours. Degree of disability at 90 days, measured with the modified Rankin scale (scores ranging from 0 to 6, with higher scores reflecting greater disability and a score of 6 indicating death) was the main study endpoint. Median interval from stroke symptom onset to beginning the assigned position was 14 hours (interquartile range, 5-35 hours). Maintaining the assigned position for 24 hours occurred in 87% of the lying-flat group and in 95% of the sitting-up group ( P < .001). The distribution of 90-day disability outcomes did not vary significantly between patients in the lying-flat group and those in the sitting-up group, based on a proportional-odds model (unadjusted odds ratio for a difference in the distribution of modified Rankin score distribution in the lying-flat group, 1.01; 95% CI, 0.92-1.10; P = .84). Ninety-day mortality did not differ significantly between groups (7.3% in the lying-flat vs 7.4% in the sitting-up group; P = .83), nor did rates of pneumonia or other serious adverse events. There was no heterogeneity of the intervention effect regarding the main study endpoint in prespecified subgroups, but these analyses had low statistical power. On the basis of their findings, the investigators conclude that disability, mortality, and adverse event outcomes after acute stroke did not differ significantly between patients assuming a lying-flat position for 24 hours and those assuming a sitting-up position with the head elevated to 30 degrees or more for 24 hours. These negative results suggest that any change in cerebral blood flow mediated by head positioning begun within 24 hours was insufficient to reduce the neurologic deficit resulting from acute stroke. However, most participants began the assigned head position after the time window had passed for reperfusion with thrombolytic or endovascular therapy. It is therefore possible that beginning the assigned head position sooner after symptom onset, when the ischemic penumbra is potentially modifiable, may have led to different findings. Study limitations include lack of blinding to assigned head positions and failure to reach the planned sample size, although the trial still had sufficient power to examine the prespecified intervention effect. In addition, the rate of pneumonia was lower in this trial than in others, which may reflect careful patient evaluation and management, use of dysphagia screening protocols and feeding regimens, and exclusion of intubated and other high-risk patients. Clinical Implications Disability, mortality, and adverse event outcomes after acute stroke did not differ significantly between patients assuming a lying-flat position for 24 hours and those assuming a sitting-up position with the head elevated to 30 degrees or more for 24 hours, according to a multinational pragmatic, cluster-randomized, crossover trial. These negative results suggest that any change in cerebral blood flow mediated by head positioning begun within 24 hours was insufficient to reduce the neurologic deficit resulting from acute stroke. Implications for the Healthcare Team: Because most participants began the assigned head position after the time window had passed for reperfusion with thrombolytic or endovascular therapy, it is possible that beginning the assigned head position sooner after symptom onset, when the ischemic penumbra is potentially modifiable, may have led to different findings. CME Test 3 ",
				"clientUrl": "/viewarticle/882977",
				"creditType": ["CME", "Nurse CE", "ABIM MOC"],
				"cmeFlag": "CME / ABIM MOC / CE",
				"leadConceptId": 477,
				"leadConcept": "Cerebrovascular Accident (CVA)",
				"concept": ["Emergency Nursing", "Ischemic Stroke", "Hemorrhagic Stroke", "Aspiration Pneumonia", "Acute Stroke"],
				"leadSpecialtyId": 26,
				"leadSpecialty": "Neurology & Neurosurgery",
				"allSpecialties": ["Neurology & Neurosurgery", "Cardiology", "Medscape Today", "Internal Medicine", "Nursing", "Critical Care", "Family Medicine/Primary Care", "Emergency Medicine"],
				"contentGroup": "Clinical Review",
				"origContentType": "Clinical Brief",
				"contentType": ["News"],
				"description": "Disability and other outcomes after acute stroke were no different whether patients were in a lying-flat or sitting-up position for 24 hours.",
				"legacyID": 882977,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Does Positioning Impact Acute Stroke Outcomes?",
				"suppressComment": "T",
				"creditsAvailable": ["PhysiciansFamily Physicians:AMA PRA Category 1 Credit(s)™AAFP Prescribed credit(s):0.25", "US Physicians:Points for ABIM MOC:0.25", "Nurses:ANCC Contact Hour(s):0.25", "Physicians:AMA PRA Category 1 Credit(s)™:0.25"],
				"maxCredits": [0.25],
				"publicationDate": 1500613200000,
				"postingDate": 1500613200000,
				"_version_": 1573539702785441792,
				"last_index_date": 1500644400397
			}, {
				"id": "pdctm_0901c79180a6b1ab",
				"activeCME": 1,
				"activityExpirationDate": 1510722000000,
				"authors": ["Lars H. Lund"],
				"body": "Subtítulos en español Introduction Voiceover: Gabriel Rossi is a 69-year-old man who was diagnosed with idiopathic dilated cardiomyopathy and heart failure (HF) 2 years ago. He is a nonsmoker with a history of hypertension. He has had several hospitalizations for HF since he was first diagnosed and received an implantable cardioverter defibrillator (ICD) for primary prevention. His electrocardiogram (ECG) shows sinus rhythm with nonspecific T wave changes anterolaterally and a QRS width of 105 ms. SCENE 1 Doctor: Good afternoon, Mr Rossi. How have you been doing since I last saw you in the hospital a few months ago? Patient: Well, I got better in the hospital, but I’ve been having more trouble with breathing again, and my primary care doctor recommended that I follow up with you. Doctor: When do you notice problems with your breathing? Have you had any chest pain with it? Patient: No -- there's no chest pain. I’m mainly just tired all the time, and it seems like it’s getting more difficult to go up the stairs. I have to take it really slowly. I’ve been trying to avoid walking lately because it tires me out. If I pace myself, I do okay. Doctor: How long has this been a problem? Patient: I guess it’s been kind of building up over the last several weeks. Doctor: Have you noticed any swelling of your ankles? Patient: I have a bit of swelling, but it’s not too bad -- not like it was when I went to the hospital last time. Doctor: Have you had any wheezing? Any problems waking up in the middle of the night because you can’t breathe? Patient: No, I haven’t noticed that. It’s mainly just feeling worn out. Doctor: I’m glad you came to see me. [looks at chart] . Let’s see. Your ECG looks good. Your blood pressure is 145/80 mm Hg and your heart rate is 75 beats per minute and regular. Your current medications include enalapril 5 mg once daily, metoprolol 200 mg once daily, and furosemide 40 mg once daily and as needed. Obviously, I need to examine you, but based on your recent labs and echocardiogram, I think we can make some adjustments to your medications to keep things from getting worse. I’d like to be able to keep you out of the hospital. Patient: I’d certainly like that, too! 3 Thought Leader Discussion 1 Dr Lund: The European Society of Cardiology (ESC) recently issued updated guidelines for treatment of HF. They emphasize the importance of treating HF with reduced ejection fraction (HFrEF) with angiotensin converting enzyme (ACE) inhibitors and beta blockers, since multiple studies have clearly shown that they reduce morbidity and mortality in these patients. [1] Slide 1. Slide 1. It is best to maximize the dosage of those medications before adding other medications. He has minimal edema so there is no need to increase his diuretic, which affects only symptoms but not prognosis. In this case, I would increase his enalapril, since he is on a rather low dose. His blood pressure requires it, and his estimated glomerular filtration rate (eGFR), and potassium allow it. If he continues to be symptomatic on maximum doses of those medications with an ejection fraction at or below 35%, a mineralocorticoid receptor antagonist (MRA) such as spironolactone should be added. MRAs tend to be underutilized by many clinicians when treating HF despite their proven benefit. Slide 2. Slide 2. In the RALES [2] and EMPHASIS [3] trials, MRAs decreased hospitalizations from HF and mortality. If Mr Rossi had an ejection fraction (EF) of 40%-49%, or 50% and above, the treatment may not be the same. Indeed, there would be no evidence-based interventions to reduce morbidity or mortality. The new guidelines recognize that most of the studies of HF treatments have been done in patients with ejection fractions of 40% or less. A patient is not considered to have preserved ejection fraction unless it is 50% or above. Slide 3. Slide 3. The patients with ejection fractions of 40%-49% are now considered to be in a new category: HF with mid-range ejection fraction (HFmrEF). The ejection fraction is clearly not normal, but there is also no evidence based therapy in this EF category. The new guidelines call for more research to characterize and determine what treatments may be beneficial for these patients. [1] SCENE 2: TWO MONTHS LATER Doctor: Mr Rossi, your lungs sound okay. With the help of our heart failure nurse in the clinic, we have increased your enalapril to 10 mg twice per day and also added spironolactone. The lab tests you had recently show that your kidney function and potassium level are still in the acceptable range. Your ECG today looks unchanged which is also good. But how have you been feeling since I last saw you? Patient: I still feel really tired, and I can’t say that my breathing is much better. I haven’t really noticed much difference. Perhaps I’m a bit better. I think my ankles aren’t quite as swollen as they were before. Doctor: Hmm. I was anticipating that you might have noticed more improvement. Our goal is primarily to reduce your chance of needing to go to the hospital, and the fact that you are still having trouble with your breathing means that we still have some work to do on adjusting your medications. Also, your recent ultrasound of your heart showed that your ejection fraction had not worsened, which is good, but it also has not improved. Your blood pressure is a bit lower today -- 130/80 -- which is expected. I think we need to stop your enalapril and switch to a different medicine called sacubitril/valsartan. It’s actually a combination of 2 different medicines in 1 pill that you take twice a day. Patient: Would I stay on my metoprolol, my water pill, and the new one? Doctor: Well, you will need to stop taking the enalapril, start the new one, and then you will stay on all of your other current medicines, including the spironolactone that you just started a few weeks ago. Patient: Ok. Doctor: Very important: Stop your enalapril now. Do not start the new medicine -- the sacubitril/valsartan -- until the day after tomorrow. You must not take the enalapril when you are taking the sacubitril/valsartan. You could develop severe lip or tongue swelling with breathing difficulty, as well as low blood pressure if you take the two of them at the same time. It is important to allow some time for the enalapril to get out of your system before starting the sacubitril/valsartan. All of this will be written down for you. I am going to order some lab tests to be done in about 2 weeks to see how your kidneys are tolerating the new medicine, and then I’ll have you come back to see me to see how you’re doing. Patient: Are there any other side effects of the new medicine? Doctor: We have covered the major side effects, but we will provide you some additional written information on the new medicine before you leave today. 4 Thought Leader Discussion 2 Dr Lund: The treatment goals for HF are to improve symptoms, reduce progression of the disease, avoid recurrent hospitalizations, and decrease morbidity and mortality. Slide 4. Slide 4. The PARADIGM-HF trial showed that sacubitril/valsartan was more effective than enalapril in decreasing cardiovascular and overall mortality and in reducing HF hospitalizations for patients with symptomatic HFrEF of 40% or less. There are some safety issues that must be considered. [4] If patients are taking an ACE inhibitor, they must stop taking it 36 hours before starting sacubitril/valsartan to reduce the risk of developing angioedema. In this case, since the patient was on a target dose of enalapril, it would be best to start the sacubitril/valsartan at 49 mg/51 mg twice daily and have the patient return to the office in a couple of weeks for reassessment and increase in dose. If the patient’s maximally tolerated dose of enalapril had been less than 10 mg twice daily, the initial dose of sacubitril/valsartan should be 24 mg/26 mg twice daily. [5] Clinicians should be aware that with sacubitril/valsartan, serum levels of statins may increase. Neprilysin, which is inhibited by sacubitril, is also one of many mechanisms for clearing amyloid-beta, and there have been theoretical concerns of increasing the risk of Alzheimer’s over the very long term. [5] Slide 5. Slide 5. The clinical implications, if any, are not yet clear. The ESC guidelines consider the proven and large benefit of sacubitril/valsartan to outweigh this theoretical risk. In addition, the patient’s heart rate needs to be monitored. Slide 6. Slide 6. The SHIFT trial showed that ivabradine reduced the risks of cardiovascular death and hospitalization for heart failure for patients in sinus rhythm with heart rates greater than 70 both in patients who were already on beta blockers and those who did not tolerate beta blockers. [6] Slide 7. Slide 7. The QRS can also progress over time, and as pointed out in the new 2016 ESC heart failure guidelines, if it is 130 ms or greater, the patient may benefit from having his ICD upgraded to include cardiac resynchronization therapy. [1] Comorbidities are increasingly recognized as important contributors to HF, and one that can now be treated is iron deficiency. Serum ferritin and iron saturation levels should be checked. Patients with chronic HF can often develop iron deficiency with or without anemia. Intravenous iron therapy improves symptoms and quality of life in patients with HF and iron deficiency. SCENE 3: THREE WEEKS LATER Doctor: How have you been feeling, Mr Rossi? Have you noticed any side effects from the new medication? Patient: Well, I felt kind of lightheaded when I first started on it. I mainly noticed it if I stood up quickly. It bothered me for about a week, but I’ve kind of gotten used to it now. Doctor: Your blood pressure is 105/70 mm Hg today. That is a significant drop, but we took it first lying down and then standing up with no significant change, so I'm pleased with that. Getting your blood pressure down helps to reduce the progression of your HF. Sometimes when the blood pressure gets very low, patients experience some lightheadedness, but it sounds like this has gotten better for you, which it generally does with time. Are you still feeling short of breath? Patient: A bit, yes, but I think it may be improving. I’m still tired but not quite as much as before. Doctor:\tI would like to keep you on the new sacubitril/valsartan medication and in fact increase the dose. Let me know if you have problems with dizziness that continues beyond a couple of weeks. Patient: I hope I don’t. I’m not sure that being dizzy is any better than being short of breath. Doctor: Since you are tolerating it so far, I suspect you won’t have significant further trouble. Staying on the medication will likely help you to stay out of the hospital. Patient: I’d certainly prefer to stay away from the hospital. I’ll let you know if I have more problems. Doctor: Good. I’d like to see you again in a few weeks, and we’ll have some lab tests done before you come in. I want to make sure that the medicine is working for you. 5 Thought Leader Summary Discussion Dr Lund: As shown in this case, patients may develop symptomatic hypotension when treated with sacubitril/valsartan. Slide 8. Slide 8. In the PARADIGM-HF trial, 14% of the sacubitril/valsartan treatment group developed symptomatic hypotension compared to around 9% of the enalapril group. As with other evidence-based HF therapy, it is important to encourage the patients to stay on the sacubitril/valsartan, if they can tolerate potential side effects such as hypotension. Sacubitril/valsartan is significantly more effective than enalapril at reducing the risk of death and hospitalizations. [4] If the patient is tolerating it well, the dose can be increased 2 to 4 weeks after starting the medication. The patient’s renal function and potassium levels must be monitored regularly since hyperkalemia can occur, especially if the patient is also on an MRA. The QRS also needs to be monitored to determine whether cardiac resynchronization therapy may become advised, as well as the heart rate and serum iron panels ",
				"clientUrl": "/viewarticle/869775",
				"creditType": ["CME"],
				"cmeFlag": "CME",
				"leadConceptId": 64646,
				"leadConcept": "Heart Failure (HF)",
				"concept": ["Beta Blockers", "Disease Management", "Clinical Guidelines", "Treatment Guidelines", "Patient Pharmaceutical Care Management", "Patient Care Management", "Adverse Effects", "Ejection Fraction", "Implantable Cardioverter-Defibrillator (ICD)", "Angiotensin II Receptor Blockade", "ACE Inhibitor", "International Practice of Medicine", "Pharmacologic Adverse Events", "Clinical Research", "Patient Assessment"],
				"leadSpecialtyId": 2,
				"leadSpecialty": "Cardiology",
				"allSpecialties": ["Cardiology", "Family Medicine/Primary Care"],
				"contentType": ["Article/Courses"],
				"description": "Dr Lund discusses guideline update for management of symptomatic chronic heart failure.",
				"legacyID": 869775,
				"pubDisplay": "Medscape Education",
				"siteOn": 2003,
				"title": "Symptomatic Chronic HF: New Guideline Recommendations for Medical Therapies",
				"suppressComment": "T",
				"creditsAvailable": ["Non-US Physicians:CPD:0.25"],
				"maxCredits": [0.25],
				"multimedia": ["/thumbnail_library/869775.jpg"],
				"publicationDate": 1479186000000,
				"postingDate": 1479186000000,
				"_version_": 1573508877500022784,
				"last_index_date": 1500615003115
			}]
		},
		"spellcheck": {
			"suggestions": []
		}
	},
	"code": 1,
	"stat": "Success",
	"msg": null
}